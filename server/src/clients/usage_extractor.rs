/// Usage extraction and standardization for multi-provider LLM API clients
/// 
/// This module provides a unified interface for extracting usage information from different
/// LLM provider responses. It standardizes token counts and timing information
/// across all supported providers, enabling consistent usage tracking.
/// 
/// The system supports:
/// - Token-based usage tracking (prompt, completion, cache tokens)
/// - Duration tracking for performance analysis
/// 
/// # Usage
/// 
/// Each provider client should implement the `UsageExtractor` trait to extract
/// usage information from their specific response formats:
/// 
/// ```rust
/// use crate::clients::usage_extractor::{UsageExtractor, ProviderUsage};
/// 
/// impl UsageExtractor for MyProviderClient {
///     fn extract_usage(&self, raw_json: &serde_json::Value) -> Option<ProviderUsage> {
///         // Extract usage from provider-specific JSON response
///         let usage = raw_json.get("usage")?;
///         Some(ProviderUsage {
///             prompt_tokens: usage.get("input_tokens")?.as_i64()? as i32,
///             completion_tokens: usage.get("output_tokens")?.as_i64()? as i32,
///             cache_write_tokens: 0,
///             cache_read_tokens: usage.get("cached_tokens")?.as_i64().unwrap_or(0) as i32,
///             duration_ms: None,
///         })
///     }
/// }
/// ```

use serde::{Deserialize, Serialize};
use tracing::debug;

/// Standardized usage information extracted from provider responses
/// 
/// This struct provides a unified representation of usage metrics across all
/// LLM providers, enabling consistent usage tracking.
/// 
/// Token counts are based on the industry-standard approach where:
/// - `prompt_tokens`: Input tokens processed by the model
/// - `completion_tokens`: Output tokens generated by the model  
/// - `cache_write_tokens`: Tokens written to provider cache
/// - `cache_read_tokens`: Tokens read from provider cache
/// 
/// Duration tracking enables performance monitoring.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ProviderUsage {
    /// Number of input/prompt tokens processed by the model
    /// These are typically the tokens from user messages, system prompts, and context
    pub prompt_tokens: i32,
    
    /// Number of output/completion tokens generated by the model
    /// These are the tokens in the assistant's response
    pub completion_tokens: i32,
    
    /// Number of tokens written to the provider's cache system
    pub cache_write_tokens: i32,
    
    /// Number of tokens read from the provider's cache system
    pub cache_read_tokens: i32,
    
    /// The model ID that was used for this request
    pub model_id: String,
    
    /// Duration of the request in milliseconds
    /// Used for performance monitoring
    pub duration_ms: Option<i64>,
    
    /// Cost of the request as calculated by the provider
    /// This preserves provider-calculated costs when available
    pub cost: Option<f64>,
}

impl ProviderUsage {
    /// Create a new ProviderUsage with basic token counts
    /// 
    /// This is a convenience constructor for the most common use case where
    /// only prompt and completion tokens are available.
    /// 
    /// # Arguments
    /// 
    /// * `prompt_tokens` - Number of input tokens
    /// * `completion_tokens` - Number of output tokens
    /// 
    /// # Example
    /// 
    /// ```rust
    /// let usage = ProviderUsage::new(150, 75, "model-id".to_string());
    /// assert_eq!(usage.prompt_tokens, 150);
    /// assert_eq!(usage.completion_tokens, 75);
    /// assert_eq!(usage.total_tokens(), 225);
    /// ```
    pub fn new(prompt_tokens: i32, completion_tokens: i32, model_id: String) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            cache_write_tokens: 0,
            cache_read_tokens: 0,
            model_id,
            duration_ms: None,
            cost: None,
        }
    }
    
    /// Create a ProviderUsage from legacy token counts without cache information
    /// 
    /// This constructor is provided for compatibility with older systems
    /// that don't support cache token tracking.
    /// 
    /// # Arguments
    /// 
    /// * `prompt_tokens` - Number of input tokens
    /// * `completion_tokens` - Number of output tokens
    /// * `model_id` - The model ID used for this request
    pub fn from_legacy(prompt_tokens: i32, completion_tokens: i32, model_id: String) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            cache_write_tokens: 0,
            cache_read_tokens: 0,
            model_id,
            duration_ms: None,
            cost: None,
        }
    }
    
    /// Create a new ProviderUsage with cache token information
    /// 
    /// This constructor supports providers that offer caching capabilities
    /// with separate billing for cache reads and writes.
    /// 
    /// # Arguments
    /// 
    /// * `prompt_tokens` - Number of uncached input tokens
    /// * `completion_tokens` - Number of output tokens
    /// * `cache_write_tokens` - Number of tokens written to cache
    /// * `cache_read_tokens` - Number of tokens read from cache
    /// * `model_id` - The model ID used for this request
    /// 
    /// # Example
    /// 
    /// ```rust
    /// let usage = ProviderUsage::with_cache(100, 50, 25, 75, "claude-3-sonnet".to_string());
    /// assert_eq!(usage.total_input_tokens(), 200); // prompt + cache_write + cache_read
    /// ```
    pub fn with_cache(
        prompt_tokens: i32, 
        completion_tokens: i32, 
        cache_write_tokens: i32, 
        cache_read_tokens: i32,
        model_id: String
    ) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            cache_write_tokens,
            cache_read_tokens,
            model_id,
            duration_ms: None,
            cost: None,
        }
    }
    
    /// Get the total number of input tokens (prompt + cache write + cache read)
    /// 
    /// This represents all tokens that were processed as input to the model,
    /// regardless of whether they came from cache or were newly processed.
    pub fn total_input_tokens(&self) -> i32 {
        self.prompt_tokens + self.cache_write_tokens + self.cache_read_tokens
    }
    
    /// Get the total number of tokens (input + output)
    /// 
    /// This is the sum of all tokens involved in the request, which is useful
    /// for providers that bill based on total token usage.
    pub fn total_tokens(&self) -> i32 {
        self.total_input_tokens() + self.completion_tokens
    }
    
    /// Update the duration information
    /// 
    /// This method allows adding timing information after the request completes,
    /// which is useful for performance monitoring.
    /// 
    /// # Arguments
    /// 
    /// * `duration_ms` - Request duration in milliseconds
    pub fn set_duration(&mut self, duration_ms: i64) {
        self.duration_ms = Some(duration_ms);
    }
    
    /// Set the cost information
    /// 
    /// This method allows adding provider-calculated cost information
    /// which is useful for accurate billing and cost tracking.
    /// 
    /// # Arguments
    /// 
    /// * `cost` - Request cost as calculated by the provider
    pub fn set_cost(&mut self, cost: f64) {
        self.cost = Some(cost);
    }
    
    /// Create a new ProviderUsage with cost information
    /// 
    /// This constructor supports providers that return cost information
    /// in their responses for accurate billing tracking.
    /// 
    /// # Arguments
    /// 
    /// * `prompt_tokens` - Number of input tokens
    /// * `completion_tokens` - Number of output tokens
    /// * `cache_write_tokens` - Number of tokens written to cache
    /// * `cache_read_tokens` - Number of tokens read from cache
    /// * `model_id` - The model ID used for this request
    /// * `cost` - Provider-calculated cost
    pub fn with_cost(
        prompt_tokens: i32,
        completion_tokens: i32,
        cache_write_tokens: i32,
        cache_read_tokens: i32,
        model_id: String,
        cost: Option<f64>
    ) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            cache_write_tokens,
            cache_read_tokens,
            model_id,
            duration_ms: None,
            cost,
        }
    }
    
    /// Validate that token counts are non-negative
    /// 
    /// This method performs basic validation to ensure usage data integrity.
    /// Negative token counts indicate a parsing error or corrupted data.
    /// 
    /// # Returns
    /// 
    /// * `Ok(())` - All token counts are valid
    /// * `Err(String)` - Description of the validation error
    pub fn validate(&self) -> Result<(), String> {
        if self.prompt_tokens < 0 {
            return Err(format!("Invalid prompt_tokens: {}", self.prompt_tokens));
        }
        if self.completion_tokens < 0 {
            return Err(format!("Invalid completion_tokens: {}", self.completion_tokens));
        }
        if self.cache_write_tokens < 0 {
            return Err(format!("Invalid cache_write_tokens: {}", self.cache_write_tokens));
        }
        if self.cache_read_tokens < 0 {
            return Err(format!("Invalid cache_read_tokens: {}", self.cache_read_tokens));
        }
        if let Some(duration) = self.duration_ms {
            if duration < 0 {
                return Err(format!("Invalid duration_ms: {}", duration));
            }
        }
        Ok(())
    }
}

impl Default for ProviderUsage {
    fn default() -> Self {
        Self::new(0, 0, "unknown".to_string())
    }
}

/// Trait for extracting standardized usage information from provider responses
/// 
/// This trait must be implemented by each LLM provider client to enable
/// consistent usage tracking across the system. The implementation should
/// parse the provider's response format and extract token counts and timing 
/// information into the standardized `ProviderUsage` struct.
/// 
/// # Implementation Guidelines
/// 
/// 1. **Token Mapping**: Map provider-specific token fields to standard fields:
///    - Input/prompt tokens → `prompt_tokens`
///    - Output/completion tokens → `completion_tokens`
///    - Cached tokens → `cache_read_tokens` (usually)
///    - Cache writes → `cache_write_tokens` (if available)
/// 
/// 2. **Error Handling**: Return None for unparseable responses rather than panicking
/// 
/// 3. **Logging**: Use debug logging to aid in troubleshooting usage extraction
/// 
/// # Example Implementation
/// 
/// ```rust
/// impl UsageExtractor for AnthropicClient {
///     fn extract_usage(&self, raw_json: &serde_json::Value) -> Option<ProviderUsage> {
///         let usage = raw_json.get("usage")?;
///         
///         let prompt_tokens = usage.get("input_tokens")?.as_i64()? as i32;
///         let completion_tokens = usage.get("output_tokens")?.as_i64()? as i32;
///         let cache_read_tokens = usage.get("cache_read_input_tokens")?.as_i64().unwrap_or(0) as i32;
///         let cache_write_tokens = usage.get("cache_creation_input_tokens")?.as_i64().unwrap_or(0) as i32;
///         
///         Some(ProviderUsage::with_cache(
///             prompt_tokens,
///             completion_tokens, 
///             cache_write_tokens,
///             cache_read_tokens
///         ))
///     }
/// }
/// ```
pub trait UsageExtractor {
    /// Extract usage information from provider's HTTP response body (2025-07 format)
    /// 
    /// This is the primary method for extracting usage from provider responses.
    /// It handles the complete HTTP response body and supports both streaming 
    /// and non-streaming responses with comprehensive error handling.
    /// 
    /// # Arguments
    /// 
    /// * `body` - The complete HTTP response body as bytes
    /// * `model_id` - The model identifier for this request
    /// * `is_streaming` - Whether this is a streaming response
    /// 
    /// # Returns
    /// 
    /// * `Ok(ProviderUsage)` - Successfully extracted usage information
    /// * `Err(AppError)` - Unable to extract usage (parse errors, missing fields, etc.)
    /// 
    /// # Implementation Requirements
    /// 
    /// - Parse provider-specific payload formats (JSON, SSE, etc.)
    /// - Handle malformed responses gracefully (return error, don't panic)
    /// - Support both streaming final chunks and complete responses
    /// - Map provider token fields to standard ProviderUsage structure
    /// - Include model_id in the returned ProviderUsage
    async fn extract_from_http_body(&self, body: &[u8], model_id: &str, is_streaming: bool) -> Result<ProviderUsage, crate::error::AppError> {
        let body_str = std::str::from_utf8(body)
            .map_err(|e| crate::error::AppError::InvalidArgument(format!("Invalid UTF-8 in response body: {}", e)))?;
        
        self.extract_usage_from_string(body_str)
            .map(|mut usage| {
                usage.model_id = model_id.to_string();
                usage
            })
            .ok_or_else(|| crate::error::AppError::External("Failed to extract usage from provider response".to_string()))
    }

    /// Extract usage information from a provider's raw JSON response
    /// 
    /// This method should parse the provider-specific response format and
    /// return standardized usage information. The implementation should be
    /// robust to variations in response format and return None rather than
    /// panicking on parse errors.
    /// 
    /// # Arguments
    /// 
    /// * `raw_json` - The complete JSON response from the provider
    /// 
    /// # Returns
    /// 
    /// * `Some(ProviderUsage)` - Successfully extracted usage information
    /// * `None` - Unable to extract usage (missing fields, parse errors, etc.)
    /// 
    /// # Implementation Notes
    /// 
    /// - Use debug logging to trace extraction process
    /// - Handle missing optional fields gracefully
    /// - Validate extracted data using `ProviderUsage::validate()`
    /// - Consider provider-specific edge cases (e.g., streaming vs non-streaming)
    fn extract_usage(&self, raw_json: &serde_json::Value) -> Option<ProviderUsage> {
        debug!("Extracting usage from provider response");
        
        // Default implementation returns None - providers must override
        // This ensures compilation but prevents silent failures
        debug!("No usage extraction implementation available for this provider");
        None
    }
    
    /// Extract usage information from a streaming response chunk
    /// 
    /// Some providers send usage information in streaming chunks rather than
    /// a final response. This method handles extraction from individual chunks.
    /// 
    /// The default implementation tries to extract from the chunk as if it
    /// were a complete response, but providers can override for chunk-specific logic.
    /// 
    /// # Arguments
    /// 
    /// * `chunk_json` - A single streaming chunk as JSON
    /// 
    /// # Returns
    /// 
    /// * `Some(ProviderUsage)` - Usage information found in this chunk
    /// * `None` - No usage information in this chunk (common for content chunks)
    fn extract_usage_from_stream_chunk(&self, chunk_json: &serde_json::Value) -> Option<ProviderUsage> {
        debug!("Extracting usage from stream chunk");
        
        // Default implementation: try normal extraction
        // Most providers send usage in final chunks with same format
        self.extract_usage(chunk_json)
    }
    
    /// Extract usage information from a raw string response
    /// 
    /// This is a convenience method that parses JSON and delegates to extract_usage.
    /// It handles JSON parsing errors gracefully and provides debug logging.
    /// 
    /// # Arguments
    /// 
    /// * `raw_response` - The raw string response from the provider
    /// 
    /// # Returns
    /// 
    /// * `Some(ProviderUsage)` - Successfully parsed and extracted usage
    /// * `None` - JSON parsing failed or usage extraction failed
    fn extract_usage_from_string(&self, raw_response: &str) -> Option<ProviderUsage> {
        debug!("Parsing JSON response for usage extraction");
        
        match serde_json::from_str::<serde_json::Value>(raw_response) {
            Ok(json) => {
                debug!("Successfully parsed JSON, extracting usage");
                self.extract_usage(&json)
            }
            Err(e) => {
                debug!("Failed to parse JSON response: {}", e);
                None
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_provider_usage_new() {
        let usage = ProviderUsage::new(100, 50, "test-model".to_string());
        assert_eq!(usage.prompt_tokens, 100);
        assert_eq!(usage.completion_tokens, 50);
        assert_eq!(usage.cache_write_tokens, 0);
        assert_eq!(usage.cache_read_tokens, 0);
        assert_eq!(usage.model_id, "test-model");
        assert_eq!(usage.total_tokens(), 150);
    }

    #[test]
    fn test_provider_usage_with_cache() {
        let usage = ProviderUsage::with_cache(100, 50, 25, 75, "test-model".to_string());
        assert_eq!(usage.prompt_tokens, 100);
        assert_eq!(usage.completion_tokens, 50);
        assert_eq!(usage.cache_write_tokens, 25);
        assert_eq!(usage.cache_read_tokens, 75);
        assert_eq!(usage.model_id, "test-model");
        assert_eq!(usage.total_input_tokens(), 200);
        assert_eq!(usage.total_tokens(), 250);
    }


    #[test]
    fn test_set_duration() {
        let mut usage = ProviderUsage::new(100, 50, "test-model".to_string());
        usage.set_duration(1500);
        assert_eq!(usage.duration_ms, Some(1500));
    }

    #[test]
    fn test_validate_positive_tokens() {
        let usage = ProviderUsage::new(100, 50, "test-model".to_string());
        assert!(usage.validate().is_ok());
    }

    #[test]
    fn test_validate_negative_tokens() {
        let usage = ProviderUsage {
            prompt_tokens: -1,
            completion_tokens: 50,
            cache_write_tokens: 0,
            cache_read_tokens: 0,
            model_id: "test-model".to_string(),
            duration_ms: None,
            cost: None,
        };
        assert!(usage.validate().is_err());
        assert!(usage.validate().unwrap_err().contains("prompt_tokens"));
    }

    #[test]
    fn test_validate_negative_duration() {
        let usage = ProviderUsage {
            prompt_tokens: 100,
            completion_tokens: 50,
            cache_write_tokens: 0,
            cache_read_tokens: 0,
            model_id: "test-model".to_string(),
            duration_ms: Some(-100),
            cost: None,
        };
        assert!(usage.validate().is_err());
        assert!(usage.validate().unwrap_err().contains("duration_ms"));
    }

    #[test]
    fn test_default() {
        let usage = ProviderUsage::default();
        assert_eq!(usage.prompt_tokens, 0);
        assert_eq!(usage.completion_tokens, 0);
        assert_eq!(usage.total_tokens(), 0);
        assert_eq!(usage.cost, None);
    }

    #[test]
    fn test_set_cost() {
        let mut usage = ProviderUsage::new(100, 50, "test-model".to_string());
        assert_eq!(usage.cost, None);
        
        usage.set_cost(0.0025);
        assert_eq!(usage.cost, Some(0.0025));
    }

    #[test]
    fn test_with_cost() {
        let usage = ProviderUsage::with_cost(100, 50, 25, 75, "test-model".to_string(), Some(0.0035));
        assert_eq!(usage.prompt_tokens, 100);
        assert_eq!(usage.completion_tokens, 50);
        assert_eq!(usage.cache_write_tokens, 25);
        assert_eq!(usage.cache_read_tokens, 75);
        assert_eq!(usage.cost, Some(0.0035));
        assert_eq!(usage.total_tokens(), 250);
    }

    // Mock implementation for testing the trait
    struct MockUsageExtractor;

    impl UsageExtractor for MockUsageExtractor {
        async fn extract_from_http_body(&self, body: &[u8], model_id: &str, is_streaming: bool) -> Result<ProviderUsage, crate::error::AppError> {
            let body_str = std::str::from_utf8(body)
                .map_err(|e| crate::error::AppError::InvalidArgument(format!("Invalid UTF-8: {}", e)))?;
            
            let json: serde_json::Value = serde_json::from_str(body_str)
                .map_err(|e| crate::error::AppError::External(format!("Failed to parse JSON: {}", e)))?;
            
            let usage = json.get("usage")
                .ok_or_else(|| crate::error::AppError::External("Missing usage field".to_string()))?;
            let prompt_tokens = usage.get("prompt_tokens")
                .and_then(|v| v.as_i64())
                .ok_or_else(|| crate::error::AppError::External("Missing prompt_tokens".to_string()))? as i32;
            let completion_tokens = usage.get("completion_tokens")
                .and_then(|v| v.as_i64())
                .ok_or_else(|| crate::error::AppError::External("Missing completion_tokens".to_string()))? as i32;
            
            Ok(ProviderUsage {
                prompt_tokens,
                completion_tokens,
                cache_write_tokens: 0,
                cache_read_tokens: 0,
                model_id: model_id.to_string(),
                duration_ms: None,
                cost: None,
            })
        }

        fn extract_usage(&self, raw_json: &serde_json::Value) -> Option<ProviderUsage> {
            let usage = raw_json.get("usage")?;
            let prompt_tokens = usage.get("prompt_tokens")?.as_i64()? as i32;
            let completion_tokens = usage.get("completion_tokens")?.as_i64()? as i32;
            Some(ProviderUsage::new(prompt_tokens, completion_tokens, "test-model".to_string()))
        }
    }

    #[test]
    fn test_extract_usage_trait() {
        let extractor = MockUsageExtractor;
        let response = json!({
            "usage": {
                "prompt_tokens": 150,
                "completion_tokens": 75
            }
        });
        
        let usage = extractor.extract_usage(&response).unwrap();
        assert_eq!(usage.prompt_tokens, 150);
        assert_eq!(usage.completion_tokens, 75);
    }

    #[test]
    fn test_extract_usage_from_string() {
        let extractor = MockUsageExtractor;
        let response_str = r#"{"usage": {"prompt_tokens": 200, "completion_tokens": 100}}"#;
        
        let usage = extractor.extract_usage_from_string(response_str).unwrap();
        assert_eq!(usage.prompt_tokens, 200);
        assert_eq!(usage.completion_tokens, 100);
    }

    #[test]
    fn test_extract_usage_from_invalid_json() {
        let extractor = MockUsageExtractor;
        let invalid_json = "invalid json";
        
        let usage = extractor.extract_usage_from_string(invalid_json);
        assert!(usage.is_none());
    }

    #[test] 
    fn test_extract_usage_missing_fields() {
        let extractor = MockUsageExtractor;
        let response = json!({
            "other_field": "value"
        });
        
        let usage = extractor.extract_usage(&response);
        assert!(usage.is_none());
    }
    
    #[tokio::test]
    async fn test_extract_from_http_body() {
        let extractor = MockUsageExtractor;
        let response_body = r#"{
            "usage": {
                "prompt_tokens": 150,
                "completion_tokens": 75
            }
        }"#;
        
        let result = extractor.extract_from_http_body(
            response_body.as_bytes(), 
            "test-model", 
            false
        ).await;
        
        assert!(result.is_ok());
        let usage = result.unwrap();
        assert_eq!(usage.prompt_tokens, 150);
        assert_eq!(usage.completion_tokens, 75);
        assert_eq!(usage.model_id, "test-model");
    }
    
    #[tokio::test]
    async fn test_extract_from_http_body_invalid_json() {
        let extractor = MockUsageExtractor;
        let invalid_body = "invalid json";
        
        let result = extractor.extract_from_http_body(
            invalid_body.as_bytes(),
            "test-model",
            false
        ).await;
        
        assert!(result.is_err());
        let error_msg = result.unwrap_err().to_string();
        assert!(error_msg.contains("Failed to extract usage from provider response"));
    }
    
    #[tokio::test] 
    async fn test_extract_from_http_body_missing_usage() {
        let extractor = MockUsageExtractor;
        let response_body = r#"{
            "other_field": "value"
        }"#;
        
        let result = extractor.extract_from_http_body(
            response_body.as_bytes(),
            "test-model",
            false
        ).await;
        
        assert!(result.is_err());
        let error_msg = result.unwrap_err().to_string();
        assert!(error_msg.contains("Missing usage field"));
    }
}