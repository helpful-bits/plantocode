{
  "meta": {
    "title": "Dokumentation - PlanToCode",
    "description": "Erfahren Sie, wie Sie Code-Änderungen mit PlanToCode planen und ausliefern: Dateisuche, Implementierungspläne, Terminal-Sitzungen, Modell-Leitplanken und Sprache."
  },
  "architecture": {
    "meta": {
      "title": "PlanToCode Architekturübersicht",
      "description": "Desktop-, Orchestrierungs- und Persistenzschichten, die Implementierungspläne, Workflows und Terminal-Sitzungen ermöglichen."
    },
    "category": "Architektur",
    "date": "2025-09-19",
    "description": "Wie die Desktop-Shell, Hintergrund-Workflows und gemeinsame Dienste organisiert sind.",
    "frontend": {
      "heading": "Frontend-Oberfläche",
      "providers": "Gemeinsame Provider verwalten Benachrichtigungen, Laufzeitkonfiguration und Plan-Status. Das Implementierungspläne-Panel bewahrt Plan-Metadaten auf, verwaltet die Modal-Sichtbarkeit und fordert Token-Schätzungen oder Prompt-Inhalte bei Bedarf an.",
      "ui": "Die Desktop-Benutzeroberfläche ist mit React-Komponenten aufgebaut. Implementierungsplan-Inhalte werden durch einen Monaco-basierten Viewer angezeigt, der große Pläne virtualisiert, Sprachen erkennt und Kopieraktionen unterstützt, damit Prüfer Plan-Text ohne Leistungsprobleme untersuchen können. Terminal-Sitzungen werden in einer gepufferten Ansicht gerendert, die an die PTY-Ausgabe angebunden ist und Verbindungsstatus-Updates anzeigt."
    },
    "intro": "PlanToCode ist eine Tauri-Desktop-Anwendung mit einem React-Frontend. Die Benutzeroberfläche rendert Implementierungspläne, Terminals und Konfigurationssteuerungen, während das Rust-Backend Befehle für Workflows, Token-Schätzung und persistente Terminal-Sitzungen bereitstellt. Diese Übersicht fasst zusammen, wie diese Teile zusammenwirken.",
    "metaDescription": "Desktop-, Orchestrierungs- und Persistenzschichten, die Implementierungspläne, Workflows und Terminal-Sitzungen ermöglichen.",
    "metaTitle": "PlanToCode Architekturübersicht",
    "ogDescription": "Erfahren Sie, wie das React-Frontend, Tauri-Befehle und Hintergrunddienste in der Desktop-App zusammenarbeiten.",
    "ogTitle": "PlanToCode Architekturübersicht",
    "persistence": {
      "database": "Terminal-Ausgaben und Sitzungs-Metadaten werden in SQLite über das Terminal-Sitzungs-Repository gespeichert. Jeder Datensatz enthält Bezeichner, Zeitstempel, Arbeitsverzeichnisse, Umgebungsvariablen und das akkumulierte Protokoll, sodass Neustarts frühere Ausgaben wiederherstellen können. Dasselbe Repository löst Ereignisse aus, wenn sich der Sitzungsstatus ändert.",
      "heading": "Persistenz und Konfiguration",
      "modelConfig": "Modell-Standardwerte befinden sich in der Anwendungskonfigurationstabelle. Jede Aufgabe definiert ein Standardmodell, eine Liste erlaubter Alternativen, Token-Budgets und optionale Kopier-Button-Voreinstellungen. Die React-Schicht liest diese Einstellungen, um den Modell-Selektor und die Leitplanken zu befüllen."
    },
    "readTime": "7 Min.",
    "tauriCommands": {
      "commands": "Die Rust-Seite der Anwendung stellt Befehle für Workflows, Terminal-Sitzungen und Modell-Werkzeuge bereit. Die Workflow-Befehle starten Hintergrundjobs über den Workflow-Orchestrator, validieren Eingaben und lösen Fortschrittsereignisse aus, während die Dateisuche-Pipeline läuft. Token-Schätzungsbefehle berechnen Prompt-Größen für das aktuell ausgewählte Modell.",
      "heading": "Tauri-Befehle und Dienste",
      "terminal": "Terminal-Befehle verwalten PTY-Prozesse, verfolgen Remote-Clients und überprüfen, ob unterstützte CLI-Binärdateien verfügbar sind, bevor eine Sitzung gestartet wird. Zustandsprüfungen kombinieren den PTY-Status mit Datenbankeinträgen, um zu melden, ob eine Sitzung noch aktiv ist."
    },
    "title": "PlanToCode-Architektur",
    "voicePipeline": {
      "description": "Die Sprachtranskription ist als React-Hook implementiert, der Medienberechtigungen, Mikrofonauswahl und Streaming-Transkriptionsanfragen koordiniert. Der Hook integriert sich mit dem Plan-Terminal und Prompt-Editoren und fügt erkannten Text direkt in die aktive Komponente ein, wobei Benachrichtigungen angezeigt werden, wenn die Transkription fehlschlägt.",
      "heading": "Sprachtranskriptions-Pipeline"
    },
    "server": {
      "heading": "Server-Schicht",
      "description": "Der Server verarbeitet Anbieter-Konfiguration (API-Schlüssel im verschlüsselten Tresor, Ratenlimits, Routing-Regeln für OpenAI, Anthropic, Google), Modell-Routing (Anfrage-Proxying, automatisches Failover, Lastverteilung, Kostenverfolgung pro Benutzer/Projekt), Abrechnung (Abonnementverwaltung, Nutzungsmessung, Kontingentdurchsetzung, Kostenwarnungen) und Web-Such-APIs (Ergebnis-Caching mit 30-Tage/7-Tage-TTL, geografische Einschränkungen, JWT-Authentifizierung)."
    },
    "dataFlows": {
      "heading": "Datenflüsse",
      "description": "Aufgaben, Pläne, Jobs und Sitzungen fließen zwischen Komponenten: (1) Aufgabenverfeinerung: React-UI → TextImprovementPopover → Tauri-Befehl → WorkflowOrchestrator → text_improvement Prompt → SQLite → React-Provider ersetzt Text. (2) Dateisuche: Implementierungspläne-Panel → Tauri-Befehl → 4 sequenzielle Jobs → Fortschrittsereignisse → SQLite → UI-Anzeige. (3) Implementierungspläne: Dateisuche → Plan generieren → Tauri-Befehl → LLM-Streaming → SQLite → Monaco-Viewer → Überprüfung/Genehmigung → Export. (4) Terminal-Ausführung: PTY-Sitzung → SQLite → Befehlsausführung → Ausgabe-Streaming → Sprachtranskriptions-Injektion → Agenten-Aufmerksamkeitserkennung → Audit-Protokolle."
    }
  },
  "deepResearch": {
    "meta": {
      "title": "Deep Research - PlanToCode",
      "description": "Technische Dokumentation für den Web-Such-Workflow: API-Integration, Abfrageoptimierung, Ergebnisverarbeitung und Integration in Entwicklungs-Workflows."
    },
    "apiIntegration": {
      "heading": "API-Integrationsdetails",
      "pipeline": {
        "description": "Forschungsergebnisse durchlaufen eine standardisierte Verarbeitungs-Pipeline, die aussagekräftige Informationen extrahiert und dabei Formatierung und Kontext bewahrt. Die Pipeline verarbeitet verschiedene Inhaltstypen und synthetisiert Erkenntnisse zu umsetzbaren Einsichten für Entwicklungs-Workflows.",
        "heading": "Inhaltsverarbeitungs-Pipeline"
      },
      "providerConfig": {
        "description": "Das System verwendet KI-Sprachmodelle über OpenRouter, um intelligente Web-Recherchen durchzuführen. Das LLM generiert zielgerichtete Recherche-Abfragen basierend auf Ihrem Aufgabenkontext und synthetisiert Erkenntnisse aus seinen Trainingsdaten und Web-Suchfähigkeiten. Modellauswahl und -konfiguration werden über die Anwendungseinstellungen verwaltet.",
        "heading": "KI-Recherche-Konfiguration"
      }
    },
    "architecture": {
      "description": "Das Deep-Research-System arbeitet als zweistufiger Workflow: (1) WebSearchPromptsGeneration - KI analysiert Ihre Aufgabe und den Projektkontext, um zielgerichtete Recherche-Abfragen zu generieren, und (2) WebSearchExecution - das LLM führt Recherche-Prompts parallel aus und synthetisiert Erkenntnisse. Jede Stufe ist auf Zuverlässigkeit, Kosteneffizienz und kontextuelle Relevanz ausgelegt.",
      "heading": "Architekturübersicht"
    },
    "bestPractices": {
      "examples": {
        "description": "Gängige Integrationsmuster zeigen, wie Web-Suchergebnisse verschiedene Entwicklungsszenarien verbessern, von der Fehlersuche bei spezifischen Fehlern bis zur Implementierung neuer Funktionen mit unbekannten APIs.",
        "heading": "Integrationsbeispiele"
      },
      "heading": "Best Practices und Beispiele",
      "strategies": {
        "description": "Um den Wert der Web-Such-Integration zu maximieren, befolgen Sie diese bewährten Strategien zur Formulierung von Abfragen, Interpretation von Ergebnissen und Integration von Erkenntnissen in Ihren Entwicklungs-Workflow.",
        "heading": "Effektive Suchstrategien",
        "queryFormulation": {
          "constraints": "Plattform- oder Umgebungsbeschränkungen einbeziehen",
          "errors": "Bibliotheksnamen mit spezifischen Fehlermeldungen kombinieren",
          "heading": "Abfrageformulierung",
          "practices": "\"Best Practices\" oder \"empfohlener Ansatz\" für Mustersuchen verwenden",
          "versions": "Spezifische Versionsnummern einbeziehen, wenn relevant"
        },
        "resultEvaluation": {
          "crossReference": "Lösungen aus mehreren Quellen gegenprüfen",
          "dates": "Veröffentlichungsdaten für zeitkritische Informationen prüfen",
          "heading": "Ergebnisbewertung",
          "official": "Offizielle Dokumentation gegenüber Drittanbieterquellen priorisieren",
          "verify": "Code-Beispiele in Ihrer Entwicklungsumgebung verifizieren"
        }
      }
    },
    "category": "Technische Referenz",
    "configuration": {
      "heading": "Konfiguration und Anpassung",
      "preferences": {
        "description": "Das Rechercheverhalten wird durch Modellauswahl und Aufgabeneinstellungen konfiguriert. Wählen Sie Ihr bevorzugtes KI-Modell für Rechercheaufgaben, konfigurieren Sie Timeouts und wählen Sie, welche Dateien für den Kontext einbezogen werden sollen.",
        "filters": "Modellauswahl bestimmt Recherchequalität und Kosten",
        "heading": "Rechercheeinstellungen",
        "limits": "Maximal 12 Recherche-Prompts pro Aufgabe generiert",
        "optionsHeading": "Konfigurierbare Optionen",
        "patterns": "Relevante Projektdateien für besseren Kontext einbeziehen",
        "sources": "Projektverzeichnis- und Dateiauswahl für Kontext",
        "triggers": "Recherche manuell über den Workflow-Befehl starten"
      },
      "projectSettings": {
        "description": "Die Recherchekonfiguration ist sitzungsbewusst. Das System verwendet das Projektverzeichnis und die einbezogenen Dateien der aktuellen Sitzung, um Kontext bereitzustellen. Ausgeschlossene Pfade (wie node_modules, dist) werden automatisch aus dem dem KI gezeigten Verzeichnisbaum gefiltert.",
        "heading": "Projektspezifische Einstellungen"
      }
    },
    "costs": {
      "heading": "Kostenüberlegungen",
      "optimization": {
        "description": "Recherchekosten werden durch intelligente Prompt-Generierung verwaltet - das System begrenzt Recherche-Prompts auf maximal 12 pro Aufgabe. Parallele Ausführung minimiert die Gesamtzeit. Jeder Job verfolgt Token-Nutzung und geschätzte Kosten in seinen Metadaten für volle Transparenz.",
        "heading": "Kostenoptimierung"
      },
      "rateLimiting": {
        "cacheFirst": "Rechercheergebnisse pro Sitzung zwischengespeichert, um redundante Abfragen zu vermeiden",
        "description": "Deep Research verwendet Ihre konfigurierten KI-Credits über OpenRouter. Jede Rechercheaufgabe generiert mehrere parallele LLM-Aufrufe, daher skalieren die Kosten mit der Anzahl der generierten Recherche-Prompts. Das System verfolgt Token-Nutzung und Kosten pro Job für Transparenz.",
        "guidelinesHeading": "Tipps zur Kostenverwaltung",
        "heading": "Nutzung und Kosten",
        "personal": "Token-Nutzung pro Recherche-Job mit detaillierter Kostenaufschlüsselung verfolgt",
        "team": "Kosten über Ihre OpenRouter- oder PlanToCode-Abonnement-Credits verwaltet",
        "throttling": "Job-Metadaten auf Token-Anzahl und geschätzte Kosten überwachen"
      }
    },
    "cta": {
      "description": "Die Deep Research- und Web-Such-Funktionen sind in der PlanToCode-Desktop-Anwendung verfügbar. Laden Sie den Build für Ihre Plattform herunter, um Web-Recherche in Ihren Entwicklungs-Workflow zu integrieren.",
      "heading": "Bereit, Deep Research zu nutzen?",
      "links": {
        "architecture": "Systemarchitektur ansehen",
        "buildYourOwn": "Eigene Integration erstellen"
      }
    },
    "date": "2025-09-20",
    "description": "Wie PlanToCode Web-Suchen durchführt, Ergebnisse verarbeitet und Erkenntnisse in Entwicklungs-Workflows integriert.",
    "devIntegration": {
      "caching": {
        "description": "Rechercheergebnisse werden in Job-Metadaten gespeichert und können über das Job-Details-Panel abgerufen werden. Ergebnisse bleiben für die Dauer der Sitzung bestehen und können bei der Erstellung von Implementierungsplänen oder Codierungsentscheidungen referenziert werden.",
        "heading": "Ergebnisspeicherung"
      },
      "contextAware": {
        "description": "Rechercheanfragen werden automatisch mit Kontext aus Ihrer aktuellen Sitzung erweitert. Das System bezieht den Verzeichnisbaum und ausgewählte Dateiinhalte Ihres Projekts in die Prompt-Generierungsphase ein, sodass die KI Rechercheabfragen formulieren kann, die spezifisch für Ihre Codebasis sind.",
        "heading": "Kontextbewusste Recherche"
      },
      "heading": "Integration in Entwicklungs-Workflows",
      "resultIntegration": {
        "description": "Rechercheergebnisse können zur Information von Implementierungsplänen verwendet werden. Wenn Rechercheaufgaben abgeschlossen sind, werden Erkenntnisse als research_finding-Tags formatiert, die in nachfolgende Planungsaufgaben einbezogen werden können, um sicherzustellen, dass Ihre Implementierung von aktuellen Best Practices und genauer Dokumentation geleitet wird.",
        "heading": "Ergebnisintegration"
      }
    },
    "intro": "Die Deep Research-Funktion ermöglicht PlanToCode, intelligente KI-gestützte Recherchen durchzuführen, relevante Informationen zu sammeln und Erkenntnisse direkt in Entwicklungs-Workflows zu integrieren. Dieses System verwendet große Sprachmodelle, um zielgerichtete Rechercheabfragen basierend auf Ihrem Projektkontext zu generieren, parallele Rechercheaufgaben auszuführen und umsetzbare Erkenntnisse zu synthetisieren, um Code-Generierung und Problemlösungsfähigkeiten zu verbessern.",
    "metaDescription": "Technische Dokumentation für den Web-Such-Workflow: API-Integration, Abfrageoptimierung, Ergebnisverarbeitung und Integration in Entwicklungs-Workflows.",
    "metaTitle": "Deep Research - PlanToCode",
    "ogDescription": "Verstehen Sie, wie die Web-Suche in PlanToCode funktioniert: von der Abfragegenerierung bis zur Ergebnisverarbeitung und Integration in Entwicklungs-Workflows.",
    "ogTitle": "Deep Research - PlanToCode",
    "readTime": "8 Min.",
    "title": "Deep Research & Web-Suche",
    "troubleshooting": {
      "commonIssues": {
        "description": "Die meisten Rechercheprobleme stammen von LLM-API-Konnektivität, unzureichenden Credits oder zu breiten Prompts. Das System bietet klare Fehlermeldungen und Job-Status-Verfolgung zur Fehlerbehebung.",
        "geographic": "Modellverfügbarkeit",
        "geographicSolution": "Einige Modelle können regionale Einschränkungen über OpenRouter haben",
        "heading": "Häufige Probleme",
        "noResults": "Keine Recherche-Prompts generiert",
        "noResultsSolution": "Spezifischere Aufgabenbeschreibungen bereitstellen oder relevante Dateien für Kontext einbeziehen",
        "rateLimit": "API-Fehler",
        "rateLimitSolution": "OpenRouter-API-Status und Credit-Guthaben prüfen"
      },
      "heading": "Fehlerbehebung und Support",
      "performance": {
        "description": "Für optimale Leistung geben Sie klare und spezifische Aufgabenbeschreibungen an. Beziehen Sie relevante Projektdateien ein, um der KI besseren Kontext zu geben. Das System führt Recherche-Prompts parallel aus, um die Gesamtausführungszeit zu minimieren.",
        "heading": "Leistungsoptimierung"
      }
    },
    "workflow": {
      "execution": {
        "blogs": "Best Practices und Implementierungsmuster",
        "description": "Recherche-Prompts werden parallel von KI-Sprachmodellen ausgeführt. Jeder Prompt wird unabhängig verarbeitet, sodass das System Informationen zu mehreren Aspekten Ihrer Aufgabe gleichzeitig sammeln kann. Ergebnisse werden in strukturierte Erkenntnisse mit Titeln und umsetzbaren Einsichten synthetisiert.",
        "documentation": "API-Dokumentation und technische Spezifikationen",
        "forums": "Fehlerbehebung und Problemlösungsansätze",
        "github": "Code-Beispiele und Implementierungsmuster",
        "heading": "Rechercheausführung",
        "releases": "Versionskompatibilität und Migrationsleitfäden",
        "sourcesHeading": "Recherche-Schwerpunktbereiche"
      },
      "heading": "Recherche-Workflow-Phasen",
      "processing": {
        "deduplication": "Erkenntnisse über mehrere Recherche-Prompts hinweg konsolidiert",
        "description": "Rechercheergebnisse werden im JSON-Format mit Titeln und detaillierten Erkenntnissen strukturiert. Das System aggregiert Ergebnisse aus parallelen Rechercheaufgaben, verfolgt Erfolgs- und Fehleranzahlen und bietet eine Zusammenfassung der Rechercheergebnisse. Ergebnisse werden in Job-Metadaten für einfachen Zugriff gespeichert.",
        "extraction": "Wichtige Erkenntnisse extrahiert und für die Integration formatiert",
        "heading": "Ergebnisverarbeitung & Synthese",
        "scoring": "Ergebnisse nach Recherchethema und Relevanz organisiert",
        "snippets": "Umsetzbare Einsichten und Empfehlungen hervorgehoben",
        "stepsHeading": "Verarbeitungsschritte",
        "timestamp": "Rechercheausführung mit Zeitmetriken verfolgt"
      },
      "queryGeneration": {
        "api": "API-Dokumentation und bibliotheksspezifische Recherche",
        "compatibility": "Versionskompatibilität und Migrationspfade",
        "description": "Recherche-Prompts werden automatisch von KI basierend auf Ihrer Aufgabenbeschreibung, dem Projektkontext und einbezogenen Dateien generiert. Das System analysiert Ihre Codebasis-Struktur über Verzeichnisbaum und Dateiinhalte, um zielgerichtete Rechercheabfragen zu formulieren. Bis zu 12 fokussierte Recherche-Prompts werden pro Aufgabe generiert.",
        "errors": "Fehlerbehebung und Debugging-Ansätze",
        "heading": "Prompt-Generierung",
        "practices": "Best Practices und empfohlene Muster",
        "security": "Sicherheitsüberlegungen und Schwachstellenbewusstsein",
        "typesHeading": "Recherchethemen"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Deep Research Pipeline",
        "description": "Der zweistufige Workflow: Prompt-Generierung und parallele Rechercheausführung.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Deep Research Pipeline-Diagramm mit Prompt-Generierung und Ausführungsphasen",
        "caption": "Deep Research Workflow mit Prompt-Generierung und parallelen Ausführungsphasen"
      },
      "workflow": {
        "title": "Deep Research Workflow",
        "description": "Der zweistufige Workflow: Prompt-Generierung und parallele Rechercheausführung.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "caption": "Deep Research Workflow mit allen Verarbeitungsphasen"
      }
    }
  },
  "fileDiscovery": {
    "meta": {
      "title": "Dateisuche-Workflow - PlanToCode",
      "description": "Umfassende technische Anleitung zum 4-stufigen KI-Workflow, der relevante Dateien für die Aufgabenausführung identifiziert und filtert."
    },
    "apiUsage": {
      "heading": "API-Verwendungsbeispiele",
      "monitoring": "Fortschrittsüberwachung",
      "retrieving": "Ergebnisse abrufen",
      "starting": "Einen Workflow starten"
    },
    "architecture": {
      "caching": "Zwischenspeicherung von Zwischenergebnissen zur Leistungsoptimierung",
      "costTracking": "Kostenverfolgung und Timeout-Verwaltung für KI-Operationen",
      "distributed": "Das System verwendet eine verteilte Job-Architektur, bei der jede Stufe als unabhängiger Hintergrundjob läuft, was Abbruch, Wiederholungslogik und detaillierte Fortschrittsverfolgung ermöglicht. Echtzeit-Ereignisse werden während der Ausführung veröffentlicht, um sofortiges Feedback an die Benutzeroberfläche zu liefern.",
      "errorHandling": "Umfassende Fehlerbehandlung mit automatischen Wiederholungsmechanismen",
      "eventDriven": "Ereignisgesteuerte Fortschrittsberichte mit WebSocket-ähnlichen Updates",
      "featuresHeading": "Wichtige Architekturmerkmale:",
      "gitIntegration": "Git-Integration mit Fallback zur Verzeichnisdurchquerung",
      "heading": "Workflow-Architektur",
      "overview": "Der Workflow arbeitet als orchestriertes Hintergrundjob-System mit vier verschiedenen Stufen, die sequenziell ausgeführt werden. Jede Stufe baut auf der Ausgabe der vorherigen Stufe auf und verfeinert die Dateiauswahl progressiv basierend auf den Aufgabenanforderungen."
    },
    "category": "Technische Anleitung",
    "configuration": {
      "exclusion": {
        "description": "Definieren Sie Verzeichnisse und Dateimuster, die vom Suchprozess ausgeschlossen werden sollen.",
        "heading": "Ausschlussmuster"
      },
      "heading": "Konfigurationsoptionen",
      "retry": {
        "description": "Legen Sie maximale Wiederholungsversuche für fehlgeschlagene Stufen mit exponentiellem Backoff fest.",
        "heading": "Wiederholungskonfiguration"
      },
      "timeout": {
        "description": "Konfigurieren Sie die maximale Ausführungszeit für den gesamten Workflow oder einzelne Stufen, um unendliches Hängen zu verhindern.",
        "heading": "Timeout-Verwaltung"
      },
      "workflowConfig": "Workflow-Konfiguration"
    },
    "cta": {
      "description": "Der Dateisuche-Workflow läuft im Desktop-Client neben Implementierungsplanung und Terminal-Sitzungen.",
      "heading": "Benötigen Sie die Desktop-App?",
      "links": {
        "architecture": "Mehr über Architektur erfahren",
        "buildYourOwn": "Eigene Pipeline erstellen"
      }
    },
    "date": "2025-09-21",
    "description": "Umfassende technische Anleitung zum 4-stufigen KI-Workflow, der relevante Dateien für die Aufgabenausführung identifiziert und filtert.",
    "errorHandling": {
      "commonIssues": {
        "binaryDetection": "Binärdatei-Erkennung: Verwendet sowohl erweiterungsbasierte als auch inhaltsbasierte Binärdatei-Erkennung",
        "gitNotFound": "Git-Repository nicht gefunden: Fallback zur Verzeichnisdurchquerung mit Standardausschlüssen",
        "heading": "Häufige Probleme",
        "networkTimeout": "Netzwerk-Timeouts: Automatische Wiederholung mit exponentiellem Backoff für vorübergehende Fehler",
        "tokenLimit": "Token-Limit überschritten: Implementiert intelligente Batchverarbeitung und liefert klare Fehlermeldungen"
      },
      "debugging": {
        "description": "Der Workflow bietet umfassende Protokollierung, Leistungsmetrik-Export und detaillierten Fehlerkontext einschließlich Stufeninformationen, Wiederholungsversuchen und Zwischendaten zur Fehlerbehebung.",
        "heading": "Debugging-Werkzeuge"
      },
      "errorCategories": {
        "billing": "Abrechnungsfehler: Unzureichende Credits oder Zahlungsfehler mit umsetzbarer Anleitung",
        "heading": "Fehlerkategorien",
        "system": "Systemfehler: Dateisystemzugriff, Git-Befehlsfehler oder Speicherbeschränkungen",
        "validation": "Validierungsfehler: Ungültige Sitzungs-ID, fehlende Aufgabenbeschreibung oder ungültiges Projektverzeichnis",
        "workflow": "Workflow-Fehler: Stufenspezifische Fehler mit detailliertem Kontext und Wiederholungsvorschlägen"
      },
      "heading": "Fehlerbehandlung & Fehlerbehebung"
    },
    "integration": {
      "desktop": {
        "description": "Der Workflow integriert sich nahtlos mit der Desktop-Anwendung über Tauri-Befehle und bietet nativen Dateisystemzugriff sowie ereignisgesteuerte Updates über die WorkflowTracker-Klasse.",
        "heading": "Desktop-Anwendung"
      },
      "heading": "Integrationsmuster",
      "implementationPlans": {
        "description": "Ausgewählte Dateien werden automatisch in das Implementierungspläne-Panel eingespeist, sodass die Plan-Generierung denselben optimierten Dateikontext verwendet, ohne dass der Suche-Workflow erneut ausgeführt werden muss.",
        "heading": "Implementierungspläne-Integration"
      },
      "sessionManagement": {
        "description": "Workflow-Ergebnisse werden pro Sitzung zwischengespeichert, sodass mehrere Operationen innerhalb derselben Sitzung den entdeckten Dateikontext wiederverwenden können, was die Leistung für iterative Entwicklungs-Workflows erheblich verbessert.",
        "heading": "Sitzungsverwaltung"
      }
    },
    "intro": "PlanToCode identifiziert die richtigen Dateien, bevor Sie planen oder Befehle ausführen. Der 4-stufige Workflow grenzt den Umfang ein und hält den Kontext fokussiert.",
    "metaDescription": "Umfassende technische Anleitung zum 4-stufigen KI-Workflow, der relevante Dateien für die Aufgabenausführung identifiziert und filtert.",
    "metaTitle": "Dateisuche-Workflow - PlanToCode",
    "ogDescription": "Technische Dokumentation für die mehrstufige Dateisuche-Workflow-Architektur.",
    "ogTitle": "Dateisuche-Workflow - PlanToCode",
    "performance": {
      "costOptimization": {
        "description": "KI-Stufen verfolgen tatsächliche Kosten aus API-Antworten, implementieren intelligente Batchverarbeitung zur Minimierung der Token-Nutzung und bieten Kostenschätzungen vor der Ausführung, um bei der Kostenverwaltung zu helfen.",
        "heading": "Kostenoptimierung"
      },
      "heading": "Leistungsüberlegungen",
      "memory": {
        "description": "Der Workflow implementiert intelligente Speicherverwaltung mit Datei-Caching (30-Sekunden-TTL), Batchverarbeitung (100 Dateien pro Batch) und automatischer Bereinigung von Zwischendaten, um Speichererschöpfung zu verhindern.",
        "heading": "Speicherverwaltung"
      },
      "monitoring": {
        "description": "Integrierte Leistungsverfolgung überwacht Ausführungszeiten, Speichernutzung, Durchsatzmetriken und liefert Empfehlungen zur Optimierung basierend auf historischer Datenanalyse.",
        "heading": "Leistungsüberwachung"
      }
    },
    "readTime": "12 Min.",
    "stages": {
      "heading": "4-stufiger Workflow-Prozess",
      "stage1": {
        "description": "Verwendet KI, um intelligent die relevantesten Stammverzeichnisse aus einer Liste von Kandidatenpfaden basierend auf der Aufgabenbeschreibung auszuwählen. Das LLM analysiert das primäre Projektverzeichnis und die Kandidaten-Stammverzeichnisse, um zu bestimmen, welche Verzeichnisse am wahrscheinlichsten für die Aufgabe relevante Dateien enthalten.",
        "heading": "Stufe 1: Stammordner-Auswahl",
        "technical": "Technische Details: Empfängt Kandidaten-Stammverzeichnisse (bis Tiefe 2) und die Aufgabenbeschreibung. Das LLM bewertet jeden Pfad gegen den Aufgabenkontext und gibt eine gefilterte Liste von Stammverzeichnissen zurück, die in nachfolgenden Stufen durchsucht werden.",
        "inputOutput": "Eingabe/Ausgabe: Empfängt candidate_roots-Array und task_description. Gibt root_directories-Array zurück, das die KI-ausgewählten, für die Aufgabe relevantesten Verzeichnisse enthält."
      },
      "stage2": {
        "binaryDetection": "Binärdatei-Erkennung: Filtert Dateien mit Binärerweiterungen (.jpg, .png, .pdf, .exe usw.) und verwendet Inhaltsanalyse, um Binärdateien durch Null-Bytes und nicht druckbare Zeichenverhältnisse zu erkennen.",
        "description": "Verwendet KI, um intelligente Regex-Mustergruppen basierend auf der Aufgabenbeschreibung und Verzeichnisstruktur zu generieren. Jede Mustergruppe kann Pfadmuster (positive und negative) und Inhaltsmuster enthalten. Der Prozessor wendet dann diese Muster an, um Dateien aus jedem ausgewählten Stammverzeichnis zu filtern.",
        "gitIntegration": "Git-Integration: Findet das Git-Repository-Stammverzeichnis für jedes ausgewählte Verzeichnis und verwendet git_utils, um alle nicht ignorierten Dateien zu erhalten, wobei .gitignore-Regeln respektiert und sowohl verfolgte als auch nicht verfolgte Dateien einbezogen werden.",
        "heading": "Stufe 2: Regex-Dateifilter",
        "technical": "Technische Details: Generiert einen Verzeichnisbaum für jedes Stammverzeichnis, ruft das LLM auf, um patternGroups mit path_pattern, content_pattern und negative_path_pattern-Feldern zu erzeugen. Verwendet fancy-regex für Lookahead/Lookbehind-Unterstützung. Verarbeitet Stammverzeichnisse parallel mit konfigurierbarer Nebenläufigkeit."
      },
      "stage3": {
        "aiProcessing": "KI-Verarbeitung: Verwendet große Sprachmodelle, um Dateiinhalte gegen Aufgabenanforderungen zu bewerten, mit intelligentem Chunking basierend auf tatsächlichen Dateigrößen und Token-Schätzungen, um Kontextfenster effizient zu verwalten.",
        "description": "Setzt KI-Modelle ein, um Dateiinhalte zu analysieren und die Relevanz für die spezifische Aufgabenbeschreibung zu bewerten. Diese Stufe führt eine tiefe Inhaltsanalyse durch, indem sie Dateiinhalte liest und das LLM identifizieren lässt, welche Dateien für die Aufgabe am relevantesten sind.",
        "heading": "Stufe 3: KI-Datei-Relevanzbewertung",
        "technical": "Technische Details: Schätzt Token pro Datei mit dateityp-bewussten Heuristiken (Code ~3 Zeichen/Token, strukturierte Daten ~5 Zeichen/Token). Erstellt inhaltsbewusste Chunks, um unter der 90k-Token-Schwelle zu bleiben. Verarbeitet Chunks parallel mit Streaming, um Timeouts zu vermeiden. Validiert alle LLM-vorgeschlagenen Pfade gegen das Dateisystem."
      },
      "stage4": {
        "description": "Entdeckt zusätzliche relevante Dateien, indem dem LLM die zuvor identifizierten Dateien und deren Inhalte zusammen mit dem Verzeichnisbaum bereitgestellt werden. Die KI analysiert Importe, Abhängigkeiten und Projektstruktur, um verwandte Dateien zu finden, die den Kontext für die Aufgabe verbessern.",
        "heading": "Stufe 4: Erweiterter Pfadfinder",
        "relationship": "Beziehungsanalyse: Liest den Inhalt aller zuvor identifizierten Dateien und stellt ihn dem LLM zusammen mit dem Verzeichnisbaum bereit (auf ausgewählte Stammverzeichnisse beschränkt, falls verfügbar). Die KI identifiziert zusätzliche Dateien basierend auf Importen, Referenzen und strukturellen Beziehungen.",
        "technical": "Technische Details: Generiert einen kombinierten Verzeichnisbaum für ausgewählte Stammverzeichnisse. Liest den Inhalt aller initial_paths-Dateien. Verwendet Streaming-LLM-Aufrufe, um Cloudflare-Timeouts zu vermeiden. Validiert entdeckte Pfade gegen das Dateisystem und normalisiert zu relativen Pfaden innerhalb des Projekts."
      }
    },
    "stateManagement": {
      "eventDriven": {
        "description": "Das System veröffentlicht Echtzeit-Ereignisse für Workflow-Statusänderungen, Stufenabschlüsse und Fehlerbedingungen. Diese Ereignisse ermöglichen reaktionsfähige Benutzeroberflächen und Integration mit externen Überwachungssystemen.",
        "heading": "Ereignisgesteuerte Updates"
      },
      "heading": "Workflow-Statusverwaltung",
      "intermediateData": {
        "description": "Jede Stufe speichert ihre Ausgabe in einem strukturierten Zwischendatenformat, einschließlich Verzeichnisbauminhalt, Regex-Muster und gefilterte Dateilisten-Ergebnisse. Diese Daten sind für Debugging zugänglich und können verwendet werden, um Workflows von bestimmten Stufen aus fortzusetzen.",
        "heading": "Zwischendatenspeicherung"
      },
      "transitions": {
        "description": "Der Workflow durchläuft klar definierte Zustände: Erstellt → Laufend → Pausiert (optional) → Abgeschlossen/Fehlgeschlagen/Abgebrochen. Jeder Zustandsübergang veröffentlicht Ereignisse, die für Echtzeit-Updates überwacht werden können.",
        "heading": "Zustandsübergänge"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Dateisuche-Pipeline",
        "description": "Der 4-stufige Workflow: Stammordner-Auswahl, Regex-Filterung, KI-Relevanzbewertung und erweiterte Pfadsuche.",
        "imageSrc": "/images/docs/file-discovery/pipeline.svg",
        "caption": "Dateisuche-Pipeline mit allen 4 Stufen",
        "imageAlt": "Diagramm des 4-stufigen Dateisuche-Workflows: Stammordner-Auswahl, Regex-Dateifilter, KI-Datei-Relevanzbewertung und Erweiterter Pfadfinder"
      }
    },
    "title": "Dateisuche-Workflow",
    "sqliteStorage": {
      "heading": "SQLite-Speicherung",
      "description": "Alle Workflow-Zustände, Zwischenergebnisse und Job-Metadaten werden in SQLite persistiert. Jede Stufe speichert ihre Ausgabe in der background_jobs-Tabelle und ermöglicht so Workflow-Fortsetzung, Debugging und Audit-Trails. Die Job-Datensätze enthalten Token-Nutzung, Kostenverfolgung und System-Prompt-Vorlagen für jede KI-Stufe."
    }
  },
  "hub": {
    "ctaDescription": "Laden Sie PlanToCode herunter, um auf den Implementierungsplaner, Modell-Leitplanken, Terminal-Sitzungen und Transkriptionsfunktionen zuzugreifen, die in dieser Dokumentation beschrieben werden.",
    "ctaHeading": "Bereit, diese Workflows auszuprobieren?",
    "ctaLinks": {
      "overview": "Mit Übersicht starten",
      "runtime": "Laufzeit-Walkthrough"
    },
    "description": "Erfahren Sie, wie Sie Code-Änderungen mit PlanToCode planen und ausliefern: Dateisuche, Implementierungspläne, Terminal-Sitzungen, Modell-Leitplanken und Sprache.",
    "exploreHeading": "Dokumentation erkunden",
    "learnMore": "Mehr erfahren",
    "searchAriaLabel": "Dokumentation durchsuchen",
    "searchPlaceholder": "Dokumentation durchsuchen...",
    "searchShortcut": "⌘K",
    "title": "PlanToCode-Dokumentation"
  },
  "onThisPage": {
    "title": "Auf dieser Seite"
  },
  "sidebar": {
    "title": "Dokumentation"
  },
  "sections": {
    "architecture": {
      "title": "Architektur & Interna"
    },
    "inputs": {
      "title": "Eingaben & Erfassung"
    },
    "planning": {
      "title": "Planungs-Pipeline"
    },
    "execution": {
      "title": "Ausführung & Automatisierung"
    },
    "research": {
      "title": "Recherche & Modelle"
    },
    "platform": {
      "title": "Build & Deployment"
    }
  },
  "items": {
    "overview": {
      "title": "Systemübersicht",
      "description": "Starten Sie hier: was das System tut, wie die Kernschleife funktioniert und wo sich jede Komponente befindet."
    },
    "runtime-walkthrough": {
      "title": "Laufzeit-Walkthrough",
      "description": "End-to-End-Zeitlinie dessen, was von der Aufgabeneingabe bis zur Ausführung passiert."
    },
    "architecture": {
      "title": "Systemarchitektur",
      "description": "Wie Desktop-Shell, Rust-Dienste, Server-APIs und Persistenzschichten zusammenpassen."
    },
    "desktop-app": {
      "title": "Desktop-App-Interna",
      "description": "Tauri v2 Shell, Rust-Befehlsschicht, PTY-Sitzungen und UI-Zustandsverwaltung."
    },
    "server-api": {
      "title": "Server-API & LLM-Proxy",
      "description": "Authentifizierung, Anbieter-Routing, Modellkonfiguration und WebSocket-Endpunkte."
    },
    "mobile-ios": {
      "title": "iOS-Client-Architektur",
      "description": "Swift-Workflows, Auth0-Anmeldeablauf und Geräteverbindungs-Sitzungsverwaltung."
    },
    "background-jobs": {
      "title": "Hintergrundjobs & Orchestrierung",
      "description": "Job-Datensätze, Workflow-Orchestrierung, Prozessoren und Ereignis-Streaming."
    },
    "data-model": {
      "title": "Datenmodell & Speicherung",
      "description": "SQLite-Entitäten, Beziehungen und wie Zustand rehydriert wird."
    },
    "decisions-tradeoffs": {
      "title": "Technische Entscheidungen & Kompromisse",
      "description": "Warum Tauri, SQLite und ein dedizierter LLM-Proxy gewählt wurden und was sie kosten."
    },
    "build-your-own": {
      "title": "Eigene Pipeline erstellen",
      "description": "Konzeptioneller Leitfaden für das Design von Dateisuche- und Plan-Generierungs-Workflows."
    },
    "meeting-ingestion": {
      "title": "Meeting- & Aufnahme-Erfassung",
      "description": "Wie Aufnahmen zu strukturierten Aufgabeneingaben und Artefakten werden."
    },
    "video-analysis": {
      "title": "Video-Analyse",
      "description": "Frame-Sampling, Prompts und Analyse-Artefakte aus Aufnahmen."
    },
    "voice-transcription": {
      "title": "Sprachtranskription",
      "description": "Aufnahme-Lebenszyklus, projektbezogene Einstellungen und Geräteverwaltung."
    },
    "text-improvement": {
      "title": "Textverbesserung",
      "description": "Auswahl-Popover, Job-Warteschlange und Integrationen zur Prompt-Bereinigung."
    },
    "file-discovery": {
      "title": "Dateisuche-Workflow",
      "description": "Hintergrund-Workflow, der relevante Pfade für jede Aufgabe sammelt."
    },
    "implementation-plans": {
      "title": "Implementierungspläne",
      "description": "Wie Pläne in den Monaco-Viewer streamen und mit der Plan-Historie verknüpft bleiben."
    },
    "merge-instructions": {
      "title": "Merge-Anweisungen",
      "description": "Wie mehrere Plan-Entwürfe mit XML-getaggten Quellplänen und Benutzerführung zusammengeführt werden."
    },
    "prompt-types": {
      "title": "Prompt-Typen & Vorlagen",
      "description": "Katalog von Prompt-gesteuerten Job-Typen und Vorlagen-Zusammenstellung."
    },
    "terminal-sessions": {
      "title": "Terminal-Sitzungen",
      "description": "Persistente PTY-Sitzungen, CLI-Erkennung und Wiederherstellungsverhalten."
    },
    "copy-buttons": {
      "title": "Kopier-Buttons",
      "description": "Vorlagen-Übergabe von Plänen an Terminals und externe Tools."
    },
    "deep-research": {
      "title": "Deep Research & Web-Suche",
      "description": "Web-Such-Workflow, API-Integration, Abfrageoptimierung und Integration in Entwicklungs-Workflows."
    },
    "provider-routing": {
      "title": "Anbieter-Routing & Streaming",
      "description": "Wie Anbieter-Anfragen normalisiert, gestreamt und verfolgt werden."
    },
    "model-configuration": {
      "title": "Modellkonfiguration",
      "description": "Erlaubte Modelle pro Aufgabe und Token-Leitplanken im Selektor-Toggle."
    },
    "server-setup": {
      "title": "Dedizierte Server-Einrichtung",
      "description": "Ansible-basierte Infrastruktur: Basis-Härtung, App-Deployment und Vault-verwaltete Secrets."
    },
    "tauri-v2": {
      "title": "Tauri v2 Entwicklungsleitfaden",
      "description": "Projektstruktur, Befehle und fähigkeitsbasierte Berechtigungen für Tauri v2."
    },
    "distribution-macos": {
      "title": "macOS-Distribution",
      "description": "Signierung, Notarisierung, DMG-Paketierung und Updater-Artefakte."
    },
    "distribution-windows": {
      "title": "Windows-Distribution & Store",
      "description": "NSIS-Builds, MSIX-Paketierung und Microsoft Store-Einreichung."
    }
  },
  "implementationPlans": {
    "meta": {
      "title": "Implementierungspläne - KI-Änderungen überprüfen",
      "description": "Leitfaden zur KI-Implementierungsplanung. Generieren, überprüfen und genehmigen Sie dateibasierte Pläne vor der Ausführung. Duplikate und falsche Pfade verhindern."
    },
    "category": "Produktleitfaden",
    "context": {
      "audit": "Alle Metadaten bleiben mit dem Plan für Audit-Zwecke erhalten. Unternehmensteams können verfolgen, welche Stakeholder welche Pläne überprüft haben, welche Änderungen angefordert wurden und die vollständige Argumentationskette von der anfänglichen Aufgabenbeschreibung über die Dateisuche bis zum endgültigen genehmigten Plan.",
      "heading": "Kontext und Metadaten für Unternehmensführung",
      "storage": "Das Panel speichert, welche Repository-Stammverzeichnisse während des Dateisuche-Workflows ausgewählt wurden, sodass Folgeaktionen denselben Umfang wiederverwenden. Es zeichnet auch planspezifische Metadaten auf, wie das Projektverzeichnis und vorbereitete Prompt-Inhalte, sodass nachgelagerte Prompts generiert oder kopiert werden können, ohne den Workflow neu zu berechnen.",
      "tokenEstimation": "Die Token-Schätzung wird vor dem Kopieren von Prompts ausgeführt. Das Panel ruft den Token-Schätzungsbefehl mit dem Projektverzeichnis, ausgewählten Dateien und dem aktuell gewählten Modell auf und zeigt sowohl System- als auch Benutzer-Prompt-Summen an, damit Teams unter den Modell-Limits bleiben können."
    },
    "cta": {
      "claudeCodeLink": "Claude Plan-Modus-Workflow ansehen",
      "codexLink": "Codex Plan-Modus-Workflow ansehen",
      "cursorLink": "Cursor Plan-Modus-Workflow ansehen",
      "description": "Human-in-the-Loop-Implementierungspläne sind in der PlanToCode-Desktop-Anwendung verfügbar. Laden Sie den Build für Ihre Plattform herunter, um sichere, kontrollierte KI-gestützte Entwicklung zu erleben.",
      "heading": "Bereit, KI-Coding-Agenten sicher einzusetzen?",
      "links": {
        "architecture": "Systemarchitektur",
        "decisions": "Entscheidungen & Kompromisse",
        "buildYourOwn": "Eigene Pipeline erstellen",
        "fileDiscovery": "Dateisuche-Workflow"
      }
    },
    "date": "2025-09-19",
    "description": "Wie PlanToCode die sichere Einführung von KI-Coding-Agenten durch Human-in-the-Loop-Führung, granulare dateibasierte Pläne und umfassende Überprüfungs-Workflows ermöglicht.",
    "fileGranularity": {
      "created": "Erstellt (mit vollständigen Dateipfaden und initialer Inhaltsstruktur)",
      "declaredFiles": "Jeder Schritt in einem Plan deklariert explizit, welche Dateien:",
      "deleted": "Gelöscht (mit Begründung und Abhängigkeitsanalyse)",
      "heading": "Datei-für-Datei-Granularität",
      "impact": "Dieses Detailniveau macht die Auswirkungen vorgeschlagener Änderungen kristallklar, bevor Code berührt wird. Teamleiter können sofort erkennen, ob kritischer Legacy-Code geändert wird, ob Breaking Changes vorgeschlagen werden oder ob der Plan Dateien berührt, die zusätzliche Prüfung erfordern.",
      "intro": "Implementierungspläne verwenden eine hochgranulare Struktur, die Entwicklungsaufgaben auf Datei-für-Datei-Basis aufschlüsselt, mit exakten Dateipfaden, die der Repository-Struktur des Projekts entsprechen. Diese Granularität ist grundlegend für die Vermeidung von Regressionen und ermöglicht die sichere Einführung von KI-Coding-Agenten in Unternehmensumgebungen.",
      "modified": "Geändert (mit spezifischen Zeilenbereichen und beschriebenen Änderungen)",
      "referenced": "Referenziert (für Kontext, aber nicht geändert)",
      "transmission": "Der Datei-für-Datei-Ansatz ermöglicht auch die präzise Übertragung genehmigter Pläne an Coding-Agenten. Anstelle vager Anweisungen wie \"aktualisiere das Authentifizierungssystem\" erhalten Agenten exakte Spezifikationen: \"ändere src/auth/session_manager.rs Zeilen 45-67, um Token-Rotation hinzuzufügen, erstelle src/auth/token_store.rs mit folgender Struktur...\""
    },
    "hitl": {
      "approve": "Genehmigen:",
      "approveDesc": "Erst nach expliziter Genehmigung können Pläne sicher an den gewählten Coding-Agenten oder zugewiesenen Softwareentwickler zur Ausführung übertragen werden.",
      "conclusion": "Dieser Workflow stellt sicher, dass alle Entwicklungsbemühungen mit den Produktanforderungen des Unternehmens, Team-Workflows und Geschäftszielen übereinstimmen. Keine Code-Änderungen erfolgen ohne explizite menschliche Genehmigung.",
      "edit": "Bearbeiten:",
      "editDesc": "Stakeholder können Schritte direkt ändern, Ansätze anpassen, Einschränkungen hinzufügen oder riskante Operationen mit VS Code-Bearbeitungsfunktionen entfernen.",
      "heading": "Human-in-the-Loop-Führung",
      "intro": "PlanToCode implementiert einen umfassenden Human-in-the-Loop (HITL)-Workflow, der sicherstellt, dass Teamleiter und Stakeholder die volle Kontrolle über jeden Aspekt der KI-generierten Implementierungspläne behalten. Dieses Führungsmodell verhindert die Regressionen, Bugs und unbeabsichtigten Änderungen, die auftreten können, wenn KI-Coding-Agenten autonom arbeiten.",
      "reject": "Ablehnen:",
      "rejectDesc": "Pläne, die die Anforderungen nicht erfüllen, können vollständig abgelehnt werden, wobei vollständige Audit-Trails für Compliance und Lernen erhalten bleiben.",
      "requestChanges": "Änderungen anfordern:",
      "requestChangesDesc": "Teams können Änderungen vom KI-System anfordern, alternative Ansätze generieren oder mehrere Pläne mit benutzerdefinierten Anweisungen zusammenführen.",
      "review": "Überprüfen:",
      "reviewDesc": "Pläne werden im Monaco-Editor geöffnet, wo Prüfer jede vorgeschlagene Änderung mit vollständiger Syntaxhervorhebung und professionellen Bearbeitungswerkzeugen untersuchen können.",
      "workflow": "Jeder Plan muss einen strukturierten Überprüfungs-Workflow durchlaufen, bevor Code-Änderungen beginnen:"
    },
    "intro": "Überprüfen und genehmigen Sie jeden Plan vor der Ausführung. Human-in-the-Loop-Führung mit Datei-für-Datei-Granularität stellt sicher, dass KI-generierte Änderungen mit Unternehmensanforderungen und Team-Workflows übereinstimmen.",
    "metaDescription": "Leitfaden zur KI-Implementierungsplanung. Generieren, überprüfen und genehmigen Sie dateibasierte Pläne vor der Ausführung. Duplikate und falsche Pfade verhindern.",
    "metaTitle": "Implementierungspläne - KI-Änderungen überprüfen",
    "multiplePlans": {
      "description": "Pläne können zusammengeführt, gelöscht oder später erneut geöffnet werden. Das Panel führt eine Liste ausgewählter Plan-Bezeichner, verwaltet ein dediziertes Modal für Terminal-Ausgabe, die an einen Plan gebunden ist, und stellt Navigationshelfer bereit, sodass Prüfer durch frühere Pläne blättern können, ohne den Viewer zu schließen. Terminal-Zugriff, Prompt-Kopiersteuerungen und Merge-Anweisungen teilen alle denselben Job-Bezeichner, sodass die Audit-Historie konsistent bleibt.",
      "heading": "Arbeiten mit mehreren Plänen"
    },
    "ogDescription": "Verstehen Sie, wie Human-in-the-Loop-Führung und Datei-für-Datei-Überprüfungs-Workflows sichere KI-Entwicklung mit vollständiger Kontrolle über Code-Änderungen gewährleisten.",
    "ogTitle": "Human-in-the-Loop-Implementierungspläne in PlanToCode",
    "plansOrigin": {
      "description": "Jeder Plan entspricht einem Hintergrundjob in der aktuellen Sitzung. Das Panel abonniert Plan-Daten, verfolgt, welcher Plan aktuell geöffnet ist, und stellt Navigation zwischen früheren und neueren Jobs bereit. Dieses Verhalten befindet sich in {code} und der umgebenden Panel-Komponente.",
      "heading": "Woher die Pläne kommen",
      "processor": "ImplementationPlanProcessor verarbeitet die Plan-Generierung. Er liest relevante Dateien, generiert optional einen Verzeichnisbaum basierend auf ausgewählten Stammverzeichnissen und stellt einen vereinheitlichten Prompt für das LLM zusammen.",
      "storage": "Plan-Antworten werden in der Jobs-Tabelle mit Metadaten gespeichert, einschließlich planTitle, summary, sessionName und Token-Nutzung. Die rohe LLM-Antwort wird für Audit-Zwecke aufbewahrt.",
      "streaming": "Pläne werden über den LlmTaskRunner mit Echtzeit-Fortschrittsereignissen gestreamt. Token-Warnungen werden für Prompts über 100k Token protokolliert, aber die Verarbeitung wird mit vollem Inhalt fortgesetzt."
    },
    "readTime": "6 Min.",
    "reviewingPlans": {
      "description": "Plan-Inhalte werden durch den gemeinsamen {code} gerendert, der den Monaco Editor umhüllt. Der Viewer erkennt automatisch gängige Sprachen, unterstützt In-Zwischenablage-Kopieren-Aktionen, virtualisiert sehr große Pläne und bietet optionale Metriken wie Zeichenanzahlen und syntaxbewusste Hervorhebung.",
      "heading": "Pläne mit Monaco überprüfen",
      "opening": "Wenn ein Plan geöffnet wird, löst das Panel den aktiven Plan nach Job-Bezeichner auf, übergibt den Inhalt an Monaco und lässt Prüfer zwischen benachbarten Jobs wechseln, ohne das aktuell geöffnete Modal zu verlieren."
    },
    "visuals": {
      "structure": {
        "title": "Implementierungsplan-Struktur",
        "description": "XML-Format für Implementierungspläne mit Datei-für-Datei-Granularität und Metadaten.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "caption": "Plan-Struktur mit Schritten, Dateien und Abhängigkeitsverfolgung"
      }
    },
    "title": "Implementierungspläne",
    "planProcessor": {
      "heading": "Plan-Generierungs-Pipeline",
      "description": "Der ImplementationPlanProcessor orchestriert die Plan-Generierung, indem er Dateiinhalte lädt, Kontext aufbaut und Ergebnisse durch den LLM-Task-Runner streamt.",
      "inputs": "Sitzungskontext, Aufgabenbeschreibung, ausgewählte relevante Dateien, optionaler Verzeichnisbaum (konfigurierbar über include_project_structure-Flag) und Web-Such-Flag für externe Recherche.",
      "prompt": "Verwendet prompt_utils::build_unified_prompt, um Aufgabenbeschreibung, vollständige Dateiinhalte (ohne Kürzung) und Verzeichnisbaum in ein modellspezifisches Format mit geschätzten Token-Anzahlen zu kombinieren.",
      "output": "Rohe LLM-Antwort als JobResultData::Text gespeichert. Metadaten umfassen planTitle, summary, Token-Nutzung, Cache-Statistiken und tatsächliche Kosten.",
      "display": "Antworten werden über Fortschrittsereignisse an die UI gestreamt. Pläne werden in einem Monaco-basierten VirtualizedCodeViewer mit Syntaxhervorhebung und Kopieraktionen gerendert."
    },
    "schema": {
      "heading": "Plan-Datenstruktur",
      "description": "Implementierungspläne werden als rohe LLM-Antworten mit zugehörigen Metadaten gespeichert. Der Antworttext wird genau wie generiert aufbewahrt, während strukturierte Metadaten den Plan-Kontext und die Nutzung verfolgen.",
      "fieldsHeading": "Metadatenfelder",
      "fields": [
        "planTitle - Generierter oder vom Benutzer bereitgestellter Titel für den Plan",
        "summary - Lesbare Zusammenfassung des Plans",
        "sessionName - Name der Sitzung, die den Plan generiert hat",
        "isStructured - Immer true für abgeschlossene Pläne",
        "isStreaming - False für abgeschlossene Pläne (true während der Generierung)",
        "planData - Enthält agent_instructions (optional) und steps-Array"
      ],
      "exampleHeading": "Metadaten-Beispiel",
      "example": "{\n  \"planTitle\": \"Authentication System Refactor\",\n  \"summary\": \"Implementation plan generated\",\n  \"sessionName\": \"my-project\",\n  \"isStructured\": true,\n  \"isStreaming\": false,\n  \"planData\": {\n    \"agent_instructions\": null,\n    \"steps\": []\n  }\n}"
    }
  },
  "modelConfiguration": {
    "meta": {
      "title": "Modellkonfiguration und Leitplanken - PlanToCode",
      "description": "Wie PlanToCode Ihnen ermöglicht, erlaubte Modelle pro Aufgabe auszuwählen und Prompts innerhalb des aktiven Kontextfensters zu halten."
    },
    "category": "Produktleitfaden",
    "date": "2025-09-20",
    "description": "Aufgabenebene-Modelllisten, Selektorsteuerungen und Token-Leitplanken im Desktop-Client.",
    "intro": "PlanToCode behandelt die Modellauswahl als Entscheidung auf Aufgabenebene. Jeder Workflow wird mit einem Standardmodell und einer erlaubten Liste ausgeliefert, und der Desktop-Client stellt diese Optionen über ein Toggle bereit, das das Senden von Prompts verhindert, die das aktive Kontextfenster überschreiten.",
    "metaDescription": "Wie PlanToCode Ihnen ermöglicht, erlaubte Modelle pro Aufgabe auszuwählen und Prompts innerhalb des aktiven Kontextfensters zu halten.",
    "metaTitle": "Modellkonfiguration und Leitplanken - PlanToCode",
    "ogDescription": "Erfahren Sie, wie Modelleinstellungen auf Aufgabenebene, Selektor-Toggles und Token-Schätzungen zusammenarbeiten.",
    "ogTitle": "Modellkonfiguration und Leitplanken - PlanToCode",
    "promptEstimation": {
      "description": "Token-Anzahlen werden durch den Token-Schätzungsbefehl berechnet. Das Panel übermittelt die Sitzungs-ID, Aufgabenbeschreibung, relevante Dateien und das ausgewählte Modell, damit das Backend System-, Benutzer- und Gesamt-Token-Werte zurückgeben kann. Diese Zahlen fließen direkt in die Selektor-Leitplanken ein und lassen Teams Prompts über dem Limit erkennen, bevor sie in ein anderes Tool kopiert werden.",
      "heading": "Prompt-Schätzung"
    },
    "readTime": "5 Min.",
    "selectorToggle": {
      "description": "Das Implementierungspläne-Panel rendert erlaubte Modelle mit dem {code}. Das Toggle zeigt jedes erlaubte Modell an, verfolgt die aktive Auswahl und prüft, ob der geschätzte Prompt plus geplante Ausgabe-Token in das beworbene Kontextfenster des Modells passen, bevor ein Wechsel erlaubt wird.",
      "guardrails": "Wenn ein Modell die gesamte Token-Anforderung nicht unterstützen kann, deaktiviert das Toggle die Schaltfläche und zeigt einen Tooltip mit der berechneten Überschreitung an, sodass Prüfer innerhalb sicherer Grenzen bleiben, bevor sie Arbeit an einen Agenten senden.",
      "heading": "Selektor-Toggle im Client"
    },
    "taskDefaults": {
      "description": "Standardmodelle und erlaubte Alternativen werden serverseitig in der Anwendungskonfiguration gespeichert. Jeder Aufgabentyp - wie Implementierungspläne, Merges, Prompt-Generierung oder Sprachtranskription - definiert ein bevorzugtes Modell, eine Liste erlaubter Optionen und Token-Limits, die die Desktop-App zur Laufzeit liest.",
      "heading": "Aufgabengesteuerte Standardwerte"
    },
    "title": "Modellkonfiguration"
  },
  "terminalSessions": {
    "meta": {
      "title": "Terminal-Sitzungen - PlanToCode",
      "description": "Technische Anleitung zur PTY-Terminal-Implementierung in PlanToCode. Erfahren Sie, wie Sitzungen persistiert werden, Agenten-Inaktivitätserkennung funktioniert und Wiederherstellungsmechanismen."
    },
    "attentionDetection": {
      "conclusion": "Dieser Ansatz hilft Ihnen zu verfolgen, wann Agenten Aufgaben abgeschlossen haben oder Anleitung benötigen, ohne zu erraten, warum sie gestoppt haben. Aufmerksamkeitsindikatoren werden automatisch gelöscht, wenn neue Ausgabe empfangen wird.",
      "heading": "Agenten-Aufmerksamkeitserkennung",
      "intro": "Das Terminal überwacht Agentenaktivität durch ein zweistufiges Inaktivitätserkennungssystem. Wenn ein Agent aufhört, Ausgabe zu produzieren, warnt das System Sie progressiv, um zu überprüfen, was passiert ist:",
      "level1": "Stufe 1 (30 Sekunden): \"Agent inaktiv - hat möglicherweise Aufgabe abgeschlossen\" mit gelbem Indikator",
      "level2": "Stufe 2 (2 Minuten): \"Agent erfordert Aufmerksamkeit - Terminal überprüfen\" mit rotem Indikator und Desktop-Benachrichtigung"
    },
    "category": "Produktleitfaden",
    "date": "2025-09-22",
    "dependencyChecks": {
      "description": "Vor dem Starten von Befehlen prüft das Terminal auf das Vorhandensein unterstützter CLI-Tools wie claude, cursor, codex und gemini. Derselbe Befehl meldet auch die Standard-Shell, sodass Benutzer wissen, welche Umgebung ausgeführt wird. Dies verhindert das Starten in eine Sitzung, die die erforderliche Binärdatei nicht finden kann.",
      "heading": "Abhängigkeitsprüfungen"
    },
    "description": "Persistente PTY-Sitzungen, Agenten-Aufmerksamkeitserkennung und Wiederherstellungsverhalten im Implementierungspläne-Terminal.",
    "intro": "Führen Sie Befehle in einer persistenten PTY mit Zustandsprüfungen und Protokollierung aus. Sprachtranskription ist verfügbar, wenn Sie sie benötigen.",
    "lifecycle": {
      "description": "Wenn ein Terminal geöffnet wird, erstellt die UI-Komponente eine PTY-Sitzung und streamt Ausgabe durch eine gepufferte Ansicht. Die Komponente zeigt sofortigen Verbindungsstatus, leitet Tastatureingaben an die PTY weiter und versucht automatisch erneut, wenn die Sitzung fehlschlägt. Sitzungs-Metadaten werden in SQLite mit Zeitstempeln, Exit-Codes, Arbeitsverzeichnissen und dem vollständigen Ausgabeprotokoll gespeichert, sodass Neustarts den vorherigen Kontext fortsetzen können.",
      "heading": "Sitzungs-Lebenszyklus"
    },
    "metaDescription": "Technische Anleitung zur PTY-Terminal-Implementierung in PlanToCode. Erfahren Sie, wie Sitzungen persistiert werden, Agenten-Inaktivitätserkennung funktioniert und Wiederherstellungsmechanismen.",
    "metaTitle": "Terminal-Sitzungen - PlanToCode",
    "ogDescription": "Verstehen Sie Sitzungspersistenz, Agenten-Aufmerksamkeitserkennung und Wiederherstellung im Plan-Terminal.",
    "ogTitle": "Terminal-Sitzungen - PlanToCode",
    "readTime": "6 Min.",
    "title": "Terminal-Sitzungen",
    "voiceRecovery": {
      "heading": "Sprachtranskription und Wiederherstellung",
      "recovery": "Wenn eine PTY-Sitzung die Verbindung trennt, zeigt die Terminal-Oberfläche Wiederherstellungssteuerungen an und versucht die Verbindung mit exponentiellem Backoff erneut. Zustandsprüfungen überwachen weiterhin den Sitzungsstatus und bieten automatische Wiederherstellungsaktionen, wenn Verbindungsprobleme erkannt werden.",
      "voice": "Im Terminal-Modal kann Sprachtranskription Sprache aufnehmen und in den Terminal-Eingabebereich einfügen. Der Aufnahme-Hook sucht projektbezogene Transkriptionseinstellungen, verfolgt den Aufnahmestatus und streamt erkannten Text in die aktive Plan-Sitzung."
    }
  },
  "copyButtons": {
    "meta": {
      "title": "Kopier-Buttons - PlanToCode",
      "description": "Wie vorlagengesteuerte Kopier-Buttons Platzhalter gegen Pläne auflösen und an Terminals oder Zwischenablage zur Agenten-Ausführung übergeben."
    },
    "category": "Ausführung",
    "date": "2025-09-23",
    "readTime": "10 Min.",
    "title": "Kopier-Buttons",
    "description": "Vorlagengesteuerte Übergabe von Implementierungsplänen an PTY-Terminals und externe Tools.",
    "intro": "Kopier-Buttons überbrücken Planung und Ausführung, indem sie Vorlagen-Platzhalter gegen den aktiven Plan auflösen und dann das Ergebnis an PTY-Sitzungen oder die Systemzwischenablage liefern. Jede Aktion ist mit Job-Metadaten für vollständige Audit-Trails verknüpft, sodass Teams genau nachverfolgen können, was an Agenten gesendet wurde.",
    "metaTitle": "Kopier-Buttons - PlanToCode",
    "metaDescription": "Wie vorlagengesteuerte Kopier-Buttons Platzhalter gegen Pläne auflösen und an Terminals oder Zwischenablage zur Agenten-Ausführung übergeben.",
    "ogTitle": "Kopier-Buttons - PlanToCode",
    "ogDescription": "Technische Anleitung zu Kopier-Button-Vorlagen, Platzhalter-Auflösung und Terminal-Übergabe.",
    "visuals": {
      "templateFlow": {
        "title": "Vorlagenauflösungs-Ablauf",
        "description": "Dieses Diagramm zeigt die Kopier-Button-Ausführungs-Pipeline. Stufe 1 'Button-Klick': Benutzer klickt einen Kopier-Button im Plan-Viewer oder Terminal-Header. Die Button-Konfiguration enthält ein Label, Vorlagentext und Ziel (Terminal oder Zwischenablage). Stufe 2 'Platzhalter-Extraktion': Der Vorlagen-Prozessor sucht nach doppelten geschweiften Klammer-Mustern wie {{IMPLEMENTATION_PLAN}}, {{STEP_CONTENT}}, {{TASK_DESCRIPTION}}. Stufe 3 'Kontext-Auflösung': Der Resolver fragt Job-Metadaten nach Plan-Inhalten ab, dann Sitzungsstatus nach Aufgabenbeschreibung und ausgewählten Dateien. Fehlende Platzhalter werden in der Ausgabe zum Debugging beibehalten. Stufe 4 'Ziel-Zustellung': Für Terminal-Ziele wird Inhalt über master.take_writer() in den PTY-Eingabepuffer geschrieben. Für Zwischenablage-Ziele wird Inhalt über Tauri Clipboard API kopiert. Eine Toast-Benachrichtigung bestätigt die Aktion mit Inhaltsvorschau.",
        "imageSrc": "/images/docs/copy-buttons/templates.svg",
        "imageAlt": "Ablauf der Kopier-Button-Vorlagenauflösung",
        "caption": "Platzhalter für ein Vorlagenauflösungs-Ablaufdiagramm."
      }
    },
    "templateConfiguration": {
      "heading": "Vorlagen-Konfigurationsquellen",
      "description": "Kopier-Button-Vorlagen folgen einem geschichteten Konfigurationsmodell. Server-Standardwerte bieten Basis-Vorlagen, Projekt-Ebenen-Überschreibungen passen für Team-Workflows an, und aufgabenspezifische Konfigurationen behandeln Einmalfälle.",
      "serverDefaults": {
        "heading": "Server-Standardwerte",
        "description": "Gemeinsame Vorlagen von /api/config/desktop-runtime-config. Enthält Button-Labels, Vorlagen-Strings, Ziel (Terminal oder Zwischenablage) und Sichtbarkeitsbedingungen."
      },
      "projectOverrides": {
        "heading": "Projekt-Überschreibungen",
        "description": "In der SQLite project_settings-Tabelle gespeicherte Vorlagen. Zur Laufzeit mit Server-Standardwerten zusammengeführt, um für Team-Standards anzupassen."
      },
      "taskSpecific": {
        "heading": "Aufgabenspezifisch",
        "description": "Pro-task_model_config-Vorlagen für spezialisierte Workflows. Ermöglicht benutzerdefinierte Übergabemuster ohne Änderung globaler Einstellungen."
      }
    },
    "placeholderResolution": {
      "heading": "Platzhalter-Auflösung",
      "description": "Vorlagen verwenden doppelte geschweifte Klammer-Platzhalter, die zum Klickzeitpunkt gegen den aktiven Plan und Sitzungskontext aufgelöst werden. Die primären Platzhalter sind {{IMPLEMENTATION_PLAN}} und {{TASK_DESCRIPTION}}.",
      "placeholdersHeading": "Verfügbare Platzhalter",
      "placeholders": [
        {
          "placeholder": "{{IMPLEMENTATION_PLAN}}",
          "description": "Vollständiger Implementierungsplan-Inhalt wie vom LLM generiert"
        },
        {
          "placeholder": "{{TASK_DESCRIPTION}}",
          "description": "Die Aufgabenbeschreibung aus der aktuellen Sitzung"
        }
      ],
      "resolutionOrder": "Auflösungsreihenfolge: Zuerst Job-Metadaten, dann Plan-Inhalt, dann Sitzungskontext. Undefinierte Platzhalter werden in der Ausgabe zum Debugging beibehalten.",
      "exampleTemplate": "Beispielvorlage:\n\n{{IMPLEMENTATION_PLAN}}\n\nVerstehen Sie den obigen Implementierungsplan gründlich. Analysieren Sie die Architektur, Datenflüsse und Ereignisabfolge.\n\nAufgabe: {{TASK_DESCRIPTION}}"
    },
    "processingPipeline": {
      "heading": "Vorlagen-Verarbeitungs-Pipeline",
      "description": "Wenn ein Button geklickt wird, führt der Vorlagen-Prozessor eine mehrstufige Pipeline aus: Platzhalter-Extraktion, Kontext-Suche, Wert-Substitution und Ausgabeformatierung.",
      "steps": [
        {
          "number": 1,
          "title": "Platzhalter extrahieren",
          "description": "Regex-Scan nach {{...}}-Mustern im Vorlagentext"
        },
        {
          "number": 2,
          "title": "Kontext suchen",
          "description": "Job-Metadaten, Plan-Inhalt und Sitzungsstatus nach Werten abfragen"
        },
        {
          "number": 3,
          "title": "Werte substituieren",
          "description": "Platzhalter durch aufgelöste Werte ersetzen, Formatierung beibehalten"
        },
        {
          "number": 4,
          "title": "Ausgabe formatieren",
          "description": "Zielspezifisches Escaping anwenden (Shell für Terminal, Plain für Zwischenablage)"
        }
      ],
      "chunking": {
        "heading": "Große Plan-Chunking",
        "description": "Pläne über 100KB werden automatisch in sequenzielle Segmente mit klaren Grenzen aufgeteilt, um Überlastung von Terminal-Puffern oder Zwischenablage-Limits zu vermeiden. Jeder Chunk wird mit seiner Position vorangestellt (z.B. '[Teil 1/3]')."
      }
    },
    "terminalHandoff": {
      "heading": "PTY-Terminal-Übergabe",
      "description": "Für Terminal-Übergabe konfigurierte Buttons schreiben direkt in den PTY-Sitzungs-Eingabepuffer. Die aufgelöste Vorlage erscheint, als wäre sie vom Benutzer getippt worden, und löst sofort die Agenten-Ausführung aus.",
      "detailsHeading": "Übergabe-Details",
      "details": [
        "Inhalt über master.take_writer() in den PTY-Eingabepuffer geschrieben",
        "Unterstützt mehrzeilige Eingabe und Escape-Sequenzen",
        "Große Inhalte in 4KB-Segmente aufgeteilt, um Pufferüberlauf zu vermeiden",
        "UI zeigt erste 100 Zeichen als Bestätigungsvorschau"
      ],
      "codeExample": "// Terminal handoff implementation\nasync fn handoff_to_terminal(\n    session_id: &str,\n    content: &str,\n    template_id: &str,\n) -> Result<HandoffResult> {\n    // Get PTY writer for session\n    let writer = terminal_manager.get_writer(session_id)?;\n\n    // Write content to PTY input buffer\n    writer.write_all(content.as_bytes()).await?;\n\n    // Log the action for audit\n    copy_button_actions.insert(CopyButtonAction {\n        session_id: session_id.to_string(),\n        template_id: template_id.to_string(),\n        content_hash: sha256(content),\n        created_at: Utc::now(),\n    })?;\n\n    Ok(HandoffResult::Terminal { session_id })\n}"
    },
    "clipboardHandoff": {
      "heading": "Zwischenablage-Übergabe",
      "description": "Für Zwischenablage konfigurierte Buttons kopieren die aufgelöste Vorlage über die Tauri Clipboard API in die Systemzwischenablage. Dies ermöglicht die Übergabe an externe Tools wie IDE-Terminals oder webbasierte Agenten.",
      "crossPlatform": {
        "heading": "Plattformübergreifende API",
        "description": "Verwendet tauri::api::clipboard::set_text() für konsistenten Zwischenablage-Zugriff über macOS, Windows und Linux."
      },
      "feedback": {
        "heading": "Benutzer-Feedback",
        "description": "Toast-Benachrichtigung bestätigt das Kopieren mit einer Inhaltsvorschau und Token-Anzahl-Schätzung für das Zielmodell."
      }
    },
    "defaultButtons": {
      "heading": "Standard-Kopier-Buttons",
      "description": "PlanToCode wird mit mehreren Standard-Kopier-Buttons ausgeliefert, die gängige Workflows abdecken. Diese können über Projekteinstellungen angepasst oder erweitert werden.",
      "buttonsHeading": "Eingebaute Buttons",
      "buttons": [
        {
          "id": "parallel-agents",
          "label": "Parallele Claude Coding-Agenten",
          "description": "Startet parallele Claude Coding-Agenten, die gleichzeitig ausgeführt werden. Jeder Agent erhält explizite Anweisungen über seine Verantwortlichkeiten. Enthält Anweisungen, veraltete Funktionen vollständig zu entfernen."
        },
        {
          "id": "investigate-results",
          "label": "Ergebnisse untersuchen",
          "description": "Überprüft Ergebnisse von gestarteten Agenten und verifiziert vollständige Implementierung. Führt Selbstprüfung durch Lesen geänderter Dateien und Analysieren von Änderungen durch, ohne zusätzliche Agenten zu starten."
        },
        {
          "id": "task-only",
          "label": "Aufgabe",
          "description": "Kopiert nur die Aufgabenbeschreibung für Kontext. Verwendet {{TASK_DESCRIPTION}}-Platzhalter."
        },
        {
          "id": "task-and-plan",
          "label": "Aufgabe + Plan",
          "description": "Kombiniert Aufgabenbeschreibung und Implementierungsplan. Nützlich, um vollständigen Kontext bereitzustellen, wenn der Agent sowohl das Ziel als auch die Ausführungsstrategie benötigt."
        },
        {
          "id": "plan-only",
          "label": "Plan",
          "description": "Kopiert nur den Implementierungsplan-Inhalt. Am besten für Agenten, die bereits Aufgabenkontext haben und nur Ausführungsanweisungen benötigen."
        }
      ]
    },
    "customization": {
      "heading": "Kopier-Buttons anpassen",
      "description": "Kopier-Buttons können auf mehreren Ebenen angepasst werden: globale Standardwerte, Projekt-Ebenen-Überschreibungen und Pro-Aufgaben-Konfigurationen.",
      "globalDefaults": {
        "heading": "Globale Standardwerte",
        "description": "Serverseitige Konfiguration in /api/config/desktop-runtime-config definiert den Basis-Satz von Kopier-Buttons. Diese werden beim Start der Desktop-App geladen und für Offline-Nutzung zwischengespeichert."
      },
      "projectSettings": {
        "heading": "Projekt-Ebenen-Anpassung",
        "description": "Jedes Projekt kann die Standard-Buttons über das Einstellungs-Panel überschreiben. Projektspezifische Buttons werden in SQLite gespeichert und zur Laufzeit mit Server-Standardwerten zusammengeführt."
      },
      "taskSettings": {
        "heading": "Aufgaben-Ebenen-Konfiguration",
        "description": "Einzelne Aufgaben können ihre eigenen Kopier-Button-Konfigurationen haben. Dies ermöglicht verschiedene Button-Sätze für Implementierungspläne, Code-Reviews oder Dokumentationsaufgaben."
      },
      "editorDescription": "Der Kopier-Button-Editor in den Einstellungen ermöglicht Drag-and-Drop-Neuanordnung, Inline-Label-Bearbeitung und Vorlagen-Inhaltsänderung. Änderungen werden verzögert und automatisch persistiert."
    },
    "uiIntegration": {
      "heading": "UI-Integration und Sicherheit",
      "description": "Kopier-Buttons erscheinen in Plan-Viewern und Terminal-Headern. Jeder Button zeigt ein Vorschau-Popover mit dem aufgelösten Inhalt und Token-Schätzung vor der Ausführung.",
      "tokenEstimation": {
        "heading": "Token-Schätzung",
        "description": "Token-Schätzungen helfen Prüfern zu validieren, dass der Prompt in das Kontextfenster des Zielmodells passt, bevor die Übergabe erfolgt. Neben der Vorschau angezeigt."
      },
      "previewModal": {
        "heading": "Vollständiges Vorschau-Modal",
        "description": "Klicken auf das Vorschau-Symbol öffnet ein Modal mit der vollständig aufgelösten Vorlage, Syntaxhervorhebung und Diff-Ansicht, wenn sich die Vorlage seit der letzten Verwendung geändert hat."
      },
      "disabledState": {
        "heading": "Deaktivierter Zustand",
        "description": "Buttons werden deaktiviert, wenn erforderlicher Kontext fehlt (z.B. kein aktiver Plan, fehlende Sitzung). Tooltips erklären, welcher Kontext benötigt wird, um den Button zu aktivieren."
      }
    },
    "auditTrail": {
      "heading": "Job-Metadaten und Audit-Trail",
      "description": "Jede Kopier-Button-Aktion ist mit Job-Metadaten für vollständige Nachverfolgbarkeit verknüpft. Der Audit-Datensatz enthält den Quellplan, Ziel-Sitzung, aufgelösten Inhalts-Hash und Benutzerkontext.",
      "schemaHeading": "Audit-Schema",
      "schema": "-- copy_button_actions table schema\nCREATE TABLE copy_button_actions (\n    action_id    TEXT PRIMARY KEY,\n    plan_id      TEXT NOT NULL REFERENCES implementation_plans(id),\n    job_id       TEXT REFERENCES background_jobs(id),\n    session_id   TEXT REFERENCES terminal_sessions(session_id),\n    template_id  TEXT NOT NULL,\n    content_hash TEXT NOT NULL,  -- SHA-256 for integrity verification\n    created_at   TEXT NOT NULL\n);\n\n-- Query to trace plan handoffs\nSELECT * FROM copy_button_actions\nWHERE plan_id = ?\nORDER BY created_at DESC;",
      "fieldsHeading": "Audit-Datensatzfelder",
      "fields": [
        {
          "field": "action_id",
          "description": "Eindeutiger Bezeichner für diese Übergabe-Aktion"
        },
        {
          "field": "plan_id",
          "description": "Quell-Implementierungsplan-Referenz"
        },
        {
          "field": "job_id",
          "description": "Zugehöriger Hintergrundjob, falls zutreffend"
        },
        {
          "field": "session_id",
          "description": "Ziel-Terminal-Sitzung oder null für Zwischenablage"
        },
        {
          "field": "template_id",
          "description": "Verwendete Vorlagen-Konfiguration"
        },
        {
          "field": "content_hash",
          "description": "SHA-256 des aufgelösten Inhalts zur Integritätsprüfung"
        },
        {
          "field": "created_at",
          "description": "Zeitstempel der Aktion"
        }
      ],
      "retention": "Aufbewahrung: Audit-Datensätze werden standardmäßig 90 Tage aufbewahrt, konfigurierbar in den Projekteinstellungen."
    },
    "mobileIntegration": {
      "heading": "Mobile Integration",
      "description": "Kopier-Buttons funktionieren über Desktop- und Mobile-Clients mit konsistentem Verhalten. Der iOS-Client verwendet dieselbe Platzhalter-Auflösungslogik und kann Inhalte an verknüpfte Terminals senden.",
      "deviceLink": {
        "heading": "Geräteverbindungs-Unterstützung",
        "description": "Wenn ein mobiles Gerät mit einer Desktop-Sitzung verknüpft ist, können Kopier-Buttons das Desktop-Terminal direkt ansteuern. Der aufgelöste Inhalt wird über die Geräteverbindungs-WebSocket-Verbindung gesendet."
      },
      "mobileButtons": {
        "heading": "Mobile-spezifische Buttons",
        "description": "Mobile Clients unterstützen dieselbe Button-Anpassung wie Desktop. Button-Konfigurationen werden über den Server synchronisiert, um Konsistenz über Geräte hinweg zu gewährleisten."
      }
    },
    "cta": {
      "heading": "Übergabe zur Ausführung nachverfolgen",
      "description": "Terminal-Sitzungen zeigen, wo Kopier-Button-Ausgabe landet und wie sie protokolliert wird.",
      "terminalLink": "Terminal-Sitzungen",
      "plansLink": "Implementierungspläne"
    }
  },
  "textImprovement": {
    "meta": {
      "title": "Text improvement - PlanToCode",
      "description": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs."
    },
    "category": "Product Guide",
    "cta": {
      "description": "Download PlanToCode to combine voice capture, video context, and inline rewriting before you generate implementation plans.",
      "heading": "Try text improvement in the desktop app",
      "links": {
        "architecture": "Architecture overview",
        "buildYourOwn": "Build your own"
      }
    },
    "date": "2025-09-21",
    "description": "How PlanToCode rewrites highlighted text without changing formatting and links the result back to your workspace.",
    "intro": "Refine text with AI context. Select text in any editor, trigger a background job, and get improved content that keeps your formatting intact.",
    "metaDescription": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs.",
    "metaTitle": "Text improvement - PlanToCode",
    "ogDescription": "Understand the selection popover, job queue, model configuration, and integrations that power text improvement.",
    "ogTitle": "Text improvement - PlanToCode",
    "readTime": "7 min",
    "selectionPopover": {
      "component": "The popover itself is a minimal component rendered by {code}, which simply triggers the provider hook and shows a loading indicator while a rewrite is running. Because the provider registers global listeners, the popover appears in Monaco plan viewers, the plan terminal dictation field, and any task description inputs without extra wiring.",
      "heading": "Selection popover behaviour",
      "provider": "The {code} listens for selection events on standard inputs and Monaco editors. When you highlight non-empty text it positions a popover near the cursor, stores the selected range, and tracks whether the popover should be visible. Clicking the button kicks off the job and disables the control until the result returns. When the job completes the provider applies the improved text back into the same selection and flushes any pending saves to keep session state in sync."
    },
    "title": "Text Improvement",
    "triggerImprovement": {
      "action": "Pressing the popover button calls {code}. The action validates the selection, ensures a session identifier exists, and invokes the Rust command {code} via Tauri. The command builds a {code} containing the original text and queues a background job against the active session.",
      "backend": "On the backend, the {code} resolves the configured model for the {code} task, wraps the selection in XML tags, and runs the request through the {code} without streaming. When the model response returns it records token usage, cost, and the system prompt template before emitting the improved text back to the UI. The default configuration ships with Claude Sonnet 4.5 and Gemini 3 Pro as the approved models, capped at 4,096 tokens with a temperature of 0.7.",
      "heading": "What happens when you trigger an improvement",
      "metadata": "The background jobs sidebar records the original text in job metadata, so you can review what was sent alongside the rewritten copy. If the selection changes while a job is running, the provider skips replacing the text to avoid clobbering manual edits."
    },
    "videoCapture": {
      "dialog": "Screen recordings pass through the video analysis dialog, which combines your current task description with an optional prompt block wrapped in semantic XML tags before sending the request to the Gemini video analysis job. Any notes you dictate during the recording are available as text once analysis completes, so you can feed the resulting summary back through the improvement popover to tighten the instructions before planning.",
      "features": "Video jobs include frame-rate controls, audio capture toggles, and cost reporting. Results appear in the same background jobs sidebar as text improvements, keeping all prompt preparation artefacts in one place.",
      "heading": "Video capture and prompt scaffolding"
    },
    "voiceIntegration": {
      "heading": "Voice transcription integration",
      "hook": "Voice recordings use the {code} hook. It loads per-project transcription defaults, requests microphone access, and inserts transcripts at the cursor inside the task description or terminal dictation buffer. The inserted text can immediately be highlighted and passed through the same improvement popover, and the original transcription job identifier is stored with the improvement payload for auditing.",
      "preferences": "Language, model, and temperature preferences persist at the project level, so teams get consistent transcription quality before refining the copy. Silence detection warns about bad audio levels, and a ten-minute cap prevents oversized recordings from blocking improvement jobs with large payloads."
    },
    "visuals": {
      "popoverFlow": {
        "title": "Text improvement flow",
        "description": "Selection popover triggers improvement job and returns enhanced text.",
        "imageSrc": "/images/docs/text-improvement/flow.svg",
        "imageAlt": "Text improvement flow diagram"
      }
    },
    "processorDetails": {
      "heading": "Processor implementation details",
      "processor": "The {code} handles the text rewriting workflow on the Rust backend.",
      "stepsHeading": "Processing steps",
      "steps": [
        "Parse the incoming payload with original text and selection metadata",
        "Build the system prompt from the configured text_improvement template",
        "Submit the request to the LLM task runner without streaming",
        "Extract the improved text from the model response",
        "Record token usage, cost, and prompt template for billing",
        "Emit the result back to the UI via Tauri events"
      ]
    },
    "inlineRewriting": {
      "heading": "Inline rewriting behaviour",
      "description": "When the improved text returns, the provider automatically replaces the original selection. The rewriting preserves whitespace, line breaks, and any inline formatting present in the source. If the editor is Monaco-based, the change is applied as a single undo-able edit operation.",
      "contextsHeading": "Supported contexts",
      "contexts": [
        "Task description input fields",
        "Plan terminal dictation area",
        "Monaco plan viewers and editors",
        "Any standard HTML input or textarea"
      ]
    },
    "modelConfiguration": {
      "heading": "Model configuration",
      "description": "Text improvement uses the text_improvement task configuration from the desktop runtime config. You can override the default model and parameters in the settings panel.",
      "settingsHeading": "Configurable settings",
      "settings": [
        "Allowed models list (default: Claude Sonnet 4.5, Gemini 3 Pro)",
        "Maximum token limit (default: 4096)",
        "Temperature setting (default: 0.7)",
        "System prompt template override"
      ]
    },
    "keyFiles": {
      "heading": "Key implementation files",
      "items": [
        "desktop/src/contexts/TextImprovementProvider.tsx",
        "desktop/src/components/TextImprovementPopover.tsx",
        "desktop/src/actions/text-improvement/index.ts",
        "desktop/src-tauri/src/jobs/processors/text_improvement.rs",
        "server/src/config/task_model_config.rs"
      ]
    }
  },
  "voiceTranscription": {
    "meta": {
      "title": "Sprachtranskription - PlanToCode",
      "description": "Wie PlanToCode Audio aufnimmt, Echtzeit-Transkripte mit gpt-4o-transcribe streamt, Berechtigungen und Projekteinstellungen verwaltet."
    },
    "category": "Produktleitfaden",
    "date": "2025-09-22",
    "description": "Aufnahme-Lebenszyklus, Geräteverwaltung und Streaming-Verhalten für sprachgesteuerte Prompts.",
    "deviceManagement": {
      "description": "Die Funktion fordert Mikrofonberechtigung an, listet verfügbare Audioeingänge auf und ermöglicht Benutzern, Geräte während einer Sitzung zu wechseln. Audiopegel werden live überwacht, sodass die UI Stillewarnungen anzeigen kann, wenn das Mikrofon stummgeschaltet oder getrennt ist.",
      "heading": "Geräteverwaltung",
      "monitoring": "Echtzeit-Audiopegel-Überwachung zeigt visuelles Feedback während der Aufnahme an. Das System erkennt Stilleperioden und warnt Benutzer, wenn das Mikrofon stummgeschaltet oder getrennt erscheint, um fehlgeschlagene Aufnahmen zu verhindern, bevor Audio zur Transkription gesendet wird."
    },
    "intro": "Sprachtranskription ist überall verfügbar, wo die Desktop-App Diktiersteuerungen bereitstellt, einschließlich dem Plan-Terminal und Prompt-Editoren. Die Funktion nimmt Audio lokal auf, sendet Chunks an den Transkriptionsdienst und fügt erkannten Text in das aktive Eingabefeld ein, ohne manuelles Tippen zu blockieren.",
    "metaDescription": "Wie PlanToCode Audio aufnimmt, Echtzeit-Transkripte mit gpt-4o-transcribe streamt, Berechtigungen und Projekteinstellungen verwaltet.",
    "metaTitle": "Sprachtranskription - PlanToCode",
    "ogDescription": "Erfahren Sie, wie der Aufnahme-Hook Geräte, Berechtigungen und Text-Streaming verwaltet.",
    "ogTitle": "Sprachtranskription - PlanToCode",
    "projectSettings": {
      "description": "Wenn eine Aufnahmesitzung startet, sucht der Hook die Transkriptionskonfiguration des aktiven Projekts. Sprachcodes, bevorzugte Modelle und andere Einstellungen werden vor der Audioaufnahme abgerufen, sodass Aufnahmen den Projektpräferenzen folgen.",
      "heading": "Projektbezogene Einstellungen",
      "storage": "Projektspezifische Transkriptionspräferenzen werden in SQLite gespeichert und umfassen das bevorzugte Modell (gpt-4o-transcribe oder gpt-4o-mini-transcribe), Sprachcode und Temperatureinstellungen. Diese Präferenzen bleiben über Sitzungen hinweg bestehen und synchronisieren sich mit dem Server für Abrechnungszwecke."
    },
    "readTime": "5 Min.",
    "recordingWorkflow": {
      "description": "Der Aufnahme-Hook hält eine Zustandsmaschine mit Leerlauf-, Aufnahme-, Verarbeitungs- und Fehlerzuständen. Er verfolgt die Dauer, verwaltet Stilleerkennung und stellt sicher, dass Aufnahmen nach zehn Minuten automatisch stoppen. Chunks werden gepuffert und an die Transkriptionsaktion weitergeleitet, die erkannten Text zur Einfügung zurückgibt.",
      "heading": "Aufnahme-Workflow",
      "statesHeading": "Aufnahmezustände",
      "states": [
        "idle: Keine Aufnahme läuft, Mikrofonberechtigungen können gewährt sein oder nicht",
        "recording: Aktive Audioaufnahme über MediaRecorder, Dauer verfolgt, visuelles Feedback angezeigt",
        "processing: Audio-Chunk an Server gesendet, warte auf Transkriptionsantwort von gpt-4o-transcribe",
        "error: Aufnahme fehlgeschlagen aufgrund Berechtigungsverweigerung, Gerätetrennung oder Transkriptions-API-Fehler"
      ]
    },
    "routingBehavior": {
      "heading": "Multi-Ziel-Routing",
      "description": "Transkribierter Text kann basierend auf dem aktiven Kontext an mehrere Ziele geroutet werden. Der insertTranscript-Callback ermöglicht flexibles Routing ohne Kopplung. Das Routing-Ziel wird in Job-Metadaten für Audit-Trails gespeichert.",
      "destinations": [
        "Aufgabenbeschreibungs-Editoren: Cursor-Einfügung mit optionaler sofortiger text_improvement-Verfeinerung",
        "Terminal-Diktierpuffer: Befehlsausführung (z.B. 'run npm test' in PTY getippt)",
        "Meeting-Notizen-Modus: Akkumulierter Puffer automatisch in SQLite gespeichert mit task_refinement, das umsetzbare Aufgaben generiert",
        "Prompt-Editoren: Direkte Einfügung in jedes Texteingabefeld in der gesamten Anwendung"
      ]
    },
    "pipeline": {
      "heading": "Transkriptions-Pipeline",
      "hook": "Der {code} React-Hook verwaltet den vollständigen Aufnahme-Lebenszyklus. Er initialisiert {code} für Audioaufnahme im WebM-Format mit Opus-Codec, überwacht Audiopegel und behandelt Gerätewechsel.",
      "command": "Die Desktop-App ruft {code} auf, um Audiodaten an den Server-Endpunkt {code} zu senden. Der Befehl validiert Audiogröße (mindestens 1KB, maximal 25MB), Dauer, Temperatur (0,0-1,0) und Prompt-Länge (max. 1000 Zeichen).",
      "constraints": "Audiodateien müssen zwischen 1KB und 25MB groß sein. Unterstützte Formate: WAV, MP3, M4A, OGG, WebM, FLAC, AAC und MP4. Das Transkriptionsmodell muss explizit angegeben werden - unterstützte Modelle sind gpt-4o-transcribe und gpt-4o-mini-transcribe von OpenAI."
    },
    "serverProcessing": {
      "heading": "Serverseitige Verarbeitung",
      "endpoint": "Der Server stellt {code} bereit, der Multipart-Formulardaten akzeptiert. Er routet Anfragen basierend auf der Anbieter-Konfiguration des Modells entweder an OpenAI oder Google, validiert Benutzer-Credits und berechnet die Abrechnung basierend auf der Audiodauer.",
      "parametersHeading": "Anfrageparameter",
      "parameters": [
        "file: Audiodatei-Daten (erforderlich) - WAV, MP3, M4A, OGG, WebM, FLAC, AAC oder MP4",
        "model: Transkriptionsmodell-ID (erforderlich) - openai/gpt-4o-transcribe oder openai/gpt-4o-mini-transcribe",
        "duration_ms: Aufnahmedauer in Millisekunden (erforderlich für Abrechnungsberechnung)",
        "language: ISO 639-1 Sprachcode (optional) - verbessert Genauigkeit für bestimmte Sprachen",
        "prompt: Kontexthinweis für Transkription (optional, max. 1000 Zeichen) - hilft bei domänenspezifischem Vokabular",
        "temperature: Sampling-Temperatur 0,0-1,0 (optional, Standard 0,0) - niedrigere Werte produzieren deterministischere Ausgabe"
      ]
    },
    "dataFlow": {
      "heading": "Datenfluss",
      "description": "Audiodaten fließen vom Browser durch die Tauri-Befehlsschicht zum Server, der Anfragen an den entsprechenden Transkriptionsanbieter weiterleitet.",
      "stepsHeading": "Verarbeitungsschritte",
      "steps": [
        "Browser MediaRecorder erfasst Audio-Chunks im WebM/Opus-Format",
        "useVoiceTranscription-Hook puffert Chunks und überwacht Dauer",
        "Beim Stoppen wird Audio-Blob in Bytes konvertiert und über transcribe_audio_command gesendet",
        "Tauri-Befehl validiert Audiogröße, Dauer und Parameter",
        "Anfrage wird an Server /api/audio/transcriptions-Endpunkt mit Auth-Token gesendet",
        "Server validiert Benutzer-Credits und routet an OpenAI- oder Google-Anbieter",
        "Anbieter gibt transkribierten Text zurück, Server protokolliert Nutzung und zieht Credits ab",
        "Transkribierter Text wird an Desktop zurückgegeben und über Callback eingefügt"
      ]
    },
    "keyFiles": {
      "heading": "Wichtige Implementierungsdateien",
      "items": [
        "desktop/src/hooks/useVoiceTranscription.ts",
        "desktop/src-tauri/src/commands/audio_commands.rs",
        "server/src/handlers/proxy/specialized/transcription.rs",
        "server/src/clients/openai/transcription.rs",
        "server/src/clients/google/transcription.rs"
      ]
    },
    "examples": {
      "heading": "Verwendungsbeispiele",
      "description": "Gängige Sprachtranskriptions-Workflows demonstrieren die Flexibilität des Systems:",
      "items": [
        "Sprint-Planung: Meeting-Aufnahme mit Transkription, die an task_refinement zur Generierung von Aufgabenbeschreibungen geleitet wird",
        "Terminal-Befehle: Diktat transkribiert und direkt in PTY zur Ausführung getippt",
        "Fehlerberichte: Verbale Beschreibung erfasst, mit text_improvement verfeinert, dann von task_refinement verarbeitet",
        "Architekturdiskussionen: Videoaufnahme mit extrahierter Audiospur zur Transkription, kombiniert mit Vision-Analyse"
      ]
    },
    "cta": {
      "heading": "Weiter erkunden",
      "description": "Erfahren Sie, wie transkribierter Text verfeinert werden kann und wie Meeting-Aufnahmen zu umsetzbaren Aufgaben verarbeitet werden.",
      "links": {
        "textImprovement": "Textverbesserung",
        "meetingIngestion": "Meeting-Erfassung"
      }
    },
    "title": "Sprachtranskription",
    "visuals": {
      "recordingFlow": {
        "title": "Sprachtranskriptions-Pipeline",
        "description": "Audioaufnahme, GPT-4o-Transkriptionsverarbeitung und Text-Routing-Ablauf.",
        "imageSrc": "/images/docs/voice-transcription/pipeline.svg",
        "imageAlt": "Sprachtranskriptions-Pipeline-Diagramm",
        "caption": "Audio fließt von der Browser-Aufnahme durch Tauri-Befehle zur serverseitigen GPT-4o-Transkription."
      }
    }
  },
  "overview": {
    "meta": {
      "title": "Systemübersicht - PlanToCode",
      "description": "Starten Sie hier: was PlanToCode tut, wie die Kernschleife funktioniert und wo sich jede Komponente im Repository befindet."
    },
    "category": "Übersicht",
    "date": "2025-09-25",
    "readTime": "15 Min.",
    "title": "Systemübersicht",
    "description": "Eine prägnante Karte des Systems, der Kernschleife und der erforderlichen Abhängigkeiten.",
    "intro": "PlanToCode ist ein Desktop-Arbeitsbereich, der Code-Änderungen vor der Ausführung plant und validiert. Er koordiniert eine lokale Rust-Job-Engine, eine React-UI und einen Server-Proxy für LLM-Aufrufe. Das System folgt einer Offline-First-Architektur, bei der die Desktop-App unabhängig mit SQLite für lokalen Zustand arbeitet, während der Server Authentifizierung, LLM-Anbieter-Routing und Abrechnung verwaltet. Ohne externe LLM-Anbieter, die mit Ihren API-Schlüsseln konfiguriert sind, werden die Planungs- und Analyse-Pipelines nicht ausgeführt.",
    "visuals": {
      "systemMap": {
        "title": "Systemkarte",
        "description": "Karte der Desktop-App, des Rust-Kerns, der lokalen SQLite-Speicherung und des Server-Proxys.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode-Systemkarten-Diagramm",
        "caption": "Vierschichtige Architektur mit Daten, die nach unten fließen, und Ereignissen, die nach oben streamen."
      }
    },
    "systemLayers": {
      "heading": "Systemschichten",
      "description": "Das System ist in vier verschiedene Schichten organisiert, die über wohldefinierte Schnittstellen kommunizieren:",
      "items": [
        "Präsentationsschicht: React-UI mit Monaco-Editoren, Terminal-Panels und Workflow-Steuerungen (desktop/src/)",
        "Befehlsschicht: Tauri-Befehle, die React und Rust verbinden, IPC und Zustandsverwaltung behandeln (desktop/src-tauri/src/commands/)",
        "Verarbeitungsschicht: Job-Prozessoren, Workflow-Orchestrator und Geschäftslogik in Rust (desktop/src-tauri/src/jobs/)",
        "Persistenzschicht: SQLite-Repositories für lokalen Zustand und Server PostgreSQL für Authentifizierung/Abrechnung (desktop/src-tauri/src/db_utils/)"
      ]
    },
    "coreLoop": {
      "heading": "Kernschleife in der Praxis",
      "description": "Jede Aufgabe durchläuft einen wohldefinierten Lebenszyklus von der Erfassung bis zur Ausführung:",
      "steps": [
        "Die Aufgabe aus Text, Sprachtranskription (über useVoiceTranscription-Hook) oder Video-Aufnahme-Analyse erfassen.",
        "Die Aufgabenbeschreibung und Ziele mit text_improvement-Jobs über TextImprovementProcessor verfeinern.",
        "Den Dateisuche-Workflow ausführen: RootFolderSelectionProcessor wählt Verzeichnisse, RegexFileFilterProcessor wendet Muster an, FileRelevanceAssessmentProcessor bewertet Inhalte, ExtendedPathFinderProcessor erweitert den Kontext.",
        "Implementierungspläne über ImplementationPlanProcessor generieren, der XML-formatierte Pläne an den Monaco-Viewer streamt.",
        "Optional mehrere Plan-Entwürfe mit ImplementationPlanMergeProcessor unter Verwendung von XML-getaggten Quellplänen zusammenführen.",
        "Den genehmigten Plan über PTY-Terminal-Sitzungen oder Kopier-Button-Vorlagen für externe Agenten ausführen oder exportieren.",
        "Jeden Job, jedes Artefakt und jedes Terminal-Protokoll in SQLite (background_jobs, terminal_sessions-Tabellen) für Auditierbarkeit persistieren."
      ]
    },
    "components": {
      "heading": "Hauptkomponenten",
      "description": "Jede Komponente hat eine spezifische Verantwortung und kommuniziert über typisierte Schnittstellen:",
      "items": [
        "Desktop-UI (React) in desktop/src/ mit Monaco-Plan-Ansichten, Terminal-Panels und Providern (SessionProvider, TextImprovementProvider).",
        "Rust-Kern (Tauri v2) in desktop/src-tauri/ für Befehle, Jobs und Persistenz mit fähigkeitsbasierten Berechtigungen.",
        "Lokales SQLite-Schema in desktop/src-tauri/migrations/consolidated_schema.sql mit WAL-Modus für gleichzeitigen Zugriff.",
        "Server-Proxy (Actix-Web) in server/src/ für Authentifizierung, Anbieter-Routing, Streaming-Antworten und Abrechnung über Stripe.",
        "Mobiler iOS-Client in mobile/ios/Core/ mit SwiftUI-Oberfläche, Auth0 PKCE und WebSocket-Geräteverbindung.",
        "Infrastruktur-Automatisierung in infrastructure/ansible/ für Hetzner (EU) und InterServer (US) dedizierte Server."
      ]
    },
    "dependencies": {
      "heading": "Erforderliche Abhängigkeiten",
      "description": "Das System erfordert diese externen Dienste und Ressourcen:",
      "items": [
        "Externe LLM-Anbieter (OpenAI, Anthropic, Google, X.AI, OpenRouter) für Plan-Generierung, Transkription und Analyse.",
        "Auth0-basierte Authentifizierung mit PKCE-Ablauf für Desktop- und Mobile-Sitzungen.",
        "PostgreSQL 17 und Redis 7+ für serverseitige Benutzerkonten, Abrechnungsstatus und Job-Warteschlangen (selbst gehostete Deployments).",
        "Lokaler Dateisystemzugriff über git ls-files oder Verzeichnisdurchquerung für Dateisuche-Workflows.",
        "Whisper-kompatibler Transkriptions-Endpunkt für Spracheingabe-Verarbeitung."
      ]
    },
    "codeMap": {
      "heading": "Wo sich das Verhalten im Repository befindet",
      "description": "Schnellreferenz zu wichtigen Verzeichnissen und Dateien:",
      "items": [
        "Tauri-Befehle: desktop/src-tauri/src/commands/ (35+ Befehlsmodule: job_commands.rs, workflow_commands.rs, terminal_commands.rs, session_commands.rs, auth0_commands.rs)",
        "Workflow-Orchestrierung: desktop/src-tauri/src/jobs/workflow_orchestrator/ (definition_loader.rs, stage_scheduler.rs, event_emitter.rs, payload_builder.rs)",
        "Job-Prozessoren: desktop/src-tauri/src/jobs/processors/ (implementation_plan_processor.rs, text_improvement_processor.rs, root_folder_selection_processor.rs)",
        "SQLite-Repositories: desktop/src-tauri/src/db_utils/ (background_job_repository/, session_repository.rs, terminal_repository.rs)",
        "Server-Routen: server/src/routes.rs (configure_routes, configure_public_auth_routes, configure_webhook_routes)",
        "LLM-Proxy-Handler: server/src/handlers/proxy_handlers.rs und server/src/handlers/proxy/ (router.rs, providers/)",
        "Anbieter-Transformatoren: server/src/handlers/provider_transformers/ (openai.rs, google.rs, anthropic.rs, xai.rs)",
        "iOS-Workflows: mobile/ios/Core/Sources/Workflows/WorkflowManager.swift mit MobileSessionManager und APIClient",
        "Infrastruktur-Playbooks: infrastructure/ansible/site-base.yml (Härtung, PostgreSQL, Redis) und site-app.yml (Deployment)"
      ]
    },
    "keyAbstractions": {
      "heading": "Schlüsselabstraktionen",
      "description": "Das Verständnis dieser Kernkonzepte hilft bei der Navigation der Codebasis:",
      "items": [
        "Session: Projektkontext gespeichert in sessions-Tabelle mit task_description, included_files und Modellpräferenzen. Identifiziert durch UUID.",
        "Background Job: LLM-gestützte Operation gespeichert in background_jobs-Tabelle mit task_type, prompt, response, Token-Verfolgung und Kosten.",
        "Workflow: Mehrstufiger orchestrierter Prozess (z.B. file_finder_workflow), koordiniert vom WorkflowOrchestrator mit IntermediateData, das zwischen Stufen übergeben wird.",
        "Terminal Session: PTY-Prozess gespeichert in terminal_sessions mit output_log, status und optionaler job_id-Verknüpfung für Audit.",
        "Provider: LLM-Dienst-Abstraktion in server/src/handlers/proxy/providers/ mit Anfrage-Transformation und Antwort-Normalisierung."
      ]
    },
    "dataFlowSummary": {
      "heading": "Datenfluss-Zusammenfassung",
      "description": "Wie Daten durch das System für eine typische Planungsaufgabe fließen:",
      "items": [
        "Benutzereingabe erfolgt durch React-Komponenten und fließt zu Tauri-Befehlen über @tauri-apps/api/core invoke().",
        "Befehle erstellen background_jobs-Datensätze und dispatchen an Job-Prozessoren über die Job-Warteschlange.",
        "Prozessoren erstellen Prompts, senden Anfragen durch den Server-LLM-Proxy und streamen Antworten über Tauri-Ereignisse.",
        "Antworten werden in SQLite gespeichert und an React-Provider emittiert, die den UI-Zustand aktualisieren.",
        "Terminal-Ausführung streamt PTY-Ausgabe an die UI und persistiert Protokolle für Sitzungs-Wiederherstellung."
      ]
    }
  },
  "runtimeWalkthrough": {
    "meta": {
      "title": "Laufzeit-Walkthrough - PlanToCode",
      "description": "End-to-End-Zeitlinie einer Aufgabe von der Eingabe bis zur Plan-Ausgabe, mit Job-Typen und Artefakt-Flüssen."
    },
    "category": "Architektur",
    "date": "2025-09-25",
    "readTime": "12 Min.",
    "title": "Laufzeit-Walkthrough",
    "description": "End-to-End-Laufzeit-Zeitlinie von der Aufgabeneingabe bis zur Plan-Ausgabe.",
    "intro": "Dieser Walkthrough verfolgt eine einzelne Aufgabe von der ersten Erfassung über die Dateisuche, Plan-Generierung bis zur Terminal-Ausführung. Jede Phase entspricht spezifischen Job-Typen und erzeugt Artefakte, die in SQLite gespeichert werden.",
    "visuals": {
      "timeline": {
        "title": "Laufzeit-Zeitlinie",
        "description": "Visuelle Zeitlinie mit Aufgabeneingabe, Workflow-Phasen und Plan-Ausgabe.",
        "imageSrc": "/images/docs/runtime-walkthrough/timeline.svg",
        "imageAlt": "Laufzeit-Zeitlinien-Diagramm",
        "caption": "Aufgabenausführung fließt durch sechs Phasen, wobei alle Artefakte in SQLite persistiert werden."
      },
      "walkthroughVideo": {
        "title": "Laufzeit-Walkthrough-Video",
        "description": "Video-Demonstration einer vollständigen Aufgabenausführung von der Eingabe bis zur Plan-Ausgabe.",
        "videoSrc": "",
        "posterSrc": "",
        "caption": "Video-Walkthrough-Platzhalter - eine Demonstration des vollständigen Planungs-Workflows aufnehmen."
      }
    },
    "timeline": {
      "heading": "Übergeordnete Laufzeitsequenz",
      "description": "Eine vollständige Aufgabenausführung folgt dieser Operationssequenz:",
      "steps": [
        "Benutzer gibt eine Aufgabenbeschreibung ein oder diktiert sie in der Desktop-UI über die TaskDescriptionEditor-Komponente.",
        "Optional: text_improvement-Job verfeinert die Roheingabe durch TextImprovementProcessor.",
        "Benutzer löst Dateisuche-Workflow über das Implementierungspläne-Panel start_file_finder_workflow-Befehl aus.",
        "WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/ erstellt einen Workflow-Datensatz und plant Stufe 1.",
        "Stufe 1 (root_folder_selection): RootFolderSelectionProcessor sendet Verzeichnisbaum an LLM, speichert ausgewählte Stammverzeichnisse in IntermediateData.selectedRoots.",
        "Stufe 2 (regex_file_filter): RegexFileFilterProcessor generiert Muster, führt git ls-files aus, speichert Treffer in IntermediateData.locallyFilteredFiles.",
        "Stufe 3 (file_relevance_assessment): FileRelevanceAssessmentProcessor chunked Dateiinhalte, bewertet Relevanz, speichert in IntermediateData.aiFilteredFiles.",
        "Stufe 4 (extended_path_finder): ExtendedPathFinderProcessor erweitert Kontext mit Importen und Abhängigkeiten, speichert in IntermediateData.verifiedPaths.",
        "UI empfängt workflow-completed-Ereignis über event_emitter.rs, aktualisiert Dateiauswahl-Anzeige.",
        "Benutzer löst Plan-Generierung mit ausgewählten Dateien über generate_implementation_plan-Befehl aus.",
        "ImplementationPlanProcessor in desktop/src-tauri/src/jobs/processors/implementation_plan_processor.rs streamt XML-Plan-Inhalt an Monaco-Viewer über job:stream-progress-Ereignisse.",
        "Benutzer überprüft Plan in VirtualizedCodeViewer-Komponente, kann direkt bearbeiten oder Merge anfordern.",
        "Genehmigter Plan wird über Kopier-Button-Vorlagen an Terminal kopiert oder für externe Agenten exportiert.",
        "Terminal-Sitzung in terminal_commands.rs erfasst PTY-Ausgabe, erkennt Agenten-Aufmerksamkeitszustände.",
        "Alle Artefakte werden in SQLite background_jobs und terminal_sessions-Tabellen für Audit und Sitzungs-Wiederherstellung persistiert."
      ]
    },
    "jobTypes": {
      "heading": "Job-Typen in der Laufzeit",
      "description": "Jeder task_type entspricht einem spezifischen Prozessor und erzeugt unterschiedliche Artefakte:",
      "items": [
        "text_improvement: TextImprovementProcessor umhüllt Text mit XML, sendet an LLM, gibt verfeinerten Text zurück. Gespeichert in background_jobs.response.",
        "root_folder_selection: RootFolderSelectionProcessor empfängt Verzeichnisbaum, gibt JSON-Array ausgewählter Verzeichnisse zurück.",
        "regex_file_filter: RegexFileFilterProcessor generiert Muster aus Aufgabenbeschreibung, wendet auf git-Dateiliste an.",
        "file_relevance_assessment: FileRelevanceAssessmentProcessor lädt Dateiinhalte, chunked nach Token-Limit, bewertet Relevanz.",
        "extended_path_finder: ExtendedPathFinderProcessor analysiert Importe/Abhängigkeiten, erweitert Kontext mit verwandten Dateien.",
        "implementation_plan: ImplementationPlanProcessor streamt XML-formatierte Pläne mit plan_step-Elementen.",
        "implementation_plan_merge: ImplementationPlanMergeProcessor kombiniert Pläne mit source_plans XML-Tags und Benutzeranweisungen.",
        "video_analysis: Verarbeitet Bildschirmaufnahmen über /api/llm/video/analyze-Endpunkt mit Frame-Sampling.",
        "web_search_prompts_generation: Generiert research_task XML-Blöcke für Deep Research-Workflow.",
        "web_search_execution: Führt Recherche-Prompts parallel aus, aggregiert Erkenntnisse."
      ]
    },
    "inputCapture": {
      "heading": "Aufgabeneingabe-Erfassung",
      "description": "Aufgaben gelangen durch mehrere Eingabeoberflächen ins System:",
      "text": "Aufgabenbeschreibungen werden in TaskDescriptionEditor getippt oder eingefügt, der in sessions.task_description persistiert und Historie-Einträge in task_description_history-Tabelle mit device_id für Multi-Geräte-Synchronisation erstellt.",
      "voice": "Spracheingabe verwendet useVoiceTranscription-Hook, der über MediaRecorder API aufnimmt, an /api/audio/transcriptions sendet und an Cursorposition einfügt.",
      "video": "Video-Analyse verwendet VideoAnalysisDialog, um Bildschirmaufnahmen zu erfassen, zu /api/llm/video/analyze hochzuladen und UI-Zustandsbeobachtungen zu extrahieren."
    },
    "workflowExecution": {
      "heading": "Workflow-Ausführungsdetails",
      "description": "Der WorkflowOrchestrator koordiniert mehrstufige Workflows:",
      "scheduling": "workflow_lifecycle_manager.rs erstellt Workflow-Datensätze und stage_scheduler.rs dispatcht Stufen sequenziell basierend auf Workflow-JSON-Definitionen.",
      "data": "IntermediateData-Strukturen in workflow_types.rs übergeben Ausgaben zwischen Stufen: selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths.",
      "events": "event_emitter.rs veröffentlicht workflow-status und workflow-stage Tauri-Ereignisse, die vom WorkflowTracker in der React-UI konsumiert werden."
    },
    "persistence": {
      "heading": "Zustandspersistenz",
      "description": "Alle Artefakte werden für Audit und Wiederherstellung persistiert:",
      "jobs": "background_job_repository/ speichert Job-Datensätze mit session_id, task_type, status, prompt, response, tokens_sent/received, actual_cost.",
      "sessions": "session_repository.rs verwaltet sessions-Tabelle mit task_description, included_files, model_used, Historie-Versionen.",
      "terminals": "terminal_repository.rs persistiert terminal_sessions mit output_log, status, exit_code, working_directory für Sitzungs-Wiederherstellung.",
      "rehydration": "Beim App-Neustart rehydriert der Rust-Kern den Sitzungsstatus aus SQLite, markiert veraltete laufende Jobs als fehlgeschlagen und stellt Terminal-Ausgabeprotokolle wieder her."
    },
    "inputs": {
      "heading": "Aufgabeneingabe-Erfassung",
      "capture": "Aufgaben gelangen durch mehrere Eingabeoberflächen ins System: getippter Text in TaskDescriptionEditor, Sprach-Diktat über useVoiceTranscription-Hook oder Video-Analyse durch VideoAnalysisDialog.",
      "artifacts": "Jeder Eingabetyp erzeugt Artefakte, die in SQLite gespeichert werden - task_description in sessions-Tabelle, Transkriptionsergebnisse in background_jobs und Video-Frames in zugehörigen Job-Metadaten."
    },
    "refinement": {
      "heading": "Eingabeverfeinerung",
      "jobs": "Der text_improvement-Job-Typ verfeinert Roheingabe durch TextImprovementProcessor, umhüllt Text mit XML und sendet an LLM für Grammatik-, Klarheits- und Strukturverbesserungen.",
      "storage": "Verfeinerter Text wird in background_jobs.response gespeichert und kann sessions.task_description über den React-Provider aktualisieren."
    },
    "discovery": {
      "heading": "Dateisuche-Workflow",
      "workflow": "FileFinderWorkflow führt vier sequenzielle Stufen aus: root_folder_selection grenzt Verzeichnisse ein, regex_file_filter wendet Muster an, file_relevance_assessment bewertet Inhalt und extended_path_finder erweitert mit Abhängigkeiten.",
      "outputs": "Jede Stufe speichert Ergebnisse in IntermediateData-Strukturen, die zwischen Prozessoren übergeben werden, wobei finale Dateiauswahlen in sessions.included_files persistiert werden."
    },
    "planGeneration": {
      "heading": "Plan-Generierung",
      "jobs": "Der implementation_plan-Job-Typ verwendet ImplementationPlanProcessor, um XML-formatierte Pläne mit plan_step-Elementen zu generieren, die Dateipfade, Operationstypen und Code-Änderungen enthalten.",
      "streaming": "Plan-Inhalt wird über job:stream-progress Tauri-Ereignisse an die UI gestreamt und in der VirtualizedCodeViewer Monaco-Komponente mit Syntaxhervorhebung angezeigt."
    },
    "merge": {
      "heading": "Plan-Zusammenführung",
      "instructions": "Der implementation_plan_merge-Job kombiniert mehrere Pläne mit source_plans XML-Tags und vom Benutzer bereitgestellten Merge-Anweisungen, um Konflikte zu lösen und Änderungen zu konsolidieren.",
      "outputs": "Zusammengeführte Pläne bewahren die Nachverfolgbarkeit zu Quellplänen und enthalten merged_from-Metadaten im finalen background_jobs-Datensatz."
    },
    "review": {
      "heading": "Plan-Überprüfung",
      "editor": "Pläne werden im Monaco-basierten VirtualizedCodeViewer zur Überprüfung geöffnet. Benutzer können Plan-Text direkt bearbeiten, Änderungen anfordern oder zur Ausführung genehmigen.",
      "audit": "Alle Überprüfungsaktionen werden mit Zeitstempeln und Benutzerkontext protokolliert und bieten einen Audit-Trail der Plan-Evolution."
    },
    "execution": {
      "heading": "Ausführungsübergabe",
      "terminal": "Genehmigte Pläne werden über Kopier-Button-Vorlagen an das integrierte Terminal kopiert oder für externe Agenten wie Claude Code, Cursor oder Codex exportiert.",
      "logging": "Terminal-Sitzungen in terminal_commands.rs erfassen PTY-Ausgabe, erkennen Agenten-Aufmerksamkeitszustände und protokollieren alle Ausführungsaktivitäten in der terminal_sessions-Tabelle."
    },
    "state": {
      "heading": "Zustandspersistenz",
      "jobs": "Alle Job-Artefakte werden in der background_jobs-Tabelle mit session_id, task_type, status, prompt, response, Token-Anzahlen und Kostenverfolgung persistiert.",
      "rehydration": "Beim App-Neustart rehydriert der Rust-Kern den Sitzungsstatus aus SQLite, markiert veraltete laufende Jobs als fehlgeschlagen und stellt Terminal-Ausgabeprotokolle wieder her."
    },
    "jobMap": {
      "heading": "Job-Typ-Zuordnung",
      "items": [
        "text_improvement → TextImprovementProcessor → verfeinerte Aufgabenbeschreibungen",
        "root_folder_selection → RootFolderSelectionProcessor → ausgewählte Verzeichnisse",
        "regex_file_filter → RegexFileFilterProcessor → musterübereinstimmende Dateien",
        "file_relevance_assessment → FileRelevanceAssessmentProcessor → bewertete Dateien",
        "extended_path_finder → ExtendedPathFinderProcessor → erweiterter Kontext",
        "implementation_plan → ImplementationPlanProcessor → XML-Plan-Dokumente",
        "implementation_plan_merge → ImplementationPlanMergeProcessor → zusammengeführte Pläne"
      ]
    },
    "cta": {
      "heading": "Architektur erkunden",
      "description": "Verstehen Sie im Detail, wie die Komponenten zusammenpassen.",
      "links": {
        "architecture": "Architekturübersicht",
        "jobs": "Hintergrundjobs",
        "desktop": "Desktop-App-Interna",
        "dataModel": "Datenmodell",
        "plans": "Implementierungspläne"
      }
    }
  },
  "desktopApp": {
    "meta": {
      "title": "Desktop-App-Interna - PlanToCode",
      "description": "Wie die Tauri-Desktop-Shell, Rust-Befehlsschicht, SQLite-Persistenz und PTY-Sitzungen zusammenarbeiten."
    },
    "category": "Desktop",
    "date": "2025-09-25",
    "readTime": "14 Min.",
    "title": "Desktop-App-Interna",
    "description": "Tauri v2 Shell, Rust-Befehlsschicht, PTY-Sitzungen und UI-Zustandsverwaltung.",
    "intro": "Die Desktop-App ist eine Tauri v2 Shell (Version 2.9.1), die eine React-UI ausführt. Rust-Dienste stellen Befehle für Workflows, Terminal-Sitzungen und Konfiguration bereit, während der Zustand lokal in SQLite persistiert wird. Das fähigkeitsbasierte Berechtigungsmodell bietet feinkörnige Sicherheitskontrollen für Dateisystemzugriff, HTTP-Anfragen, Shell-Ausführung und Systembenachrichtigungen.",
    "visuals": {
      "shell": {
        "title": "Desktop-Shell-Übersicht",
        "description": "Screenshot mit Plan-Editor, Terminal-Tabs und Job-Status-Seitenleiste.",
        "imageSrc": "/assets/images/demo-implementation-plans.jpg",
        "imageAlt": "PlanToCode Desktop-Shell",
        "caption": "Die Desktop-App mit dem Implementierungspläne-Panel und der Seitenleiste."
      }
    },
    "projectLayout": {
      "heading": "Projektstruktur",
      "description": "Die Desktop-Anwendung folgt der Standard-Tauri-v2-Struktur:",
      "items": [
        "desktop/src/: React-UI-Komponenten, Hooks, Provider und Desktop-spezifische Adapter.",
        "desktop/src-tauri/: Rust-Kern einschließlich Befehle, Jobs, Repositories und Dienste.",
        "desktop/src-tauri/src/lib.rs: Anwendungs-Einstiegspunkt mit Plugin-Registrierung und AppState-Verwaltung.",
        "desktop/src-tauri/src/commands/: 35+ Tauri-Befehlshandler-Module, nach Domäne organisiert.",
        "desktop/src-tauri/src/jobs/: Hintergrundjob-Prozessoren, Workflow-Orchestrierung und Warteschlangenverwaltung.",
        "desktop/src-tauri/capabilities/: JSON-Fähigkeitsdefinitionen für Sicherheitsberechtigungen (default.json, desktop-default.json, plantocode-api.json).",
        "desktop/src-tauri/migrations/: SQLite-Schema-Migrationen in consolidated_schema.sql."
      ]
    },
    "ui": {
      "heading": "React-UI und Oberfläche",
      "description": "Die React-UI rendert den Aufgabenbeschreibungs-Editor, Plan-Viewer und Terminal-Panels:",
      "components": [
        "TaskDescriptionEditor: Mehrzeilige Eingabe mit Sprachtranskriptions-Integration und Textverbesserungs-Popover.",
        "VirtualizedCodeViewer: Monaco-basierte Plan-Anzeige mit Syntaxhervorhebung und Kopieraktionen.",
        "TerminalSurface: PTY-Ausgabepuffer mit Verbindungsstatus, Agenten-Aufmerksamkeitsindikatoren und Spracheingabe.",
        "SessionProvider: Globale Zustandsverwaltung für aktive Sitzung, Dateiauswahlen und Modellpräferenzen.",
        "TextImprovementProvider: Auswahl-Listener und Popover-Positionierung für Inline-Umschreibungen.",
        "WorkflowTracker: Echtzeit-Fortschrittsanzeige für mehrstufige Workflows."
      ]
    },
    "commands": {
      "heading": "Tauri-Befehle",
      "description": "Befehle in desktop/src-tauri/src/commands/ stellen Rust-Funktionalität der React-UI bereit. Wichtige Module umfassen:",
      "modules": [
        "job_commands.rs: create_job, get_job, cancel_job, get_jobs_for_session, clear_job_history.",
        "workflow_commands.rs: start_file_finder_workflow, get_workflow_status, retry_workflow, pause_workflow, resume_workflow.",
        "terminal_commands.rs: create_terminal_session, send_terminal_input, resize_terminal, get_terminal_output, check_cli_availability.",
        "session_commands.rs: create_session, get_session, update_session, sync_task_description_history, sync_file_selection_history.",
        "auth0_commands.rs: initiate_login, complete_login, refresh_token, logout, get_user_info.",
        "implementation_plan_commands.rs: generate_implementation_plan, merge_implementation_plans, estimate_tokens.",
        "config_commands.rs: get_runtime_config, get_model_config, get_system_prompts, refresh_config_cache.",
        "settings_commands.rs: get_setting, set_setting, get_project_system_prompt, set_project_system_prompt."
      ]
    },
    "appState": {
      "heading": "AppState-Verwaltung",
      "description": "Der Rust-Kern verwaltet den Anwendungszustand über Tauris Zustandssystem:",
      "structure": "AppState-Struct in lib.rs enthält: config_load_error (Option<String>), HTTP-Client (reqwest::Client), RuntimeConfig (Server-URL, Onboarding-Status) hinter Mutex und Auth0State für Authentifizierung.",
      "config": "RuntimeConfig enthält server_url, onboarding_complete-Flag und wird über set_runtime_config-Befehl aktualisiert. ConfigCache speichert Laufzeit-KI-Konfiguration mit projektbezogenen Überschreibungen.",
      "tokens": "TokenManager verwendet den OS-Schlüsselbund (über keyring-Crate), um access_token, refresh_token und jwt sicher mit automatischer Erneuerung vor Ablauf zu speichern."
    },
    "jobs": {
      "heading": "Job-Prozessoren und Workflows",
      "description": "Job-Verarbeitungsarchitektur in desktop/src-tauri/src/jobs/:",
      "queue": "queue.rs verwaltet die Job-Warteschlange mit In-Memory-ausstehenden Jobs und SQLite-Persistenz. Jobs durchlaufen Status: idle, created, queued, acknowledged_by_worker, preparing, preparing_input, running, generating_stream, processing_stream, completed, failed, canceled.",
      "processors": "processors/-Verzeichnis enthält aufgabenspezifische Prozessoren: ImplementationPlanProcessor (Streaming-Pläne), TextImprovementProcessor (Inline-Umschreibungen), RootFolderSelectionProcessor, RegexFileFilterProcessor, FileRelevanceAssessmentProcessor, ExtendedPathFinderProcessor.",
      "orchestrator": "workflow_orchestrator/ koordiniert mehrstufige Workflows: definition_loader.rs lädt JSON-Workflow-Definitionen, stage_scheduler.rs dispatcht Stufen, payload_builder.rs konstruiert Eingaben, event_emitter.rs veröffentlicht Fortschrittsereignisse.",
      "streaming": "processors/generic_llm_stream_processor.rs verarbeitet Streaming-LLM-Antworten, emittiert job:stream-progress-Ereignisse und akkumuliert Inhalt in background_jobs.response."
    },
    "persistence": {
      "heading": "Lokale Persistenz",
      "description": "SQLite-Speicherung in desktop/src-tauri/migrations/consolidated_schema.sql:",
      "tables": [
        "sessions: id (UUID), name, project_directory, project_hash, task_description, included_files, force_excluded_files, model_used, Historie-Versionen.",
        "background_jobs: id (UUID), session_id (FK), task_type, status, prompt, response, tokens_sent/received, cache_read/write_tokens, actual_cost, metadata (JSON), server_request_id.",
        "terminal_sessions: id, job_id (nullable FK), session_id, status, process_pid, output_log, working_directory, environment_vars, last_output_at.",
        "task_description_history: session_id (FK), description, device_id, sequence_number, version für Multi-Geräte-Sync.",
        "file_selection_history: session_id (FK), included_files, force_excluded_files, device_id, sequence_number.",
        "project_system_prompts: project_hash, task_type, system_prompt für projektbezogene Prompt-Überschreibungen.",
        "key_value_store: key, value (JSON), updated_at für App-Einstellungen.",
        "error_logs: timestamp, level, error_type, message, context, stack, metadata für clientseitige Fehlerverfolgung."
      ],
      "repositories": "Repositories in db_utils/ bieten typisierten Zugriff: background_job_repository/ (modular mit base.rs, worker.rs, metadata.rs, cleanup.rs), session_repository.rs, terminal_repository.rs, settings_repository.rs, error_log_repository.rs."
    },
    "terminal": {
      "heading": "Terminal-Sitzungen",
      "description": "PTY-Terminal-Implementierung:",
      "commands": "terminal_commands.rs verwaltet den Sitzungs-Lebenszyklus: create_terminal_session spawnt PTY über portable-pty-Crate, send_terminal_input leitet Tastatureingaben weiter, resize_terminal passt Dimensionen an, check_cli_availability verifiziert Tool-Präsenz (claude, cursor, codex, gemini).",
      "persistence": "terminal_repository.rs persistiert Sitzungen mit output_log (akkumulierte Terminal-Ausgabe), status (idle/running/completed/failed/agent_requires_attention), exit_code, working_directory. Sitzungen können nach App-Neustart wiederhergestellt werden.",
      "attention": "Agenten-Aufmerksamkeitserkennung überwacht last_output_at-Zeitstempel. Stufe 1 (30s inaktiv): gelber Indikator. Stufe 2 (2min inaktiv): roter Indikator mit Desktop-Benachrichtigung."
    },
    "inputStability": {
      "heading": "Aufgabenbeschreibungs-Stabilität",
      "description": "Der Aufgabenbeschreibungs-Editor enthält Schutzmaßnahmen, um Cursorsprünge zu verhindern:",
      "items": [
        "Remote-Updates werden eingereiht, während der Benutzer tippt, und bei Leerlauf oder Blur geleert.",
        "Auswahl-Zustand wird verfolgt und nach React-Neurendering wiederhergestellt.",
        "Hintergrund-Schreiber rufen sessionActions.updateCurrentSessionFields auf, um Updates zu koordinieren.",
        "Multi-Geräte-Sync verwendet sequence_number und version-Felder, um Konflikte zu lösen."
      ]
    },
    "plugins": {
      "heading": "Tauri-Plugins",
      "description": "PlanToCode verwendet das Tauri v2 Plugin-Ökosystem:",
      "list": [
        "tauri-plugin-http (2.5.2): HTTP-Client mit CSP-bewusstem Fetch für API-Aufrufe.",
        "tauri-plugin-dialog (2.4.2): Native Datei-/Ordnerauswahl und Meldungsdialoge.",
        "tauri-plugin-shell (2.3.3): Shell-Befehlsausführung für externe CLI-Tools.",
        "tauri-plugin-store (2.4.1): Persistente Schlüssel-Wert-Speicherung für App-Einstellungen.",
        "tauri-plugin-notification (2.3.0): Desktop-Benachrichtigungen für Agenten-Aufmerksamkeit.",
        "tauri-plugin-updater (2.9.0): In-App-Updates mit Signaturverifizierung.",
        "tauri-plugin-single-instance (2.3.4): Einzelinstanz-Durchsetzung.",
        "tauri-plugin-process (2.3.1): Prozess-Neustart-Fähigkeit."
      ]
    }
  },
  "serverApi": {
    "meta": {
      "title": "Server API and LLM proxy - PlanToCode",
      "description": "Auth, provider routing, model configuration, and WebSocket endpoints used by desktop and mobile clients."
    },
    "category": "Server",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Server API & LLM Proxy",
    "description": "Auth, provider routing, model configuration, billing, and WebSocket endpoints.",
    "intro": "The server is an Actix-Web service written in Rust that provides authentication, model configuration, LLM proxying, and billing. Desktop and mobile clients depend on it for secure provider routing and streaming responses. The server runs on dedicated infrastructure in two regions: Hetzner (EU) at api-eu.plantocode.com and InterServer (US) at api-us.plantocode.com.",
    "visuals": {
      "flow": {
        "title": "Server request flow",
        "description": "Diagram showing clients, API routes, and the LLM proxy.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Server request flow diagram",
        "caption": "Placeholder for the server request flow."
      }
    },
    "routeOrganization": {
      "heading": "Route organization",
      "description": "Routes are organized in server/src/routes.rs with three configuration functions:",
      "functions": [
        "configure_routes(): JWT-authenticated routes under /api scope. Includes auth, billing, config, providers, models, llm proxy, audio, system-prompts, consent, devices, notifications.",
        "configure_public_auth_routes(): Browser-based auth flow under /auth scope. Includes Auth0 initiate-login, callback, and logged-out routes.",
        "configure_webhook_routes(): Unauthenticated webhook endpoints under /webhooks scope. Currently handles Stripe webhooks."
      ]
    },
    "auth": {
      "heading": "Authentication endpoints",
      "description": "Authentication uses Auth0 with PKCE flow:",
      "routes": [
        "/auth/auth0/initiate-login (GET): Starts OAuth flow with code_challenge, redirects to Auth0.",
        "/auth/auth0/callback (GET): Handles Auth0 redirect, exchanges code for tokens.",
        "/api/auth/userinfo (GET): Returns authenticated user info from Auth0.",
        "/api/auth/logout (POST): Revokes tokens and clears session.",
        "/api/auth/account (DELETE): Account deletion with cascading cleanup.",
        "/api/auth0/refresh-app-token (POST): Refreshes access token using refresh token."
      ],
      "implementation": "Auth handlers in server/src/handlers/auth0_handlers.rs and server/src/handlers/auth/. JWT validation uses services/auth/jwt.rs with JWKS rotation. Revoked tokens tracked in revoked_token_repository.rs."
    },
    "llmProxy": {
      "heading": "LLM proxy and streaming",
      "description": "The LLM proxy normalizes requests across providers and streams responses:",
      "routes": [
        "/api/llm/chat/completions (POST): Main chat completion endpoint. Routes to OpenAI, Anthropic, Google, X.AI, or OpenRouter based on model ID.",
        "/api/llm/video/analyze (POST): Multipart video upload for frame analysis. Requires google/* models with video capability.",
        "/api/llm/cancel (POST): Cancels in-flight streaming request by request_id.",
        "/api/llm/status/{request_id} (GET): Returns status of a request (active, completed, cancelled).",
        "/api/audio/transcriptions (POST): Whisper-compatible transcription. Multipart upload with audio file and parameters."
      ],
      "routing": "Router in server/src/handlers/proxy/router.rs selects provider based on model ID prefix (openai/, anthropic/, google/, xai/, openrouter/). Provider-specific handlers in server/src/handlers/proxy/providers/ transform requests and normalize responses.",
      "streaming": "Streaming responses use Server-Sent Events (SSE) via streaming/sse_adapter.rs. The proxy forwards chunks from providers, transforms them to a common format, and tracks token usage in real-time."
    },
    "providers": {
      "heading": "Provider routing",
      "description": "Provider handlers in server/src/handlers/proxy/providers/:",
      "handlers": [
        "openai.rs: OpenAI and OpenAI-compatible APIs (GPT-4, o1, o3).",
        "anthropic.rs: Anthropic Claude models with prompt caching support.",
        "google.rs: Google Gemini models including video analysis capability.",
        "xai.rs: X.AI Grok models.",
        "openrouter.rs: OpenRouter aggregation for model routing."
      ],
      "transformers": "Request/response transformers in server/src/handlers/provider_transformers/ normalize API differences. Each transformer handles: request body format, authentication headers, streaming chunk format, usage extraction, error normalization."
    },
    "config": {
      "heading": "Configuration endpoints",
      "description": "Configuration and model metadata endpoints:",
      "routes": [
        "/api/config/all-configurations (GET): Returns all application configurations including model settings per task type.",
        "/api/config/desktop-runtime-config (GET): Desktop-specific runtime configuration.",
        "/api/config/billing (GET/PUT): Billing configuration management.",
        "/api/providers (GET): List of available LLM providers with capabilities.",
        "/api/providers/with-counts (GET): Providers with model counts.",
        "/api/providers/by-capability/{capability} (GET): Filter providers by capability.",
        "/api/models (GET): All available models with pricing.",
        "/api/models/{id} (GET): Single model details.",
        "/api/models/by-provider/{provider_code} (GET): Models for a specific provider.",
        "/api/models/estimate-cost (POST): Cost estimation for a request.",
        "/api/models/estimate-tokens (POST): Token count estimation.",
        "/api/system-prompts/defaults (GET): Default system prompts by task type."
      ]
    },
    "billing": {
      "heading": "Billing endpoints",
      "description": "Credit-based billing system integrated with Stripe:",
      "routes": [
        "/api/billing/dashboard (GET): User billing dashboard data.",
        "/api/billing/usage-summary (GET): Detailed usage with cost breakdown.",
        "/api/billing/credits/balance (GET): Current credit balance.",
        "/api/billing/credits/details (GET): Credit details including grants and purchases.",
        "/api/billing/credits/unified-history (GET): Transaction history.",
        "/api/billing/checkout/credit-purchase (POST): Create Stripe checkout for credits.",
        "/api/billing/checkout/setup (POST): Create Stripe setup session for payment method.",
        "/api/billing/auto-top-off (GET/PUT): Auto top-off settings management."
      ],
      "implementation": "Billing handlers in server/src/handlers/billing/. Credit service in services/credit_service.rs. Stripe integration via services/stripe_service.rs with webhook handling in webhook_handlers.rs."
    },
    "devices": {
      "heading": "Device management",
      "description": "Device registration and push notifications:",
      "routes": [
        "/api/devices/register (POST): Register desktop device with device_id.",
        "/api/devices/mobile/register (POST): Register mobile device with platform info.",
        "/api/devices/{device_id}/heartbeat (POST): Device heartbeat for presence.",
        "/api/devices/{device_id}/push-token (POST): Save push notification token.",
        "/api/devices/{device_id}/connection-descriptor (GET): WebSocket connection info for device linking.",
        "/api/notifications/job-completed (POST): Send push notification for completed job.",
        "/api/notifications/job-progress (POST): Send progress notification."
      ]
    },
    "websockets": {
      "heading": "WebSocket endpoints",
      "description": "Real-time communication via WebSocket:",
      "endpoints": [
        "/ws/device-link: Relay for desktop-mobile device linking. Handles terminal output streaming, job status updates, and RPC commands between linked devices.",
        "/ws/events: General event stream for real-time updates."
      ],
      "implementation": "Device link relay in server/src/handlers/device_link_ws.rs. Sessions managed by services/relay_session_store.rs with heartbeat monitoring and reconnection support."
    },
    "serverStorage": {
      "heading": "Server-side persistence",
      "description": "PostgreSQL database with repositories in server/src/db/repositories/:",
      "repositories": [
        "user_repository.rs: User accounts linked to Auth0 sub.",
        "customer_billing_repository.rs: Stripe customer and credit state.",
        "credit_transaction_repository.rs: Credit transaction history.",
        "provider_repository.rs: LLM provider configuration.",
        "system_prompts_repository.rs: System prompt templates.",
        "consent_repository.rs: Legal consent tracking.",
        "audit_log_repository.rs: Audit trail for sensitive operations.",
        "revoked_token_repository.rs: JWT revocation list.",
        "api_key_repository.rs: API key management with secure hashing."
      ]
    }
  },
  "backgroundJobs": {
    "meta": {
      "title": "Background jobs - PlanToCode",
      "description": "Job queue architecture, processor types, state machine, and artifact storage for the desktop job engine."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Background Jobs",
    "description": "Job queue, processors, state machine, event streaming, and artifact storage.",
    "intro": "All LLM-backed work runs through the background job system in the desktop app. The job queue dispatches work to processors, streams progress events, and persists every prompt and response in SQLite for audit and recovery. This architecture enables cancellation, retry, cost tracking, and real-time UI updates.",
    "visuals": {
      "stateMachine": {
        "title": "Job state machine",
        "description": "Diagram showing job status transitions from created through completion or failure.",
        "imageSrc": "/images/docs/background-jobs/state-machine.svg",
        "imageAlt": "Job state machine diagram",
        "caption": "Placeholder for job state machine diagram."
      }
    },
    "jobRecord": {
      "heading": "Job record structure",
      "description": "Each job creates a background_jobs row in SQLite with these fields:",
      "fields": [
        "id (TEXT PRIMARY KEY): UUID for the job.",
        "session_id (TEXT NOT NULL, FK): References sessions.id with CASCADE DELETE.",
        "task_type (TEXT DEFAULT 'unknown'): Processor identifier (e.g., implementation_plan, text_improvement, root_folder_selection).",
        "status (TEXT): Current state with CHECK constraint for valid values.",
        "prompt (TEXT NOT NULL): Full text sent to the LLM, stored for audit.",
        "response (TEXT): LLM output or error message.",
        "error_message (TEXT): Detailed error information on failure.",
        "tokens_sent (INTEGER DEFAULT 0): Input token count from provider response.",
        "tokens_received (INTEGER DEFAULT 0): Output token count.",
        "cache_read_tokens (INTEGER DEFAULT 0): Tokens read from provider cache (Anthropic).",
        "cache_write_tokens (INTEGER DEFAULT 0): Tokens written to cache.",
        "model_used (TEXT): Model identifier used for the request.",
        "actual_cost (REAL): Computed cost based on token usage and model pricing.",
        "metadata (TEXT): JSON with task-specific data, workflow IDs, stage names.",
        "system_prompt_template (TEXT): Template identifier used for the system prompt.",
        "server_request_id (TEXT): Links to server-side usage tracking.",
        "created_at, updated_at, start_time, end_time (INTEGER): Timestamps.",
        "is_finalized (INTEGER DEFAULT 0): Whether final cost/usage has been recorded."
      ]
    },
    "statusValues": {
      "heading": "Status values and transitions",
      "description": "Jobs transition through well-defined statuses tracked in the database:",
      "statuses": [
        "idle: Initial state before processing starts.",
        "created: Job record created, not yet queued.",
        "queued: Added to job queue, waiting for processor.",
        "acknowledged_by_worker: Processor has picked up the job.",
        "preparing: Processor is gathering inputs (files, prompts).",
        "preparing_input: Building the LLM request payload.",
        "running: Request sent to LLM, awaiting response.",
        "generating_stream: Streaming response in progress.",
        "processing_stream: Processing streamed chunks.",
        "completed: Job finished successfully.",
        "completed_by_tag: Completed via stream end tag detection.",
        "failed: Job failed with error_message populated.",
        "canceled: User requested cancellation."
      ],
      "transitions": "Transitions are enforced in background_job_repository/worker.rs. Invalid transitions are rejected. Status changes emit job:status-changed Tauri events."
    },
    "orchestrator": {
      "heading": "Workflow orchestrator",
      "description": "Multi-stage workflows are managed by WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/:",
      "modules": [
        "mod.rs: Main orchestrator struct and workflow execution entry point.",
        "definition_loader.rs: Loads workflow JSON definitions (e.g., file_finder_workflow.json) specifying stage order and processor types.",
        "stage_scheduler.rs: Schedules stages sequentially, waits for upstream completion.",
        "stage_job_manager.rs: Creates background_job records for each stage.",
        "payload_builder.rs: Constructs stage inputs from IntermediateData.",
        "data_extraction.rs: Extracts outputs from completed stage jobs.",
        "event_emitter.rs: Publishes workflow-status and workflow-stage Tauri events.",
        "state_updater.rs: Updates workflow state in memory and database.",
        "completion_handler.rs: Handles workflow completion and cleanup.",
        "failure_handler.rs: Manages stage failures and retry decisions.",
        "retry_handler.rs: Implements retry logic with exponential backoff."
      ],
      "dataFlow": "Workflows use WorkflowIntermediateData (defined in workflow_types.rs) to pass outputs between stages: directoryTreeContent, selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths, unverifiedPaths."
    },
    "processors": {
      "heading": "Job processors",
      "description": "Each task_type maps to a processor in desktop/src-tauri/src/jobs/processors/:",
      "implementations": [
        "implementation_plan_processor.rs: Loads selected file contents, builds structured prompt with directory tree, streams XML plan to UI. Uses generic_llm_stream_processor for streaming.",
        "text_improvement_processor.rs: Wraps selection in XML tags, sends non-streaming request, returns improved text. Runs via LlmTaskRunner.",
        "root_folder_selection_processor.rs: Sends directory tree to LLM, parses JSON array response of selected directories.",
        "RegexFileFilterProcessor (in processors/mod.rs): Generates regex patterns from task, applies to git file list, filters binaries.",
        "FileRelevanceAssessmentProcessor: Chunks file contents by token limit, scores relevance in batches, aggregates relevant paths.",
        "ExtendedPathFinderProcessor (path_finder_types.rs): Analyzes imports/dependencies, suggests related files, validates paths exist.",
        "web_search_prompts_generator_processor.rs: Generates research_task XML blocks for deep research.",
        "web_search_executor_processor.rs: Executes research prompts in parallel via server search API.",
        "generic_llm_stream_processor.rs: Reusable streaming processor that handles chunk accumulation, event emission, and response finalization."
      ]
    },
    "events": {
      "heading": "Event streaming",
      "description": "Job progress emits Tauri events consumed by the React UI:",
      "eventTypes": [
        "job:status-changed: Payload {jobId, status, error?}. Emitted on every status transition.",
        "job:stream-progress: Payload {jobId, content, tokensReceived}. Emitted for each streaming chunk.",
        "job:completed: Payload {jobId, response, tokensTotal, cost}. Emitted on successful completion.",
        "workflow-status: Payload {workflowId, status, currentStage?}. Workflow-level status updates.",
        "workflow-stage: Payload {workflowId, stageName, status}. Individual stage status."
      ],
      "reactConsumption": "React components subscribe via useEffect with listen() from @tauri-apps/api/event. WorkflowTracker aggregates workflow events. JobStatusIndicator displays real-time status."
    },
    "retry": {
      "heading": "Retry and cancellation",
      "description": "Job retry and cancellation mechanisms:",
      "retryLogic": "retry_handler.rs manages retry counts and delays. Retries use exponential backoff with configurable max attempts. Retry state stored in job.metadata.retryCount.",
      "cancellation": "Cancellation sets a flag checked between streaming chunks in generic_llm_stream_processor.rs. Server-side cancellation sends /api/llm/cancel with request_id.",
      "cleanup": "workflow_cleanup.rs handles cleanup of incomplete workflows. Stale jobs (running status after app restart) are marked failed."
    },
    "artifacts": {
      "heading": "Artifact storage",
      "description": "Job inputs and outputs are fully persisted for audit:",
      "stored": [
        "prompt: Complete LLM prompt including system prompt and user content.",
        "response: Full LLM response text or streaming accumulation.",
        "metadata: JSON with task-specific data (original text for improvements, file lists, workflow context).",
        "system_prompt_template: Identifier linking to server-side prompt template version.",
        "Token counts and cost: Captured from provider response for billing and analysis."
      ],
      "access": "background_job_repository provides queries: get_jobs_for_session, get_job_by_id, get_jobs_by_task_type, get_recent_jobs. Job history displayed in BackgroundJobsSidebar component."
    },
    "costTracking": {
      "heading": "Cost tracking",
      "description": "Per-job cost tracking enables budget management:",
      "calculation": "Cost calculated using model pricing from server/src/models/model_pricing.rs. Formula: (tokens_sent * input_price + tokens_received * output_price) with cache adjustments.",
      "accumulation": "Session-level cost aggregated from background_jobs. UI displays cumulative cost in session header.",
      "serverSync": "server_request_id links desktop jobs to server-side usage records for billing reconciliation."
    },
    "cta": {
      "heading": "See the data model",
      "description": "Understand the SQLite schema that stores jobs, sessions, and terminal output.",
      "links": {
        "dataModel": "Data model",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "buildYourOwn": {
    "meta": {
      "title": "Build your own pipeline - PlanToCode",
      "description": "Conceptual guide for designing file discovery and plan generation workflows similar to PlanToCode."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Build Your Own Pipeline",
    "description": "Conceptual guide for designing file discovery and plan generation workflows.",
    "intro": "This guide distills the key architectural patterns from PlanToCode into a conceptual blueprint. Whether you want to build a similar system or understand why certain design decisions were made, this document covers the foundational patterns you can reuse or adapt.",
    "visuals": {
      "pipelineMap": {
        "title": "Pipeline architecture map",
        "description": "Overview of the multi-stage pipeline from task input to plan output.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Pipeline architecture diagram",
        "caption": "Placeholder for pipeline architecture diagram."
      }
    },
    "keyPatterns": {
      "heading": "Key Architectural Patterns",
      "jobQueue": {
        "title": "Job Queue Pattern",
        "description": "All LLM-backed operations run as background jobs with status tracking, cancellation support, and retry logic. Jobs are persisted to SQLite so state survives app restarts.",
        "benefits": [
          "Decouples UI responsiveness from LLM latency",
          "Enables cancellation mid-stream",
          "Provides audit trail of all operations",
          "Supports retry with exponential backoff"
        ],
        "pitfalls": [
          "Job status management adds complexity",
          "Need careful handling of stale jobs on restart",
          "Stream accumulation can consume memory for large responses"
        ]
      },
      "workflowOrchestrator": {
        "title": "Workflow Orchestrator Pattern",
        "description": "Multi-stage workflows are coordinated by an orchestrator that schedules stages sequentially, passes intermediate data between them, and handles failures at any stage.",
        "components": [
          "Definition loader reads workflow JSON specs",
          "Stage scheduler dispatches stages in order",
          "Payload builder constructs inputs from prior outputs",
          "Event emitter publishes progress for UI updates"
        ]
      },
      "repositoryPattern": {
        "title": "Repository Pattern",
        "description": "All persistence goes through typed repositories that abstract SQLite operations. This provides a clean API, enables testing, and centralizes database access.",
        "benefits": [
          "Typed access prevents SQL injection",
          "Repositories can be mocked for testing",
          "Centralized query optimization",
          "Consistent error handling"
        ]
      }
    },
    "steps": {
      "step1": {
        "title": "1. Define your task model",
        "description": "Start by defining what constitutes a task in your system. PlanToCode uses sessions with task descriptions, file selections, and model preferences.",
        "details": "Store task metadata in a dedicated table with versioning for history tracking."
      },
      "step2": {
        "title": "2. Build the job queue",
        "description": "Create a job queue that persists jobs to storage, emits status events, and supports cancellation. Jobs should track prompts, responses, tokens, and cost.",
        "details": "Use a semaphore-based concurrency limiter to control parallel LLM requests."
      },
      "step3": {
        "title": "3. Implement processors",
        "description": "Each job type needs a processor that builds prompts, calls the LLM, and parses responses. Use streaming for long outputs.",
        "details": "Processors should be stateless and receive all context through job parameters."
      },
      "step4": {
        "title": "4. Create the workflow orchestrator",
        "description": "For multi-stage workflows, build an orchestrator that schedules stages, manages intermediate data, and handles failures.",
        "details": "Store workflow definitions as JSON for easy modification without code changes."
      },
      "step5": {
        "title": "5. Add the routing layer",
        "description": "Route LLM requests through a server proxy that normalizes payloads, manages API keys, and tracks usage.",
        "details": "Keep provider credentials on the server; never embed them in desktop clients."
      }
    },
    "architectureDecisions": {
      "heading": "Architecture Decisions",
      "decisions": [
        {
          "question": "Should you use a local database or server-side storage?",
          "recommendation": "Use local SQLite for job state and artifacts. This enables offline operation and fast queries. Sync to server only for billing and cross-device state."
        },
        {
          "question": "Streaming vs non-streaming responses?",
          "recommendation": "Use streaming for plan generation and any output shown progressively. Use non-streaming for short transformations like text improvement."
        },
        {
          "question": "How to handle LLM provider failures?",
          "recommendation": "Implement automatic retry with exponential backoff. Consider a fallback provider like OpenRouter for resilience."
        },
        {
          "question": "Where should file content be loaded?",
          "recommendation": "Load file content in the processor just before building the prompt. This ensures fresh content and avoids storing large blobs in job records."
        }
      ]
    },
    "customizeVsReuse": {
      "heading": "What to Customize vs Reuse",
      "customize": [
        "Prompt templates for your specific use case",
        "File discovery patterns for your project types",
        "Output format (XML, JSON, Markdown)",
        "Model selection per task type"
      ],
      "reuse": [
        "Job queue architecture with status tracking",
        "Workflow orchestrator pattern",
        "Repository pattern for persistence",
        "Streaming response handling",
        "Provider routing and normalization"
      ]
    },
    "commonPitfalls": {
      "heading": "Common Pitfalls to Avoid",
      "items": [
        {
          "pitfall": "Embedding API keys in the client",
          "solution": "Route all LLM requests through a server proxy that manages credentials securely."
        },
        {
          "pitfall": "Not persisting job state",
          "solution": "Store every job with full prompt and response for audit and recovery."
        },
        {
          "pitfall": "Blocking UI on LLM calls",
          "solution": "Use background jobs with event-driven UI updates for responsive interfaces."
        },
        {
          "pitfall": "Ignoring token limits",
          "solution": "Estimate tokens before sending and chunk large inputs to stay within context windows."
        },
        {
          "pitfall": "No cancellation support",
          "solution": "Check cancellation flags between streaming chunks and propagate to server."
        }
      ]
    },
    "artifacts": {
      "heading": "Artifacts to Persist",
      "items": [
        "Full prompt sent to the LLM (for debugging and audit)",
        "Complete response including streaming accumulation",
        "Token counts from provider response",
        "Computed cost based on model pricing",
        "System prompt template identifier for versioning",
        "Workflow intermediate data for multi-stage flows"
      ]
    },
    "implementationNotes": {
      "heading": "Implementation Notes",
      "items": [
        "Use SQLite with WAL mode for concurrent read/write access",
        "Implement graceful shutdown that marks running jobs as failed",
        "Add health checks for external dependencies before job processing",
        "Log all LLM errors with full context for debugging",
        "Consider caching file content with short TTL to avoid redundant reads"
      ]
    }
  },
  "decisionsTradeoffs": {
    "meta": {
      "title": "Technical decisions and tradeoffs - PlanToCode",
      "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen, and what operational tradeoffs they create."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Technical Decisions & Tradeoffs",
    "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen and what they cost.",
    "intro": "Every architecture involves tradeoffs. This document explains the major technology choices in PlanToCode, what benefits they provide, and what costs or limitations they introduce.",
    "visuals": {
      "tradeoffMatrix": {
        "title": "Tradeoff matrix",
        "description": "Visual comparison of technology choices with their benefits and costs.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Technology tradeoff matrix",
        "caption": "System architecture overview illustrating the technology stack decisions."
      }
    },
    "sections": {
      "tauri": {
        "title": "Tauri v2 for Desktop",
        "description": "Tauri provides a Rust backend with a web-based frontend, enabling cross-platform desktop apps with native performance and small binary sizes.",
        "benefits": [
          "Small binary size (~15MB vs 200MB+ for Electron)",
          "Native Rust performance for file operations and job processing",
          "Capability-based security model with fine-grained permissions",
          "Single codebase for macOS, Windows, and Linux",
          "Access to system APIs (PTY, keychain, notifications)"
        ],
        "tradeoffs": [
          "Smaller ecosystem than Electron",
          "Rust learning curve for backend development",
          "WebView rendering differences across platforms",
          "Less mature tooling for debugging IPC issues"
        ],
        "implementation": "PlanToCode uses Tauri 2.9.1 with ~35 command modules, capability-based permissions, and plugins for shell, dialog, and notifications."
      },
      "sqlite": {
        "title": "SQLite for Local Persistence",
        "description": "SQLite stores all local state including sessions, jobs, terminal output, and settings. This enables offline operation and fast queries.",
        "benefits": [
          "Zero-config embedded database",
          "Fast queries for local data",
          "Enables offline operation",
          "Single file backup and restore",
          "WAL mode for concurrent access"
        ],
        "tradeoffs": [
          "No built-in replication or sync",
          "Large terminal logs can grow the database",
          "Need manual schema migrations",
          "Single-writer limitation (mitigated by WAL)"
        ],
        "implementation": "Schema in consolidated_schema.sql with ~10 tables. Repositories provide typed access with rusqlite."
      },
      "llmProxy": {
        "title": "Dedicated LLM Proxy Server",
        "description": "All LLM requests route through a server proxy that manages API keys, normalizes requests, tracks usage, and handles billing.",
        "benefits": [
          "API keys never leave the server",
          "Single request format for all providers",
          "Centralized usage tracking and billing",
          "Provider failover without client updates",
          "Content filtering and rate limiting"
        ],
        "tradeoffs": [
          "Requires server infrastructure",
          "Adds network latency to requests",
          "Server becomes single point of failure",
          "Need to maintain provider integrations"
        ],
        "implementation": "Actix-Web server with handlers in server/src/handlers/proxy/. Transformers in provider_transformers/ normalize requests."
      },
      "websocket": {
        "title": "WebSocket Relay for Mobile",
        "description": "Desktop and mobile clients connect through a WebSocket relay for device linking, terminal streaming, and job synchronization.",
        "benefits": [
          "Real-time bidirectional communication",
          "No direct P2P networking required",
          "Works across NAT and firewalls",
          "Supports multiple linked devices"
        ],
        "tradeoffs": [
          "Requires persistent server connections",
          "Relay adds latency for large payloads",
          "Connection management complexity",
          "Need reconnection and heartbeat logic"
        ],
        "implementation": "device_link_ws.rs implements the relay with session tracking, heartbeats, and PTC1 binary framing for terminal output."
      }
    },
    "operational": {
      "heading": "Operational Consequences",
      "items": [
        "Tauri: Need separate builds for each platform. CI/CD must cross-compile or use platform-specific runners.",
        "SQLite: Database file grows with terminal output. May need periodic cleanup for long-running instances.",
        "LLM Proxy: Server downtime blocks all LLM operations. Need monitoring and redundancy for production.",
        "WebSocket: Reconnection logic adds complexity. Clients must handle connection drops gracefully."
      ]
    },
    "securityBoundaries": {
      "heading": "Security Boundaries",
      "description": "The architecture creates clear security boundaries that limit exposure:",
      "items": [
        "API keys stored in server vault, never sent to clients",
        "JWT tokens validated on every request with JWKS rotation",
        "Capability-based permissions limit filesystem access",
        "Content sent to LLMs requires explicit user approval",
        "Audit logs track all LLM requests with user context"
      ]
    },
    "whenToReconsider": {
      "heading": "When to Reconsider",
      "description": "These decisions may need revisiting if requirements change significantly:",
      "items": [
        "If browser-only access is required, consider a web-based alternative to Tauri",
        "If multi-device sync is critical, consider server-side job storage",
        "If provider lock-in is acceptable, direct API calls may reduce latency",
        "If mobile is primary, consider native apps instead of device linking"
      ]
    }
  },
  "dataModel": {
    "meta": {
      "title": "Data model and storage - PlanToCode",
      "description": "SQLite entities, relationships, and how state is rehydrated on app restart."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Data Model & Storage",
    "description": "SQLite entities, relationships, and how state is rehydrated.",
    "intro": "PlanToCode uses SQLite for all local state. This document describes the schema, entity relationships, and how state is restored when the app restarts.",
    "sqlite": {
      "heading": "SQLite Configuration",
      "description": "The database uses WAL mode for concurrent read/write access. The file is stored in the Tauri app data directory (~/.local/share/plantocode on Linux, ~/Library/Application Support/plantocode on macOS).",
      "migrations": "Schema migrations are consolidated in consolidated_schema.sql. The app checks schema version on startup and runs any pending migrations."
    },
    "entities": {
      "heading": "Core Entities",
      "items": [
        "sessions: Project context with task description, file selections, model preferences, search settings, video/merge prompts, history indexes",
        "background_jobs: LLM-backed operations with prompt, response, tokens, cost, is_finalized flag, error_message",
        "terminal_sessions: PTY sessions with output log, status, process info",
        "task_description_history: Version history for task descriptions",
        "file_selection_history: Version history for file selections",
        "project_system_prompts: Per-project prompt overrides",
        "key_value_store: App settings and configuration",
        "error_logs: Client-side error tracking",
        "migrations: Tracks applied database migrations with timestamps",
        "db_diagnostic_logs: Records database diagnostic issues and errors",
        "app_settings: Application configuration key-value pairs with descriptions"
      ]
    },
    "visuals": {
      "schema": {
        "title": "Entity relationship diagram",
        "description": "Visual representation of the SQLite schema and relationships.",
        "imageSrc": "/images/docs/data-model/schema.svg",
        "imageAlt": "Database schema diagram",
        "caption": "Placeholder for database schema diagram."
      }
    },
    "relationships": {
      "heading": "Entity Relationships",
      "description": "Entities are linked through foreign keys with cascade delete rules:",
      "links": [
        "sessions → background_jobs: One-to-many, cascade delete",
        "background_jobs → terminal_sessions: Optional one-to-one link via job_id",
        "sessions → task_description_history: One-to-many for version tracking",
        "sessions → file_selection_history: One-to-many for version tracking"
      ]
    },
    "repositories": {
      "heading": "Repository Layer",
      "description": "All database access goes through typed repositories in desktop/src-tauri/src/db_utils/:",
      "examples": [
        "background_job_repository/: Modular with base.rs, worker.rs, metadata.rs, cleanup.rs",
        "session_repository.rs: Session CRUD with history management",
        "terminal_repository.rs: Terminal session persistence and output logging",
        "settings_repository.rs: Key-value settings storage"
      ]
    },
    "rehydration": {
      "heading": "State Rehydration",
      "description": "When the app starts, state is restored from SQLite:",
      "sessions": "Active session is loaded with task description, file selections, and model preferences. Recent sessions are available in the session picker."
    },
    "retention": {
      "heading": "Data Retention",
      "description": "Old data is cleaned up based on configurable retention periods:",
      "exports": "Sessions and jobs can be exported for backup before cleanup."
    },
    "cta": {
      "heading": "Explore job processing",
      "description": "See how background jobs use this data model.",
      "links": {
        "jobs": "Background jobs",
        "terminals": "Terminal sessions"
      }
    }
  },
  "serverSetup": {
    "meta": {
      "title": "Dedicated server setup - PlanToCode",
      "description": "Ansible-based infrastructure setup: base hardening, PostgreSQL, Redis, and application deployment."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Dedicated Server Setup",
    "description": "Ansible-based infrastructure: base hardening, app deployment, and vault-managed secrets.",
    "intro": "PlanToCode runs on dedicated servers managed through Ansible playbooks. This document covers the infrastructure setup, security hardening, and deployment process.",
    "layers": {
      "heading": "Infrastructure Layers",
      "description": "The infrastructure is organized into layers, each managed by dedicated playbooks:",
      "items": [
        "Base layer: OS hardening, SSH configuration, firewall rules",
        "Database layer: PostgreSQL 17 with replication and backups",
        "Cache layer: Redis 7+ for session state and job queues",
        "Application layer: Rust server binary with systemd service",
        "Proxy layer: Nginx reverse proxy with SSL termination"
      ]
    },
    "servers": {
      "heading": "Server Regions",
      "description": "PlanToCode runs in two regions for geographic redundancy:",
      "items": [
        "EU region: Hetzner dedicated server (api-eu.plantocode.com)",
        "US region: InterServer dedicated server (api-us.plantocode.com)"
      ]
    },
    "requirements": {
      "heading": "Server Requirements",
      "items": [
        "Debian 12 or Ubuntu 22.04 LTS",
        "4+ CPU cores, 16GB+ RAM, 200GB+ SSD",
        "Public IPv4 with firewall access to ports 22, 80, 443",
        "SSH key access for Ansible deployment"
      ]
    },
    "hardening": {
      "heading": "Base Hardening",
      "description": "site-base.yml applies security hardening:",
      "items": [
        "Disable root SSH login, require key authentication",
        "Configure UFW firewall with minimal open ports",
        "Install fail2ban for brute force protection",
        "Enable automatic security updates",
        "Configure audit logging"
      ]
    },
    "postgresql": {
      "heading": "PostgreSQL Setup",
      "description": "PostgreSQL 17 is configured for production use:",
      "items": [
        "Connection pooling with PgBouncer",
        "Automated daily backups with pg_dump",
        "WAL archiving for point-in-time recovery",
        "SSL required for all connections",
        "Row-level security for multi-tenant data"
      ]
    },
    "redis": {
      "heading": "Redis Setup",
      "description": "Redis 7+ handles caching and session state:",
      "items": [
        "Password authentication required",
        "AOF persistence for durability",
        "Memory limits with eviction policy",
        "TLS encryption for connections"
      ]
    },
    "zeroDowntime": {
      "heading": "Zero-Downtime Deployment",
      "description": "Deployments use a rolling update strategy:",
      "items": [
        "New binary uploaded alongside running version",
        "Health check confirms new version is ready",
        "Systemd restarts with graceful shutdown",
        "Load balancer drains connections during switch",
        "Rollback available via previous binary symlink"
      ]
    },
    "quickStart": {
      "heading": "Quick Start",
      "steps": [
        "Clone the infrastructure repository",
        "Copy inventory.example to inventory and configure hosts",
        "Set vault password in .vault_pass",
        "Run: ansible-playbook -i inventory site-base.yml",
        "Run: ansible-playbook -i inventory site-app.yml"
      ]
    },
    "vault": {
      "heading": "Secrets Management",
      "description": "Sensitive configuration uses Ansible Vault:",
      "items": [
        "Database credentials",
        "API keys for LLM providers",
        "SSL certificates and private keys",
        "Auth0 client secrets",
        "Stripe webhook secrets"
      ]
    },
    "operations": {
      "heading": "Common Operations",
      "items": [
        "ansible-playbook -i inventory site-app.yml --tags deploy",
        "ansible-playbook -i inventory site-base.yml --tags backup",
        "ansible-playbook -i inventory site-app.yml --tags rollback",
        "ansible-playbook -i inventory site-base.yml --tags logs"
      ]
    },
    "ssl": {
      "heading": "SSL/TLS Configuration",
      "description": "Let's Encrypt provides free SSL certificates:",
      "items": [
        "Certbot configured with Nginx plugin",
        "Automatic renewal via cron job",
        "HSTS headers enabled",
        "TLS 1.2+ only, modern cipher suite"
      ]
    },
    "security": {
      "heading": "Security Checklist",
      "items": [
        "All default passwords changed",
        "SSH key rotation scheduled",
        "Firewall rules audited",
        "Security updates automated",
        "Backup restoration tested"
      ]
    },
    "recovery": {
      "heading": "Disaster Recovery",
      "description": "Recovery procedures for common failure scenarios:",
      "items": [
        "Database corruption: Restore from latest pg_dump backup",
        "Server failure: Provision new server and run playbooks",
        "SSL expiration: Manual certbot renew --force-renewal",
        "Security breach: Rotate all credentials, audit logs"
      ]
    }
  },
  "tauriV2": {
    "meta": {
      "title": "Tauri v2 development guide - PlanToCode",
      "description": "Project layout, commands, capabilities, and development workflow for Tauri v2."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Tauri v2 Development Guide",
    "description": "Project layout, commands, and capability-based permissions for Tauri v2.",
    "intro": "PlanToCode uses Tauri v2 for the desktop application. This guide covers the project structure, command system, capability-based permissions, and development workflow.",
    "projectLayout": {
      "heading": "Project Layout",
      "description": "The desktop application follows standard Tauri v2 conventions:",
      "items": [
        "desktop/src/: React frontend with components, hooks, and providers",
        "desktop/src-tauri/: Rust backend with commands, jobs, and services",
        "desktop/src-tauri/src/lib.rs: Application entry point",
        "desktop/src-tauri/src/commands/: Tauri command handlers (~35 modules)",
        "desktop/src-tauri/capabilities/: Permission definitions",
        "desktop/src-tauri/tauri.conf.json: Tauri configuration"
      ]
    },
    "configuration": {
      "heading": "Tauri Configuration",
      "description": "tauri.conf.json configures the application:",
      "items": [
        "productName, version, identifier for app metadata",
        "build.beforeDevCommand and beforeBuildCommand for frontend",
        "bundle settings for installers (DMG, NSIS, AppImage)",
        "security.csp for Content Security Policy",
        "plugins configuration for official plugins"
      ]
    },
    "capabilities": {
      "heading": "Capability-Based Permissions",
      "description": "Tauri v2 uses capabilities to control what the app can access:",
      "items": [
        "default.json: Base permissions for all windows",
        "desktop-default.json: Desktop-specific permissions",
        "plantocode-api.json: Custom permissions for PlanToCode commands",
        "Permissions grant access to: filesystem, shell, http, dialog, notification"
      ]
    },
    "plugins": {
      "heading": "Tauri Plugins",
      "description": "PlanToCode uses several official Tauri plugins:",
      "items": [
        "tauri-plugin-http: HTTP client for API calls",
        "tauri-plugin-dialog: Native file/folder pickers",
        "tauri-plugin-shell: Shell command execution",
        "tauri-plugin-store: Persistent key-value storage",
        "tauri-plugin-notification: Desktop notifications",
        "tauri-plugin-updater: In-app updates",
        "tauri-plugin-single-instance: Single instance enforcement"
      ]
    },
    "appState": {
      "heading": "Application State",
      "description": "Rust state managed through Tauri's state system:",
      "items": [
        "AppState struct holds shared state",
        "RuntimeConfig for server URLs and feature flags",
        "TokenManager for secure credential storage",
        "ConfigCache for AI model configuration"
      ]
    },
    "commands": {
      "heading": "Creating Commands",
      "description": "Tauri commands expose Rust functions to the frontend:",
      "items": [
        "Use #[tauri::command] attribute on async functions",
        "Return Result<T, String> for error handling",
        "Access state via State<AppState> parameter",
        "Register in lib.rs invoke_handler"
      ]
    },
    "singleInstance": {
      "heading": "Single Instance",
      "description": "The app enforces single instance to prevent data conflicts:",
      "items": [
        "tauri-plugin-single-instance handles detection",
        "Second launch focuses existing window",
        "Deep links forwarded to running instance"
      ]
    },
    "devWorkflow": {
      "heading": "Development Workflow",
      "description": "Common commands for development:",
      "items": [
        "pnpm tauri dev: Start development with hot reload",
        "pnpm tauri build: Build production release",
        "cargo test: Run Rust tests",
        "cargo clippy: Lint Rust code"
      ]
    },
    "mobile": {
      "heading": "Mobile Considerations",
      "description": "Tauri v2 supports mobile, but PlanToCode uses native Swift:",
      "items": [
        "iOS app built with SwiftUI for native experience",
        "Shared API contracts between desktop and mobile",
        "Device linking via WebSocket relay"
      ]
    },
    "distribution": {
      "heading": "Distribution",
      "description": "Build artifacts for each platform:",
      "items": [
        "macOS: .dmg with universal binary (Intel + Apple Silicon)",
        "Windows: NSIS installer and MSIX package",
        "Linux: AppImage for broad compatibility"
      ]
    }
  },
  "distributionMacos": {
    "meta": {
      "title": "macOS distribution - PlanToCode",
      "description": "Code signing, notarization, DMG packaging, and updater configuration for macOS."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "macOS Distribution",
    "description": "Signing, notarization, DMG packaging, and updater artifacts.",
    "intro": "Distributing on macOS requires code signing, notarization, and proper packaging. This document covers the complete process for PlanToCode.",
    "signing": {
      "heading": "Code Signing",
      "description": "All binaries must be signed with an Apple Developer ID:",
      "items": [
        "Developer ID Application certificate for app signing",
        "Developer ID Installer certificate for PKG signing",
        "Certificates stored in CI secrets, imported to keychain",
        "Hardened runtime enabled for notarization compatibility"
      ]
    },
    "entitlements": {
      "heading": "Entitlements",
      "description": "Required entitlements for PlanToCode features:",
      "items": [
        "com.apple.security.cs.allow-jit",
        "com.apple.security.cs.allow-unsigned-executable-memory",
        "com.apple.security.device.audio-input",
        "com.apple.security.network.client",
        "com.apple.security.files.user-selected.read-write"
      ]
    },
    "build": {
      "heading": "Build Process",
      "description": "Steps to build a signed release:",
      "steps": [
        "Run pnpm tauri build --target universal-apple-darwin",
        "Tauri signs with APPLE_SIGNING_IDENTITY from environment",
        "Universal binary created with lipo for Intel + ARM",
        "DMG packaged with custom background and layout"
      ]
    },
    "universalBinaries": {
      "heading": "Universal Binaries",
      "description": "PlanToCode ships as a universal binary:",
      "items": [
        "Single .app supports both Intel and Apple Silicon",
        "Built with --target universal-apple-darwin",
        "Slightly larger binary but simpler distribution",
        "Native performance on both architectures"
      ]
    },
    "notarization": {
      "heading": "Notarization",
      "description": "Apple notarization is required for Gatekeeper approval:",
      "items": [
        "DMG submitted to Apple notary service",
        "Uses notarytool with App Store Connect credentials",
        "Stapling attaches notarization ticket to DMG",
        "Process takes 1-5 minutes typically"
      ]
    },
    "updater": {
      "heading": "In-App Updates",
      "description": "tauri-plugin-updater handles automatic updates:",
      "items": [
        "Checks update endpoint on launch",
        "Downloads new version in background",
        "Prompts user to restart to apply",
        "Signature verification before installation"
      ]
    },
    "latestJson": {
      "heading": "Update Manifest",
      "description": "latest.json describes available updates:",
      "items": [
        "version: Semantic version string",
        "platforms.darwin-universal: URL and signature",
        "notes: Release notes in markdown",
        "pub_date: ISO 8601 publish timestamp"
      ]
    },
    "pitfalls": {
      "heading": "Common Pitfalls",
      "description": "Issues frequently encountered:",
      "items": [
        "Keychain locked during CI: Unlock before signing",
        "Notarization timeout: Retry with exponential backoff",
        "Invalid signature: Check entitlements match capabilities",
        "Gatekeeper rejection: Verify notarization stapled correctly"
      ]
    },
    "verification": {
      "heading": "Verification Commands",
      "description": "Commands to verify signing and notarization:",
      "items": [
        "codesign -dv --verbose=4 PlanToCode.app",
        "spctl --assess --verbose PlanToCode.app",
        "stapler validate PlanToCode.dmg",
        "xcrun notarytool log <submission-id>"
      ]
    }
  },
  "distributionWindows": {
    "meta": {
      "title": "Windows distribution - PlanToCode",
      "description": "NSIS installer, MSIX packaging, Microsoft Store submission, and code signing for Windows."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Windows Distribution & Store",
    "description": "NSIS builds, MSIX packaging, and Microsoft Store submission.",
    "intro": "PlanToCode distributes on Windows through both direct download (NSIS installer) and the Microsoft Store (MSIX package). This document covers both distribution methods.",
    "prereqs": {
      "heading": "Prerequisites",
      "description": "Required tools and certificates:",
      "items": [
        "Code signing certificate (EV or standard)",
        "Windows SDK for signtool",
        "NSIS for installer building",
        "MSIX Packaging Tool for Store submissions"
      ]
    },
    "nsisBuild": {
      "heading": "NSIS Installer",
      "description": "Tauri builds NSIS installers by default:",
      "items": [
        "Custom installer UI with PlanToCode branding",
        "Per-user installation (no admin required)",
        "Start menu and desktop shortcuts",
        "Uninstaller with clean removal"
      ]
    },
    "codeSigning": {
      "heading": "Code Signing",
      "description": "Windows code signing with Authenticode:",
      "items": [
        "Sign with signtool from Windows SDK",
        "Timestamp from trusted TSA server",
        "EV certificate provides SmartScreen reputation",
        "CI uses secrets for certificate and password"
      ]
    },
    "msixPackaging": {
      "heading": "MSIX for Microsoft Store",
      "description": "MSIX provides Store-compatible packaging:",
      "items": [
        "AppxManifest.xml defines capabilities",
        "Virtual filesystem isolation",
        "Automatic updates through Store",
        "Sandboxed execution environment"
      ]
    },
    "msixConfig": {
      "heading": "MSIX Configuration",
      "description": "Key AppxManifest settings:",
      "items": [
        "Identity: Name, Publisher, Version",
        "Capabilities: internetClient, microphone",
        "Visual elements: Tiles, splash screen",
        "File associations and protocol handlers"
      ]
    },
    "msixSteps": {
      "heading": "MSIX Build Steps",
      "description": "Process to create MSIX package:",
      "steps": [
        "Build release with pnpm tauri build",
        "Create AppxManifest.xml with correct identity",
        "Package with MakeAppx.exe",
        "Sign with SignTool",
        "Validate with Windows App Cert Kit"
      ]
    },
    "store": {
      "heading": "Microsoft Store Submission",
      "description": "Store submission process:",
      "items": [
        "Create app in Partner Center",
        "Upload MSIX package",
        "Configure pricing (free with IAP credits)",
        "Submit for certification",
        "Review takes 1-3 business days"
      ]
    },
    "updaterWindows": {
      "heading": "Windows Updates",
      "description": "Update mechanisms for each distribution:",
      "items": [
        "NSIS: tauri-plugin-updater with GitHub releases",
        "MSIX/Store: Automatic through Microsoft Store",
        "Both check for updates on launch"
      ]
    },
    "webview2": {
      "heading": "WebView2 Runtime",
      "description": "Tauri uses WebView2 on Windows:",
      "items": [
        "Bundled WebView2 bootstrapper in installer",
        "Evergreen version auto-updates",
        "Fixed version available for isolation",
        "Windows 10 1803+ required"
      ]
    },
    "troubleshooting": {
      "heading": "Troubleshooting",
      "description": "Common Windows distribution issues:",
      "items": [
        "SmartScreen warning: Use EV certificate or build reputation",
        "Missing WebView2: Ensure bootstrapper runs",
        "Store rejection: Review certification report details",
        "Update failure: Check signature and manifest version"
      ]
    }
  },
  "promptTypes": {
    "meta": {
      "title": "Prompt types and templates - PlanToCode",
      "description": "Catalog of prompt-driven job types and template assembly process."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Prompt Types & Templates",
    "description": "Catalog of prompt-driven job types and template assembly.",
    "intro": "Every LLM-backed job in PlanToCode uses a structured prompt built from templates. This document catalogs the job types and explains how prompts are assembled.",
    "catalog": {
      "heading": "Job Type Catalog",
      "items": [
        {
          "job": "implementation_plan",
          "title": "Implementation Plan",
          "description": "Generates file-by-file implementation plans with XML structure. Uses streaming for progressive display."
        },
        {
          "job": "implementation_plan_merge",
          "title": "Plan Merge",
          "description": "Combines multiple plans with user instructions. Source plans wrapped in XML tags."
        },
        {
          "job": "text_improvement",
          "title": "Text Improvement",
          "description": "Refines selected text while preserving formatting. Non-streaming for quick results."
        },
        {
          "job": "root_folder_selection",
          "title": "Root Folder Selection",
          "description": "Analyzes directory tree to select relevant project roots. Returns JSON array."
        },
        {
          "job": "regex_file_filter",
          "title": "Regex File Filter",
          "description": "Generates regex patterns for file filtering based on task description."
        },
        {
          "job": "file_relevance_assessment",
          "title": "File Relevance Assessment",
          "description": "Scores file content relevance to task. Processes in batches."
        },
        {
          "job": "extended_path_finder",
          "title": "Extended Path Finder",
          "description": "Discovers related files through imports and dependencies."
        },
        {
          "job": "web_search_prompts",
          "title": "Web Search Prompts",
          "description": "Generates research queries for deep research workflow."
        },
        {
          "job": "video_analysis",
          "title": "Video Analysis",
          "description": "Analyzes screen recordings for UI state and action sequences."
        }
      ]
    },
    "templateStructure": {
      "heading": "Template Structure",
      "description": "Prompts are assembled from system templates and user content:",
      "sampleLabel": "Example template structure:",
      "sample": "<system_prompt>\n  You are an AI assistant that generates implementation plans.\n  [template content from server]\n</system_prompt>\n\n<task>\n  [user's task description]\n</task>\n\n<files>\n  [selected file paths and content]\n</files>\n\n<directory_tree>\n  [project structure]\n</directory_tree>"
    },
    "visuals": {
      "template": {
        "title": "Prompt assembly flow",
        "description": "How templates combine with user content to form complete prompts.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "imageAlt": "Prompt template assembly diagram",
        "caption": "Placeholder for prompt assembly diagram."
      }
    },
    "assembly": {
      "heading": "Assembly Process",
      "steps": [
        "Processor retrieves template ID from task model config",
        "System prompt template loaded from server cache",
        "User content wrapped in semantic XML tags",
        "Context (files, tree) added based on job type",
        "Complete prompt stored in job record before sending"
      ]
    },
    "serverConfig": {
      "heading": "Server-Side Configuration",
      "description": "Templates and model settings are configured server-side:",
      "fields": "task_model_config defines: default_model, allowed_models, system_prompt_template_id, max_tokens, temperature"
    },
    "tokenGuards": {
      "heading": "Token Guardrails",
      "description": "Each task type has token limits to prevent context overflow:",
      "items": [
        "max_tokens_input: Maximum prompt size",
        "max_tokens_output: Maximum response size",
        "Validation before sending prevents wasted API calls",
        "UI shows token count and warns when approaching limits"
      ]
    },
    "versioning": {
      "heading": "Template Versioning",
      "description": "System prompt templates are versioned for reproducibility. Each job records the template ID used, enabling audit and comparison of results across template versions."
    },
    "designNotes": {
      "heading": "Design Notes",
      "items": [
        "XML tags provide clear boundaries for LLM parsing",
        "Semantic naming (task, files, context) aids model understanding",
        "Templates avoid instruction injection by sanitizing user input",
        "Streaming jobs use end tags for completion detection"
      ]
    },
    "cta": {
      "heading": "See job processing in action",
      "description": "Learn how these prompts flow through the job system.",
      "links": {
        "jobs": "Background jobs",
        "merge": "Merge instructions"
      }
    }
  },
  "mergeInstructionsDoc": {
    "meta": {
      "title": "Merge instructions - PlanToCode",
      "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance."
    },
    "category": "Planning",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Merge Instructions",
    "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance.",
    "intro": "When you have multiple implementation plans that need to be combined, the merge workflow lets you select plans, provide guidance, and generate a unified plan that incorporates the best elements from each source.",
    "processor": {
      "heading": "ImplementationPlanMergeProcessor",
      "description": "The ImplementationPlanMergeProcessor fetches source plan responses, wraps them in XML-tagged sections, and streams the merged result through the LlmTaskRunner.",
      "payload": "Accepts source_job_ids array, optional merge_instructions string, and inherits model configuration from the session.",
      "storage": "Merged plan stored as JobResultData::Text with metadata including source_job_ids, merge_instructions, source_count, merged_at timestamp, and session context."
    },
    "inputs": {
      "heading": "Merge Inputs",
      "items": [
        "Source plans: 2-5 implementation plans selected from the plan list",
        "Merge instructions: User guidance on how to combine (prioritize, resolve conflicts)",
        "Model selection: LLM model for merge generation",
        "Task context: Original task description for reference"
      ]
    },
    "xmlFormat": {
      "heading": "XML-Tagged Source Plans",
      "description": "Source plans are wrapped in XML tags with sequential identifiers:",
      "example": "<task_description>\n  [original task from session]\n</task_description>\n\n<source_plans>\n  <implementation_plan_1>\n    [full plan content from first source]\n  </implementation_plan_1>\n  <implementation_plan_2>\n    [full plan content from second source]\n  </implementation_plan_2>\n</source_plans>\n\n<user_instructions>\n  Prioritize API structure from plan 1.\n  Use database schema from plan 2.\n  Resolve conflicts by preferring newer patterns.\n</user_instructions>"
    },
    "prompt": {
      "heading": "Merge Prompt Structure",
      "description": "The merge prompt includes all context needed for intelligent combination:",
      "sections": [
        "System prompt with merge guidelines",
        "Source plans in XML tags",
        "User's merge instructions",
        "Task description for context",
        "Output format requirements"
      ]
    },
    "visuals": {
      "mergeWalkthrough": {
        "title": "Merge workflow walkthrough",
        "description": "Video showing the complete merge process from selection to output.",
        "videoSrc": "/videos/docs/merge-instructions/walkthrough.mp4",
        "posterSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Placeholder for merge walkthrough video."
      },
      "mergeFlow": {
        "title": "Merge instructions flow",
        "description": "Diagram showing multi-model merge workflow with XML-tagged source plans.",
        "imageSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Merge flow showing source selection, instruction processing, and output generation"
      }
    },
    "rules": {
      "heading": "Merge Rules",
      "description": "The LLM follows these rules when merging plans:",
      "examples": [
        "Preserve file paths exactly as specified in source plans",
        "Combine non-conflicting changes from all sources",
        "For conflicts, follow explicit user instructions",
        "Maintain consistent code style across merged content",
        "Include provenance comments indicating source plan"
      ]
    },
    "output": {
      "heading": "Merged Output",
      "description": "The merged plan is returned as raw text from the LLM, following the same flexible format as individual plans.",
      "provenance": "Each section includes comments indicating which source plan contributed the content.",
      "metadata": "source_job_ids, merge_instructions, source_count, merged_at timestamp, planTitle, summary, isStructured (false), and sessionName stored in job metadata."
    },
    "ui": {
      "heading": "UI Integration",
      "description": "The Implementation Plans panel supports merge workflow:",
      "audit": "Merged plans link back to source plans for complete audit trail."
    },
    "cta": {
      "heading": "Learn about plan generation",
      "description": "Understand how individual plans are created before merging.",
      "links": {
        "plans": "Implementation plans",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "meetingIngestionDoc": {
    "meta": {
      "title": "Meeting and recording ingestion - PlanToCode",
      "description": "How recordings become structured task inputs and artifacts through video analysis."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Meeting & Recording Ingestion",
    "description": "How recordings become structured task inputs and artifacts.",
    "intro": "PlanToCode can process meeting recordings and screen captures to extract task-relevant information. This document describes the ingestion workflow from recording to structured artifacts.",
    "visuals": {
      "ingestionFlow": {
        "title": "Recording ingestion flow",
        "description": "How recordings flow through transcription and analysis.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Recording ingestion flow diagram",
        "caption": "Placeholder for ingestion flow diagram."
      }
    },
    "inputs": {
      "heading": "Supported Inputs",
      "description": "The meeting ingestion pipeline accepts various recording formats:",
      "items": [
        "Screen recordings (MP4, WebM, MOV)",
        "Meeting recordings from Zoom, Meet, Teams",
        "Audio-only files (MP3, WAV, M4A)",
        "Direct screen capture from desktop"
      ]
    },
    "uploadProcess": {
      "heading": "Upload Process",
      "description": "Recordings are uploaded through multipart form data to the server:",
      "stepsHeading": "Processing Steps",
      "steps": [
        "File uploaded to server temporary storage",
        "Metadata extracted (duration, format, resolution)",
        "Audio track separated for transcription",
        "Video frames sampled for visual analysis",
        "Results combined and returned to client"
      ]
    },
    "normalization": {
      "heading": "Format Normalization",
      "description": "Various input formats are normalized before processing. Audio is converted to 16kHz mono WAV for Whisper compatibility. Video is processed at native resolution with configurable frame sampling.",
      "outputs": "Normalized outputs ensure consistent downstream processing regardless of input format."
    },
    "multimodalAnalysis": {
      "heading": "Multimodal Analysis",
      "description": "Recordings with both audio and video are analyzed using multimodal models. Models with {code} prefix support native video understanding.",
      "combined": "Audio transcription and visual analysis are combined to produce a comprehensive understanding of the recording content."
    },
    "transcription": {
      "heading": "Audio Transcription",
      "description": "Audio tracks are transcribed using OpenAI Whisper through the server API.",
      "attribution": "Speaker diarization attempts to attribute text to different speakers when multiple voices are detected.",
      "featuresHeading": "Transcription Features",
      "features": [
        "Multiple language support with auto-detection",
        "Word-level timestamps for alignment",
        "Speaker diarization (multi-speaker)",
        "Punctuation and formatting restoration"
      ]
    },
    "frames": {
      "heading": "Frame Sampling",
      "description": "Video frames are sampled at configurable intervals to capture UI state changes and user actions.",
      "timestamps": "Each frame includes its timestamp for correlation with the audio transcript."
    },
    "structuredExtraction": {
      "heading": "Structured Extraction",
      "description": "The combined analysis produces structured outputs suitable for planning:",
      "extractedHeading": "Extracted Elements",
      "items": [
        "Action items and decisions mentioned",
        "UI elements and navigation paths shown",
        "Error states and issues demonstrated",
        "Technical context for implementation"
      ]
    },
    "artifacts": {
      "heading": "Analysis Artifacts",
      "description": "Meeting analysis produces several artifacts stored in the session:",
      "items": [
        "meeting_transcript: Full text with timestamps",
        "action_items: Extracted tasks and decisions",
        "ui_observations: Visual state changes",
        "combined_context: Merged analysis summary"
      ]
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "desktop/src/components/meeting/MeetingUploader.tsx",
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs"
      ]
    },
    "handoff": {
      "heading": "Planning Handoff",
      "description": "Meeting analysis artifacts can be incorporated into the task description:",
      "pipeline": "The combined context flows into the file discovery and plan generation pipeline, providing rich context for implementation planning."
    },
    "cta": {
      "heading": "Continue to video analysis",
      "description": "Learn more about how video frames are analyzed.",
      "links": {
        "video": "Video analysis",
        "textImprovement": "Text improvement"
      }
    }
  },
  "videoAnalysisDoc": {
    "meta": {
      "title": "Video analysis - PlanToCode",
      "description": "Frame sampling, prompts, and analysis artifacts from screen recordings."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "6 min",
    "title": "Video Analysis",
    "description": "Frame sampling, prompts, and analysis artifacts from recordings.",
    "intro": "Video analysis extracts UI state and action sequences from screen recordings. This enables understanding of user workflows and bug reproduction contexts.",
    "visuals": {
      "frameNotes": {
        "title": "Video analysis pipeline",
        "description": "How frames flow through the analysis model.",
        "imageSrc": "/assets/images/demo-video-analysis.jpg",
        "imageAlt": "Video analysis interface",
        "caption": "The video analysis interface showing frame capture and analysis options."
      }
    },
    "apiEndpoint": {
      "heading": "API Endpoint",
      "endpoint": "Video analysis is handled by {code} on the server. The endpoint accepts multipart form data with the video file and analysis parameters.",
      "payloadHeading": "Payload Fields",
      "payloadFields": [
        "video: The video file (MP4, WebM, MOV)",
        "model: Model identifier for analysis",
        "prompt: Optional custom analysis prompt",
        "max_frames: Maximum frames to sample",
        "fps: Frame sampling rate"
      ]
    },
    "inputs": {
      "heading": "Supported Input Formats",
      "items": [
        "MP4 with H.264 or H.265 codec",
        "WebM with VP8 or VP9 codec",
        "MOV from screen recording tools",
        "Maximum file size: 100MB"
      ]
    },
    "sampling": {
      "heading": "Frame Sampling",
      "description": "Frames are extracted at configurable intervals to balance coverage and API costs. Lower frame rates reduce token usage but may miss rapid changes.",
      "fps": "Default rate is 1 frame per second. For detailed UI analysis, 2-3 FPS may be needed.",
      "parametersHeading": "Sampling Parameters",
      "parameters": [
        "fps: Frames per second to extract (0.5-5)",
        "max_frames: Maximum total frames (10-100)",
        "start_time: Offset to begin sampling",
        "end_time: Offset to stop sampling"
      ]
    },
    "modelRequirements": {
      "heading": "Model Requirements",
      "format": "Video analysis requires vision-capable models. Model identifiers follow {code} format. Currently only {code} models support native video analysis.",
      "reasoning": "Google Gemini models can process video natively, while other vision models require frame-by-frame image analysis."
    },
    "analysis": {
      "heading": "Analysis Process",
      "description": "Sampled frames are sent to the vision model along with the analysis prompt. The model produces structured observations about UI state and user actions.",
      "prompting": "System prompts guide the model to focus on specific aspects of the recording.",
      "promptElementsHeading": "Prompt Elements",
      "promptElements": [
        "UI inventory: List visible elements and controls",
        "Action sequence: Describe user actions in order",
        "Error detection: Identify error states and messages",
        "Navigation paths: Track screen transitions"
      ]
    },
    "outputs": {
      "heading": "Analysis Outputs",
      "items": [
        "frame_observations: Per-frame UI descriptions",
        "action_timeline: Ordered list of user actions",
        "error_summary: Any errors or issues observed",
        "context_summary: High-level workflow description"
      ]
    },
    "billing": {
      "heading": "Token Usage & Billing",
      "description": "Video analysis consumes tokens based on frame count and resolution. Each frame is processed as an image token.",
      "tracked": [
        "tokens_sent: Prompt + image tokens",
        "tokens_received: Analysis response tokens",
        "actual_cost: Computed from model pricing"
      ]
    },
    "storage": {
      "heading": "Result Storage",
      "description": "Analysis results are stored in the background_jobs table with task_type 'video_analysis'. The response contains the full analysis in JSON format.",
      "reuse": "Results can be incorporated into task descriptions or used directly in the planning workflow."
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs",
        "desktop/src/components/video/VideoAnalyzer.tsx"
      ]
    },
    "integration": {
      "heading": "Integration with Planning",
      "description": "Video analysis outputs can feed directly into the task description for context-aware planning.",
      "followup": "The context_summary is particularly useful as a starting point for implementation planning."
    },
    "cta": {
      "heading": "See meeting ingestion",
      "description": "Learn how video analysis fits into the broader meeting ingestion workflow.",
      "links": {
        "meeting": "Meeting ingestion",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "mobileIos": {
    "meta": {
      "title": "iOS client architecture - PlanToCode",
      "description": "Swift workflows, Auth0 login flow, and device-link session management for the iOS companion app."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "iOS Client Architecture",
    "description": "Swift workflows, Auth0 login flow, and device-link session management.",
    "intro": "The PlanToCode iOS app is a companion client that connects to linked desktop sessions. It provides mobile access to terminal output, job status, and voice transcription while maintaining the desktop as the primary planning workspace.",
    "visuals": {
      "app": {
        "title": "iOS app interface",
        "description": "Screenshots of the iOS app showing device linking and terminal view.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode iOS app screenshots",
        "caption": "Placeholder for iOS app screenshots."
      }
    },
    "packageStructure": {
      "heading": "Swift Package Structure",
      "description": "The iOS app is organized into Swift packages:",
      "packages": [
        {
          "name": "Core",
          "path": "mobile/ios/Core/",
          "description": "Business logic and API clients",
          "components": [
            "WorkflowManager",
            "APIClient",
            "MobileSessionManager",
            "DeviceLinkClient"
          ]
        },
        {
          "name": "Security",
          "path": "mobile/ios/Security/",
          "description": "Authentication and credential storage",
          "components": [
            "Auth0Manager",
            "KeychainHelper",
            "TokenStore"
          ]
        },
        {
          "name": "VibeUI",
          "path": "mobile/ios/VibeUI/",
          "description": "SwiftUI components and design system",
          "components": [
            "TerminalView",
            "JobListView",
            "SettingsView",
            "DeviceLinkView"
          ]
        }
      ]
    },
    "auth": {
      "heading": "Auth0 PKCE Integration",
      "description": "The iOS app uses Auth0 with PKCE flow for secure authentication:",
      "flow": [
        "User taps Sign In, app generates code verifier and challenge",
        "ASWebAuthenticationSession opens Auth0 login page",
        "User authenticates and Auth0 redirects with authorization code",
        "App exchanges code for tokens using code verifier",
        "Tokens stored securely in iOS Keychain"
      ],
      "tokenManagement": {
        "heading": "Token Management",
        "items": [
          "Access token used for API requests",
          "Refresh token stored for silent renewal",
          "Token refresh triggered before expiry",
          "Logout clears all tokens from Keychain"
        ]
      }
    },
    "deviceLink": {
      "heading": "Device Linking via WebSocket Relay",
      "description": "iOS connects to desktop sessions through the server's WebSocket relay:",
      "protocol": {
        "heading": "Linking Protocol",
        "steps": [
          "Desktop generates link code and displays QR",
          "iOS scans QR or enters code manually",
          "Both connect to /ws/device-link with credentials",
          "Server validates and establishes relay",
          "Bidirectional communication enabled"
        ]
      },
      "messageTypes": {
        "heading": "Message Types",
        "items": [
          "terminal_output: PTY output from desktop terminal",
          "job_status: Background job status updates",
          "session_sync: Session state synchronization",
          "rpc_command: Commands from mobile to desktop"
        ]
      },
      "reconnection": {
        "heading": "Reconnection Handling",
        "description": "The WebSocket connection handles network interruptions with automatic reconnection, exponential backoff, and session state recovery."
      }
    },
    "rpcRouting": {
      "heading": "RPC Command Routing",
      "description": "iOS can send commands to the linked desktop:",
      "commands": {
        "heading": "Supported Commands",
        "items": [
          "send_terminal_input: Send keystrokes to terminal",
          "request_job_status: Get status of specific job",
          "start_voice_transcription: Begin recording on mobile",
          "sync_session: Request full session state"
        ]
      },
      "implementation": {
        "heading": "Implementation",
        "description": "Commands are JSON-RPC messages sent over WebSocket. Desktop validates commands and returns results asynchronously."
      }
    },
    "offlineQueue": {
      "heading": "Offline Action Queue",
      "description": "Actions performed while disconnected are queued for sync:",
      "architecture": {
        "heading": "Queue Architecture",
        "items": [
          "Actions stored in local SQLite database",
          "Queue processed on reconnection",
          "Conflicts resolved with server timestamps",
          "Failed actions reported to user"
        ]
      },
      "supportedActions": {
        "heading": "Supported Offline Actions",
        "items": [
          "Voice transcription recording (stored locally)",
          "Session notes and annotations",
          "Preference changes"
        ]
      }
    },
    "localStorage": {
      "heading": "SQLite Local Storage",
      "description": "iOS uses SQLite for local persistence:",
      "database": {
        "heading": "Database Schema",
        "path": "~/Documents/plantocode.sqlite",
        "tables": [
          "linked_devices: Desktop connections",
          "offline_queue: Pending sync actions",
          "cached_sessions: Recent session data",
          "transcriptions: Local voice recordings"
        ]
      },
      "migrations": {
        "heading": "Migrations",
        "description": "Schema version tracked in user_version pragma. Migrations run on app launch."
      }
    },
    "sessions": {
      "heading": "Mobile Sessions",
      "description": "MobileSessionManager coordinates session state:",
      "lifecycle": [
        "Load last active session on launch",
        "Connect to linked desktop if available",
        "Subscribe to session updates via WebSocket",
        "Cache session data for offline access"
      ]
    },
    "workflows": {
      "heading": "Workflow Entry Points",
      "description": "Key workflows accessible from mobile:",
      "items": [
        "Terminal monitoring: View output, send input",
        "Job status: Track background job progress",
        "Voice capture: Record and transcribe on mobile",
        "Session browsing: Review plans and history"
      ]
    },
    "region": {
      "heading": "Region Settings",
      "description": "iOS respects user region preference for API routing:",
      "implementation": "Region stored in UserDefaults, used to select api-eu.plantocode.com or api-us.plantocode.com for all requests."
    }
  },
  "providerRouting": {
    "meta": {
      "title": "Provider routing and streaming - PlanToCode",
      "description": "How PlanToCode routes LLM requests through a proxy, normalizes responses, and streams tokens to the desktop client."
    },
    "category": "Research & Models",
    "date": "2025-09-24",
    "readTime": "10 min",
    "title": "Provider Routing and Streaming",
    "description": "Routing layer that mediates all external LLM requests with normalization, streaming, and usage tracking.",
    "visuals": {
      "routingMap": {
        "title": "Provider routing map",
        "description": "Diagram of how requests flow from the desktop app to the proxy and out to providers.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Diagram of provider routing flow from desktop to external providers",
        "caption": "Placeholder for provider routing diagram."
      }
    },
    "cta": {
      "heading": "Continue into model configuration",
      "description": "Model configuration explains how allowed lists and token guardrails are exposed to the UI.",
      "links": {
        "modelConfiguration": "Model configuration",
        "runtimeWalkthrough": "Runtime walkthrough"
      }
    }
  }
}