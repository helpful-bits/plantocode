{
  "meta": {
    "title": "Documentation - PlanToCode",
    "description": "Apprenez à planifier et livrer des modifications de code avec PlanToCode : découverte de fichiers, plans d'implémentation, sessions terminal, garde-fous de modèle et voix."
  },
  "architecture": {
    "meta": {
      "title": "Vue d'ensemble de l'architecture PlanToCode",
      "description": "Couches bureau, orchestration et persistance qui alimentent les plans d'implémentation, les workflows et les sessions terminal."
    },
    "category": "Architecture",
    "date": "2025-09-19",
    "description": "Comment le shell bureau, les workflows en arrière-plan et les services partagés sont organisés.",
    "frontend": {
      "heading": "Surface frontend",
      "providers": "Les providers partagés gèrent les notifications, la configuration d'exécution et l'état des plans. Le panneau Plans d'implémentation conserve les métadonnées du plan, gère la visibilité des modales et demande des estimations de tokens ou du contenu de prompt selon les besoins.",
      "ui": "L'interface bureau est construite avec des composants React. Le contenu des plans d'implémentation est affiché via un visualiseur basé sur Monaco qui virtualise les grands plans, détecte les langages et prend en charge les actions de copie pour que les réviseurs puissent examiner le texte du plan sans problèmes de performance. Les sessions terminal s'affichent dans une vue bufferisée qui se connecte à la sortie PTY et affiche les mises à jour d'état de connexion."
    },
    "intro": "PlanToCode est une application bureau Tauri avec un frontend React. L'interface affiche les plans d'implémentation, les terminaux et les contrôles de configuration, tandis que le backend Rust expose des commandes pour les workflows, l'estimation de tokens et les sessions terminal persistantes. Cette vue d'ensemble résume comment ces éléments s'assemblent.",
    "metaDescription": "Couches bureau, orchestration et persistance qui alimentent les plans d'implémentation, les workflows et les sessions terminal.",
    "metaTitle": "Vue d'ensemble de l'architecture PlanToCode",
    "ogDescription": "Découvrez comment le frontend React, les commandes Tauri et les services en arrière-plan coopèrent dans l'application bureau.",
    "ogTitle": "Vue d'ensemble de l'architecture PlanToCode",
    "persistence": {
      "database": "La sortie terminal et les métadonnées de session sont stockées dans SQLite via le repository des sessions terminal. Chaque enregistrement inclut des identifiants, horodatages, répertoires de travail, variables d'environnement et le log accumulé pour que les redémarrages puissent récupérer la sortie précédente. Le même repository émet des événements quand l'état de la session change.",
      "heading": "Persistance et configuration",
      "modelConfig": "Les valeurs par défaut des modèles résident dans la table de configuration de l'application. Chaque tâche définit un modèle par défaut, une liste d'alternatives autorisées, des budgets de tokens et des préréglages optionnels de boutons de copie. La couche React lit ces paramètres pour alimenter le sélecteur de modèle et les garde-fous."
    },
    "readTime": "7 min",
    "tauriCommands": {
      "commands": "Le côté Rust de l'application expose des commandes pour les workflows, les sessions terminal et les outils de modèle. Les commandes de workflow démarrent des tâches en arrière-plan via le Workflow Orchestrator, validant les entrées et émettant des événements de progression pendant l'exécution du pipeline de découverte de fichiers. Les commandes d'estimation de tokens calculent les tailles de prompt pour le modèle actuellement sélectionné.",
      "heading": "Commandes et services Tauri",
      "terminal": "Les commandes terminal gèrent les processus PTY, suivent les clients distants et vérifient si les binaires CLI supportés sont disponibles avant de lancer une session. Les vérifications de santé combinent l'état PTY avec les enregistrements de base de données pour signaler si une session est toujours active."
    },
    "title": "Architecture PlanToCode",
    "voicePipeline": {
      "description": "La transcription vocale est implémentée comme un hook React qui coordonne les permissions média, la sélection du microphone et les requêtes de transcription en streaming. Le hook s'intègre au terminal de plan et aux éditeurs de prompt, insérant le texte reconnu directement dans le composant actif et affichant des notifications si la transcription échoue.",
      "heading": "Pipeline de transcription vocale"
    },
    "server": {
      "heading": "Couche serveur",
      "description": "Le serveur gère la configuration des providers (clés API dans un vault chiffré, limites de débit, règles de routage pour OpenAI, Anthropic, Google), le routage de modèle (proxy de requêtes, failover automatique, équilibrage de charge, suivi des coûts par utilisateur/projet), la facturation (gestion des abonnements, mesure de l'utilisation, application des quotas, alertes de coût) et les APIs de recherche web (mise en cache des résultats avec TTL de 30/7 jours, restrictions géographiques, auth JWT)."
    },
    "dataFlows": {
      "heading": "Flux de données",
      "description": "Les tâches, plans, jobs et sessions circulent entre les composants : (1) Raffinement de tâche : React UI → TextImprovementPopover → commande Tauri → WorkflowOrchestrator → prompt text_improvement → SQLite → le provider React remplace le texte. (2) Découverte de fichiers : panneau Plans d'implémentation → commande Tauri → 4 jobs séquentiels → événements de progression → SQLite → affichage UI. (3) Plans d'implémentation : Découverte de fichiers → Générer Plan → commande Tauri → streaming LLM → SQLite → visualiseur Monaco → révision/approbation → export. (4) Exécution terminal : session PTY → SQLite → exécution de commande → streaming de sortie → injection de transcription vocale → détection d'attention de l'agent → logs d'audit."
    },
    "visuals": {
      "systemMap": {
        "description": "This diagram depicts the PlanToCode system architecture as four interconnected layers arranged vertically. Top Layer - Desktop Frontend: A React/Next.js box containing components (Plan Viewer, Terminal Panel, Session Manager) connected via labeled arrows \"invoke()\" and \"listen()\" to the Tauri IPC bridge. Second Layer - Rust Backend: WorkflowOrchestrator (scheduling multi-stage jobs), TerminalSessionManager (PTY lifecycle), and job processors (FileDiscovery, PlanGeneration, TextImprovement, DeepResearch). Third Layer - Persistence: SQLite tables for sessions, background_jobs, and terminal_sessions with read/write arrows. Fourth Layer - External Services: Server routes under /api/llm/* and /api/auth with provider icons (OpenAI, Anthropic, Google, OpenRouter). Data flows run down through the layers; streaming responses and job events flow back up to the UI."
      }
    }
  },
  "deepResearch": {
    "meta": {
      "title": "Recherche approfondie - PlanToCode",
      "description": "Documentation technique du workflow de recherche web : intégration API, optimisation des requêtes, traitement des résultats et intégration au workflow de développement."
    },
    "apiIntegration": {
      "heading": "Détails de l'intégration API",
      "pipeline": {
        "description": "Les résultats de recherche passent par un pipeline de traitement standardisé qui extrait les informations significatives tout en préservant le formatage et le contexte. Le pipeline gère différents types de contenu et synthétise les résultats en insights actionnables pour les workflows de développement.",
        "heading": "Pipeline de traitement du contenu"
      },
      "providerConfig": {
        "description": "Le système utilise des modèles de langage IA via OpenRouter pour effectuer des recherches web intelligentes. Le LLM génère des requêtes de recherche ciblées basées sur le contexte de votre tâche et synthétise les résultats à partir de ses données d'entraînement et de ses capacités de recherche web. La sélection et la configuration du modèle sont gérées via les paramètres de l'application.",
        "heading": "Configuration de la recherche IA"
      }
    },
    "architecture": {
      "description": "Le système de recherche approfondie fonctionne comme un workflow en deux étapes : (1) WebSearchPromptsGeneration - l'IA analyse votre tâche et le contexte du projet pour générer des requêtes de recherche ciblées, et (2) WebSearchExecution - le LLM exécute les prompts de recherche en parallèle et synthétise les résultats. Chaque étape est conçue pour la fiabilité, l'efficacité des coûts et la pertinence contextuelle.",
      "heading": "Vue d'ensemble de l'architecture"
    },
    "bestPractices": {
      "examples": {
        "description": "Les patterns d'intégration courants démontrent comment les résultats de recherche web améliorent différents scénarios de développement, du débogage d'erreurs spécifiques à l'implémentation de nouvelles fonctionnalités avec des APIs non familières.",
        "heading": "Exemples d'intégration"
      },
      "heading": "Bonnes pratiques et exemples",
      "strategies": {
        "description": "Pour maximiser la valeur de l'intégration de la recherche web, suivez ces stratégies éprouvées pour formuler des requêtes, interpréter les résultats et intégrer les découvertes dans votre workflow de développement.",
        "heading": "Stratégies de recherche efficaces",
        "queryFormulation": {
          "constraints": "Inclure les contraintes de plateforme ou d'environnement",
          "errors": "Combiner les noms de bibliothèques avec des messages d'erreur spécifiques",
          "heading": "Formulation de requête",
          "practices": "Utiliser « bonnes pratiques » ou « approche recommandée » pour les recherches de patterns",
          "versions": "Inclure des numéros de version spécifiques quand pertinent"
        },
        "resultEvaluation": {
          "crossReference": "Croiser les solutions entre plusieurs sources",
          "dates": "Vérifier les dates de publication pour les informations sensibles au temps",
          "heading": "Évaluation des résultats",
          "official": "Prioriser la documentation officielle par rapport aux sources tierces",
          "verify": "Vérifier les exemples de code dans votre environnement de développement"
        }
      }
    },
    "category": "Référence technique",
    "configuration": {
      "heading": "Configuration et personnalisation",
      "preferences": {
        "description": "Le comportement de recherche est configuré via la sélection du modèle et les paramètres de tâche. Choisissez votre modèle IA préféré pour les tâches de recherche, configurez les timeouts et sélectionnez les fichiers à inclure pour le contexte.",
        "filters": "La sélection du modèle détermine la qualité et le coût de la recherche",
        "heading": "Paramètres de recherche",
        "limits": "Maximum 12 prompts de recherche générés par tâche",
        "optionsHeading": "Options configurables",
        "patterns": "Inclure les fichiers de projet pertinents pour un meilleur contexte",
        "sources": "Répertoire de projet et sélection de fichiers pour le contexte",
        "triggers": "Démarrer la recherche manuellement via la commande de workflow"
      },
      "projectSettings": {
        "description": "La configuration de recherche est consciente de la session. Le système utilise le répertoire de projet de la session actuelle et les fichiers inclus pour fournir le contexte. Les chemins exclus (comme node_modules, dist) sont automatiquement filtrés de l'arborescence de répertoires montrée à l'IA.",
        "heading": "Paramètres spécifiques au projet"
      }
    },
    "costs": {
      "heading": "Considérations de coût",
      "optimization": {
        "description": "Les coûts de recherche sont gérés via la génération intelligente de prompts - le système limite les prompts de recherche à un maximum de 12 par tâche. L'exécution parallèle minimise le temps d'attente. Chaque job suit l'utilisation des tokens et les coûts estimés dans ses métadonnées pour une transparence totale.",
        "heading": "Optimisation des coûts"
      },
      "rateLimiting": {
        "cacheFirst": "Résultats de recherche mis en cache par session pour éviter les requêtes redondantes",
        "description": "La recherche approfondie utilise vos crédits IA configurés via OpenRouter. Chaque tâche de recherche génère plusieurs appels LLM en parallèle, donc les coûts augmentent avec le nombre de prompts de recherche générés. Le système suit l'utilisation des tokens et les coûts par job pour la transparence.",
        "guidelinesHeading": "Conseils de gestion des coûts",
        "heading": "Utilisation et coûts",
        "personal": "Utilisation de tokens suivie par job de recherche avec détail des coûts",
        "team": "Coûts gérés via vos crédits d'abonnement OpenRouter ou PlanToCode",
        "throttling": "Surveiller les métadonnées de job pour les comptages de tokens et coûts estimés"
      }
    },
    "cta": {
      "description": "Les fonctionnalités de recherche approfondie et de recherche web sont disponibles dans l'application bureau PlanToCode. Téléchargez la version pour votre plateforme pour commencer à intégrer la recherche web dans votre workflow de développement.",
      "heading": "Prêt à utiliser la recherche approfondie ?",
      "links": {
        "architecture": "Voir l'architecture système",
        "buildYourOwn": "Construisez votre propre intégration"
      }
    },
    "date": "2025-09-20",
    "description": "Comment PlanToCode effectue des recherches web, traite les résultats et intègre les découvertes dans les workflows de développement.",
    "devIntegration": {
      "caching": {
        "description": "Les résultats de recherche sont stockés dans les métadonnées du job et peuvent être consultés via le panneau de détails du job. Les résultats persistent pendant la durée de la session et peuvent être référencés lors de la création de plans d'implémentation ou de décisions de codage.",
        "heading": "Stockage des résultats"
      },
      "contextAware": {
        "description": "Les requêtes de recherche sont automatiquement enrichies avec le contexte de votre session actuelle. Le système inclut l'arborescence de répertoires de votre projet et le contenu des fichiers sélectionnés dans la phase de génération de prompts, permettant à l'IA de formuler des requêtes de recherche spécifiques à votre codebase.",
        "heading": "Recherche contextuelle"
      },
      "heading": "Intégration au workflow de développement",
      "resultIntegration": {
        "description": "Les résultats de recherche peuvent être utilisés pour éclairer les plans d'implémentation. Quand les tâches de recherche se terminent, les résultats sont formatés comme des tags research_finding qui peuvent être incorporés dans les tâches de planification suivantes, garantissant que votre implémentation est guidée par les bonnes pratiques actuelles et une documentation précise.",
        "heading": "Intégration des résultats"
      }
    },
    "intro": "La fonctionnalité de recherche approfondie permet à PlanToCode d'effectuer des recherches intelligentes alimentées par l'IA, de rassembler des informations pertinentes et d'intégrer les découvertes directement dans les workflows de développement. Ce système utilise de grands modèles de langage pour générer des requêtes de recherche ciblées basées sur le contexte de votre projet, exécuter des tâches de recherche en parallèle et synthétiser des insights actionnables pour améliorer la génération de code et les capacités de résolution de problèmes.",
    "metaDescription": "Documentation technique du workflow de recherche web : intégration API, optimisation des requêtes, traitement des résultats et intégration au workflow de développement.",
    "metaTitle": "Recherche approfondie - PlanToCode",
    "ogDescription": "Comprenez comment la recherche web fonctionne dans PlanToCode : de la génération de requêtes au traitement des résultats et à l'intégration avec les workflows de développement.",
    "ogTitle": "Recherche approfondie - PlanToCode",
    "readTime": "8 min",
    "title": "Recherche approfondie & recherche web",
    "troubleshooting": {
      "commonIssues": {
        "description": "La plupart des problèmes de recherche proviennent de la connectivité API LLM, de crédits insuffisants ou de prompts trop larges. Le système fournit des messages d'erreur clairs et un suivi de l'état des jobs pour le dépannage.",
        "geographic": "Disponibilité des modèles",
        "geographicSolution": "Certains modèles peuvent avoir des restrictions régionales via OpenRouter",
        "heading": "Problèmes courants",
        "noResults": "Aucun prompt de recherche généré",
        "noResultsSolution": "Fournissez des descriptions de tâche plus spécifiques ou incluez des fichiers pertinents pour le contexte",
        "rateLimit": "Erreurs API",
        "rateLimitSolution": "Vérifiez le statut de l'API OpenRouter et le solde de crédits"
      },
      "heading": "Dépannage et support",
      "performance": {
        "description": "Pour des performances optimales, fournissez des descriptions de tâche claires et spécifiques. Incluez les fichiers de projet pertinents pour donner à l'IA un meilleur contexte. Le système exécute les prompts de recherche en parallèle pour minimiser le temps d'exécution total.",
        "heading": "Optimisation des performances"
      }
    },
    "workflow": {
      "execution": {
        "blogs": "Bonnes pratiques et patterns d'implémentation",
        "description": "Les prompts de recherche sont exécutés en parallèle par des modèles de langage IA. Chaque prompt est traité indépendamment, permettant au système de rassembler des informations sur plusieurs aspects de votre tâche simultanément. Les résultats sont synthétisés en découvertes structurées avec des titres et des insights actionnables.",
        "documentation": "Documentation API et spécifications techniques",
        "forums": "Résolution d'erreurs et approches de dépannage",
        "github": "Exemples de code et patterns d'implémentation",
        "heading": "Exécution de la recherche",
        "releases": "Compatibilité de version et guide de migration",
        "sourcesHeading": "Domaines de recherche"
      },
      "heading": "Étapes du workflow de recherche",
      "processing": {
        "deduplication": "Résultats consolidés à travers plusieurs prompts de recherche",
        "description": "Les résultats de recherche sont structurés en format JSON avec des titres et des découvertes détaillées. Le système agrège les résultats des tâches de recherche parallèles, suit les comptages de succès et d'échecs et fournit un résumé des résultats de la recherche. Les résultats sont stockés dans les métadonnées du job pour un accès facile.",
        "extraction": "Découvertes clés extraites et formatées pour l'intégration",
        "heading": "Traitement et synthèse des résultats",
        "scoring": "Résultats organisés par sujet de recherche et pertinence",
        "snippets": "Insights actionnables et recommandations mis en évidence",
        "stepsHeading": "Étapes de traitement",
        "timestamp": "Exécution de la recherche suivie avec métriques de temps"
      },
      "queryGeneration": {
        "api": "Documentation API et recherche spécifique aux bibliothèques",
        "compatibility": "Compatibilité de version et chemins de migration",
        "description": "Les prompts de recherche sont automatiquement générés par l'IA basée sur votre description de tâche, le contexte du projet et les fichiers inclus. Le système analyse la structure de votre codebase via l'arborescence de répertoires et le contenu des fichiers pour formuler des requêtes de recherche ciblées. Jusqu'à 12 prompts de recherche focalisés sont générés par tâche.",
        "errors": "Résolution d'erreurs et approches de débogage",
        "heading": "Génération de prompts",
        "practices": "Bonnes pratiques et patterns recommandés",
        "security": "Considérations de sécurité et sensibilisation aux vulnérabilités",
        "typesHeading": "Sujets de recherche"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Pipeline de recherche approfondie",
        "description": "Le workflow en deux étapes : génération de prompts et exécution de recherche en parallèle.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Diagramme du pipeline de recherche approfondie montrant les étapes de génération de prompts et d'exécution",
        "caption": "Workflow de recherche approfondie montrant la génération de prompts et les étapes d'exécution parallèle"
      },
      "workflow": {
        "title": "Workflow de recherche approfondie",
        "description": "Le workflow en deux étapes : génération de prompts et exécution de recherche en parallèle.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "caption": "Workflow de recherche approfondie montrant toutes les étapes de traitement"
      }
    }
  },
  "fileDiscovery": {
    "meta": {
      "title": "File discovery workflow - PlanToCode",
      "description": "Comprehensive technical guide to the 4-stage AI workflow that identifies and filters relevant files for task execution."
    },
    "apiUsage": {
      "heading": "API Usage Examples",
      "monitoring": "Monitoring Progress",
      "retrieving": "Retrieving Results",
      "starting": "Starting a Workflow"
    },
    "architecture": {
      "caching": "Intermediate results are persisted in SQLite job records for reuse and debugging.",
      "costTracking": "Cost tracking and timeout management for AI operations",
      "distributed": "The system uses a distributed job architecture where each stage runs as an independent background job, enabling cancellation, retry logic, and detailed progress tracking. Real-time events are published throughout execution to provide immediate feedback to the user interface.",
      "errorHandling": "Comprehensive error handling with automatic retry mechanisms",
      "eventDriven": "Event-driven progress reporting with WebSocket-like updates",
      "featuresHeading": "Key Architecture Features:",
      "gitIntegration": "Git integration with fallback to directory traversal",
      "heading": "Workflow Architecture",
      "overview": "The workflow operates as an orchestrated background job system with four distinct stages that execute sequentially. Each stage builds upon the previous stage's output, progressively refining the file selection based on task requirements."
    },
    "category": "Technical Guide",
    "configuration": {
      "exclusion": {
        "description": "Define directories and file patterns to exclude from the discovery process.",
        "heading": "Exclusion Patterns"
      },
      "heading": "Configuration Options",
      "retry": {
        "description": "Set maximum retry attempts for failed stages with exponential backoff.",
        "heading": "Retry Configuration"
      },
      "timeout": {
        "description": "Configure maximum execution time for the entire workflow or individual stages to prevent indefinite hanging.",
        "heading": "Timeout Management"
      },
      "workflowConfig": "Workflow Configuration"
    },
    "cta": {
      "description": "The file discovery workflow runs inside the desktop client alongside implementation planning and terminal sessions.",
      "heading": "Need the desktop app?",
      "links": {
        "architecture": "Learn about architecture",
        "buildYourOwn": "Build your own pipeline"
      }
    },
    "date": "2025-09-21",
    "description": "Comprehensive technical guide to the 4-stage AI workflow that identifies and filters relevant files for task execution.",
    "errorHandling": {
      "commonIssues": {
        "binaryDetection": "Binary file detection: Uses both extension-based and content-based binary detection",
        "gitNotFound": "Git repository not found: Falls back to directory traversal with standard exclusions",
        "heading": "Common Issues",
        "networkTimeout": "Network timeouts: Automatic retry with exponential backoff for transient failures",
        "tokenLimit": "Token limit exceeded: Implements intelligent batching and provides clear error messages"
      },
      "debugging": {
        "description": "The workflow provides comprehensive logging, performance metrics export, and detailed error context including stage information, retry attempts, and intermediate data for troubleshooting.",
        "heading": "Debugging Tools"
      },
      "errorCategories": {
        "billing": "Billing Errors: Insufficient credits or payment failures with actionable guidance",
        "heading": "Error Categories",
        "system": "System Errors: File system access, git command failures, or memory constraints",
        "validation": "Validation Errors: Invalid session ID, missing task description, or invalid project directory",
        "workflow": "Workflow Errors: Stage-specific failures with detailed context and retry suggestions"
      },
      "heading": "Error Handling & Troubleshooting"
    },
    "integration": {
      "desktop": {
        "description": "The workflow integrates seamlessly with the desktop application through Tauri commands, providing native file system access and event-driven updates via the WorkflowTracker class.",
        "heading": "Desktop Application"
      },
      "heading": "Integration Patterns",
      "implementationPlans": {
        "description": "Selected files are automatically fed into the Implementation Plans panel, ensuring that plan generation uses the same optimized file context without requiring re-execution of the discovery workflow.",
        "heading": "Implementation Plans Integration"
      },
      "sessionManagement": {
        "description": "Selected files and task history persist per session so follow-up actions can reuse the same context without rerunning discovery.",
        "heading": "Session Management"
      }
    },
    "intro": "PlanToCode identifies the right files before you plan or run commands. The 4-stage workflow narrows scope and keeps context tight.",
    "metaDescription": "Comprehensive technical guide to the 4-stage AI workflow that identifies and filters relevant files for task execution.",
    "metaTitle": "File discovery workflow - PlanToCode",
    "ogDescription": "Technical documentation for the multi-stage file discovery workflow architecture.",
    "ogTitle": "File discovery workflow - PlanToCode",
    "performance": {
      "costOptimization": {
        "description": "AI stages track actual costs from API responses, implement intelligent batching to minimize token usage, and provide cost estimates before execution to help manage expenses.",
        "heading": "Cost Optimization"
      },
      "heading": "Performance Considerations",
      "memory": {
        "description": "The workflow uses token-aware chunking, streaming responses, and cleanup of temporary data to manage memory. There is no fixed file batch size.",
        "heading": "Memory Management"
      },
      "monitoring": {
        "description": "Built-in performance tracking monitors execution times, memory usage, throughput metrics, and provides recommendations for optimization based on historical data analysis.",
        "heading": "Performance Monitoring"
      }
    },
    "readTime": "12 min",
    "stages": {
      "heading": "4-Stage Workflow Process",
      "stage1": {
        "description": "Uses AI to intelligently select the most relevant root directories from a list of candidate paths based on the task description. The LLM analyzes the primary project directory and candidate roots to determine which directories are most likely to contain files relevant to the task.",
        "heading": "Stage 1: Root Folder Selection",
        "technical": "Technical Details: Receives candidate root directories (up to depth 2) and the task description. The LLM evaluates each path against the task context and returns a filtered list of root directories that will be searched in subsequent stages.",
        "inputOutput": "Input/Output: Receives candidate_roots array and task_description. Returns root_directories array containing the AI-selected directories most relevant to the task."
      },
      "stage2": {
        "binaryDetection": "Binary Detection: Filters out files with binary extensions (.jpg, .png, .pdf, .exe, etc.) and uses content analysis to detect binary files by null bytes and non-printable character ratios.",
        "description": "Uses AI to generate intelligent regex pattern groups based on the task description and directory structure. Each pattern group can include path patterns (positive and negative) and content patterns. The processor then applies these patterns to filter files from each selected root directory.",
        "gitIntegration": "Git Integration: Finds the git repository root for each selected directory and uses git_utils to get all non-ignored files, respecting .gitignore rules while including both tracked and untracked files.",
        "heading": "Stage 2: Regex File Filter",
        "technical": "Technical Details: Generates a directory tree for each root, calls the LLM to produce patternGroups with path_pattern, content_pattern, and negative_path_pattern fields. Uses fancy-regex for lookahead/lookbehind support. Processes roots in parallel with configurable concurrency."
      },
      "stage3": {
        "aiProcessing": "AI Processing: Uses large language models to evaluate file content against task requirements, with intelligent chunking based on actual file sizes and token estimates to manage context windows efficiently.",
        "description": "Employs AI models to analyze file content and assess relevance to the specific task description. This stage performs deep content analysis by reading file contents and having the LLM identify which files are most relevant to the task.",
        "heading": "Stage 3: AI File Relevance Assessment",
        "technical": "Technical Details: Estimates tokens per file using file-type-aware heuristics (code ~3 chars/token, structured data ~5 chars/token). Creates content-aware chunks to stay under the 90k token threshold. Processes chunks in parallel with streaming to avoid timeouts. Validates all LLM-suggested paths against the filesystem."
      },
      "stage4": {
        "description": "Discovers additional relevant files by providing the LLM with the previously identified files and their contents, along with the directory tree. The AI analyzes imports, dependencies, and project structure to find related files that enhance the context for the task.",
        "heading": "Stage 4: Extended Path Finder",
        "relationship": "Relationship Analysis: Reads content of all previously identified files and provides it to the LLM alongside the directory tree (scoped to selected roots if available). The AI identifies additional files based on imports, references, and structural relationships.",
        "technical": "Technical Details: Generates a combined directory tree for selected root directories. Reads content of all initial_paths files. Uses streaming LLM calls to avoid Cloudflare timeouts. Validates discovered paths against the filesystem and normalizes to relative paths within the project."
      }
    },
    "stateManagement": {
      "eventDriven": {
        "description": "The system publishes real-time events for workflow status changes, stage completions, and error conditions. These events enable responsive user interfaces and integration with external monitoring systems.",
        "heading": "Event-Driven Updates"
      },
      "heading": "Workflow State Management",
      "intermediateData": {
        "description": "Each stage stores its output in a structured intermediate data format, including directory tree content, regex patterns, filtered file lists results. This data is accessible for debugging and can be used to resume workflows from specific stages.",
        "heading": "Intermediate Data Storage"
      },
      "transitions": {
        "description": "The workflow progresses through clearly defined states: Created → Running → Paused (optional) → Completed/Failed/Canceled. Each state transition publishes events that can be monitored for real-time updates.",
        "heading": "State Transitions"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "File discovery pipeline",
        "description": "The 4-stage workflow: root folder selection, regex filtering, AI relevance assessment, and extended path discovery.",
        "imageSrc": "/images/docs/file-discovery/pipeline.svg",
        "caption": "File discovery pipeline showing all 4 stages",
        "imageAlt": "Diagram showing the 4-stage file discovery workflow: Root Folder Selection, Regex File Filter, AI File Relevance Assessment, and Extended Path Finder"
      }
    },
    "title": "File Discovery Workflow",
    "sqliteStorage": {
      "heading": "SQLite Storage",
      "description": "All workflow state, intermediate results, and job metadata are persisted in SQLite. Each stage stores its output in the background_jobs table, enabling workflow resumption and debugging. The job records include token usage, cost tracking, and system prompt templates for each AI stage."
    }
  },
  "hub": {
    "ctaDescription": "Téléchargez PlanToCode pour accéder au planificateur d'implémentation, aux garde-fous de modèle, aux sessions terminal et aux fonctionnalités de transcription décrites dans cette documentation.",
    "ctaHeading": "Prêt à essayer ces workflows ?",
    "ctaLinks": {
      "overview": "Commencer par la vue d'ensemble",
      "runtime": "Parcours d'exécution"
    },
    "description": "Apprenez à planifier et livrer des modifications de code avec PlanToCode : découverte de fichiers, plans d'implémentation, sessions terminal, garde-fous de modèle et voix.",
    "exploreHeading": "Explorer la documentation",
    "learnMore": "En savoir plus",
    "searchAriaLabel": "Rechercher dans la documentation",
    "searchPlaceholder": "Rechercher dans la documentation...",
    "searchShortcut": "⌘K",
    "title": "Documentation PlanToCode"
  },
  "onThisPage": {
    "title": "Sur cette page"
  },
  "sidebar": {
    "title": "Documentation"
  },
  "sections": {
    "architecture": {
      "title": "Architecture et fonctionnement interne"
    },
    "inputs": {
      "title": "Entrées et capture"
    },
    "planning": {
      "title": "Pipeline de planification"
    },
    "execution": {
      "title": "Exécution et automatisation"
    },
    "research": {
      "title": "Recherche et modèles"
    },
    "platform": {
      "title": "Build et déploiement"
    }
  },
  "items": {
    "overview": {
      "title": "Vue d'ensemble du système",
      "description": "Commencez ici : ce que fait le système, comment fonctionne la boucle principale et où se trouve chaque composant."
    },
    "runtime-walkthrough": {
      "title": "Parcours d'exécution",
      "description": "Chronologie de bout en bout de ce qui se passe de l'entrée de tâche à l'exécution."
    },
    "architecture": {
      "title": "Architecture système",
      "description": "Comment le shell bureau, les services Rust, les APIs serveur et les couches de persistance s'articulent."
    },
    "desktop-app": {
      "title": "Fonctionnement interne de l'app bureau",
      "description": "Shell Tauri v2, couche de commandes Rust, sessions PTY et gestion de l'état UI."
    },
    "server-api": {
      "title": "API serveur et proxy LLM",
      "description": "Auth, routage de providers, configuration de modèle et endpoints WebSocket."
    },
    "mobile-ios": {
      "title": "Architecture client iOS",
      "description": "Workflows Swift, flux de connexion Auth0 et gestion de session device-link."
    },
    "background-jobs": {
      "title": "Jobs en arrière-plan et orchestration",
      "description": "Enregistrements de jobs, orchestration de workflow, processeurs et streaming d'événements."
    },
    "data-model": {
      "title": "Modèle de données et stockage",
      "description": "Entités SQLite, relations et comment l'état est réhydraté."
    },
    "decisions-tradeoffs": {
      "title": "Décisions techniques et compromis",
      "description": "Pourquoi Tauri, SQLite et un proxy LLM dédié ont été choisis et ce qu'ils coûtent."
    },
    "build-your-own": {
      "title": "Construisez votre propre pipeline",
      "description": "Guide conceptuel pour concevoir des workflows de découverte de fichiers et de génération de plans."
    },
    "meeting-ingestion": {
      "title": "Ingestion de réunions et enregistrements",
      "description": "Comment les enregistrements deviennent des entrées de tâches structurées et des artefacts."
    },
    "video-analysis": {
      "title": "Analyse vidéo",
      "description": "Échantillonnage de frames, prompts et artefacts d'analyse à partir des enregistrements."
    },
    "voice-transcription": {
      "title": "Transcription vocale",
      "description": "Cycle de vie d'enregistrement, paramètres conscients du projet et gestion des périphériques."
    },
    "text-improvement": {
      "title": "Amélioration de texte",
      "description": "Popover de sélection, file de jobs et intégrations pour le nettoyage de prompts."
    },
    "file-discovery": {
      "title": "Workflow de découverte de fichiers",
      "description": "Workflow en arrière-plan qui rassemble les chemins pertinents pour chaque tâche."
    },
    "implementation-plans": {
      "title": "Plans d'implémentation",
      "description": "Comment les plans sont streamés dans le visualiseur Monaco et restent liés à l'historique des plans."
    },
    "merge-instructions": {
      "title": "Instructions de fusion",
      "description": "Comment plusieurs brouillons de plans sont fusionnés en utilisant des plans source balisés XML et les directives utilisateur."
    },
    "prompt-types": {
      "title": "Types de prompts et templates",
      "description": "Catalogue des types de jobs pilotés par prompts et assemblage de templates."
    },
    "terminal-sessions": {
      "title": "Sessions terminal",
      "description": "Sessions PTY persistantes, détection CLI et comportement de récupération."
    },
    "copy-buttons": {
      "title": "Boutons de copie",
      "description": "Transfert de templates des plans vers les terminaux et outils externes."
    },
    "deep-research": {
      "title": "Recherche approfondie et recherche web",
      "description": "Workflow de recherche web, intégration API, optimisation des requêtes et intégration au workflow de développement."
    },
    "provider-routing": {
      "title": "Routage de providers et streaming",
      "description": "Comment les requêtes de providers sont normalisées, streamées et suivies."
    },
    "model-configuration": {
      "title": "Configuration de modèle",
      "description": "Modèles autorisés par tâche et garde-fous de tokens dans le toggle de sélection."
    },
    "server-setup": {
      "title": "Configuration de serveur dédié",
      "description": "Infrastructure basée sur Ansible : hardening de base, déploiement d'app et secrets gérés par vault."
    },
    "tauri-v2": {
      "title": "Guide de développement Tauri v2",
      "description": "Structure de projet, commandes et permissions basées sur les capabilities pour Tauri v2."
    },
    "distribution-macos": {
      "title": "Distribution macOS",
      "description": "Signature, notarisation, packaging DMG et artefacts de mise à jour."
    },
    "distribution-windows": {
      "title": "Distribution Windows et Store",
      "description": "Builds NSIS, packaging MSIX et soumission au Microsoft Store."
    }
  },
  "implementationPlans": {
    "meta": {
      "title": "Plans d'implémentation - Révision des modifications IA",
      "description": "Guide de planification d'implémentation IA. Générez, révisez et approuvez des plans fichier par fichier avant l'exécution. Évitez les doublons et les mauvais chemins."
    },
    "category": "Guide produit",
    "context": {
      "audit": "Plan metadata persists with each job so you can review which inputs were used (task description, selected roots/files, model settings) and compare drafts later.",
      "heading": "Contexte et métadonnées pour la gouvernance d'entreprise",
      "storage": "Le panneau stocke quelles racines de dépôt ont été sélectionnées pendant le workflow de découverte de fichiers pour que les actions de suivi réutilisent la même portée. Il enregistre également les métadonnées spécifiques au plan, comme le répertoire du projet et tout contenu de prompt préparé, pour que les prompts en aval puissent être générés ou copiés sans recalculer le workflow.",
      "tokenEstimation": "L'estimation de tokens s'exécute avant que les prompts ne soient copiés. Le panneau appelle la commande d'estimation de tokens avec le répertoire du projet, les fichiers sélectionnés et le modèle actuellement choisi, affichant les totaux de prompt système et utilisateur pour que les équipes puissent rester sous les limites du modèle."
    },
    "cta": {
      "claudeCodeLink": "Voir le workflow mode plan Claude",
      "codexLink": "Voir le workflow mode plan Codex",
      "cursorLink": "Voir le workflow mode plan Cursor",
      "description": "Les plans d'implémentation avec humain dans la boucle sont disponibles dans l'application bureau PlanToCode. Téléchargez la version pour votre plateforme pour expérimenter un développement assisté par IA sûr et gouverné.",
      "heading": "Prêt à adopter les agents de codage IA en toute sécurité ?",
      "links": {
        "architecture": "Architecture système",
        "decisions": "Décisions et compromis",
        "buildYourOwn": "Construisez votre propre pipeline",
        "fileDiscovery": "Workflow de découverte de fichiers"
      }
    },
    "date": "2025-09-19",
    "description": "How PlanToCode enables confident adoption of AI coding agents through human-in-the-loop review, granular file-by-file plans, and clear handoff workflows.",
    "fileGranularity": {
      "created": "Créés (avec chemins de fichiers complets et structure de contenu initiale)",
      "declaredFiles": "Chaque étape d'un plan déclare explicitement quels fichiers seront :",
      "deleted": "Supprimés (avec justification et analyse des dépendances)",
      "heading": "Granularité fichier par fichier",
      "impact": "Reviewers can immediately identify if critical legacy code will be modified, if breaking changes are proposed, or if the plan touches files that require additional scrutiny.",
      "intro": "Implementation plans use a highly granular structure that breaks down development tasks on a file-by-file basis, with exact file paths corresponding to the project's repository structure. This granularity makes scope explicit before any code is touched.",
      "modified": "Modifiés (avec plages de lignes spécifiques et modifications décrites)",
      "referenced": "Référencés (pour le contexte mais non modifiés)",
      "transmission": "L'approche fichier par fichier permet également une transmission précise des plans approuvés aux agents de codage. Au lieu d'instructions vagues comme « mettre à jour le système d'authentification », les agents reçoivent des spécifications exactes : « modifier src/auth/session_manager.rs lignes 45-67 pour ajouter la rotation de token, créer src/auth/token_store.rs avec la structure suivante... »"
    },
    "hitl": {
      "approve": "Approuver :",
      "approveDesc": "When you are ready, you can hand the plan off to a coding agent or developer for execution.",
      "conclusion": "This workflow keeps execution aligned with the plan you reviewed and helps prevent surprise changes.",
      "edit": "Modifier :",
      "editDesc": "You can directly modify steps, adjust approaches, add constraints, or remove risky operations using VS Code editing features.",
      "heading": "Gouvernance avec humain dans la boucle",
      "intro": "PlanToCode keeps planning human-in-the-loop so you can review, edit, and decide when to hand off a plan for execution.",
      "reject": "Discard:",
      "rejectDesc": "If a draft isn't useful, you can delete it from the session list.",
      "requestChanges": "Demander des modifications :",
      "requestChangesDesc": "Generate alternative plans or merge drafts with custom instructions to converge on the approach you want.",
      "review": "Réviser :",
      "reviewDesc": "Les plans s'ouvrent dans l'éditeur Monaco où les réviseurs peuvent examiner chaque modification proposée avec coloration syntaxique complète et outils d'édition professionnels.",
      "workflow": "Plans are designed for a structured review workflow before any code modifications begin:"
    },
    "intro": "Review and approve every plan before execution. File-by-file granularity keeps scope explicit and changes aligned with your requirements.",
    "metaDescription": "Guide de planification d'implémentation IA. Générez, révisez et approuvez des plans fichier par fichier avant l'exécution. Évitez les doublons et les mauvais chemins.",
    "metaTitle": "Plans d'implémentation - Révision des modifications IA",
    "multiplePlans": {
      "description": "Plans can be merged, deleted, or reopened later. The panel keeps a list of selected plan identifiers, manages a dedicated modal for terminal output tied to a plan, and exposes navigation helpers so reviewers can page through earlier plans without closing the viewer. Terminal access, prompt copy controls, and merge instructions all share the same job identifier so plan history stays consistent.",
      "heading": "Travailler avec plusieurs plans"
    },
    "ogDescription": "Comprenez comment la gouvernance avec humain dans la boucle et les workflows de révision fichier par fichier garantissent un développement IA sûr avec un contrôle complet sur les modifications de code.",
    "ogTitle": "Plans d'implémentation avec humain dans la boucle dans PlanToCode",
    "plansOrigin": {
      "description": "Chaque plan correspond à un job en arrière-plan dans la session actuelle. Le panneau s'abonne aux données de plan, garde une trace de quel plan est actuellement ouvert et expose la navigation entre les jobs plus anciens et plus récents. Ce comportement réside dans {code} et le composant de panneau environnant.",
      "heading": "D'où viennent les plans",
      "processor": "ImplementationPlanProcessor gère la génération de plan. Il lit les fichiers pertinents, génère optionnellement une arborescence de répertoires basée sur les répertoires racine sélectionnés et assemble un prompt unifié pour le LLM.",
      "storage": "Plan responses are stored in the background_jobs table with metadata including planTitle, summary, sessionName, and token usage. The raw LLM response is preserved for review and debugging.",
      "streaming": "Les plans sont streamés via le LlmTaskRunner avec des événements de progression en temps réel. Des avertissements de tokens sont journalisés pour les prompts dépassant 100k tokens mais le traitement continue avec le contenu complet."
    },
    "readTime": "6 min",
    "reviewingPlans": {
      "description": "Le contenu du plan est rendu via le {code} partagé, qui encapsule Monaco Editor. Le visualiseur détecte automatiquement les langages courants, supporte les actions copier-vers-presse-papiers, virtualise les très grands plans et offre des métriques optionnelles comme les comptages de caractères et la coloration syntaxique.",
      "heading": "Réviser les plans avec Monaco",
      "opening": "Quand un plan est ouvert, le panneau résout le plan actif par identifiant de job, passe le contenu à Monaco et permet aux réviseurs de se déplacer entre les jobs voisins sans perdre la modale actuellement ouverte."
    },
    "visuals": {
      "structure": {
        "title": "Structure du plan d'implémentation",
        "description": "Format XML pour les plans d'implémentation avec granularité fichier par fichier et métadonnées.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "caption": "Structure du plan montrant les étapes, fichiers et suivi des dépendances"
      }
    },
    "title": "Plans d'implémentation",
    "planProcessor": {
      "heading": "Pipeline de génération de plan",
      "description": "Le ImplementationPlanProcessor orchestre la génération de plan en chargeant le contenu des fichiers, construisant le contexte et streamant les résultats via le LLM task runner.",
      "inputs": "Contexte de session, description de tâche, fichiers pertinents sélectionnés, arborescence de répertoires optionnelle (configurable via le flag include_project_structure) et flag de recherche web pour la recherche externe.",
      "prompt": "Utilise prompt_utils::build_unified_prompt pour combiner la description de tâche, le contenu complet des fichiers (sans troncature) et l'arborescence de répertoires dans un format spécifique au modèle avec des comptages de tokens estimés.",
      "output": "Réponse LLM brute stockée comme JobResultData::Text. Les métadonnées incluent planTitle, summary, utilisation de tokens, statistiques de cache et coût réel.",
      "display": "Les réponses sont streamées vers l'UI via des événements de progression. Les plans sont rendus dans un VirtualizedCodeViewer basé sur Monaco supportant la coloration syntaxique et les actions de copie."
    },
    "schema": {
      "heading": "Structure de données du plan",
      "description": "Les plans d'implémentation sont stockés comme des réponses LLM brutes avec des métadonnées associées. Le texte de la réponse est préservé exactement tel que généré, tandis que les métadonnées structurées suivent le contexte et l'utilisation du plan.",
      "fieldsHeading": "Champs de métadonnées",
      "fields": [
        "planTitle - Titre généré ou fourni par l'utilisateur pour le plan",
        "summary - Résumé lisible par un humain du plan",
        "sessionName - Nom de la session qui a généré le plan",
        "isStructured - True for implementation_plan jobs; false for merge outputs",
        "isStreaming - False pour les plans terminés (true pendant la génération)",
        "planData - Contient agent_instructions (optionnel) et le tableau steps"
      ],
      "exampleHeading": "Exemple de métadonnées",
      "example": "{\n  \"planTitle\": \"Authentication System Refactor\",\n  \"summary\": \"Implementation plan generated\",\n  \"sessionName\": \"my-project\",\n  \"isStructured\": true,\n  \"isStreaming\": false,\n  \"planData\": {\n    \"agent_instructions\": null,\n    \"steps\": []\n  }\n}"
    }
  },
  "modelConfiguration": {
    "meta": {
      "title": "Configuration des modèles et garde-fous - PlanToCode",
      "description": "Comment PlanToCode vous permet de choisir les modèles autorisés par tâche et maintient les prompts dans la fenêtre de contexte active."
    },
    "category": "Guide Produit",
    "date": "2025-09-20",
    "description": "Listes de modèles par tâche, contrôles de sélection et garde-fous de tokens dans le client desktop.",
    "intro": "PlanToCode traite la sélection de modèle comme une décision au niveau de la tâche. Chaque workflow est livré avec un modèle par défaut et une liste autorisée, et le client desktop expose ces options via un basculeur qui empêche l'envoi de prompts dépassant la fenêtre de contexte active.",
    "metaDescription": "Comment PlanToCode vous permet de choisir les modèles autorisés par tâche et maintient les prompts dans la fenêtre de contexte active.",
    "metaTitle": "Configuration des modèles et garde-fous - PlanToCode",
    "ogDescription": "Découvrez comment les paramètres de modèle par tâche, les basculeurs de sélection et les estimations de tokens fonctionnent ensemble.",
    "ogTitle": "Configuration des modèles et garde-fous - PlanToCode",
    "promptEstimation": {
      "description": "Les comptages de tokens sont calculés via la commande d'estimation de tokens. Le panneau soumet l'identifiant de session, la description de tâche, les fichiers pertinents et le modèle sélectionné pour que le backend puisse retourner les valeurs de tokens système, utilisateur et total. Ces nombres alimentent directement les garde-fous du sélecteur et permettent aux équipes de repérer les prompts hors limite avant de les copier dans un autre outil.",
      "heading": "Estimation de prompt"
    },
    "readTime": "5 min",
    "selectorToggle": {
      "description": "Le panneau Plans d'implémentation affiche les modèles autorisés avec le {code}. Le basculeur affiche chaque modèle autorisé, suit la sélection active et vérifie si le prompt estimé plus les tokens de sortie planifiés tiennent dans la fenêtre de contexte annoncée du modèle avant d'autoriser un changement.",
      "guardrails": "Si un modèle ne peut pas supporter l'exigence totale de tokens, le basculeur désactive le bouton et affiche une infobulle avec le dépassement calculé, maintenant les réviseurs dans des limites sûres avant qu'ils n'envoient du travail à un agent.",
      "heading": "Basculeur de sélection dans le client"
    },
    "taskDefaults": {
      "description": "Les modèles par défaut et les alternatives autorisées sont stockés côté serveur dans la configuration de l'application. Chaque type de tâche - comme les plans d'implémentation, les fusions, la génération de prompts ou la transcription vocale - définit un modèle préféré, une liste d'options autorisées et des limites de tokens que l'application desktop lit au démarrage.",
      "heading": "Paramètres par défaut pilotés par la tâche"
    },
    "title": "Configuration des Modèles"
  },
  "terminalSessions": {
    "meta": {
      "title": "Sessions terminal - PlanToCode",
      "description": "Guide technique de l'implémentation terminal PTY dans PlanToCode. Apprenez comment les sessions persistent, comment fonctionne la détection d'inactivité des agents et les mécanismes de récupération."
    },
    "attentionDetection": {
      "conclusion": "Cette approche vous aide à suivre quand les agents ont terminé des tâches ou ont besoin de conseils, sans essayer de deviner pourquoi ils se sont arrêtés. Les indicateurs d'attention s'effacent automatiquement lorsqu'une nouvelle sortie est reçue.",
      "heading": "Détection d'attention des agents",
      "intro": "Le terminal surveille l'activité des agents via un système de détection d'inactivité à deux niveaux. Quand un agent cesse de produire une sortie, le système vous alerte progressivement pour vérifier ce qui s'est passé :",
      "level1": "Niveau 1 (30 secondes) : \"Agent inactif - peut avoir terminé la tâche\" avec indicateur jaune",
      "level2": "Niveau 2 (2 minutes) : \"L'agent nécessite de l'attention - vérifiez le terminal\" avec indicateur rouge et notification bureau"
    },
    "category": "Guide Produit",
    "date": "2025-09-22",
    "dependencyChecks": {
      "description": "Avant de lancer des commandes, le terminal vérifie la présence d'outils CLI supportés comme claude, cursor, codex et gemini. La même commande rapporte également le shell par défaut pour que les utilisateurs sachent quel environnement sera exécuté. Cela empêche de lancer une session qui ne peut pas trouver le binaire requis.",
      "heading": "Vérifications des dépendances"
    },
    "description": "Sessions PTY persistantes, détection d'attention des agents et comportement de récupération dans le terminal Plans d'implémentation.",
    "intro": "Exécutez des commandes dans un PTY persistant avec vérifications de santé et journalisation. La transcription vocale est disponible quand vous en avez besoin.",
    "lifecycle": {
      "description": "Quand un terminal s'ouvre, le composant UI crée une session PTY et diffuse la sortie via une vue tamponnée. Le composant affiche immédiatement l'état de connexion, transmet les frappes au PTY et réessaie automatiquement si la session échoue. Les métadonnées de session sont stockées dans SQLite avec les horodatages, codes de sortie, répertoires de travail et le journal complet de sortie pour que les redémarrages puissent reprendre le contexte précédent.",
      "heading": "Cycle de vie de la session"
    },
    "metaDescription": "Guide technique de l'implémentation terminal PTY dans PlanToCode. Apprenez comment les sessions persistent, comment fonctionne la détection d'inactivité des agents et les mécanismes de récupération.",
    "metaTitle": "Sessions terminal - PlanToCode",
    "ogDescription": "Comprenez la persistance des sessions, la détection d'attention des agents et la récupération dans le terminal de plan.",
    "ogTitle": "Sessions terminal - PlanToCode",
    "readTime": "6 min",
    "title": "Sessions Terminal",
    "voiceRecovery": {
      "heading": "Transcription vocale et récupération",
      "recovery": "Si une session PTY se déconnecte, la surface du terminal affiche des contrôles de récupération et réessaie la connexion avec un délai exponentiel. Les vérifications de santé continuent de surveiller l'état de la session et fournissent des actions de récupération automatiques lorsque des problèmes de connexion sont détectés.",
      "voice": "Inside the terminal modal, voice transcription can capture speech and paste it into the terminal input area. The recording hook looks up project-level transcription settings, tracks recording state, and inserts transcribed text when the recording stops."
    }
  },
  "copyButtons": {
    "meta": {
      "title": "Copy Buttons - PlanToCode",
      "description": "How template-driven copy buttons resolve placeholders against plans and hand off to terminals or clipboard for agent execution."
    },
    "category": "Execution",
    "date": "2025-09-23",
    "readTime": "10 min",
    "title": "Copy Buttons",
    "description": "Template-driven handoff from implementation plans to PTY terminals and external tools.",
    "intro": "Copy buttons resolve template placeholders against the active plan and then send the result to the clipboard (plan views) or the PTY (terminal modal).",
    "metaTitle": "Copy buttons - PlanToCode",
    "metaDescription": "How template-driven copy buttons resolve placeholders against plans and hand off to terminals or clipboard for agent execution.",
    "ogTitle": "Copy buttons - PlanToCode",
    "ogDescription": "Technical guide to copy button templates, placeholder resolution, and terminal handoff.",
    "visuals": {
      "templateFlow": {
        "title": "Template resolution flow",
        "description": "Templates resolve {{IMPLEMENTATION_PLAN}}, {{TASK_DESCRIPTION}}, and {{STEP_CONTENT}} before copying or sending to the terminal.",
        "imageSrc": "/images/docs/copy-buttons/templates.svg",
        "imageAlt": "Flow showing copy button template resolution",
        "caption": "Placeholder for a template resolution flow diagram."
      }
    },
    "templateConfiguration": {
      "heading": "Template Configuration Sources",
      "description": "Copy button templates follow a layered configuration model. Server defaults provide baseline templates, and project-level overrides customize the implementation_plan task for a given repo.",
      "serverDefaults": {
        "heading": "Server Defaults",
        "description": "Shared templates from /api/config/desktop-runtime-config. Includes button labels and template strings."
      },
      "projectOverrides": {
        "heading": "Project Overrides",
        "description": "Project overrides are stored in SQLite key_value_store under project_task_settings and merged with server defaults."
      },
      "taskSpecific": {
        "heading": "Task-Specific",
        "description": "Copy buttons are configured per task type (implementation_plan) and stored per project. There are no per-job overrides."
      }
    },
    "placeholderResolution": {
      "heading": "Placeholder Resolution",
      "description": "Templates use double-brace placeholders that are resolved against plan content and the current task description.",
      "placeholdersHeading": "Available Placeholders",
      "placeholders": [
        {
          "placeholder": "{{IMPLEMENTATION_PLAN}}",
          "description": "Full implementation plan content as generated by the LLM"
        },
        {
          "placeholder": "{{TASK_DESCRIPTION}}",
          "description": "The task description from the current session"
        },
        {
          "placeholder": "{{STEP_CONTENT}}",
          "description": "Content for the selected plan step (when a step is selected)"
        }
      ],
      "resolutionOrder": "Missing placeholders are replaced with empty strings. Step content is only available when a plan step is selected.",
      "exampleTemplate": "Example template:\n\n{{IMPLEMENTATION_PLAN}}\n\nUnderstand the implementation plan above thoroughly. Analyze the architecture, data flows, and sequence of events.\n\nTask: {{TASK_DESCRIPTION}}"
    },
    "processingPipeline": {
      "heading": "Template Processing Pipeline",
      "description": "When a button is clicked, placeholders are extracted, values are resolved, and the output is sent to clipboard or PTY depending on where the button is used.",
      "steps": [
        {
          "number": 1,
          "title": "Extract Placeholders",
          "description": "Regex scan for {{...}} patterns in the template string"
        },
        {
          "number": 2,
          "title": "Lookup Context",
          "description": "Resolve plan content and task description values for placeholders"
        },
        {
          "number": 3,
          "title": "Substitute Values",
          "description": "Replace placeholders with resolved values"
        },
        {
          "number": 4,
          "title": "Send Output",
          "description": "Copy to clipboard or write to the PTY input buffer"
        }
      ],
      "chunking": {
        "heading": "Large Plan Chunking",
        "description": "When sending to the PTY, the text is chunked into 4KB segments and a carriage return is appended."
      }
    },
    "terminalHandoff": {
      "heading": "PTY Terminal Handoff",
      "description": "In the plan terminal modal, copy buttons write the resolved template to the PTY input buffer as if typed by the user.",
      "detailsHeading": "Handoff Details",
      "details": [
        "Content sent via write_terminal_input_command to the PTY input buffer",
        "Chunked into 4KB segments for large plans",
        "Appends a carriage return after sending"
      ],
      "codeExample": "// Terminal handoff (PlanTerminalModal)\nconst textToSend = replacePlaceholders(button.content, {\n  IMPLEMENTATION_PLAN: planContent,\n  TASK_DESCRIPTION: taskDescription ?? \"\"\n});\nawait sendInChunks(sessionId, textToSend);"
    },
    "clipboardHandoff": {
      "heading": "Clipboard Handoff",
      "description": "In plan cards and plan modals, buttons copy the resolved template to the system clipboard using the browser clipboard API.",
      "crossPlatform": {
        "heading": "Cross-Platform API",
        "description": "Uses navigator.clipboard.writeText() inside the Tauri webview for clipboard access."
      },
      "feedback": {
        "heading": "User Feedback",
        "description": "Toast notification confirms the copy action."
      }
    },
    "defaultButtons": {
      "heading": "Default Copy Buttons",
      "description": "PlanToCode ships with several default copy buttons for implementation plans. These are templates you can edit in settings.",
      "buttonsHeading": "Built-in Buttons",
      "buttons": [
        {
          "id": "parallel-agents",
          "label": "Parallel Claude Coding Agents",
          "description": "Template that instructs Claude Code to launch parallel agents using the plan."
        },
        {
          "id": "investigate-results",
          "label": "Investigate Results",
          "description": "Template that asks the agent to review changes without launching new agents."
        },
        {
          "id": "task-only",
          "label": "Task",
          "description": "Copies only the task description."
        },
        {
          "id": "task-and-plan",
          "label": "Task + Plan",
          "description": "Combines task description and implementation plan for full context."
        },
        {
          "id": "plan-only",
          "label": "Plan",
          "description": "Copies only the implementation plan content."
        }
      ]
    },
    "customization": {
      "heading": "Customizing Copy Buttons",
      "description": "Copy buttons can be customized at multiple levels: global defaults, project-level overrides, and per-task configurations.",
      "globalDefaults": {
        "heading": "Global Defaults",
        "description": "Server-side configuration in /api/config/desktop-runtime-config defines the base set of copy buttons. These are loaded when the desktop app starts and cached for offline use."
      },
      "projectSettings": {
        "heading": "Project-Level Customization",
        "description": "Each project can override the default buttons through the Settings panel. Project-specific buttons are stored in key_value_store and merged with server defaults at runtime."
      },
      "taskSettings": {
        "heading": "Task-Level Configuration",
        "description": "Copy buttons are configured per task type (implementation_plan) and applied per project."
      },
      "editorDescription": "The copy button editor supports drag-and-drop ordering, inline label editing, and template content modification. Changes are persisted automatically."
    },
    "uiIntegration": {
      "heading": "UI Integration and Safety",
      "description": "Copy buttons appear in plan viewers and terminal headers. Clicking a button sends output immediately; there is no preview step by default.",
      "tokenEstimation": {
        "heading": "Token Estimation",
        "description": "Plan cards display token counts for the plan job; copy buttons do not compute per-template token estimates."
      },
      "previewModal": {
        "heading": "Full Preview Modal",
        "description": "There is no dedicated preview modal; open the plan content to inspect what will be copied."
      },
      "disabledState": {
        "heading": "Disabled State",
        "description": "Buttons are disabled when required context is missing (e.g., no active plan, missing session). Tooltips explain what context is needed to enable the button."
      }
    },
    "auditTrail": {
      "heading": "History and signoff",
      "description": "Copy button clicks are not stored in a dedicated table. Plan edits are stored in background_jobs.response and signoff state is recorded in background_jobs.metadata.userSignoff.",
      "schemaHeading": "Notes",
      "schema": "No copy_button_actions table exists in the current release.",
      "fieldsHeading": "Stored plan signals",
      "fields": [
        {
          "field": "background_jobs.response",
          "description": "Plan content after edits or merges"
        },
        {
          "field": "background_jobs.metadata.userSignoff",
          "description": "User signoff state and timestamp"
        }
      ],
      "retention": "No separate retention policy exists for copy button actions; job history retention is controlled in app settings."
    },
    "mobileIntegration": {
      "heading": "Mobile Integration",
      "description": "Copy buttons work in the iOS remote terminal actions bar. Resolved templates are sent to the linked desktop terminal.",
      "deviceLink": {
        "heading": "Device Link Support",
        "description": "When a mobile device is linked to a desktop session, copy buttons can target the desktop terminal directly. The resolved content is sent through the device link WebSocket connection."
      },
      "mobileButtons": {
        "heading": "Mobile-Specific Buttons",
        "description": "Mobile clients use the same copy button configuration stored in project task settings."
      }
    },
    "cta": {
      "heading": "Trace handoff to execution",
      "description": "Terminal sessions show where copy button output lands and how it is logged.",
      "terminalLink": "Terminal sessions",
      "plansLink": "Implementation plans"
    }
  },
  "textImprovement": {
    "meta": {
      "title": "Text improvement - PlanToCode",
      "description": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs."
    },
    "category": "Product Guide",
    "cta": {
      "description": "Download PlanToCode to combine voice capture, video context, and inline rewriting before you generate implementation plans.",
      "heading": "Try text improvement in the desktop app",
      "links": {
        "architecture": "Architecture overview",
        "buildYourOwn": "Build your own"
      }
    },
    "date": "2025-09-21",
    "description": "How PlanToCode rewrites highlighted text without changing formatting and links the result back to your workspace.",
    "intro": "Refine text with AI context. Select text in any editor, trigger a background job, and get improved content that keeps your formatting intact.",
    "metaDescription": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs.",
    "metaTitle": "Text improvement - PlanToCode",
    "ogDescription": "Understand the selection popover, job queue, model configuration, and integrations that power text improvement.",
    "ogTitle": "Text improvement - PlanToCode",
    "readTime": "7 min",
    "selectionPopover": {
      "component": "The popover itself is a minimal component rendered by {code}, which simply triggers the provider hook and shows a loading indicator while a rewrite is running. Because the provider registers global listeners, the popover appears in Monaco plan viewers, the plan terminal dictation field, and any task description inputs without extra wiring.",
      "heading": "Selection popover behaviour",
      "provider": "The {code} listens for selection events on standard inputs and Monaco editors. When you highlight non-empty text it positions a popover near the cursor, stores the selected range, and tracks whether the popover should be visible. Clicking the button kicks off the job and disables the control until the result returns. When the job completes the provider applies the improved text back into the same selection and flushes any pending saves to keep session state in sync."
    },
    "title": "Text Improvement",
    "triggerImprovement": {
      "action": "Pressing the popover button calls {code}. The action validates the selection, ensures a session identifier exists, and invokes the Rust command {code} via Tauri. The command builds a {code} containing the original text and queues a background job against the active session.",
      "backend": "On the backend, the {code} resolves the configured model for the {code} task, wraps the selection in XML tags, and runs the request through the {code} without streaming. When the model response returns it records token usage, cost, and the system prompt template before emitting the improved text back to the UI. The default configuration ships with Claude Sonnet 4.5 and Gemini 3 Pro as the approved models, capped at 4,096 tokens with a temperature of 0.7.",
      "heading": "What happens when you trigger an improvement",
      "metadata": "The background jobs sidebar records the original text in job metadata, so you can review what was sent alongside the rewritten copy. If the selection changes while a job is running, the provider skips replacing the text to avoid clobbering manual edits."
    },
    "videoCapture": {
      "dialog": "The video analysis dialog combines the current task description with an optional focus prompt wrapped in <description> and <video_attention_prompt> tags before sending the job. You can narrate while recording; the resulting summary can be pasted into the task description and refined with the improvement popover.",
      "features": "Video jobs include frame-rate controls, optional audio capture, and usage tracking. Results appear in the background jobs sidebar alongside text improvements.",
      "heading": "Video capture and prompt scaffolding"
    },
    "voiceIntegration": {
      "heading": "Voice transcription integration",
      "hook": "Voice recordings use the {code} hook. It loads per-project transcription defaults, requests microphone access, and inserts transcribed text at the cursor inside the task description or terminal dictation buffer. The inserted text can be highlighted and passed through the improvement popover.",
      "preferences": "Language, model, and temperature preferences persist at the project level, so teams get consistent transcription quality before refining the copy. Silence detection warns about bad audio levels, and a ten-minute cap prevents oversized recordings from blocking improvement jobs with large payloads."
    },
    "visuals": {
      "popoverFlow": {
        "title": "Text improvement flow",
        "description": "Selection popover triggers improvement job and returns enhanced text.",
        "imageSrc": "/images/docs/text-improvement/flow.svg",
        "imageAlt": "Text improvement flow diagram"
      }
    },
    "processorDetails": {
      "heading": "Processor implementation details",
      "processor": "The {code} handles the text rewriting workflow on the Rust backend.",
      "stepsHeading": "Processing steps",
      "steps": [
        "Parse the incoming payload with original text and selection metadata",
        "Build the system prompt from the configured text_improvement template",
        "Submit the request to the LLM task runner without streaming",
        "Extract the improved text from the model response",
        "Record token usage, cost, and prompt template for billing",
        "Emit the result back to the UI via Tauri events"
      ]
    },
    "inlineRewriting": {
      "heading": "Inline rewriting behaviour",
      "description": "When the improved text returns, the provider automatically replaces the original selection. The rewriting preserves whitespace, line breaks, and any inline formatting present in the source. If the editor is Monaco-based, the change is applied as a single undo-able edit operation.",
      "contextsHeading": "Supported contexts",
      "contexts": [
        "Task description input fields",
        "Plan terminal dictation area",
        "Monaco plan viewers and editors",
        "Any standard HTML input or textarea"
      ]
    },
    "modelConfiguration": {
      "heading": "Model configuration",
      "description": "Text improvement uses the text_improvement task configuration from the desktop runtime config. You can override the default model and parameters in the settings panel.",
      "settingsHeading": "Configurable settings",
      "settings": [
        "Allowed models list (default: Claude Sonnet 4.5, Gemini 3 Pro)",
        "Maximum token limit (default: 4096)",
        "Temperature setting (default: 0.7)",
        "System prompt template override"
      ]
    },
    "keyFiles": {
      "heading": "Key implementation files",
      "items": [
        "desktop/src/contexts/TextImprovementProvider.tsx",
        "desktop/src/components/TextImprovementPopover.tsx",
        "desktop/src/actions/text-improvement/index.ts",
        "desktop/src-tauri/src/jobs/processors/text_improvement.rs",
        "server/src/config/task_model_config.rs"
      ]
    }
  },
  "voiceTranscription": {
    "meta": {
      "title": "Voice transcription - PlanToCode",
      "description": "How PlanToCode records audio, sends it to the configured transcription provider, and inserts text into task or terminal inputs."
    },
    "category": "Product Guide",
    "date": "2025-09-22",
    "description": "Recording lifecycle, device management, and transcription behavior for voice-driven prompts.",
    "deviceManagement": {
      "description": "The feature requests microphone permission, enumerates available audio inputs, and lets users choose the active device before recording. Changes take effect on the next recording.",
      "heading": "Device management",
      "monitoring": "Real-time audio level monitoring displays visual feedback during recording. The system warns when audio is silent so you can catch muted microphones before sending the recording."
    },
    "intro": "Voice transcription is available anywhere the desktop app exposes dictation controls, including the plan terminal and prompt editors. The feature records audio locally and sends a single recording to the transcription service when you stop, then inserts text into the active input field without blocking manual typing.",
    "metaDescription": "How PlanToCode records audio, sends it to the configured transcription provider, manages permissions, and inserts text into task or terminal inputs.",
    "metaTitle": "Voice transcription - PlanToCode",
    "ogDescription": "Learn how the recording hook manages devices, permissions, and streaming text.",
    "ogTitle": "Voice transcription - PlanToCode",
    "projectSettings": {
      "description": "When a recording session starts, the hook looks up the active project's transcription configuration so recordings follow the project's preferences.",
      "heading": "Project-aware settings",
      "storage": "Project transcription preferences are stored in SQLite key_value_store under project_task_settings and include the preferred model, language code, prompt, and temperature. Hosted uses managed providers; self-hosting can adjust the allowlist."
    },
    "readTime": "5 min",
    "recordingWorkflow": {
      "description": "The recording hook keeps a state machine with idle, recording, processing, and error states. It records audio into a single blob, enforces a ten-minute cap, and sends the recording on stop.",
      "heading": "Recording workflow",
      "statesHeading": "Recording states",
      "states": [
        "idle: No recording in progress, microphone permissions may or may not be granted",
        "recording: Capturing audio via MediaRecorder with live level monitoring",
        "processing: Uploading the recording to the transcription endpoint and awaiting a response",
        "error: Recording failed due to permission denial, device disconnection, or transcription API error"
      ]
    },
    "routingBehavior": {
      "heading": "Multi-destination routing",
      "description": "Transcribed text is routed based on the active UI context and inserted into the appropriate input.",
      "destinations": [
        "Task description editors: Cursor insertion with optional follow-up text_improvement",
        "Terminal dictation buffer: Command text inserted into PTY input",
        "Prompt editors: Direct insertion into active text inputs"
      ]
    },
    "pipeline": {
      "heading": "Transcription pipeline",
      "hook": "The {code} React hook manages the complete recording lifecycle. It initializes {code} for audio capture in WebM format with Opus codec, monitors audio levels, and handles device switching.",
      "command": "The desktop app invokes {code} to send audio data to the server endpoint {code}. The command validates minimum size (1KB), duration, temperature (0.0-1.0), and prompt length (max 1000 characters); the server enforces max file size (100MB).",
      "constraints": "Audio files must be between 1KB and 100MB. Supported formats: WAV, MP3, M4A, OGG, WebM, FLAC, AAC, and MP4. The transcription model must be specified explicitly and must be in the server allowlist (OpenAI models by default on hosted)."
    },
    "serverProcessing": {
      "heading": "Server-side processing",
      "endpoint": "The server exposes {code} which accepts multipart form data. It routes requests to OpenAI or Google based on the model's provider configuration, validates user credits, and calculates billing based on audio duration.",
      "parametersHeading": "Request parameters",
      "parameters": [
        "file: Audio file data (required) - WAV, MP3, M4A, OGG, WebM, FLAC, AAC, or MP4",
        "model: Transcription model ID (required) - from server allowlist (e.g., openai/gpt-4o-transcribe)",
        "durationMs: Recording duration in milliseconds (required for billing calculation)",
        "language: ISO 639-1 language code (optional) - improves accuracy for specific languages",
        "prompt: Context hint for transcription (optional, max 1000 characters) - helps with domain-specific vocabulary",
        "temperature: Sampling temperature 0.0-1.0 (optional, default 0.0) - lower values produce more deterministic output"
      ]
    },
    "dataFlow": {
      "heading": "Data flow",
      "description": "Audio data flows from the browser through the Tauri command layer to the server, which proxies requests to the appropriate transcription provider.",
      "stepsHeading": "Processing steps",
      "steps": [
        "Browser MediaRecorder captures audio in a single recording (WebM by default)",
        "useVoiceTranscription tracks duration and recording state",
        "On stop, the audio blob is converted to bytes and sent via transcribe_audio_command",
        "Tauri command validates size, duration, temperature, and prompt length",
        "Request sent to server /api/audio/transcriptions endpoint with auth token",
        "Server routes to the configured provider and returns transcribed text",
        "Transcribed text returned to desktop and inserted via callback"
      ]
    },
    "keyFiles": {
      "heading": "Key implementation files",
      "items": [
        "desktop/src/hooks/use-voice-recording/use-voice-transcription.ts",
        "desktop/src/actions/voice-transcription/transcribe.ts",
        "desktop/src-tauri/src/commands/audio_commands.rs",
        "server/src/handlers/proxy/specialized/transcription.rs",
        "server/src/clients/openai/transcription.rs",
        "server/src/clients/google_client.rs"
      ]
    },
    "examples": {
      "heading": "Usage examples",
      "description": "Common voice transcription workflows:",
      "items": [
        "Sprint planning: Dictate tasks, then run text_improvement and task_refinement",
        "Terminal commands: Dictation transcribed and typed directly into PTY for execution",
        "Bug reports: Verbal description captured, refined with text_improvement, then stored in task history",
        "Walkthrough notes: Narrate a screen recording and attach the video analysis summary to the task"
      ]
    },
    "cta": {
      "heading": "Continue exploring",
      "description": "Learn how transcribed text can be refined and how meeting recordings are processed into actionable tasks.",
      "links": {
        "textImprovement": "Text Improvement",
        "meetingIngestion": "Meeting Ingestion"
      }
    },
    "title": "Voice Transcription",
    "visuals": {
      "recordingFlow": {
        "title": "Voice transcription pipeline",
        "description": "Audio capture, provider transcription, and text insertion flow.",
        "imageSrc": "/images/docs/voice-transcription/pipeline.svg",
        "imageAlt": "Voice transcription pipeline diagram",
        "caption": "Audio flows from browser capture through Tauri commands to the configured transcription provider."
      }
    }
  },
  "overview": {
    "meta": {
      "title": "System overview - PlanToCode",
      "description": "Start here: what PlanToCode does, how the core loop works, and where each component lives in the repo."
    },
    "category": "Overview",
    "date": "2025-09-25",
    "readTime": "15 min",
    "title": "System Overview",
    "description": "A concise map of the system, the core loop, and the required dependencies.",
    "intro": "PlanToCode is a desktop workspace that plans and validates code changes before execution. It coordinates a local Rust job engine, a React UI, and a server proxy for LLM calls. The system follows an offline-first architecture where the desktop app operates independently using SQLite for local state, while the server handles authentication, LLM provider routing, and billing. Without LLM provider access (managed on hosted or self-hosted with your keys), the planning and analysis pipelines will not run.",
    "visuals": {
      "systemMap": {
        "title": "System map",
        "description": "Map of the desktop app, the Rust core, local SQLite storage, and the server proxy.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode system map diagram",
        "caption": "Four-layer architecture with data flowing down and events streaming back up."
      }
    },
    "systemLayers": {
      "heading": "System layers",
      "description": "The system is organized into four distinct layers that communicate through well-defined interfaces:",
      "items": [
        "Presentation Layer: React UI with Monaco editors, terminal panels, and workflow controls (desktop/src/)",
        "Command Layer: Tauri commands that bridge React and Rust, handling IPC and state management (desktop/src-tauri/src/commands/)",
        "Processing Layer: Job processors, workflow orchestrator, and business logic in Rust (desktop/src-tauri/src/jobs/)",
        "Persistence Layer: SQLite repositories for local state and server PostgreSQL for auth/billing (desktop/src-tauri/src/db_utils/)"
      ]
    },
    "coreLoop": {
      "heading": "Core loop in practice",
      "description": "Every task flows through a well-defined lifecycle from capture to execution:",
      "steps": [
        "Capture the task from text, voice transcription (via useVoiceTranscription hook), or video recording analysis.",
        "Refine the task description and objectives with text_improvement jobs through TextImprovementProcessor.",
        "Run the file discovery workflow: RootFolderSelectionProcessor selects directories, RegexFileFilterProcessor applies patterns, FileRelevanceAssessmentProcessor scores contents, ExtendedPathFinderProcessor expands context.",
        "Generate implementation plans via ImplementationPlanProcessor, which streams XML-formatted plans to the Monaco viewer.",
        "Optionally merge multiple plan drafts with ImplementationPlanMergeProcessor using XML-tagged source plans.",
        "Execute or export the approved plan through PTY terminal sessions or copy-button templates for external agents.",
        "Persist every job, artifact, and terminal log to SQLite (background_jobs, terminal_sessions tables) for history and recovery."
      ]
    },
    "components": {
      "heading": "Major components",
      "description": "Each component has a specific responsibility and communicates through typed interfaces:",
      "items": [
        "Desktop UI (React) in desktop/src/ with Monaco plan views, terminal panels, and providers (SessionProvider, TextImprovementProvider).",
        "Rust core (Tauri v2) in desktop/src-tauri/ handling commands, jobs, and persistence with capability-based permissions.",
        "Local SQLite schema in desktop/src-tauri/migrations/consolidated_schema.sql with WAL mode for concurrent access.",
        "Server proxy (Actix-Web) in server/src/ for auth, provider routing, streaming responses, and billing via Stripe.",
        "Mobile iOS client in mobile/ios/Core/ with SwiftUI interface, Auth0 PKCE, and WebSocket device linking.",
        "Infrastructure automation in infrastructure/ansible/ for Hetzner (EU) and InterServer (US) dedicated servers."
      ]
    },
    "dependencies": {
      "heading": "Required dependencies",
      "description": "The system requires these external services and resources:",
      "items": [
        "External LLM providers (OpenAI, Anthropic, Google, X.AI, OpenRouter) for plan generation, transcription, and analysis.",
        "Auth0-based authentication with PKCE flow for desktop and mobile sessions.",
        "PostgreSQL 17 and Redis 7+ for server-side user accounts, billing state, and job queues (self-hosted deployments).",
        "Local filesystem access via git ls-files or directory traversal for file discovery workflows.",
        "Whisper-compatible transcription endpoint for voice input processing."
      ]
    },
    "codeMap": {
      "heading": "Where the behavior lives in the repo",
      "description": "Quick reference to key directories and files:",
      "items": [
        "Tauri commands: desktop/src-tauri/src/commands/ (35+ command modules: job_commands.rs, workflow_commands.rs, terminal_commands.rs, session_commands.rs, auth0_commands.rs)",
        "Workflow orchestration: desktop/src-tauri/src/jobs/workflow_orchestrator/ (definition_loader.rs, stage_scheduler.rs, event_emitter.rs, payload_builder.rs)",
        "Job processors: desktop/src-tauri/src/jobs/processors/ (implementation_plan_processor.rs, text_improvement_processor.rs, root_folder_selection_processor.rs)",
        "SQLite repositories: desktop/src-tauri/src/db_utils/ (background_job_repository/, session_repository.rs, terminal_repository.rs)",
        "Server routes: server/src/routes.rs (configure_routes, configure_public_auth_routes, configure_webhook_routes)",
        "LLM proxy handlers: server/src/handlers/proxy_handlers.rs and server/src/handlers/proxy/ (router.rs, providers/)",
        "Provider transformers: server/src/handlers/provider_transformers/ (openai.rs, google.rs, anthropic.rs, xai.rs)",
        "iOS workflows: mobile/ios/Core/Sources/Workflows/WorkflowManager.swift with MobileSessionManager and APIClient",
        "Infrastructure playbooks: infrastructure/ansible/site-base.yml (hardening, PostgreSQL, Redis) and site-app.yml (deployment)"
      ]
    },
    "keyAbstractions": {
      "heading": "Key abstractions",
      "description": "Understanding these core concepts helps navigate the codebase:",
      "items": [
        "Session: Project context stored in sessions table with task_description, included_files, and model preferences. Identified by UUID.",
        "Background Job: LLM-backed operation stored in background_jobs table with task_type, prompt, response, token tracking, and cost.",
        "Workflow: Multi-stage orchestrated process (e.g., file_finder_workflow) coordinated by WorkflowOrchestrator with IntermediateData passing between stages.",
        "Terminal Session: PTY process stored in terminal_sessions with output_log, status, and optional job_id linking for traceability.",
        "Provider: LLM service abstraction in server/src/handlers/proxy/providers/ with request transformation and response normalization."
      ]
    },
    "dataFlowSummary": {
      "heading": "Data flow summary",
      "description": "How data moves through the system for a typical planning task:",
      "items": [
        "User input enters through React components and flows to Tauri commands via @tauri-apps/api/core invoke().",
        "Commands create background_jobs records and dispatch to job processors via the job queue.",
        "Processors build prompts, send requests through the server LLM proxy, and stream responses via Tauri events.",
        "Responses are stored in SQLite and emitted to React providers that update the UI state.",
        "Terminal execution streams PTY output to the UI and persists logs for session recovery."
      ]
    }
  },
  "runtimeWalkthrough": {
    "meta": {
      "title": "Runtime walkthrough - PlanToCode",
      "description": "End-to-end timeline of a task from input to plan output, with job types and artifact flows."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Runtime Walkthrough",
    "description": "End-to-end runtime timeline from task input to plan output.",
    "intro": "This walkthrough traces a single task from initial capture through file discovery, plan generation, and terminal execution. Each stage maps to specific job types and produces artifacts stored in SQLite.",
    "visuals": {
      "timeline": {
        "title": "Runtime timeline",
        "description": "Visual timeline showing task input, workflow stages, and plan output.",
        "imageSrc": "/images/docs/runtime-walkthrough/timeline.svg",
        "imageAlt": "Runtime timeline diagram",
        "caption": "Task execution flows through six stages, with all artifacts persisted to SQLite."
      },
      "walkthroughVideo": {
        "title": "Runtime walkthrough video",
        "description": "Video demonstration of a complete task execution from input to plan output.",
        "videoSrc": "",
        "posterSrc": "",
        "caption": "Video walkthrough placeholder - record a demonstration of the full planning workflow."
      }
    },
    "timeline": {
      "heading": "High-level runtime sequence",
      "description": "A complete task execution follows this sequence of operations:",
      "steps": [
        "User enters or dictates a task description in the desktop UI via TaskDescriptionEditor component.",
        "Optional: text_improvement job refines the raw input through TextImprovementProcessor.",
        "User triggers file discovery workflow via the Implementation Plans panel start_file_finder_workflow command.",
        "WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/ creates a workflow record and schedules stage 1.",
        "Stage 1 (root_folder_selection): RootFolderSelectionProcessor sends directory tree to LLM, stores selected roots in IntermediateData.selectedRoots.",
        "Stage 2 (regex_file_filter): RegexFileFilterProcessor generates patterns, runs git ls-files, stores matches in IntermediateData.locallyFilteredFiles.",
        "Stage 3 (file_relevance_assessment): FileRelevanceAssessmentProcessor chunks file contents, scores relevance, stores in IntermediateData.aiFilteredFiles.",
        "Stage 4 (extended_path_finder): ExtendedPathFinderProcessor expands context with imports and dependencies, stores in IntermediateData.verifiedPaths.",
        "UI receives workflow-completed event via event_emitter.rs, updates file selection display.",
        "User triggers plan generation with selected files via generate_implementation_plan command.",
        "ImplementationPlanProcessor in desktop/src-tauri/src/jobs/processors/implementation_plan_processor.rs streams XML plan content to Monaco viewer via job:stream-progress events.",
        "User reviews plan in VirtualizedCodeViewer component, can edit directly or request merge.",
        "Approved plan is copied to terminal via copy-button templates or exported for external agents.",
        "Terminal session in terminal_commands.rs captures PTY output, detects agent attention states.",
        "All artifacts persist in SQLite background_jobs and terminal_sessions tables for history and session recovery."
      ]
    },
    "jobTypes": {
      "heading": "Job types in the runtime",
      "description": "Each task_type maps to a specific processor and produces distinct artifacts:",
      "items": [
        "text_improvement: TextImprovementProcessor wraps text in XML, sends to LLM, returns refined text. Stored in background_jobs.response.",
        "root_folder_selection: RootFolderSelectionProcessor receives directory tree, returns JSON array of selected directories.",
        "regex_file_filter: RegexFileFilterProcessor generates patterns from task description, applies to git file list.",
        "file_relevance_assessment: FileRelevanceAssessmentProcessor loads file contents, chunks by token limit, scores relevance.",
        "extended_path_finder: ExtendedPathFinderProcessor analyzes imports/dependencies, expands context with related files.",
        "implementation_plan: ImplementationPlanProcessor streams XML-formatted plans with plan_step elements.",
        "implementation_plan_merge: ImplementationPlanMergeProcessor combines plans using source_plans XML tags and user instructions.",
        "video_analysis: Processes screen recordings via /api/llm/video/analyze with a framerate hint.",
        "web_search_prompts_generation: Generates research_task XML blocks for deep research workflow.",
        "web_search_execution: Executes research prompts in parallel, aggregates findings."
      ]
    },
    "inputCapture": {
      "heading": "Task input capture",
      "description": "Tasks enter the system through multiple input surfaces:",
      "text": "Task descriptions are typed or pasted into TaskDescriptionEditor which persists to sessions.task_description and creates history entries in task_description_history table with device_id for multi-device sync.",
      "voice": "Voice input uses useVoiceTranscription hook which records via MediaRecorder API, sends to /api/audio/transcriptions, and inserts at cursor position.",
      "video": "Video analysis uses VideoAnalysisDialog to capture screen recordings, upload to /api/llm/video/analyze, and extract UI state observations."
    },
    "workflowExecution": {
      "heading": "Workflow execution details",
      "description": "The WorkflowOrchestrator coordinates multi-stage workflows:",
      "scheduling": "workflow_lifecycle_manager.rs creates workflow records and stage_scheduler.rs dispatches stages sequentially based on workflow JSON definitions.",
      "data": "IntermediateData structures in workflow_types.rs pass outputs between stages: selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths.",
      "events": "event_emitter.rs publishes workflow-status and workflow-stage Tauri events consumed by WorkflowTracker in the React UI."
    },
    "persistence": {
      "heading": "State persistence",
      "description": "All artifacts are persisted for review and recovery:",
      "jobs": "background_job_repository/ stores job records with session_id, task_type, status, prompt, response, tokens_sent/received, actual_cost.",
      "sessions": "session_repository.rs manages sessions table with task_description, included_files, model_used, history versions.",
      "terminals": "terminal_repository.rs persists terminal_sessions with output_log, status, exit_code, working_directory for session recovery.",
      "rehydration": "On app restart, the Rust core rehydrates session state from SQLite, marks stale running jobs as failed, and restores terminal output logs."
    },
    "inputs": {
      "heading": "Task input capture",
      "capture": "Tasks enter the system through multiple input surfaces: typed text in TaskDescriptionEditor, voice dictation via useVoiceTranscription hook, or video analysis through VideoAnalysisDialog.",
      "artifacts": "Each input type updates SQLite state: task_description in sessions and task_description_history, voice transcription inserts text into the session or terminal input, and video analysis responses are stored in background_jobs."
    },
    "refinement": {
      "heading": "Input refinement",
      "jobs": "The text_improvement job type refines raw input through TextImprovementProcessor, wrapping text in XML and sending to the LLM for grammar, clarity, and structure improvements.",
      "storage": "Refined text is stored in background_jobs.response and can update sessions.task_description via the React provider."
    },
    "discovery": {
      "heading": "File discovery workflow",
      "workflow": "FileFinderWorkflow runs four sequential stages: root_folder_selection narrows directories, regex_file_filter applies patterns, file_relevance_assessment scores content, and extended_path_finder expands with dependencies.",
      "outputs": "Each stage stores results in IntermediateData structures passed between processors, with final file selections persisted to sessions.included_files."
    },
    "planGeneration": {
      "heading": "Plan generation",
      "jobs": "The implementation_plan job type uses ImplementationPlanProcessor to generate XML-formatted plans with plan_step elements containing file paths, operation types, and code changes.",
      "streaming": "Plan content streams to the UI via job:stream-progress Tauri events, displayed in the VirtualizedCodeViewer Monaco component with syntax highlighting."
    },
    "merge": {
      "heading": "Plan merging",
      "instructions": "The implementation_plan_merge job combines multiple plans using source_plans XML tags and user-provided merge instructions to resolve conflicts and consolidate changes.",
      "outputs": "Merged plans maintain traceability to source plans and include merged_from metadata in the final background_jobs record."
    },
    "review": {
      "heading": "Plan review",
      "editor": "Plans open in the Monaco-based VirtualizedCodeViewer for review. Users can edit plan text directly, request modifications, or approve for execution.",
      "audit": "Plan edits are persisted in background_jobs.response; signoff state is recorded in background_jobs.metadata.userSignoff."
    },
    "execution": {
      "heading": "Execution handoff",
      "terminal": "Approved plans are copied to the integrated terminal via copy-button templates, or exported for external agents like Claude Code, Cursor, or Codex.",
      "logging": "Terminal sessions in terminal_commands.rs capture PTY output, detect agent attention states, and log all execution activity to terminal_sessions table."
    },
    "state": {
      "heading": "State persistence",
      "jobs": "All job artifacts persist in background_jobs table with session_id, task_type, status, prompt, response, token counts, and cost tracking.",
      "rehydration": "On app restart, the Rust core rehydrates session state from SQLite, marks stale running jobs as failed, and restores terminal output logs."
    },
    "jobMap": {
      "heading": "Job type mapping",
      "items": [
        "text_improvement → TextImprovementProcessor → refined task descriptions",
        "root_folder_selection → RootFolderSelectionProcessor → selected directories",
        "regex_file_filter → RegexFileFilterProcessor → pattern-matched files",
        "file_relevance_assessment → FileRelevanceAssessmentProcessor → scored files",
        "extended_path_finder → ExtendedPathFinderProcessor → expanded context",
        "implementation_plan → ImplementationPlanProcessor → XML plan documents",
        "implementation_plan_merge → ImplementationPlanMergeProcessor → merged plans"
      ]
    },
    "cta": {
      "heading": "Explore the architecture",
      "description": "Understand how the components fit together in detail.",
      "links": {
        "architecture": "Architecture overview",
        "jobs": "Background jobs",
        "desktop": "Desktop app internals",
        "dataModel": "Data model",
        "plans": "Implementation plans"
      }
    }
  },
  "desktopApp": {
    "meta": {
      "title": "Desktop app internals - PlanToCode",
      "description": "How the Tauri desktop shell, Rust command layer, SQLite persistence, and PTY sessions work together."
    },
    "category": "Desktop",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Desktop App Internals",
    "description": "Tauri v2 shell, Rust command layer, PTY sessions, and UI state management.",
    "intro": "The desktop app is a Tauri v2 shell (version 2.9.1) running a React UI. Rust services expose commands for workflows, terminal sessions, and configuration while persisting state locally in SQLite. The capability-based permission model provides fine-grained security controls for filesystem access, HTTP requests, shell execution, and system notifications.",
    "visuals": {
      "shell": {
        "title": "Desktop shell overview",
        "description": "Screenshot showing the plan editor, terminal tabs, and job status sidebar.",
        "imageSrc": "/assets/images/demo-implementation-plans.jpg",
        "imageAlt": "PlanToCode desktop shell",
        "caption": "The desktop app showing the implementation plans panel and sidebar."
      }
    },
    "projectLayout": {
      "heading": "Project layout",
      "description": "The desktop application follows the standard Tauri v2 structure:",
      "items": [
        "desktop/src/: React UI components, hooks, providers, and desktop-specific adapters.",
        "desktop/src-tauri/: Rust core including commands, jobs, repositories, and services.",
        "desktop/src-tauri/src/lib.rs: Application entry point with plugin registration and AppState management.",
        "desktop/src-tauri/src/commands/: 35+ Tauri command handler modules organized by domain.",
        "desktop/src-tauri/src/jobs/: Background job processors, workflow orchestration, and queue management.",
        "desktop/src-tauri/capabilities/: JSON capability definitions for security permissions (default.json, desktop-default.json, plantocode-api.json).",
        "desktop/src-tauri/migrations/: SQLite schema migrations in consolidated_schema.sql."
      ]
    },
    "ui": {
      "heading": "React UI and surface area",
      "description": "The React UI renders the task description editor, plan viewer, and terminal panels:",
      "components": [
        "TaskDescriptionEditor: Multi-line input with voice transcription integration and text improvement popover.",
        "VirtualizedCodeViewer: Monaco-based plan display with syntax highlighting and copy actions.",
        "TerminalSurface: PTY output buffer with connection status, agent attention indicators, and voice input.",
        "SessionProvider: Global state management for active session, file selections, and model preferences.",
        "TextImprovementProvider: Selection listener and popover positioning for inline rewrites.",
        "WorkflowTracker: Real-time progress display for multi-stage workflows."
      ]
    },
    "commands": {
      "heading": "Tauri commands",
      "description": "Commands in desktop/src-tauri/src/commands/ expose Rust functionality to the React UI. Key modules include:",
      "modules": [
        "job_commands.rs: create_job, get_job, cancel_job, get_jobs_for_session, clear_job_history.",
        "workflow_commands.rs: start_file_finder_workflow, get_workflow_status, retry_workflow, pause_workflow, resume_workflow.",
        "terminal_commands.rs: start_terminal_session, attach_terminal_output, write_terminal_input, resize_terminal_session, get_terminal_metadata, graceful_exit_terminal.",
        "session_commands.rs: create_session, get_session, update_session, sync_task_description_history, sync_file_selection_history.",
        "auth0_commands.rs: initiate_login, complete_login, refresh_token, logout, get_user_info.",
        "implementation_plan_commands.rs: generate_implementation_plan, merge_implementation_plans, estimate_tokens.",
        "config_commands.rs: get_runtime_config, get_model_config, get_system_prompts, refresh_config_cache.",
        "settings_commands.rs: get_setting, set_setting, get_project_system_prompt, set_project_system_prompt."
      ]
    },
    "appState": {
      "heading": "AppState management",
      "description": "The Rust core manages application state through Tauri's state system:",
      "structure": "AppState struct in lib.rs holds: config_load_error (Option<String>), HTTP client (reqwest::Client), RuntimeConfig (server URL, onboarding status) behind Mutex, and Auth0State for authentication.",
      "config": "RuntimeConfig contains server_url, onboarding_complete flag, and is updated via set_runtime_config command. ConfigCache stores runtime AI configuration with per-project overrides.",
      "tokens": "TokenManager uses the OS keyring (via keyring crate) to securely store access_token, refresh_token, and jwt with automatic refresh before expiry."
    },
    "jobs": {
      "heading": "Job processors and workflows",
      "description": "Job processing architecture in desktop/src-tauri/src/jobs/:",
      "queue": "queue.rs manages the job queue with in-memory pending jobs and SQLite persistence. Jobs transition through statuses: idle, created, queued, acknowledged_by_worker, preparing, preparing_input, running, generating_stream, processing_stream, completed, failed, canceled.",
      "processors": "processors/ directory contains task-specific processors: ImplementationPlanProcessor (streaming plans), TextImprovementProcessor (inline rewrites), RootFolderSelectionProcessor, RegexFileFilterProcessor, FileRelevanceAssessmentProcessor, ExtendedPathFinderProcessor.",
      "orchestrator": "workflow_orchestrator/ coordinates multi-stage workflows: definition_loader.rs loads JSON workflow definitions, stage_scheduler.rs dispatches stages, payload_builder.rs constructs inputs, event_emitter.rs publishes progress events.",
      "streaming": "processors/generic_llm_stream_processor.rs handles streaming LLM responses, emitting job:stream-progress events and accumulating content in background_jobs.response."
    },
    "persistence": {
      "heading": "Local persistence",
      "description": "SQLite storage in desktop/src-tauri/migrations/consolidated_schema.sql:",
      "tables": [
        "sessions: id (UUID), name, project_directory, project_hash, task_description, included_files, force_excluded_files, model_used, history versions.",
        "background_jobs: id (UUID), session_id (FK), task_type, status, prompt, response, tokens_sent/received, cache_read/write_tokens, actual_cost, metadata (JSON), server_request_id.",
        "terminal_sessions: id, job_id (nullable FK), session_id, status, process_pid, output_log, working_directory, environment_vars, last_output_at.",
        "task_description_history: session_id (FK), description, device_id, sequence_number, version for multi-device sync.",
        "file_selection_history: session_id (FK), included_files, force_excluded_files, device_id, sequence_number.",
        "project_system_prompts: project_hash, task_type, system_prompt for per-project prompt overrides.",
        "key_value_store: key, value (JSON), updated_at for app settings.",
        "error_logs: timestamp, level, error_type, message, context, stack, metadata for client-side error tracking."
      ],
      "repositories": "Repositories in db_utils/ provide typed access: background_job_repository/ (modular with base.rs, worker.rs, metadata.rs, cleanup.rs), session_repository.rs, terminal_repository.rs, settings_repository.rs, error_log_repository.rs."
    },
    "terminal": {
      "heading": "Terminal sessions",
      "description": "PTY terminal implementation:",
      "commands": "terminal_commands.rs manages session lifecycle: create_terminal_session spawns PTY via portable-pty crate, send_terminal_input forwards keystrokes, resize_terminal adjusts dimensions, check_cli_availability verifies tool presence (claude, cursor, codex, gemini).",
      "persistence": "terminal_repository.rs persists sessions with output_log (accumulated terminal output), status (idle/running/completed/failed/agent_requires_attention), exit_code, working_directory. Sessions can be restored after app restart.",
      "attention": "Agent attention detection monitors last_output_at timestamps. Level 1 (30s idle): yellow indicator. Level 2 (2min idle): red indicator with desktop notification."
    },
    "inputStability": {
      "heading": "Task description stability",
      "description": "The task description editor includes safeguards to prevent cursor jumps:",
      "items": [
        "Remote updates are queued while the user is typing and flushed on idle or blur.",
        "Selection state is tracked and restored after React re-renders.",
        "Background writers call sessionActions.updateCurrentSessionFields to coordinate updates.",
        "Multi-device sync uses sequence_number and version fields to resolve conflicts."
      ]
    },
    "plugins": {
      "heading": "Tauri plugins",
      "description": "PlanToCode uses the Tauri v2 plugin ecosystem:",
      "list": [
        "tauri-plugin-http (2.5.2): HTTP client with CSP-aware fetch for API calls.",
        "tauri-plugin-dialog (2.4.2): Native file/folder picker and message dialogs.",
        "tauri-plugin-shell (2.3.3): Shell command execution for external CLI tools.",
        "tauri-plugin-store (2.4.1): Persistent key-value storage for app settings.",
        "tauri-plugin-notification (2.3.0): Desktop notifications for agent attention.",
        "tauri-plugin-updater (2.9.0): In-app updates with signature verification.",
        "tauri-plugin-single-instance (2.3.4): Single instance enforcement.",
        "tauri-plugin-process (2.3.1): Process restart capability."
      ]
    }
  },
  "serverApi": {
    "meta": {
      "title": "Server API and LLM proxy - PlanToCode",
      "description": "Auth, provider routing, model configuration, and WebSocket endpoints used by desktop and mobile clients."
    },
    "category": "Server",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Server API & LLM Proxy",
    "description": "Auth, provider routing, model configuration, billing, and WebSocket endpoints.",
    "intro": "The server is an Actix-Web service written in Rust that provides authentication, model configuration, LLM proxying, and billing. Desktop and mobile clients depend on it for secure provider routing and streaming responses. The server runs on dedicated infrastructure in two regions: Hetzner (EU) at api-eu.plantocode.com and InterServer (US) at api-us.plantocode.com.",
    "visuals": {
      "flow": {
        "title": "Server request flow",
        "description": "Diagram showing clients, API routes, and the LLM proxy.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Server request flow diagram",
        "caption": "Placeholder for the server request flow."
      }
    },
    "routeOrganization": {
      "heading": "Route organization",
      "description": "Routes are organized in server/src/routes.rs with three configuration functions:",
      "functions": [
        "configure_routes(): JWT-authenticated routes under /api scope. Includes auth, billing, config, providers, models, llm proxy, audio, system-prompts, consent, devices, notifications.",
        "configure_public_auth_routes(): Browser-based auth flow under /auth scope. Includes Auth0 initiate-login, callback, and logged-out routes.",
        "configure_webhook_routes(): Unauthenticated webhook endpoints under /webhooks scope. Currently handles Stripe webhooks."
      ]
    },
    "auth": {
      "heading": "Authentication endpoints",
      "description": "Authentication uses Auth0 with PKCE flow:",
      "routes": [
        "/auth/auth0/initiate-login (GET): Starts OAuth flow with code_challenge, redirects to Auth0.",
        "/auth/auth0/callback (GET): Handles Auth0 redirect, exchanges code for tokens.",
        "/api/auth/userinfo (GET): Returns authenticated user info from Auth0.",
        "/api/auth/logout (POST): Revokes tokens and clears session.",
        "/api/auth/account (DELETE): Account deletion with cascading cleanup.",
        "/api/auth0/refresh-app-token (POST): Refreshes access token using refresh token."
      ],
      "implementation": "Auth handlers in server/src/handlers/auth0_handlers.rs and server/src/handlers/auth/. JWT validation uses services/auth/jwt.rs with JWKS rotation. Revoked tokens tracked in revoked_token_repository.rs."
    },
    "llmProxy": {
      "heading": "LLM proxy and streaming",
      "description": "The LLM proxy normalizes requests across providers and streams responses:",
      "routes": [
        "/api/llm/chat/completions (POST): Main chat completion endpoint. Routes to OpenAI, Anthropic, Google, X.AI, or OpenRouter based on model ID.",
        "/api/llm/video/analyze (POST): Multipart video upload for video analysis (FPS hint). Requires google/* models with video capability.",
        "/api/llm/cancel (POST): Cancels in-flight streaming request by request_id.",
        "/api/llm/status/{request_id} (GET): Returns status of a request (active, completed, cancelled).",
        "/api/audio/transcriptions (POST): Whisper-compatible transcription. Multipart upload with audio file and parameters."
      ],
      "routing": "Router in server/src/handlers/proxy/router.rs selects provider based on model ID prefix (openai/, anthropic/, google/, xai/, openrouter/). Provider-specific handlers in server/src/handlers/proxy/providers/ transform requests and normalize responses.",
      "streaming": "Streaming responses use Server-Sent Events (SSE) via streaming/sse_adapter.rs. The proxy forwards chunks from providers, transforms them to a common format, and tracks token usage in real-time."
    },
    "providers": {
      "heading": "Provider routing",
      "description": "Provider handlers in server/src/handlers/proxy/providers/:",
      "handlers": [
        "openai.rs: OpenAI and OpenAI-compatible APIs (GPT-4, o1, o3).",
        "anthropic.rs: Anthropic Claude models with prompt caching support.",
        "google.rs: Google Gemini models including video analysis capability.",
        "xai.rs: X.AI Grok models.",
        "openrouter.rs: OpenRouter aggregation for model routing."
      ],
      "transformers": "Request/response transformers in server/src/handlers/provider_transformers/ normalize API differences. Each transformer handles: request body format, authentication headers, streaming chunk format, usage extraction, error normalization."
    },
    "config": {
      "heading": "Configuration endpoints",
      "description": "Configuration and model metadata endpoints:",
      "routes": [
        "/api/config/all-configurations (GET): Returns all application configurations including model settings per task type.",
        "/api/config/desktop-runtime-config (GET): Desktop-specific runtime configuration.",
        "/api/config/billing (GET/PUT): Billing configuration management.",
        "/api/providers (GET): List of available LLM providers with capabilities.",
        "/api/providers/with-counts (GET): Providers with model counts.",
        "/api/providers/by-capability/{capability} (GET): Filter providers by capability.",
        "/api/models (GET): All available models with pricing.",
        "/api/models/{id} (GET): Single model details.",
        "/api/models/by-provider/{provider_code} (GET): Models for a specific provider.",
        "/api/models/estimate-cost (POST): Cost estimation for a request.",
        "/api/models/estimate-tokens (POST): Token count estimation.",
        "/api/system-prompts/defaults (GET): Default system prompts by task type."
      ]
    },
    "billing": {
      "heading": "Billing endpoints",
      "description": "Credit-based billing system integrated with Stripe:",
      "routes": [
        "/api/billing/dashboard (GET): User billing dashboard data.",
        "/api/billing/usage-summary (GET): Detailed usage with cost breakdown.",
        "/api/billing/credits/balance (GET): Current credit balance.",
        "/api/billing/credits/details (GET): Credit details including grants and purchases.",
        "/api/billing/credits/unified-history (GET): Transaction history.",
        "/api/billing/checkout/credit-purchase (POST): Create Stripe checkout for credits.",
        "/api/billing/checkout/setup (POST): Create Stripe setup session for payment method.",
        "/api/billing/auto-top-off (GET/PUT): Auto top-off settings management."
      ],
      "implementation": "Billing handlers in server/src/handlers/billing/. Credit service in services/credit_service.rs. Stripe integration via services/stripe_service.rs with webhook handling in webhook_handlers.rs."
    },
    "devices": {
      "heading": "Device management",
      "description": "Device registration and push notifications:",
      "routes": [
        "/api/devices/register (POST): Register desktop device with device_id.",
        "/api/devices/mobile/register (POST): Register mobile device with platform info.",
        "/api/devices/{device_id}/heartbeat (POST): Device heartbeat for presence.",
        "/api/devices/{device_id}/push-token (POST): Save push notification token.",
        "/api/devices/{device_id}/connection-descriptor (GET): WebSocket connection info for device linking.",
        "/api/notifications/job-completed (POST): Send push notification for completed job.",
        "/api/notifications/job-progress (POST): Send progress notification."
      ]
    },
    "websockets": {
      "heading": "WebSocket endpoints",
      "description": "Real-time communication via WebSocket:",
      "endpoints": [
        "/ws/device-link: Relay for desktop-mobile device linking. Handles terminal output streaming, job status updates, and RPC commands between linked devices.",
        "/ws/events: General event stream for real-time updates."
      ],
      "implementation": "Device link relay in server/src/handlers/device_link_ws.rs. Sessions managed by services/relay_session_store.rs with heartbeat monitoring and reconnection support."
    },
    "serverStorage": {
      "heading": "Server-side persistence",
      "description": "PostgreSQL database with repositories in server/src/db/repositories/:",
      "repositories": [
        "user_repository.rs: User accounts linked to Auth0 sub.",
        "customer_billing_repository.rs: Stripe customer and credit state.",
        "credit_transaction_repository.rs: Credit transaction history.",
        "provider_repository.rs: LLM provider configuration.",
        "system_prompts_repository.rs: System prompt templates.",
        "consent_repository.rs: Legal consent tracking.",
        "audit_log_repository.rs: Audit trail for sensitive operations.",
        "revoked_token_repository.rs: JWT revocation list.",
        "api_key_repository.rs: API key management with secure hashing."
      ]
    }
  },
  "backgroundJobs": {
    "meta": {
      "title": "Background jobs - PlanToCode",
      "description": "Job queue architecture, processor types, state machine, and artifact storage for the desktop job engine."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Background Jobs",
    "description": "Job queue, processors, state machine, event streaming, and artifact storage.",
    "intro": "All LLM-backed work runs through the background job system in the desktop app. The job queue dispatches work to processors, streams progress events, and persists every prompt and response in SQLite for review and recovery. This architecture enables cancellation, retry, cost tracking, and real-time UI updates.",
    "visuals": {
      "stateMachine": {
        "title": "Job state machine",
        "description": "Diagram showing job status transitions from created through completion or failure.",
        "imageSrc": "/images/docs/background-jobs/state-machine.svg",
        "imageAlt": "Job state machine diagram",
        "caption": "Placeholder for job state machine diagram."
      }
    },
    "jobRecord": {
      "heading": "Job record structure",
      "description": "Each job creates a background_jobs row in SQLite with these fields:",
      "fields": [
        "id (TEXT PRIMARY KEY): UUID for the job.",
        "session_id (TEXT NOT NULL, FK): References sessions.id with CASCADE DELETE.",
        "task_type (TEXT DEFAULT 'unknown'): Processor identifier (e.g., implementation_plan, text_improvement, root_folder_selection).",
        "status (TEXT): Current state with CHECK constraint for valid values.",
        "prompt (TEXT NOT NULL): Full text sent to the LLM, stored for review and debugging.",
        "response (TEXT): LLM output or error message.",
        "error_message (TEXT): Detailed error information on failure.",
        "tokens_sent (INTEGER DEFAULT 0): Input token count from provider response.",
        "tokens_received (INTEGER DEFAULT 0): Output token count.",
        "cache_read_tokens (INTEGER DEFAULT 0): Tokens read from provider cache (Anthropic).",
        "cache_write_tokens (INTEGER DEFAULT 0): Tokens written to cache.",
        "model_used (TEXT): Model identifier used for the request.",
        "actual_cost (REAL): Computed cost based on token usage and model pricing.",
        "metadata (TEXT): JSON with task-specific data, workflow IDs, stage names.",
        "system_prompt_template (TEXT): Template identifier used for the system prompt.",
        "server_request_id (TEXT): Links to server-side usage tracking.",
        "created_at, updated_at, start_time, end_time (INTEGER): Timestamps.",
        "is_finalized (INTEGER DEFAULT 0): Whether final cost/usage has been recorded."
      ]
    },
    "statusValues": {
      "heading": "Status values and transitions",
      "description": "Jobs transition through well-defined statuses tracked in the database:",
      "statuses": [
        "idle: Initial state before processing starts.",
        "created: Job record created, not yet queued.",
        "queued: Added to job queue, waiting for processor.",
        "acknowledged_by_worker: Processor has picked up the job.",
        "preparing: Processor is gathering inputs (files, prompts).",
        "preparing_input: Building the LLM request payload.",
        "running: Request sent to LLM, awaiting response.",
        "generating_stream: Streaming response in progress.",
        "processing_stream: Processing streamed chunks.",
        "completed: Job finished successfully.",
        "completed_by_tag: Completed via stream end tag detection.",
        "failed: Job failed with error_message populated.",
        "canceled: User requested cancellation."
      ],
      "transitions": "Transitions are enforced in background_job_repository/worker.rs. Invalid transitions are rejected. Status changes emit job:status-changed Tauri events."
    },
    "orchestrator": {
      "heading": "Workflow orchestrator",
      "description": "Multi-stage workflows are managed by WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/:",
      "modules": [
        "mod.rs: Main orchestrator struct and workflow execution entry point.",
        "definition_loader.rs: Loads workflow JSON definitions (e.g., file_finder_workflow.json) specifying stage order and processor types.",
        "stage_scheduler.rs: Schedules stages sequentially, waits for upstream completion.",
        "stage_job_manager.rs: Creates background_job records for each stage.",
        "payload_builder.rs: Constructs stage inputs from IntermediateData.",
        "data_extraction.rs: Extracts outputs from completed stage jobs.",
        "event_emitter.rs: Publishes workflow-status and workflow-stage Tauri events.",
        "state_updater.rs: Updates workflow state in memory and database.",
        "completion_handler.rs: Handles workflow completion and cleanup.",
        "failure_handler.rs: Manages stage failures and retry decisions.",
        "retry_handler.rs: Implements retry logic with exponential backoff."
      ],
      "dataFlow": "Workflows use WorkflowIntermediateData (defined in workflow_types.rs) to pass outputs between stages: directoryTreeContent, selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths, unverifiedPaths."
    },
    "processors": {
      "heading": "Job processors",
      "description": "Each task_type maps to a processor in desktop/src-tauri/src/jobs/processors/:",
      "implementations": [
        "implementation_plan_processor.rs: Loads selected file contents, builds structured prompt with directory tree, streams XML plan to UI. Uses generic_llm_stream_processor for streaming.",
        "text_improvement_processor.rs: Wraps selection in XML tags, sends non-streaming request, returns improved text. Runs via LlmTaskRunner.",
        "root_folder_selection_processor.rs: Sends directory tree to LLM, parses JSON array response of selected directories.",
        "RegexFileFilterProcessor (in processors/mod.rs): Generates regex patterns from task, applies to git file list, filters binaries.",
        "FileRelevanceAssessmentProcessor: Chunks file contents by token limit, scores relevance in batches, aggregates relevant paths.",
        "ExtendedPathFinderProcessor (path_finder_types.rs): Analyzes imports/dependencies, suggests related files, validates paths exist.",
        "web_search_prompts_generator_processor.rs: Generates research_task XML blocks for deep research.",
        "web_search_executor_processor.rs: Executes research prompts in parallel via server search API.",
        "generic_llm_stream_processor.rs: Reusable streaming processor that handles chunk accumulation, event emission, and response finalization."
      ]
    },
    "events": {
      "heading": "Event streaming",
      "description": "Job progress emits Tauri events consumed by the React UI:",
      "eventTypes": [
        "job:status-changed: Payload {jobId, status, error?}. Emitted on every status transition.",
        "job:stream-progress: Payload {jobId, content, tokensReceived}. Emitted for each streaming chunk.",
        "job:completed: Payload {jobId, response, tokensTotal, cost}. Emitted on successful completion.",
        "workflow-status: Payload {workflowId, status, currentStage?}. Workflow-level status updates.",
        "workflow-stage: Payload {workflowId, stageName, status}. Individual stage status."
      ],
      "reactConsumption": "React components subscribe via useEffect with listen() from @tauri-apps/api/event. WorkflowTracker aggregates workflow events. JobStatusIndicator displays real-time status."
    },
    "retry": {
      "heading": "Retry and cancellation",
      "description": "Job retry and cancellation mechanisms:",
      "retryLogic": "retry_handler.rs manages retry counts and delays. Retries use exponential backoff with configurable max attempts. Retry state stored in job.metadata.retryCount.",
      "cancellation": "Cancellation sets a flag checked between streaming chunks in generic_llm_stream_processor.rs. Server-side cancellation sends /api/llm/cancel with request_id.",
      "cleanup": "workflow_cleanup.rs handles cleanup of incomplete workflows. Stale jobs (running status after app restart) are marked failed."
    },
    "artifacts": {
      "heading": "Artifact storage",
      "description": "Job inputs and outputs are fully persisted for review:",
      "stored": [
        "prompt: Complete LLM prompt including system prompt and user content.",
        "response: Full LLM response text or streaming accumulation.",
        "metadata: JSON with task-specific data (original text for improvements, file lists, workflow context).",
        "system_prompt_template: Identifier linking to server-side prompt template version.",
        "Token counts and cost: Captured from provider response for billing and analysis."
      ],
      "access": "background_job_repository provides queries: get_jobs_for_session, get_job_by_id, get_jobs_by_task_type, get_recent_jobs. Job history displayed in BackgroundJobsSidebar component."
    },
    "costTracking": {
      "heading": "Cost tracking",
      "description": "Per-job cost tracking enables budget management:",
      "calculation": "Cost calculated using model pricing from server/src/models/model_pricing.rs. Formula: (tokens_sent * input_price + tokens_received * output_price) with cache adjustments.",
      "accumulation": "Session-level cost aggregated from background_jobs. UI displays cumulative cost in session header.",
      "serverSync": "server_request_id links desktop jobs to server-side usage records for billing reconciliation."
    },
    "cta": {
      "heading": "See the data model",
      "description": "Understand the SQLite schema that stores jobs, sessions, and terminal session logs.",
      "links": {
        "dataModel": "Data model",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "buildYourOwn": {
    "meta": {
      "title": "Build your own pipeline - PlanToCode",
      "description": "Conceptual guide for designing file discovery and plan generation workflows similar to PlanToCode."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Build Your Own Pipeline",
    "description": "Conceptual guide for designing file discovery and plan generation workflows.",
    "intro": "This guide distills the key architectural patterns from PlanToCode into a conceptual blueprint. Whether you want to build a similar system or understand why certain design decisions were made, this document covers the foundational patterns you can reuse or adapt.",
    "visuals": {
      "pipelineMap": {
        "title": "Pipeline architecture map",
        "description": "Overview of the multi-stage pipeline from task input to plan output.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Pipeline architecture diagram",
        "caption": "Placeholder for pipeline architecture diagram."
      }
    },
    "keyPatterns": {
      "heading": "Key Architectural Patterns",
      "jobQueue": {
        "title": "Job Queue Pattern",
        "description": "All LLM-backed operations run as background jobs with status tracking, cancellation support, and retry logic. Jobs are persisted to SQLite so state survives app restarts.",
        "benefits": [
          "Decouples UI responsiveness from LLM latency",
          "Enables cancellation mid-stream",
          "Provides job history of all operations",
          "Supports retry with exponential backoff"
        ],
        "pitfalls": [
          "Job status management adds complexity",
          "Need careful handling of stale jobs on restart",
          "Stream accumulation can consume memory for large responses"
        ]
      },
      "workflowOrchestrator": {
        "title": "Workflow Orchestrator Pattern",
        "description": "Multi-stage workflows are coordinated by an orchestrator that schedules stages sequentially, passes intermediate data between them, and handles failures at any stage.",
        "components": [
          "Definition loader reads workflow JSON specs",
          "Stage scheduler dispatches stages in order",
          "Payload builder constructs inputs from prior outputs",
          "Event emitter publishes progress for UI updates"
        ]
      },
      "repositoryPattern": {
        "title": "Repository Pattern",
        "description": "All persistence goes through typed repositories that abstract SQLite operations. This provides a clean API, enables testing, and centralizes database access.",
        "benefits": [
          "Typed access prevents SQL injection",
          "Repositories can be mocked for testing",
          "Centralized query optimization",
          "Consistent error handling"
        ]
      }
    },
    "steps": {
      "step1": {
        "title": "1. Define your task model",
        "description": "Start by defining what constitutes a task in your system. PlanToCode uses sessions with task descriptions, file selections, and model preferences.",
        "details": "Store task metadata in a dedicated table with versioning for history tracking."
      },
      "step2": {
        "title": "2. Build the job queue",
        "description": "Create a job queue that persists jobs to storage, emits status events, and supports cancellation. Jobs should track prompts, responses, tokens, and cost.",
        "details": "Use a semaphore-based concurrency limiter to control parallel LLM requests."
      },
      "step3": {
        "title": "3. Implement processors",
        "description": "Each job type needs a processor that builds prompts, calls the LLM, and parses responses. Use streaming for long outputs.",
        "details": "Processors should be stateless and receive all context through job parameters."
      },
      "step4": {
        "title": "4. Create the workflow orchestrator",
        "description": "For multi-stage workflows, build an orchestrator that schedules stages, manages intermediate data, and handles failures.",
        "details": "Store workflow definitions as JSON for easy modification without code changes."
      },
      "step5": {
        "title": "5. Add the routing layer",
        "description": "Route LLM requests through a server proxy that normalizes payloads, manages API keys, and tracks usage.",
        "details": "Keep provider credentials on the server; never embed them in desktop clients."
      }
    },
    "architectureDecisions": {
      "heading": "Architecture Decisions",
      "decisions": [
        {
          "question": "Should you use a local database or server-side storage?",
          "recommendation": "Use local SQLite for job state and artifacts. This enables offline operation and fast queries. Sync to server only for billing and cross-device state."
        },
        {
          "question": "Streaming vs non-streaming responses?",
          "recommendation": "Use streaming for plan generation and any output shown progressively. Use non-streaming for short transformations like text improvement."
        },
        {
          "question": "How to handle LLM provider failures?",
          "recommendation": "Implement automatic retry with exponential backoff. Consider a fallback provider like OpenRouter for resilience."
        },
        {
          "question": "Where should file content be loaded?",
          "recommendation": "Load file content in the processor just before building the prompt. This ensures fresh content and avoids storing large blobs in job records."
        }
      ]
    },
    "customizeVsReuse": {
      "heading": "What to Customize vs Reuse",
      "customize": [
        "Prompt templates for your specific use case",
        "File discovery patterns for your project types",
        "Output format (XML, JSON, Markdown)",
        "Model selection per task type"
      ],
      "reuse": [
        "Job queue architecture with status tracking",
        "Workflow orchestrator pattern",
        "Repository pattern for persistence",
        "Streaming response handling",
        "Provider routing and normalization"
      ]
    },
    "commonPitfalls": {
      "heading": "Common Pitfalls to Avoid",
      "items": [
        {
          "pitfall": "Embedding API keys in the client",
          "solution": "Route all LLM requests through a server proxy that manages credentials securely."
        },
        {
          "pitfall": "Not persisting job state",
          "solution": "Store every job with full prompt and response for review and recovery."
        },
        {
          "pitfall": "Blocking UI on LLM calls",
          "solution": "Use background jobs with event-driven UI updates for responsive interfaces."
        },
        {
          "pitfall": "Ignoring token limits",
          "solution": "Estimate tokens before sending and chunk large inputs to stay within context windows."
        },
        {
          "pitfall": "No cancellation support",
          "solution": "Check cancellation flags between streaming chunks and propagate to server."
        }
      ]
    },
    "artifacts": {
      "heading": "Artifacts to Persist",
      "items": [
        "Full prompt sent to the LLM (for debugging and review)",
        "Complete response including streaming accumulation",
        "Token counts from provider response",
        "Computed cost based on model pricing",
        "System prompt template identifier for versioning",
        "Workflow intermediate data for multi-stage flows"
      ]
    },
    "implementationNotes": {
      "heading": "Implementation Notes",
      "items": [
        "Use SQLite with WAL mode for concurrent read/write access",
        "Implement graceful shutdown that marks running jobs as failed",
        "Add health checks for external dependencies before job processing",
        "Log all LLM errors with full context for debugging",
        "Consider caching file content with short TTL to avoid redundant reads"
      ]
    }
  },
  "decisionsTradeoffs": {
    "meta": {
      "title": "Technical decisions and tradeoffs - PlanToCode",
      "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen, and what operational tradeoffs they create."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Technical Decisions & Tradeoffs",
    "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen and what they cost.",
    "intro": "Every architecture involves tradeoffs. This document explains the major technology choices in PlanToCode, what benefits they provide, and what costs or limitations they introduce.",
    "visuals": {
      "tradeoffMatrix": {
        "title": "Tradeoff matrix",
        "description": "Visual comparison of technology choices with their benefits and costs.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Technology tradeoff matrix",
        "caption": "System architecture overview illustrating the technology stack decisions."
      }
    },
    "sections": {
      "tauri": {
        "title": "Tauri v2 for Desktop",
        "description": "Tauri provides a Rust backend with a web-based frontend, enabling cross-platform desktop apps with native performance and small binary sizes.",
        "benefits": [
          "Small binary size (~15MB vs 200MB+ for Electron)",
          "Native Rust performance for file operations and job processing",
          "Capability-based security model with fine-grained permissions",
          "Single codebase for macOS, Windows, and Linux",
          "Access to system APIs (PTY, keychain, notifications)"
        ],
        "tradeoffs": [
          "Smaller ecosystem than Electron",
          "Rust learning curve for backend development",
          "WebView rendering differences across platforms",
          "Less mature tooling for debugging IPC issues"
        ],
        "implementation": "PlanToCode uses Tauri 2.9.1 with ~35 command modules, capability-based permissions, and plugins for shell, dialog, and notifications."
      },
      "sqlite": {
        "title": "SQLite for Local Persistence",
        "description": "SQLite stores all local state including sessions, jobs, terminal output, and settings. This enables offline operation and fast queries.",
        "benefits": [
          "Zero-config embedded database",
          "Fast queries for local data",
          "Enables offline operation",
          "Single file backup and restore",
          "WAL mode for concurrent access"
        ],
        "tradeoffs": [
          "No built-in replication or sync",
          "Large terminal logs can grow the database",
          "Need manual schema migrations",
          "Single-writer limitation (mitigated by WAL)"
        ],
        "implementation": "Schema in consolidated_schema.sql with ~10 tables. Repositories provide typed access with rusqlite."
      },
      "llmProxy": {
        "title": "Dedicated LLM Proxy Server",
        "description": "All LLM requests route through a server proxy that manages API keys, normalizes requests, tracks usage, and handles billing.",
        "benefits": [
          "API keys never leave the server",
          "Single request format for all providers",
          "Centralized usage tracking and billing",
          "Provider failover without client updates",
          "Content filtering and rate limiting"
        ],
        "tradeoffs": [
          "Requires server infrastructure",
          "Adds network latency to requests",
          "Server becomes single point of failure",
          "Need to maintain provider integrations"
        ],
        "implementation": "Actix-Web server with handlers in server/src/handlers/proxy/. Transformers in provider_transformers/ normalize requests."
      },
      "websocket": {
        "title": "WebSocket Relay for Mobile",
        "description": "Desktop and mobile clients connect through a WebSocket relay for device linking, terminal streaming, and job synchronization.",
        "benefits": [
          "Real-time bidirectional communication",
          "No direct P2P networking required",
          "Works across NAT and firewalls",
          "Supports multiple linked devices"
        ],
        "tradeoffs": [
          "Requires persistent server connections",
          "Relay adds latency for large payloads",
          "Connection management complexity",
          "Need reconnection and heartbeat logic"
        ],
        "implementation": "device_link_ws.rs implements the relay with session tracking, heartbeats, and PTC1 binary framing for terminal output."
      }
    },
    "operational": {
      "heading": "Operational Consequences",
      "items": [
        "Tauri: Need separate builds for each platform. CI/CD must cross-compile or use platform-specific runners.",
        "SQLite: Database file grows with terminal output. May need periodic cleanup for long-running instances.",
        "LLM Proxy: Server downtime blocks all LLM operations. Need monitoring and redundancy for production.",
        "WebSocket: Reconnection logic adds complexity. Clients must handle connection drops gracefully."
      ]
    },
    "securityBoundaries": {
      "heading": "Security Boundaries",
      "description": "The architecture creates clear security boundaries that limit exposure:",
      "items": [
        "API keys stored in server vault, never sent to clients",
        "JWT tokens validated on every request with JWKS rotation",
        "Capability-based permissions limit filesystem access",
        "Content sent to LLMs requires explicit user approval",
        "Audit logs track all LLM requests with user context"
      ]
    },
    "whenToReconsider": {
      "heading": "When to Reconsider",
      "description": "These decisions may need revisiting if requirements change significantly:",
      "items": [
        "If browser-only access is required, consider a web-based alternative to Tauri",
        "If multi-device sync is critical, consider server-side job storage",
        "If provider lock-in is acceptable, direct API calls may reduce latency",
        "If mobile is primary, consider native apps instead of device linking"
      ]
    }
  },
  "dataModel": {
    "meta": {
      "title": "Data model and storage - PlanToCode",
      "description": "SQLite entities, relationships, and how state is rehydrated on app restart."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Data Model & Storage",
    "description": "SQLite entities, relationships, and how state is rehydrated.",
    "intro": "PlanToCode uses SQLite for all local state. This document describes the schema, entity relationships, and how state is restored when the app restarts.",
    "sqlite": {
      "heading": "SQLite Configuration",
      "description": "The database uses WAL mode for concurrent read/write access. The file is stored in the Tauri app data directory (~/.local/share/plantocode on Linux, ~/Library/Application Support/plantocode on macOS).",
      "migrations": "Schema migrations are consolidated in consolidated_schema.sql. The app checks schema version on startup and runs any pending migrations."
    },
    "entities": {
      "heading": "Core Entities",
      "items": [
        "sessions: Project context with task description, file selections, model preferences, search settings, video/merge prompts, history indexes",
        "background_jobs: LLM-backed operations with prompt, response, tokens, cost, is_finalized flag, error_message",
        "terminal_sessions: PTY sessions with output log, status, process info",
        "task_description_history: Version history for task descriptions",
        "file_selection_history: Version history for file selections",
        "project_system_prompts: Per-project prompt overrides",
        "key_value_store: App settings and configuration",
        "error_logs: Client-side error tracking",
        "migrations: Tracks applied database migrations with timestamps",
        "db_diagnostic_logs: Records database diagnostic issues and errors",
        "app_settings: Application configuration key-value pairs with descriptions"
      ]
    },
    "visuals": {
      "schema": {
        "title": "Entity relationship diagram",
        "description": "Visual representation of the SQLite schema and relationships.",
        "imageSrc": "/images/docs/data-model/schema.svg",
        "imageAlt": "Database schema diagram",
        "caption": "Placeholder for database schema diagram."
      }
    },
    "relationships": {
      "heading": "Entity Relationships",
      "description": "Entities are linked through foreign keys with cascade delete rules:",
      "links": [
        "sessions → background_jobs: One-to-many, cascade delete",
        "background_jobs → terminal_sessions: Optional one-to-one link via job_id",
        "sessions → task_description_history: One-to-many for version tracking",
        "sessions → file_selection_history: One-to-many for version tracking"
      ]
    },
    "repositories": {
      "heading": "Repository Layer",
      "description": "All database access goes through typed repositories in desktop/src-tauri/src/db_utils/:",
      "examples": [
        "background_job_repository/: Modular with base.rs, worker.rs, metadata.rs, cleanup.rs",
        "session_repository.rs: Session CRUD with history management",
        "terminal_repository.rs: Terminal session persistence and output logging",
        "settings_repository.rs: Key-value settings storage"
      ]
    },
    "rehydration": {
      "heading": "State Rehydration",
      "description": "When the app starts, state is restored from SQLite:",
      "sessions": "Active session is loaded with task description, file selections, and model preferences. Recent sessions are available in the session picker."
    },
    "retention": {
      "heading": "Data Retention",
      "description": "Old data is cleaned up based on configurable retention periods:",
      "exports": "Sessions and jobs can be exported for backup before cleanup."
    },
    "cta": {
      "heading": "Explore job processing",
      "description": "See how background jobs use this data model.",
      "links": {
        "jobs": "Background jobs",
        "terminals": "Terminal sessions"
      }
    }
  },
  "serverSetup": {
    "meta": {
      "title": "Dedicated server setup - PlanToCode",
      "description": "Ansible-based infrastructure setup: base hardening, PostgreSQL, Redis, and application deployment."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Dedicated Server Setup",
    "description": "Ansible-based infrastructure: base hardening, app deployment, and vault-managed secrets.",
    "intro": "PlanToCode runs on dedicated servers managed through Ansible playbooks. This document covers the infrastructure setup, security hardening, and deployment process.",
    "layers": {
      "heading": "Infrastructure Layers",
      "description": "The infrastructure is organized into layers, each managed by dedicated playbooks:",
      "items": [
        "Base layer: OS hardening, SSH configuration, firewall rules",
        "Database layer: PostgreSQL 17 with replication and backups",
        "Cache layer: Redis 7+ for session state and job queues",
        "Application layer: Rust server binary with systemd service",
        "Proxy layer: Nginx reverse proxy with SSL termination"
      ]
    },
    "servers": {
      "heading": "Server Regions",
      "description": "PlanToCode runs in two regions for geographic redundancy:",
      "items": [
        "EU region: Hetzner dedicated server (api-eu.plantocode.com)",
        "US region: InterServer dedicated server (api-us.plantocode.com)"
      ]
    },
    "requirements": {
      "heading": "Server Requirements",
      "items": [
        "Debian 12 or Ubuntu 22.04 LTS",
        "4+ CPU cores, 16GB+ RAM, 200GB+ SSD",
        "Public IPv4 with firewall access to ports 22, 80, 443",
        "SSH key access for Ansible deployment"
      ]
    },
    "hardening": {
      "heading": "Base Hardening",
      "description": "site-base.yml applies security hardening:",
      "items": [
        "Disable root SSH login, require key authentication",
        "Configure UFW firewall with minimal open ports",
        "Install fail2ban for brute force protection",
        "Enable automatic security updates",
        "Configure audit logging"
      ]
    },
    "postgresql": {
      "heading": "PostgreSQL Setup",
      "description": "PostgreSQL 17 is configured for production use:",
      "items": [
        "Connection pooling with PgBouncer",
        "Automated daily backups with pg_dump",
        "WAL archiving for point-in-time recovery",
        "SSL required for all connections",
        "Row-level security for multi-tenant data"
      ]
    },
    "redis": {
      "heading": "Redis Setup",
      "description": "Redis 7+ handles caching and session state:",
      "items": [
        "Password authentication required",
        "AOF persistence for durability",
        "Memory limits with eviction policy",
        "TLS encryption for connections"
      ]
    },
    "zeroDowntime": {
      "heading": "Zero-Downtime Deployment",
      "description": "Deployments use a rolling update strategy:",
      "items": [
        "New binary uploaded alongside running version",
        "Health check confirms new version is ready",
        "Systemd restarts with graceful shutdown",
        "Load balancer drains connections during switch",
        "Rollback available via previous binary symlink"
      ]
    },
    "quickStart": {
      "heading": "Quick Start",
      "steps": [
        "Clone the infrastructure repository",
        "Copy inventory.example to inventory and configure hosts",
        "Set vault password in .vault_pass",
        "Run: ansible-playbook -i inventory site-base.yml",
        "Run: ansible-playbook -i inventory site-app.yml"
      ]
    },
    "vault": {
      "heading": "Secrets Management",
      "description": "Sensitive configuration uses Ansible Vault:",
      "items": [
        "Database credentials",
        "API keys for LLM providers",
        "SSL certificates and private keys",
        "Auth0 client secrets",
        "Stripe webhook secrets"
      ]
    },
    "operations": {
      "heading": "Common Operations",
      "items": [
        "ansible-playbook -i inventory site-app.yml --tags deploy",
        "ansible-playbook -i inventory site-base.yml --tags backup",
        "ansible-playbook -i inventory site-app.yml --tags rollback",
        "ansible-playbook -i inventory site-base.yml --tags logs"
      ]
    },
    "ssl": {
      "heading": "SSL/TLS Configuration",
      "description": "Let's Encrypt provides free SSL certificates:",
      "items": [
        "Certbot configured with Nginx plugin",
        "Automatic renewal via cron job",
        "HSTS headers enabled",
        "TLS 1.2+ only, modern cipher suite"
      ]
    },
    "security": {
      "heading": "Security Checklist",
      "items": [
        "All default passwords changed",
        "SSH key rotation scheduled",
        "Firewall rules audited",
        "Security updates automated",
        "Backup restoration tested"
      ]
    },
    "recovery": {
      "heading": "Disaster Recovery",
      "description": "Recovery procedures for common failure scenarios:",
      "items": [
        "Database corruption: Restore from latest pg_dump backup",
        "Server failure: Provision new server and run playbooks",
        "SSL expiration: Manual certbot renew --force-renewal",
        "Security breach: Rotate all credentials, audit logs"
      ]
    }
  },
  "tauriV2": {
    "meta": {
      "title": "Tauri v2 development guide - PlanToCode",
      "description": "Project layout, commands, capabilities, and development workflow for Tauri v2."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Tauri v2 Development Guide",
    "description": "Project layout, commands, and capability-based permissions for Tauri v2.",
    "intro": "PlanToCode uses Tauri v2 for the desktop application. This guide covers the project structure, command system, capability-based permissions, and development workflow.",
    "projectLayout": {
      "heading": "Project Layout",
      "description": "The desktop application follows standard Tauri v2 conventions:",
      "items": [
        "desktop/src/: React frontend with components, hooks, and providers",
        "desktop/src-tauri/: Rust backend with commands, jobs, and services",
        "desktop/src-tauri/src/lib.rs: Application entry point",
        "desktop/src-tauri/src/commands/: Tauri command handlers (~35 modules)",
        "desktop/src-tauri/capabilities/: Permission definitions",
        "desktop/src-tauri/tauri.conf.json: Tauri configuration"
      ]
    },
    "configuration": {
      "heading": "Tauri Configuration",
      "description": "tauri.conf.json configures the application:",
      "items": [
        "productName, version, identifier for app metadata",
        "build.beforeDevCommand and beforeBuildCommand for frontend",
        "bundle settings for installers (DMG, NSIS, AppImage)",
        "security.csp for Content Security Policy",
        "plugins configuration for official plugins"
      ]
    },
    "capabilities": {
      "heading": "Capability-Based Permissions",
      "description": "Tauri v2 uses capabilities to control what the app can access:",
      "items": [
        "default.json: Base permissions for all windows",
        "desktop-default.json: Desktop-specific permissions",
        "plantocode-api.json: Custom permissions for PlanToCode commands",
        "Permissions grant access to: filesystem, shell, http, dialog, notification"
      ]
    },
    "plugins": {
      "heading": "Tauri Plugins",
      "description": "PlanToCode uses several official Tauri plugins:",
      "items": [
        "tauri-plugin-http: HTTP client for API calls",
        "tauri-plugin-dialog: Native file/folder pickers",
        "tauri-plugin-shell: Shell command execution",
        "tauri-plugin-store: Persistent key-value storage",
        "tauri-plugin-notification: Desktop notifications",
        "tauri-plugin-updater: In-app updates",
        "tauri-plugin-single-instance: Single instance enforcement"
      ]
    },
    "appState": {
      "heading": "Application State",
      "description": "Rust state managed through Tauri's state system:",
      "items": [
        "AppState struct holds shared state",
        "RuntimeConfig for server URLs and feature flags",
        "TokenManager for secure credential storage",
        "ConfigCache for AI model configuration"
      ]
    },
    "commands": {
      "heading": "Creating Commands",
      "description": "Tauri commands expose Rust functions to the frontend:",
      "items": [
        "Use #[tauri::command] attribute on async functions",
        "Return Result<T, String> for error handling",
        "Access state via State<AppState> parameter",
        "Register in lib.rs invoke_handler"
      ]
    },
    "singleInstance": {
      "heading": "Single Instance",
      "description": "The app enforces single instance to prevent data conflicts:",
      "items": [
        "tauri-plugin-single-instance handles detection",
        "Second launch focuses existing window",
        "Deep links forwarded to running instance"
      ]
    },
    "devWorkflow": {
      "heading": "Development Workflow",
      "description": "Common commands for development:",
      "items": [
        "pnpm tauri dev: Start development with hot reload",
        "pnpm tauri build: Build production release",
        "cargo test: Run Rust tests",
        "cargo clippy: Lint Rust code"
      ]
    },
    "mobile": {
      "heading": "Mobile Considerations",
      "description": "Tauri v2 supports mobile, but PlanToCode uses native Swift:",
      "items": [
        "iOS app built with SwiftUI for native experience",
        "Shared API contracts between desktop and mobile",
        "Device linking via WebSocket relay"
      ]
    },
    "distribution": {
      "heading": "Distribution",
      "description": "Build artifacts for each platform:",
      "items": [
        "macOS: .dmg with universal binary (Intel + Apple Silicon)",
        "Windows: NSIS installer and MSIX package",
        "Linux: AppImage for broad compatibility"
      ]
    }
  },
  "distributionMacos": {
    "meta": {
      "title": "macOS distribution - PlanToCode",
      "description": "Code signing, notarization, DMG packaging, and updater configuration for macOS."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "macOS Distribution",
    "description": "Signing, notarization, DMG packaging, and updater artifacts.",
    "intro": "Distributing on macOS requires code signing, notarization, and proper packaging. This document covers the complete process for PlanToCode.",
    "signing": {
      "heading": "Code Signing",
      "description": "All binaries must be signed with an Apple Developer ID:",
      "items": [
        "Developer ID Application certificate for app signing",
        "Developer ID Installer certificate for PKG signing",
        "Certificates stored in CI secrets, imported to keychain",
        "Hardened runtime enabled for notarization compatibility"
      ]
    },
    "entitlements": {
      "heading": "Entitlements",
      "description": "Required entitlements for PlanToCode features:",
      "items": [
        "com.apple.security.cs.allow-jit",
        "com.apple.security.cs.allow-unsigned-executable-memory",
        "com.apple.security.device.audio-input",
        "com.apple.security.network.client",
        "com.apple.security.files.user-selected.read-write"
      ]
    },
    "build": {
      "heading": "Build Process",
      "description": "Steps to build a signed release:",
      "steps": [
        "Run pnpm tauri build --target universal-apple-darwin",
        "Tauri signs with APPLE_SIGNING_IDENTITY from environment",
        "Universal binary created with lipo for Intel + ARM",
        "DMG packaged with custom background and layout"
      ]
    },
    "universalBinaries": {
      "heading": "Universal Binaries",
      "description": "PlanToCode ships as a universal binary:",
      "items": [
        "Single .app supports both Intel and Apple Silicon",
        "Built with --target universal-apple-darwin",
        "Slightly larger binary but simpler distribution",
        "Native performance on both architectures"
      ]
    },
    "notarization": {
      "heading": "Notarization",
      "description": "Apple notarization is required for Gatekeeper approval:",
      "items": [
        "DMG submitted to Apple notary service",
        "Uses notarytool with App Store Connect credentials",
        "Stapling attaches notarization ticket to DMG",
        "Process takes 1-5 minutes typically"
      ]
    },
    "updater": {
      "heading": "In-App Updates",
      "description": "tauri-plugin-updater handles automatic updates:",
      "items": [
        "Checks update endpoint on launch",
        "Downloads new version in background",
        "Prompts user to restart to apply",
        "Signature verification before installation"
      ]
    },
    "latestJson": {
      "heading": "Update Manifest",
      "description": "latest.json describes available updates:",
      "items": [
        "version: Semantic version string",
        "platforms.darwin-universal: URL and signature",
        "notes: Release notes in markdown",
        "pub_date: ISO 8601 publish timestamp"
      ]
    },
    "pitfalls": {
      "heading": "Common Pitfalls",
      "description": "Issues frequently encountered:",
      "items": [
        "Keychain locked during CI: Unlock before signing",
        "Notarization timeout: Retry with exponential backoff",
        "Invalid signature: Check entitlements match capabilities",
        "Gatekeeper rejection: Verify notarization stapled correctly"
      ]
    },
    "verification": {
      "heading": "Verification Commands",
      "description": "Commands to verify signing and notarization:",
      "items": [
        "codesign -dv --verbose=4 PlanToCode.app",
        "spctl --assess --verbose PlanToCode.app",
        "stapler validate PlanToCode.dmg",
        "xcrun notarytool log <submission-id>"
      ]
    }
  },
  "distributionWindows": {
    "meta": {
      "title": "Windows distribution - PlanToCode",
      "description": "NSIS installer, MSIX packaging, Microsoft Store submission, and code signing for Windows."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Windows Distribution & Store",
    "description": "NSIS builds, MSIX packaging, and Microsoft Store submission.",
    "intro": "PlanToCode distributes on Windows through both direct download (NSIS installer) and the Microsoft Store (MSIX package). This document covers both distribution methods.",
    "prereqs": {
      "heading": "Prerequisites",
      "description": "Required tools and certificates:",
      "items": [
        "Code signing certificate (EV or standard)",
        "Windows SDK for signtool",
        "NSIS for installer building",
        "MSIX Packaging Tool for Store submissions"
      ]
    },
    "nsisBuild": {
      "heading": "NSIS Installer",
      "description": "Tauri builds NSIS installers by default:",
      "items": [
        "Custom installer UI with PlanToCode branding",
        "Per-user installation (no admin required)",
        "Start menu and desktop shortcuts",
        "Uninstaller with clean removal"
      ]
    },
    "codeSigning": {
      "heading": "Code Signing",
      "description": "Windows code signing with Authenticode:",
      "items": [
        "Sign with signtool from Windows SDK",
        "Timestamp from trusted TSA server",
        "EV certificate provides SmartScreen reputation",
        "CI uses secrets for certificate and password"
      ]
    },
    "msixPackaging": {
      "heading": "MSIX for Microsoft Store",
      "description": "MSIX provides Store-compatible packaging:",
      "items": [
        "AppxManifest.xml defines capabilities",
        "Virtual filesystem isolation",
        "Automatic updates through Store",
        "Sandboxed execution environment"
      ]
    },
    "msixConfig": {
      "heading": "MSIX Configuration",
      "description": "Key AppxManifest settings:",
      "items": [
        "Identity: Name, Publisher, Version",
        "Capabilities: internetClient, microphone",
        "Visual elements: Tiles, splash screen",
        "File associations and protocol handlers"
      ]
    },
    "msixSteps": {
      "heading": "MSIX Build Steps",
      "description": "Process to create MSIX package:",
      "steps": [
        "Build release with pnpm tauri build",
        "Create AppxManifest.xml with correct identity",
        "Package with MakeAppx.exe",
        "Sign with SignTool",
        "Validate with Windows App Cert Kit"
      ]
    },
    "store": {
      "heading": "Microsoft Store Submission",
      "description": "Store submission process:",
      "items": [
        "Create app in Partner Center",
        "Upload MSIX package",
        "Configure pricing (free with IAP credits)",
        "Submit for certification",
        "Review takes 1-3 business days"
      ]
    },
    "updaterWindows": {
      "heading": "Windows Updates",
      "description": "Update mechanisms for each distribution:",
      "items": [
        "NSIS: tauri-plugin-updater with GitHub releases",
        "MSIX/Store: Automatic through Microsoft Store",
        "Both check for updates on launch"
      ]
    },
    "webview2": {
      "heading": "WebView2 Runtime",
      "description": "Tauri uses WebView2 on Windows:",
      "items": [
        "Bundled WebView2 bootstrapper in installer",
        "Evergreen version auto-updates",
        "Fixed version available for isolation",
        "Windows 10 1803+ required"
      ]
    },
    "troubleshooting": {
      "heading": "Troubleshooting",
      "description": "Common Windows distribution issues:",
      "items": [
        "SmartScreen warning: Use EV certificate or build reputation",
        "Missing WebView2: Ensure bootstrapper runs",
        "Store rejection: Review certification report details",
        "Update failure: Check signature and manifest version"
      ]
    }
  },
  "promptTypes": {
    "meta": {
      "title": "Prompt types and templates - PlanToCode",
      "description": "Catalog of prompt-driven job types and template assembly process."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Prompt Types & Templates",
    "description": "Catalog of prompt-driven job types and template assembly.",
    "intro": "Every LLM-backed job in PlanToCode uses a structured prompt built from templates. This document catalogs the job types and explains how prompts are assembled.",
    "catalog": {
      "heading": "Job Type Catalog",
      "items": [
        {
          "job": "implementation_plan",
          "title": "Implementation Plan",
          "description": "Generates file-by-file implementation plans with XML structure. Uses streaming for progressive display."
        },
        {
          "job": "implementation_plan_merge",
          "title": "Plan Merge",
          "description": "Combines multiple plans with user instructions. Source plans wrapped in XML tags."
        },
        {
          "job": "text_improvement",
          "title": "Text Improvement",
          "description": "Refines selected text while preserving formatting. Non-streaming for quick results."
        },
        {
          "job": "root_folder_selection",
          "title": "Root Folder Selection",
          "description": "Analyzes directory tree to select relevant project roots. Returns JSON array."
        },
        {
          "job": "regex_file_filter",
          "title": "Regex File Filter",
          "description": "Generates regex patterns for file filtering based on task description."
        },
        {
          "job": "file_relevance_assessment",
          "title": "File Relevance Assessment",
          "description": "Scores file content relevance to task. Processes in batches."
        },
        {
          "job": "extended_path_finder",
          "title": "Extended Path Finder",
          "description": "Discovers related files through imports and dependencies."
        },
        {
          "job": "web_search_prompts",
          "title": "Web Search Prompts",
          "description": "Generates research queries for deep research workflow."
        },
        {
          "job": "video_analysis",
          "title": "Video Analysis",
          "description": "Analyzes screen recordings for UI state and action sequences."
        }
      ]
    },
    "templateStructure": {
      "heading": "Template Structure",
      "description": "Prompts are assembled from system templates and user content:",
      "sampleLabel": "Example template structure:",
      "sample": "<system_prompt>\n  You are an AI assistant that generates implementation plans.\n  [template content from server]\n</system_prompt>\n\n<task>\n  [user's task description]\n</task>\n\n<files>\n  [selected file paths and content]\n</files>\n\n<directory_tree>\n  [project structure]\n</directory_tree>"
    },
    "visuals": {
      "template": {
        "title": "Prompt assembly flow",
        "description": "How templates combine with user content to form complete prompts.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "imageAlt": "Prompt template assembly diagram",
        "caption": "Placeholder for prompt assembly diagram."
      }
    },
    "assembly": {
      "heading": "Assembly Process",
      "steps": [
        "Processor retrieves template ID from task model config",
        "System prompt template loaded from server cache",
        "User content wrapped in semantic XML tags",
        "Context (files, tree) added based on job type",
        "Complete prompt stored in job record before sending"
      ]
    },
    "serverConfig": {
      "heading": "Server-Side Configuration",
      "description": "Templates and model settings are configured server-side:",
      "fields": "task_model_config defines: default_model, allowed_models, system_prompt_template_id, max_tokens, temperature"
    },
    "tokenGuards": {
      "heading": "Token Guardrails",
      "description": "Each task type has token limits to prevent context overflow:",
      "items": [
        "max_tokens_input: Maximum prompt size",
        "max_tokens_output: Maximum response size",
        "Validation before sending prevents wasted API calls",
        "UI shows token count and warns when approaching limits"
      ]
    },
    "versioning": {
      "heading": "Template Versioning",
      "description": "System prompt templates are versioned for reproducibility. Each job records the template ID used, enabling traceability and comparison of results across template versions."
    },
    "designNotes": {
      "heading": "Design Notes",
      "items": [
        "XML tags provide clear boundaries for LLM parsing",
        "Semantic naming (task, files, context) aids model understanding",
        "Templates avoid instruction injection by sanitizing user input",
        "Streaming jobs use end tags for completion detection"
      ]
    },
    "cta": {
      "heading": "See job processing in action",
      "description": "Learn how these prompts flow through the job system.",
      "links": {
        "jobs": "Background jobs",
        "merge": "Merge instructions"
      }
    }
  },
  "mergeInstructionsDoc": {
    "meta": {
      "title": "Merge instructions - PlanToCode",
      "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance."
    },
    "category": "Planning",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Merge Instructions",
    "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance.",
    "intro": "When you have multiple implementation plans that need to be combined, the merge workflow lets you select plans, provide guidance, and generate a unified plan that incorporates the best elements from each source.",
    "processor": {
      "heading": "ImplementationPlanMergeProcessor",
      "description": "The ImplementationPlanMergeProcessor fetches source plan responses, wraps them in XML-tagged sections, and streams the merged result through the LlmTaskRunner.",
      "payload": "Accepts source_job_ids array, optional merge_instructions string, and inherits model configuration from the session.",
      "storage": "Merged plan stored as JobResultData::Text with metadata including source_job_ids, merge_instructions, source_count, merged_at timestamp, and session context."
    },
    "inputs": {
      "heading": "Merge Inputs",
      "items": [
        "Source plans: 2-5 implementation plans selected from the plan list",
        "Merge instructions: User guidance on how to combine (prioritize, resolve conflicts)",
        "Model selection: LLM model for merge generation",
        "Task context: Original task description for reference"
      ]
    },
    "xmlFormat": {
      "heading": "XML-Tagged Source Plans",
      "description": "Source plans are wrapped in XML tags with sequential identifiers:",
      "example": "<task_description>\n  [original task from session]\n</task_description>\n\n<source_plans>\n  <implementation_plan_1>\n    [full plan content from first source]\n  </implementation_plan_1>\n  <implementation_plan_2>\n    [full plan content from second source]\n  </implementation_plan_2>\n</source_plans>\n\n<user_instructions>\n  Prioritize API structure from plan 1.\n  Use database schema from plan 2.\n  Resolve conflicts by preferring newer patterns.\n</user_instructions>"
    },
    "prompt": {
      "heading": "Merge Prompt Structure",
      "description": "The merge prompt includes all context needed for intelligent combination:",
      "sections": [
        "System prompt with merge guidelines",
        "Source plans in XML tags",
        "User's merge instructions",
        "Task description for context",
        "Output format requirements"
      ]
    },
    "visuals": {
      "mergeWalkthrough": {
        "title": "Merge workflow walkthrough",
        "description": "Video showing the complete merge process from selection to output.",
        "videoSrc": "/videos/docs/merge-instructions/walkthrough.mp4",
        "posterSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Placeholder for merge walkthrough video."
      },
      "mergeFlow": {
        "title": "Merge instructions flow",
        "description": "Diagram showing multi-model merge workflow with XML-tagged source plans.",
        "imageSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Merge flow showing source selection, instruction processing, and output generation"
      }
    },
    "rules": {
      "heading": "Merge Rules",
      "description": "The LLM follows these rules when merging plans:",
      "examples": [
        "Preserve file paths exactly as specified in source plans",
        "Combine non-conflicting changes from all sources",
        "For conflicts, follow explicit user instructions",
        "Maintain consistent code style across merged content",
        "Include provenance comments indicating source plan"
      ]
    },
    "output": {
      "heading": "Merged Output",
      "description": "The merged plan is returned as raw text from the LLM, following the same flexible format as individual plans.",
      "provenance": "Each section includes comments indicating which source plan contributed the content.",
      "metadata": "source_job_ids, merge_instructions, source_count, merged_at timestamp, planTitle, summary, isStructured (false), and sessionName stored in job metadata."
    },
    "ui": {
      "heading": "UI Integration",
      "description": "The Implementation Plans panel supports merge workflow:",
      "audit": "Merged plans link back to source plans for traceability."
    },
    "cta": {
      "heading": "Learn about plan generation",
      "description": "Understand how individual plans are created before merging.",
      "links": {
        "plans": "Implementation plans",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "meetingIngestionDoc": {
    "meta": {
      "title": "Meeting and recording ingestion - PlanToCode",
      "description": "How recordings are analyzed into task summaries through the video analysis pipeline."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Meeting & Recording Ingestion",
    "description": "How recordings become task summaries and planning inputs.",
    "intro": "PlanToCode can analyze meeting recordings and screen captures with the video analysis job. The model is guided by a system prompt that adapts to your goal, whether you are debugging, reviewing UI, or documenting a workflow.",
    "visuals": {
      "ingestionFlow": {
        "title": "Recording ingestion flow",
        "description": "How recordings flow through upload and analysis.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Recording ingestion flow diagram",
        "caption": "Placeholder for ingestion flow diagram."
      }
    },
    "inputs": {
      "heading": "Supported Inputs",
      "description": "The ingestion workflow accepts video recordings captured in the app or uploaded from other tools.",
      "items": [
        "Screen recordings captured in the desktop app",
        "Meeting recordings exported from Zoom, Meet, or Teams (video files)",
        "Design walkthroughs or bug reproductions recorded as video",
        "For audio-only notes, use voice transcription"
      ]
    },
    "uploadProcess": {
      "heading": "Upload Process",
      "description": "Recordings are uploaded to the server as multipart form data for analysis.",
      "stepsHeading": "Processing Steps",
      "steps": [
        "Desktop saves the recording locally and calculates duration",
        "Video file and analysis prompt are uploaded to /api/llm/video/analyze",
        "Server stores the file temporarily and routes it to Gemini video models",
        "Long recordings are split into 2-minute chunks by the desktop and processed in parallel",
        "Analysis summary is returned and stored in the job response"
      ]
    },
    "normalization": {
      "heading": "Format Normalization",
      "description": "Recordings are sent mostly as-is. WebM recordings are remuxed to fix container metadata before analysis.",
      "outputs": "No separate transcript or frame artifacts are generated; the output is a text analysis summary."
    },
    "multimodalAnalysis": {
      "heading": "Multimodal Analysis",
      "description": "Recordings are analyzed with {code} video models, which accept video and audio in a single request.",
      "combined": "The default video analysis system prompt adapts the output to your goal rather than forcing a fixed schema."
    },
    "transcription": {
      "heading": "Audio context",
      "description": "Audio is analyzed as part of the video; the app does not generate a standalone transcript.",
      "attribution": "If spoken content is unclear, the model may mark it as partially visible rather than guessing.",
      "featuresHeading": "Audio analysis notes",
      "features": [
        "Narration steers the summary",
        "Spoken intent and errors can be quoted",
        "No diarization or timestamped transcript"
      ]
    },
    "frames": {
      "heading": "Frame rate hint",
      "description": "FPS is a sampling hint sent with the analysis request. For large files the provider may ignore it.",
      "timestamps": "Long recordings can be chunked to keep analysis responsive."
    },
    "structuredExtraction": {
      "heading": "Structured Extraction",
      "description": "The analysis output is freeform and adapts to your prompt. Typical outputs include:",
      "extractedHeading": "Extracted Elements",
      "items": [
        "Bug reproduction steps and observed errors",
        "UI walkthrough notes and navigation paths",
        "Design feedback or UX issues shown on screen",
        "Suggested fixes or follow-up tasks"
      ]
    },
    "artifacts": {
      "heading": "Analysis Artifacts",
      "description": "Video analysis produces artifacts stored with the job:",
      "items": [
        "analysis_summary: Text summary stored in background_jobs.response",
        "job_metadata: durationMs, framerate, videoPath",
        "chunk_info: chunk boundaries for long recordings (when applicable)"
      ]
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "desktop/src/app/components/generate-prompt/_components/video-recording-dialog.tsx",
        "desktop/src/contexts/screen-recording/Provider.tsx",
        "desktop/src-tauri/src/jobs/processors/video_analysis_processor.rs",
        "server/src/handlers/proxy/specialized/video_analysis.rs",
        "server/src/utils/multipart_utils.rs",
        "server/src/clients/google_client.rs"
      ]
    },
    "handoff": {
      "heading": "Planning Handoff",
      "description": "Video analysis summaries can be incorporated into the task description for planning.",
      "pipeline": "The summary can be refined with text_improvement and task_refinement before file discovery."
    },
    "cta": {
      "heading": "Continue to video analysis",
      "description": "Learn more about how video frames are analyzed.",
      "links": {
        "video": "Video analysis",
        "textImprovement": "Text improvement"
      }
    }
  },
  "videoAnalysisDoc": {
    "meta": {
      "title": "Video analysis - PlanToCode",
      "description": "Adaptive analysis of screen recordings with Gemini video models."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "6 min",
    "title": "Video Analysis",
    "description": "Adaptive analysis and prompts for screen recordings.",
    "intro": "Video analysis sends the recording to Gemini video models with a system prompt that adapts to your goal. The output is a text summary, not a frame-by-frame export or separate transcript.",
    "visuals": {
      "frameNotes": {
        "title": "Video analysis pipeline",
        "description": "How recordings flow through the analysis model.",
        "imageSrc": "/assets/images/demo-video-analysis.jpg",
        "imageAlt": "Video analysis interface",
        "caption": "The video analysis interface showing analysis options."
      }
    },
    "apiEndpoint": {
      "heading": "API Endpoint",
      "endpoint": "Video analysis is handled by {code} on the server. The endpoint accepts multipart form data with the video file and analysis parameters.",
      "payloadHeading": "Payload Fields",
      "payloadFields": [
        "video: The video file",
        "model: Model identifier for analysis (google/* required)",
        "prompt: Task description and optional focus prompt (wrapped in <description> and <video_attention_prompt>)",
        "temperature: Sampling temperature from task settings",
        "durationMs: Recording duration in milliseconds",
        "framerate: Sampling hint (0.1-20 from the UI)",
        "systemPrompt: Composed system prompt (server-generated)"
      ]
    },
    "inputs": {
      "heading": "Supported Input Formats",
      "items": [
        "MP4, WebM, MOV, and AVI are common inputs",
        "Large files may be uploaded with the provider File API",
        "Long recordings are chunked by the desktop app before analysis"
      ]
    },
    "sampling": {
      "heading": "Frame rate hint",
      "description": "FPS is a hint for how densely to sample the video. For large files the provider may ignore it; for long recordings the desktop may downsample when chunking.",
      "fps": "Default recorder rate is 5 FPS. Lower rates reduce cost but may miss rapid UI changes.",
      "parametersHeading": "Sampling Parameters",
      "parameters": [
        "framerate: 0.1-20 selection in the UI (provider requests are clamped to 1-20)",
        "chunking: long recordings split into 2-minute segments",
        "audio: include narration when \"Include dictation\" is enabled"
      ]
    },
    "modelRequirements": {
      "heading": "Model Requirements",
      "format": "Video analysis requires Gemini video models. Model identifiers follow {code} format; only {code} models are supported.",
      "reasoning": "The server restricts video analysis to Google Gemini models that accept video inputs."
    },
    "analysis": {
      "heading": "Analysis Process",
      "description": "The model analyzes the full video (and audio if present) and produces a goal-oriented summary.",
      "prompting": "The default system prompt (default_video_analysis) tells the model to adapt to your goal, quote visible text when relevant, and mark unclear content instead of guessing.",
      "promptElementsHeading": "Prompt Elements",
      "promptElements": [
        "Goal alignment: focus on the user's stated intent",
        "Evidence: quote visible errors, logs, or UI text when relevant",
        "Sequence: describe the order of events or steps shown",
        "Next steps: suggest fixes or follow-up tasks"
      ]
    },
    "outputs": {
      "heading": "Analysis Outputs",
      "items": [
        "Analysis summary text tailored to the prompt",
        "Quoted errors or UI text when visible",
        "Workflow notes describing what happened on screen",
        "Suggested fixes or follow-up tasks"
      ]
    },
    "billing": {
      "heading": "Token Usage & Billing",
      "description": "Video analysis usage and cost are tracked per job using provider-reported tokens or duration-based estimates.",
      "tracked": [
        "tokens_sent: Prompt + video tokens",
        "tokens_received: Analysis response tokens",
        "actual_cost: Computed from model pricing"
      ]
    },
    "storage": {
      "heading": "Result Storage",
      "description": "Analysis results are stored in background_jobs.response with task_type \"video_analysis\". Long recordings may include chunk metadata.",
      "reuse": "Results can be incorporated into task descriptions or used directly in the planning workflow."
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "desktop/src/app/components/generate-prompt/_components/video-recording-dialog.tsx",
        "desktop/src/contexts/screen-recording/Provider.tsx",
        "desktop/src-tauri/src/jobs/processors/video_analysis_processor.rs",
        "server/src/handlers/proxy/specialized/video_analysis.rs",
        "server/src/clients/google_client.rs"
      ]
    },
    "integration": {
      "heading": "Integration with Planning",
      "description": "Video analysis summaries can be appended to the task description for context-aware planning.",
      "followup": "Use text_improvement or task_refinement to polish the summary before file discovery."
    },
    "cta": {
      "heading": "See meeting ingestion",
      "description": "Learn more about how video analysis works.",
      "links": {
        "meeting": "Meeting ingestion",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "mobileIos": {
    "meta": {
      "title": "iOS client architecture - PlanToCode",
      "description": "Swift workflows, Auth0 login flow, and device-link session management for the iOS companion app."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "iOS Client Architecture",
    "description": "Swift workflows, Auth0 login flow, and device-link session management.",
    "intro": "The PlanToCode iOS app is a companion client that connects to linked desktop sessions. It provides mobile access to terminal output, job status, and voice transcription while maintaining the desktop as the primary planning workspace.",
    "visuals": {
      "app": {
        "title": "iOS app interface",
        "description": "Screenshots of the iOS app showing device linking and terminal view.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode iOS app screenshots",
        "caption": "Placeholder for iOS app screenshots."
      }
    },
    "packageStructure": {
      "heading": "Swift Package Structure",
      "description": "The iOS app is organized into Swift packages:",
      "packages": [
        {
          "name": "Core",
          "path": "mobile/ios/Core/",
          "description": "Business logic and API clients",
          "components": [
            "WorkflowManager",
            "APIClient",
            "MobileSessionManager",
            "DeviceLinkClient"
          ]
        },
        {
          "name": "Security",
          "path": "mobile/ios/Security/",
          "description": "Authentication and credential storage",
          "components": [
            "Auth0Manager",
            "KeychainHelper",
            "TokenStore"
          ]
        },
        {
          "name": "VibeUI",
          "path": "mobile/ios/VibeUI/",
          "description": "SwiftUI components and design system",
          "components": [
            "TerminalView",
            "JobListView",
            "SettingsView",
            "DeviceLinkView"
          ]
        }
      ]
    },
    "auth": {
      "heading": "Auth0 PKCE Integration",
      "description": "The iOS app uses Auth0 with PKCE flow for secure authentication:",
      "flow": [
        "User taps Sign In, app generates code verifier and challenge",
        "ASWebAuthenticationSession opens Auth0 login page",
        "User authenticates and Auth0 redirects with authorization code",
        "App exchanges code for tokens using code verifier",
        "Tokens stored securely in iOS Keychain"
      ],
      "tokenManagement": {
        "heading": "Token Management",
        "items": [
          "Access token used for API requests",
          "Refresh token stored for silent renewal",
          "Token refresh triggered before expiry",
          "Logout clears all tokens from Keychain"
        ]
      }
    },
    "deviceLink": {
      "heading": "Device Linking via WebSocket Relay",
      "description": "iOS connects to desktop sessions through the server's WebSocket relay:",
      "protocol": {
        "heading": "Linking Protocol",
        "steps": [
          "Desktop generates link code and displays QR",
          "iOS scans QR or enters code manually",
          "Both connect to /ws/device-link with credentials",
          "Server validates and establishes relay",
          "Bidirectional communication enabled"
        ]
      },
      "messageTypes": {
        "heading": "Message Types",
        "items": [
          "terminal_output: PTY output from desktop terminal",
          "job_status: Background job status updates",
          "session_sync: Session state synchronization",
          "rpc_command: Commands from mobile to desktop"
        ]
      },
      "reconnection": {
        "heading": "Reconnection Handling",
        "description": "The WebSocket connection handles network interruptions with automatic reconnection, exponential backoff, and session state recovery."
      }
    },
    "rpcRouting": {
      "heading": "RPC Command Routing",
      "description": "iOS can send commands to the linked desktop:",
      "commands": {
        "heading": "Supported Commands",
        "items": [
          "send_terminal_input: Send keystrokes to terminal",
          "request_job_status: Get status of specific job",
          "start_voice_transcription: Begin recording on mobile",
          "sync_session: Request full session state"
        ]
      },
      "implementation": {
        "heading": "Implementation",
        "description": "Commands are JSON-RPC messages sent over WebSocket. Desktop validates commands and returns results asynchronously."
      }
    },
    "offlineQueue": {
      "heading": "Offline Action Queue",
      "description": "Actions performed while disconnected are queued for sync:",
      "architecture": {
        "heading": "Queue Architecture",
        "items": [
          "Actions stored in local SQLite database",
          "Queue processed on reconnection",
          "Conflicts resolved with server timestamps",
          "Failed actions reported to user"
        ]
      },
      "supportedActions": {
        "heading": "Supported Offline Actions",
        "items": [
          "Voice transcription recording (stored locally)",
          "Session notes and annotations",
          "Preference changes"
        ]
      }
    },
    "localStorage": {
      "heading": "SQLite Local Storage",
      "description": "iOS uses SQLite for local persistence:",
      "database": {
        "heading": "Database Schema",
        "path": "~/Documents/plantocode.sqlite",
        "tables": [
          "linked_devices: Desktop connections",
          "offline_queue: Pending sync actions",
          "cached_sessions: Recent session data",
          "transcriptions: Local voice recordings"
        ]
      },
      "migrations": {
        "heading": "Migrations",
        "description": "Schema version tracked in user_version pragma. Migrations run on app launch."
      }
    },
    "sessions": {
      "heading": "Mobile Sessions",
      "description": "MobileSessionManager coordinates session state:",
      "lifecycle": [
        "Load last active session on launch",
        "Connect to linked desktop if available",
        "Subscribe to session updates via WebSocket",
        "Cache session data for offline access"
      ]
    },
    "workflows": {
      "heading": "Workflow Entry Points",
      "description": "Key workflows accessible from mobile:",
      "items": [
        "Terminal monitoring: View output, send input",
        "Job status: Track background job progress",
        "Voice capture: Record and transcribe on mobile",
        "Session browsing: Review plans and history"
      ]
    },
    "region": {
      "heading": "Region Settings",
      "description": "iOS respects user region preference for API routing:",
      "implementation": "Region stored in UserDefaults, used to select api-eu.plantocode.com or api-us.plantocode.com for all requests."
    }
  },
  "providerRouting": {
    "meta": {
      "title": "Provider routing and streaming - PlanToCode",
      "description": "How PlanToCode routes LLM requests through a proxy, normalizes responses, and streams tokens to the desktop client."
    },
    "category": "Research & Models",
    "date": "2025-09-24",
    "readTime": "10 min",
    "title": "Provider Routing and Streaming",
    "description": "Routing layer that mediates all external LLM requests with normalization, streaming, and usage tracking.",
    "visuals": {
      "routingMap": {
        "title": "Provider routing map",
        "description": "Diagram of how requests flow from the desktop app to the proxy and out to providers.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Diagram of provider routing flow from desktop to external providers",
        "caption": "Placeholder for provider routing diagram."
      }
    },
    "cta": {
      "heading": "Continue into model configuration",
      "description": "Model configuration explains how allowed lists and token guardrails are exposed to the UI.",
      "links": {
        "modelConfiguration": "Model configuration",
        "runtimeWalkthrough": "Runtime walkthrough"
      }
    }
  }
}
