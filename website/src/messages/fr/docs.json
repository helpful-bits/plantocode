{
  "meta": {
    "title": "Documentation - PlanToCode",
    "description": "Apprenez à planifier et livrer des modifications de code avec PlanToCode : découverte de fichiers, plans d'implémentation, sessions terminal, garde-fous de modèle et voix."
  },
  "architecture": {
    "meta": {
      "title": "Vue d'ensemble de l'architecture PlanToCode",
      "description": "Couches bureau, orchestration et persistance qui alimentent les plans d'implémentation, les workflows et les sessions terminal."
    },
    "category": "Architecture",
    "date": "2025-09-19",
    "description": "Comment le shell bureau, les workflows en arrière-plan et les services partagés sont organisés.",
    "frontend": {
      "heading": "Surface frontend",
      "providers": "Les providers partagés gèrent les notifications, la configuration d'exécution et l'état des plans. Le panneau Plans d'implémentation conserve les métadonnées du plan, gère la visibilité des modales et demande des estimations de tokens ou du contenu de prompt selon les besoins.",
      "ui": "L'interface bureau est construite avec des composants React. Le contenu des plans d'implémentation est affiché via un visualiseur basé sur Monaco qui virtualise les grands plans, détecte les langages et prend en charge les actions de copie pour que les réviseurs puissent examiner le texte du plan sans problèmes de performance. Les sessions terminal s'affichent dans une vue bufferisée qui se connecte à la sortie PTY et affiche les mises à jour d'état de connexion."
    },
    "intro": "PlanToCode est une application bureau Tauri avec un frontend React. L'interface affiche les plans d'implémentation, les terminaux et les contrôles de configuration, tandis que le backend Rust expose des commandes pour les workflows, l'estimation de tokens et les sessions terminal persistantes. Cette vue d'ensemble résume comment ces éléments s'assemblent.",
    "metaDescription": "Couches bureau, orchestration et persistance qui alimentent les plans d'implémentation, les workflows et les sessions terminal.",
    "metaTitle": "Vue d'ensemble de l'architecture PlanToCode",
    "ogDescription": "Découvrez comment le frontend React, les commandes Tauri et les services en arrière-plan coopèrent dans l'application bureau.",
    "ogTitle": "Vue d'ensemble de l'architecture PlanToCode",
    "persistence": {
      "database": "La sortie terminal et les métadonnées de session sont stockées dans SQLite via le repository des sessions terminal. Chaque enregistrement inclut des identifiants, horodatages, répertoires de travail, variables d'environnement et le log accumulé pour que les redémarrages puissent récupérer la sortie précédente. Le même repository émet des événements quand l'état de la session change.",
      "heading": "Persistance et configuration",
      "modelConfig": "Les valeurs par défaut des modèles résident dans la table de configuration de l'application. Chaque tâche définit un modèle par défaut, une liste d'alternatives autorisées, des budgets de tokens et des préréglages optionnels de boutons de copie. La couche React lit ces paramètres pour alimenter le sélecteur de modèle et les garde-fous."
    },
    "readTime": "7 min",
    "tauriCommands": {
      "commands": "Le côté Rust de l'application expose des commandes pour les workflows, les sessions terminal et les outils de modèle. Les commandes de workflow démarrent des tâches en arrière-plan via le Workflow Orchestrator, validant les entrées et émettant des événements de progression pendant l'exécution du pipeline de découverte de fichiers. Les commandes d'estimation de tokens calculent les tailles de prompt pour le modèle actuellement sélectionné.",
      "heading": "Commandes et services Tauri",
      "terminal": "Les commandes terminal gèrent les processus PTY, suivent les clients distants et vérifient si les binaires CLI supportés sont disponibles avant de lancer une session. Les vérifications de santé combinent l'état PTY avec les enregistrements de base de données pour signaler si une session est toujours active."
    },
    "title": "Architecture PlanToCode",
    "voicePipeline": {
      "description": "La transcription vocale est implémentée comme un hook React qui coordonne les permissions média, la sélection du microphone et les requêtes de transcription en streaming. Le hook s'intègre au terminal de plan et aux éditeurs de prompt, insérant le texte reconnu directement dans le composant actif et affichant des notifications si la transcription échoue.",
      "heading": "Pipeline de transcription vocale"
    },
    "server": {
      "heading": "Couche serveur",
      "description": "Le serveur gère la configuration des providers (clés API dans un vault chiffré, limites de débit, règles de routage pour OpenAI, Anthropic, Google), le routage de modèle (proxy de requêtes, failover automatique, équilibrage de charge, suivi des coûts par utilisateur/projet), la facturation (gestion des abonnements, mesure de l'utilisation, application des quotas, alertes de coût) et les APIs de recherche web (mise en cache des résultats avec TTL de 30/7 jours, restrictions géographiques, auth JWT)."
    },
    "dataFlows": {
      "heading": "Flux de données",
      "description": "Les tâches, plans, jobs et sessions circulent entre les composants : (1) Raffinement de tâche : React UI → TextImprovementPopover → commande Tauri → WorkflowOrchestrator → prompt text_improvement → SQLite → le provider React remplace le texte. (2) Découverte de fichiers : panneau Plans d'implémentation → commande Tauri → 4 jobs séquentiels → événements de progression → SQLite → affichage UI. (3) Plans d'implémentation : Découverte de fichiers → Générer Plan → commande Tauri → streaming LLM → SQLite → visualiseur Monaco → révision/approbation → export. (4) Exécution terminal : session PTY → SQLite → exécution de commande → streaming de sortie → injection de transcription vocale → détection d'attention de l'agent → logs d'audit."
    }
  },
  "deepResearch": {
    "meta": {
      "title": "Recherche approfondie - PlanToCode",
      "description": "Documentation technique du workflow de recherche web : intégration API, optimisation des requêtes, traitement des résultats et intégration au workflow de développement."
    },
    "apiIntegration": {
      "heading": "Détails de l'intégration API",
      "pipeline": {
        "description": "Les résultats de recherche passent par un pipeline de traitement standardisé qui extrait les informations significatives tout en préservant le formatage et le contexte. Le pipeline gère différents types de contenu et synthétise les résultats en insights actionnables pour les workflows de développement.",
        "heading": "Pipeline de traitement du contenu"
      },
      "providerConfig": {
        "description": "Le système utilise des modèles de langage IA via OpenRouter pour effectuer des recherches web intelligentes. Le LLM génère des requêtes de recherche ciblées basées sur le contexte de votre tâche et synthétise les résultats à partir de ses données d'entraînement et de ses capacités de recherche web. La sélection et la configuration du modèle sont gérées via les paramètres de l'application.",
        "heading": "Configuration de la recherche IA"
      }
    },
    "architecture": {
      "description": "Le système de recherche approfondie fonctionne comme un workflow en deux étapes : (1) WebSearchPromptsGeneration - l'IA analyse votre tâche et le contexte du projet pour générer des requêtes de recherche ciblées, et (2) WebSearchExecution - le LLM exécute les prompts de recherche en parallèle et synthétise les résultats. Chaque étape est conçue pour la fiabilité, l'efficacité des coûts et la pertinence contextuelle.",
      "heading": "Vue d'ensemble de l'architecture"
    },
    "bestPractices": {
      "examples": {
        "description": "Les patterns d'intégration courants démontrent comment les résultats de recherche web améliorent différents scénarios de développement, du débogage d'erreurs spécifiques à l'implémentation de nouvelles fonctionnalités avec des APIs non familières.",
        "heading": "Exemples d'intégration"
      },
      "heading": "Bonnes pratiques et exemples",
      "strategies": {
        "description": "Pour maximiser la valeur de l'intégration de la recherche web, suivez ces stratégies éprouvées pour formuler des requêtes, interpréter les résultats et intégrer les découvertes dans votre workflow de développement.",
        "heading": "Stratégies de recherche efficaces",
        "queryFormulation": {
          "constraints": "Inclure les contraintes de plateforme ou d'environnement",
          "errors": "Combiner les noms de bibliothèques avec des messages d'erreur spécifiques",
          "heading": "Formulation de requête",
          "practices": "Utiliser « bonnes pratiques » ou « approche recommandée » pour les recherches de patterns",
          "versions": "Inclure des numéros de version spécifiques quand pertinent"
        },
        "resultEvaluation": {
          "crossReference": "Croiser les solutions entre plusieurs sources",
          "dates": "Vérifier les dates de publication pour les informations sensibles au temps",
          "heading": "Évaluation des résultats",
          "official": "Prioriser la documentation officielle par rapport aux sources tierces",
          "verify": "Vérifier les exemples de code dans votre environnement de développement"
        }
      }
    },
    "category": "Référence technique",
    "configuration": {
      "heading": "Configuration et personnalisation",
      "preferences": {
        "description": "Le comportement de recherche est configuré via la sélection du modèle et les paramètres de tâche. Choisissez votre modèle IA préféré pour les tâches de recherche, configurez les timeouts et sélectionnez les fichiers à inclure pour le contexte.",
        "filters": "La sélection du modèle détermine la qualité et le coût de la recherche",
        "heading": "Paramètres de recherche",
        "limits": "Maximum 12 prompts de recherche générés par tâche",
        "optionsHeading": "Options configurables",
        "patterns": "Inclure les fichiers de projet pertinents pour un meilleur contexte",
        "sources": "Répertoire de projet et sélection de fichiers pour le contexte",
        "triggers": "Démarrer la recherche manuellement via la commande de workflow"
      },
      "projectSettings": {
        "description": "La configuration de recherche est consciente de la session. Le système utilise le répertoire de projet de la session actuelle et les fichiers inclus pour fournir le contexte. Les chemins exclus (comme node_modules, dist) sont automatiquement filtrés de l'arborescence de répertoires montrée à l'IA.",
        "heading": "Paramètres spécifiques au projet"
      }
    },
    "costs": {
      "heading": "Considérations de coût",
      "optimization": {
        "description": "Les coûts de recherche sont gérés via la génération intelligente de prompts - le système limite les prompts de recherche à un maximum de 12 par tâche. L'exécution parallèle minimise le temps d'attente. Chaque job suit l'utilisation des tokens et les coûts estimés dans ses métadonnées pour une transparence totale.",
        "heading": "Optimisation des coûts"
      },
      "rateLimiting": {
        "cacheFirst": "Résultats de recherche mis en cache par session pour éviter les requêtes redondantes",
        "description": "La recherche approfondie utilise vos crédits IA configurés via OpenRouter. Chaque tâche de recherche génère plusieurs appels LLM en parallèle, donc les coûts augmentent avec le nombre de prompts de recherche générés. Le système suit l'utilisation des tokens et les coûts par job pour la transparence.",
        "guidelinesHeading": "Conseils de gestion des coûts",
        "heading": "Utilisation et coûts",
        "personal": "Utilisation de tokens suivie par job de recherche avec détail des coûts",
        "team": "Coûts gérés via vos crédits d'abonnement OpenRouter ou PlanToCode",
        "throttling": "Surveiller les métadonnées de job pour les comptages de tokens et coûts estimés"
      }
    },
    "cta": {
      "description": "Les fonctionnalités de recherche approfondie et de recherche web sont disponibles dans l'application bureau PlanToCode. Téléchargez la version pour votre plateforme pour commencer à intégrer la recherche web dans votre workflow de développement.",
      "heading": "Prêt à utiliser la recherche approfondie ?",
      "links": {
        "architecture": "Voir l'architecture système",
        "buildYourOwn": "Construisez votre propre intégration"
      }
    },
    "date": "2025-09-20",
    "description": "Comment PlanToCode effectue des recherches web, traite les résultats et intègre les découvertes dans les workflows de développement.",
    "devIntegration": {
      "caching": {
        "description": "Les résultats de recherche sont stockés dans les métadonnées du job et peuvent être consultés via le panneau de détails du job. Les résultats persistent pendant la durée de la session et peuvent être référencés lors de la création de plans d'implémentation ou de décisions de codage.",
        "heading": "Stockage des résultats"
      },
      "contextAware": {
        "description": "Les requêtes de recherche sont automatiquement enrichies avec le contexte de votre session actuelle. Le système inclut l'arborescence de répertoires de votre projet et le contenu des fichiers sélectionnés dans la phase de génération de prompts, permettant à l'IA de formuler des requêtes de recherche spécifiques à votre codebase.",
        "heading": "Recherche contextuelle"
      },
      "heading": "Intégration au workflow de développement",
      "resultIntegration": {
        "description": "Les résultats de recherche peuvent être utilisés pour éclairer les plans d'implémentation. Quand les tâches de recherche se terminent, les résultats sont formatés comme des tags research_finding qui peuvent être incorporés dans les tâches de planification suivantes, garantissant que votre implémentation est guidée par les bonnes pratiques actuelles et une documentation précise.",
        "heading": "Intégration des résultats"
      }
    },
    "intro": "La fonctionnalité de recherche approfondie permet à PlanToCode d'effectuer des recherches intelligentes alimentées par l'IA, de rassembler des informations pertinentes et d'intégrer les découvertes directement dans les workflows de développement. Ce système utilise de grands modèles de langage pour générer des requêtes de recherche ciblées basées sur le contexte de votre projet, exécuter des tâches de recherche en parallèle et synthétiser des insights actionnables pour améliorer la génération de code et les capacités de résolution de problèmes.",
    "metaDescription": "Documentation technique du workflow de recherche web : intégration API, optimisation des requêtes, traitement des résultats et intégration au workflow de développement.",
    "metaTitle": "Recherche approfondie - PlanToCode",
    "ogDescription": "Comprenez comment la recherche web fonctionne dans PlanToCode : de la génération de requêtes au traitement des résultats et à l'intégration avec les workflows de développement.",
    "ogTitle": "Recherche approfondie - PlanToCode",
    "readTime": "8 min",
    "title": "Recherche approfondie & recherche web",
    "troubleshooting": {
      "commonIssues": {
        "description": "La plupart des problèmes de recherche proviennent de la connectivité API LLM, de crédits insuffisants ou de prompts trop larges. Le système fournit des messages d'erreur clairs et un suivi de l'état des jobs pour le dépannage.",
        "geographic": "Disponibilité des modèles",
        "geographicSolution": "Certains modèles peuvent avoir des restrictions régionales via OpenRouter",
        "heading": "Problèmes courants",
        "noResults": "Aucun prompt de recherche généré",
        "noResultsSolution": "Fournissez des descriptions de tâche plus spécifiques ou incluez des fichiers pertinents pour le contexte",
        "rateLimit": "Erreurs API",
        "rateLimitSolution": "Vérifiez le statut de l'API OpenRouter et le solde de crédits"
      },
      "heading": "Dépannage et support",
      "performance": {
        "description": "Pour des performances optimales, fournissez des descriptions de tâche claires et spécifiques. Incluez les fichiers de projet pertinents pour donner à l'IA un meilleur contexte. Le système exécute les prompts de recherche en parallèle pour minimiser le temps d'exécution total.",
        "heading": "Optimisation des performances"
      }
    },
    "workflow": {
      "execution": {
        "blogs": "Bonnes pratiques et patterns d'implémentation",
        "description": "Les prompts de recherche sont exécutés en parallèle par des modèles de langage IA. Chaque prompt est traité indépendamment, permettant au système de rassembler des informations sur plusieurs aspects de votre tâche simultanément. Les résultats sont synthétisés en découvertes structurées avec des titres et des insights actionnables.",
        "documentation": "Documentation API et spécifications techniques",
        "forums": "Résolution d'erreurs et approches de dépannage",
        "github": "Exemples de code et patterns d'implémentation",
        "heading": "Exécution de la recherche",
        "releases": "Compatibilité de version et guide de migration",
        "sourcesHeading": "Domaines de recherche"
      },
      "heading": "Étapes du workflow de recherche",
      "processing": {
        "deduplication": "Résultats consolidés à travers plusieurs prompts de recherche",
        "description": "Les résultats de recherche sont structurés en format JSON avec des titres et des découvertes détaillées. Le système agrège les résultats des tâches de recherche parallèles, suit les comptages de succès et d'échecs et fournit un résumé des résultats de la recherche. Les résultats sont stockés dans les métadonnées du job pour un accès facile.",
        "extraction": "Découvertes clés extraites et formatées pour l'intégration",
        "heading": "Traitement et synthèse des résultats",
        "scoring": "Résultats organisés par sujet de recherche et pertinence",
        "snippets": "Insights actionnables et recommandations mis en évidence",
        "stepsHeading": "Étapes de traitement",
        "timestamp": "Exécution de la recherche suivie avec métriques de temps"
      },
      "queryGeneration": {
        "api": "Documentation API et recherche spécifique aux bibliothèques",
        "compatibility": "Compatibilité de version et chemins de migration",
        "description": "Les prompts de recherche sont automatiquement générés par l'IA basée sur votre description de tâche, le contexte du projet et les fichiers inclus. Le système analyse la structure de votre codebase via l'arborescence de répertoires et le contenu des fichiers pour formuler des requêtes de recherche ciblées. Jusqu'à 12 prompts de recherche focalisés sont générés par tâche.",
        "errors": "Résolution d'erreurs et approches de débogage",
        "heading": "Génération de prompts",
        "practices": "Bonnes pratiques et patterns recommandés",
        "security": "Considérations de sécurité et sensibilisation aux vulnérabilités",
        "typesHeading": "Sujets de recherche"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Pipeline de recherche approfondie",
        "description": "Le workflow en deux étapes : génération de prompts et exécution de recherche en parallèle.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Diagramme du pipeline de recherche approfondie montrant les étapes de génération de prompts et d'exécution",
        "caption": "Workflow de recherche approfondie montrant la génération de prompts et les étapes d'exécution parallèle"
      },
      "workflow": {
        "title": "Workflow de recherche approfondie",
        "description": "Le workflow en deux étapes : génération de prompts et exécution de recherche en parallèle.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "caption": "Workflow de recherche approfondie montrant toutes les étapes de traitement"
      }
    }
  },
  "fileDiscovery": {
    "meta": {
      "title": "Workflow de découverte de fichiers - PlanToCode",
      "description": "Guide technique complet du workflow IA en 4 étapes qui identifie et filtre les fichiers pertinents pour l'exécution des tâches."
    },
    "apiUsage": {
      "heading": "Exemples d'utilisation de l'API",
      "monitoring": "Surveillance de la progression",
      "retrieving": "Récupération des résultats",
      "starting": "Démarrage d'un workflow"
    },
    "architecture": {
      "caching": "Mise en cache des résultats intermédiaires pour l'optimisation des performances",
      "costTracking": "Suivi des coûts et gestion des timeouts pour les opérations IA",
      "distributed": "Le système utilise une architecture de jobs distribuée où chaque étape s'exécute comme un job en arrière-plan indépendant, permettant l'annulation, la logique de retry et le suivi détaillé de la progression. Des événements en temps réel sont publiés tout au long de l'exécution pour fournir un retour immédiat à l'interface utilisateur.",
      "errorHandling": "Gestion complète des erreurs avec mécanismes de retry automatique",
      "eventDriven": "Reporting de progression événementiel avec mises à jour de type WebSocket",
      "featuresHeading": "Fonctionnalités clés de l'architecture :",
      "gitIntegration": "Intégration Git avec fallback vers le parcours de répertoires",
      "heading": "Architecture du workflow",
      "overview": "Le workflow fonctionne comme un système de jobs en arrière-plan orchestré avec quatre étapes distinctes qui s'exécutent séquentiellement. Chaque étape s'appuie sur la sortie de l'étape précédente, affinant progressivement la sélection de fichiers selon les exigences de la tâche."
    },
    "category": "Guide technique",
    "configuration": {
      "exclusion": {
        "description": "Définissez les répertoires et patterns de fichiers à exclure du processus de découverte.",
        "heading": "Patterns d'exclusion"
      },
      "heading": "Options de configuration",
      "retry": {
        "description": "Définissez le nombre maximum de tentatives de retry pour les étapes échouées avec backoff exponentiel.",
        "heading": "Configuration des retry"
      },
      "timeout": {
        "description": "Configurez le temps d'exécution maximum pour l'ensemble du workflow ou les étapes individuelles pour éviter les blocages indéfinis.",
        "heading": "Gestion des timeouts"
      },
      "workflowConfig": "Configuration du workflow"
    },
    "cta": {
      "description": "Le workflow de découverte de fichiers s'exécute dans le client bureau aux côtés de la planification d'implémentation et des sessions terminal.",
      "heading": "Besoin de l'application bureau ?",
      "links": {
        "architecture": "En savoir plus sur l'architecture",
        "buildYourOwn": "Construisez votre propre pipeline"
      }
    },
    "date": "2025-09-21",
    "description": "Guide technique complet du workflow IA en 4 étapes qui identifie et filtre les fichiers pertinents pour l'exécution des tâches.",
    "errorHandling": {
      "commonIssues": {
        "binaryDetection": "Détection de fichiers binaires : Utilise à la fois la détection basée sur l'extension et sur le contenu",
        "gitNotFound": "Dépôt Git non trouvé : Repli vers le parcours de répertoires avec exclusions standard",
        "heading": "Problèmes courants",
        "networkTimeout": "Timeouts réseau : Retry automatique avec backoff exponentiel pour les erreurs transitoires",
        "tokenLimit": "Limite de tokens dépassée : Implémente un batching intelligent et fournit des messages d'erreur clairs"
      },
      "debugging": {
        "description": "Le workflow fournit une journalisation complète, l'export de métriques de performance et un contexte d'erreur détaillé incluant les informations d'étape, les tentatives de retry et les données intermédiaires pour le dépannage.",
        "heading": "Outils de débogage"
      },
      "errorCategories": {
        "billing": "Erreurs de facturation : Crédits insuffisants ou échecs de paiement avec guidance actionnable",
        "heading": "Catégories d'erreurs",
        "system": "Erreurs système : Accès au système de fichiers, échecs de commandes git ou contraintes de mémoire",
        "validation": "Erreurs de validation : ID de session invalide, description de tâche manquante ou répertoire de projet invalide",
        "workflow": "Erreurs de workflow : Échecs spécifiques à l'étape avec contexte détaillé et suggestions de retry"
      },
      "heading": "Gestion des erreurs et dépannage"
    },
    "integration": {
      "desktop": {
        "description": "Le workflow s'intègre de manière transparente avec l'application bureau via les commandes Tauri, fournissant un accès natif au système de fichiers et des mises à jour événementielles via la classe WorkflowTracker.",
        "heading": "Application bureau"
      },
      "heading": "Patterns d'intégration",
      "implementationPlans": {
        "description": "Les fichiers sélectionnés sont automatiquement transmis au panneau Plans d'implémentation, garantissant que la génération de plan utilise le même contexte de fichiers optimisé sans nécessiter une ré-exécution du workflow de découverte.",
        "heading": "Intégration aux plans d'implémentation"
      },
      "sessionManagement": {
        "description": "Les résultats du workflow sont mis en cache par session, permettant à plusieurs opérations au sein de la même session de réutiliser le contexte de fichiers découvert, améliorant significativement les performances pour les workflows de développement itératifs.",
        "heading": "Gestion de session"
      }
    },
    "intro": "PlanToCode identifie les bons fichiers avant de planifier ou d'exécuter des commandes. Le workflow en 4 étapes restreint la portée et maintient un contexte serré.",
    "metaDescription": "Guide technique complet du workflow IA en 4 étapes qui identifie et filtre les fichiers pertinents pour l'exécution des tâches.",
    "metaTitle": "Workflow de découverte de fichiers - PlanToCode",
    "ogDescription": "Documentation technique de l'architecture du workflow de découverte de fichiers multi-étapes.",
    "ogTitle": "Workflow de découverte de fichiers - PlanToCode",
    "performance": {
      "costOptimization": {
        "description": "Les étapes IA suivent les coûts réels des réponses API, implémentent un batching intelligent pour minimiser l'utilisation de tokens et fournissent des estimations de coûts avant l'exécution pour aider à gérer les dépenses.",
        "heading": "Optimisation des coûts"
      },
      "heading": "Considérations de performance",
      "memory": {
        "description": "Le workflow implémente une gestion intelligente de la mémoire avec mise en cache de fichiers (TTL de 30 secondes), traitement par lots (100 fichiers par lot) et nettoyage automatique des données intermédiaires pour éviter l'épuisement de la mémoire.",
        "heading": "Gestion de la mémoire"
      },
      "monitoring": {
        "description": "Le suivi de performance intégré surveille les temps d'exécution, l'utilisation mémoire, les métriques de débit et fournit des recommandations d'optimisation basées sur l'analyse des données historiques.",
        "heading": "Surveillance des performances"
      }
    },
    "readTime": "12 min",
    "stages": {
      "heading": "Processus du workflow en 4 étapes",
      "stage1": {
        "description": "Utilise l'IA pour sélectionner intelligemment les répertoires racine les plus pertinents à partir d'une liste de chemins candidats basée sur la description de la tâche. Le LLM analyse le répertoire principal du projet et les racines candidates pour déterminer quels répertoires sont les plus susceptibles de contenir des fichiers pertinents pour la tâche.",
        "heading": "Étape 1 : Sélection du dossier racine",
        "technical": "Détails techniques : Reçoit les répertoires racine candidats (jusqu'à profondeur 2) et la description de la tâche. Le LLM évalue chaque chemin par rapport au contexte de la tâche et retourne une liste filtrée de répertoires racine qui seront recherchés dans les étapes suivantes.",
        "inputOutput": "Entrée/Sortie : Reçoit le tableau candidate_roots et task_description. Retourne le tableau root_directories contenant les répertoires sélectionnés par l'IA les plus pertinents pour la tâche."
      },
      "stage2": {
        "binaryDetection": "Détection binaire : Filtre les fichiers avec des extensions binaires (.jpg, .png, .pdf, .exe, etc.) et utilise l'analyse de contenu pour détecter les fichiers binaires par octets nuls et ratios de caractères non imprimables.",
        "description": "Utilise l'IA pour générer des groupes de patterns regex intelligents basés sur la description de la tâche et la structure de répertoires. Chaque groupe de patterns peut inclure des patterns de chemin (positifs et négatifs) et des patterns de contenu. Le processeur applique ensuite ces patterns pour filtrer les fichiers de chaque répertoire racine sélectionné.",
        "gitIntegration": "Intégration Git : Trouve la racine du dépôt git pour chaque répertoire sélectionné et utilise git_utils pour obtenir tous les fichiers non ignorés, respectant les règles .gitignore tout en incluant les fichiers suivis et non suivis.",
        "heading": "Étape 2 : Filtre de fichiers Regex",
        "technical": "Détails techniques : Génère une arborescence de répertoires pour chaque racine, appelle le LLM pour produire des patternGroups avec les champs path_pattern, content_pattern et negative_path_pattern. Utilise fancy-regex pour le support lookahead/lookbehind. Traite les racines en parallèle avec concurrence configurable."
      },
      "stage3": {
        "aiProcessing": "Traitement IA : Utilise de grands modèles de langage pour évaluer le contenu des fichiers par rapport aux exigences de la tâche, avec un chunking intelligent basé sur les tailles de fichiers réelles et les estimations de tokens pour gérer efficacement les fenêtres de contexte.",
        "description": "Emploie des modèles IA pour analyser le contenu des fichiers et évaluer la pertinence par rapport à la description de tâche spécifique. Cette étape effectue une analyse approfondie du contenu en lisant le contenu des fichiers et en demandant au LLM d'identifier quels fichiers sont les plus pertinents pour la tâche.",
        "heading": "Étape 3 : Évaluation de pertinence IA des fichiers",
        "technical": "Détails techniques : Estime les tokens par fichier en utilisant des heuristiques conscientes du type de fichier (code ~3 chars/token, données structurées ~5 chars/token). Crée des chunks conscients du contenu pour rester sous le seuil de 90k tokens. Traite les chunks en parallèle avec streaming pour éviter les timeouts. Valide tous les chemins suggérés par le LLM contre le système de fichiers."
      },
      "stage4": {
        "description": "Découvre des fichiers pertinents supplémentaires en fournissant au LLM les fichiers précédemment identifiés et leur contenu, ainsi que l'arborescence de répertoires. L'IA analyse les imports, les dépendances et la structure du projet pour trouver des fichiers connexes qui enrichissent le contexte pour la tâche.",
        "heading": "Étape 4 : Recherche de chemins étendus",
        "relationship": "Analyse des relations : Lit le contenu de tous les fichiers précédemment identifiés et le fournit au LLM aux côtés de l'arborescence de répertoires (limitée aux racines sélectionnées si disponibles). L'IA identifie des fichiers supplémentaires basés sur les imports, références et relations structurelles.",
        "technical": "Détails techniques : Génère une arborescence de répertoires combinée pour les répertoires racine sélectionnés. Lit le contenu de tous les fichiers initial_paths. Utilise des appels LLM en streaming pour éviter les timeouts Cloudflare. Valide les chemins découverts contre le système de fichiers et normalise en chemins relatifs au sein du projet."
      }
    },
    "stateManagement": {
      "eventDriven": {
        "description": "Le système publie des événements en temps réel pour les changements d'état du workflow, les complétions d'étapes et les conditions d'erreur. Ces événements permettent des interfaces utilisateur réactives et l'intégration avec des systèmes de monitoring externes.",
        "heading": "Mises à jour événementielles"
      },
      "heading": "Gestion de l'état du workflow",
      "intermediateData": {
        "description": "Chaque étape stocke sa sortie dans un format de données intermédiaires structuré, incluant le contenu de l'arborescence de répertoires, les patterns regex, les résultats de listes de fichiers filtrés. Ces données sont accessibles pour le débogage et peuvent être utilisées pour reprendre les workflows à partir d'étapes spécifiques.",
        "heading": "Stockage des données intermédiaires"
      },
      "transitions": {
        "description": "Le workflow progresse à travers des états clairement définis : Créé → En cours → En pause (optionnel) → Terminé/Échoué/Annulé. Chaque transition d'état publie des événements qui peuvent être surveillés pour des mises à jour en temps réel.",
        "heading": "Transitions d'état"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Pipeline de découverte de fichiers",
        "description": "Le workflow en 4 étapes : sélection du dossier racine, filtrage regex, évaluation de pertinence IA et découverte de chemins étendus.",
        "imageSrc": "/images/docs/file-discovery/pipeline.svg",
        "caption": "Pipeline de découverte de fichiers montrant les 4 étapes",
        "imageAlt": "Diagramme montrant le workflow de découverte de fichiers en 4 étapes : Sélection du dossier racine, Filtre de fichiers Regex, Évaluation de pertinence IA des fichiers et Recherche de chemins étendus"
      }
    },
    "title": "Workflow de découverte de fichiers",
    "sqliteStorage": {
      "heading": "Stockage SQLite",
      "description": "Tout l'état du workflow, les résultats intermédiaires et les métadonnées de job sont persistés dans SQLite. Chaque étape stocke sa sortie dans la table background_jobs, permettant la reprise de workflow, le débogage et les pistes d'audit. Les enregistrements de job incluent l'utilisation de tokens, le suivi des coûts et les templates de prompts système pour chaque étape IA."
    }
  },
  "hub": {
    "ctaDescription": "Téléchargez PlanToCode pour accéder au planificateur d'implémentation, aux garde-fous de modèle, aux sessions terminal et aux fonctionnalités de transcription décrites dans cette documentation.",
    "ctaHeading": "Prêt à essayer ces workflows ?",
    "ctaLinks": {
      "overview": "Commencer par la vue d'ensemble",
      "runtime": "Parcours d'exécution"
    },
    "description": "Apprenez à planifier et livrer des modifications de code avec PlanToCode : découverte de fichiers, plans d'implémentation, sessions terminal, garde-fous de modèle et voix.",
    "exploreHeading": "Explorer la documentation",
    "learnMore": "En savoir plus",
    "searchAriaLabel": "Rechercher dans la documentation",
    "searchPlaceholder": "Rechercher dans la documentation...",
    "searchShortcut": "⌘K",
    "title": "Documentation PlanToCode"
  },
  "onThisPage": {
    "title": "Sur cette page"
  },
  "sidebar": {
    "title": "Documentation"
  },
  "sections": {
    "architecture": {
      "title": "Architecture et fonctionnement interne"
    },
    "inputs": {
      "title": "Entrées et capture"
    },
    "planning": {
      "title": "Pipeline de planification"
    },
    "execution": {
      "title": "Exécution et automatisation"
    },
    "research": {
      "title": "Recherche et modèles"
    },
    "platform": {
      "title": "Build et déploiement"
    }
  },
  "items": {
    "overview": {
      "title": "Vue d'ensemble du système",
      "description": "Commencez ici : ce que fait le système, comment fonctionne la boucle principale et où se trouve chaque composant."
    },
    "runtime-walkthrough": {
      "title": "Parcours d'exécution",
      "description": "Chronologie de bout en bout de ce qui se passe de l'entrée de tâche à l'exécution."
    },
    "architecture": {
      "title": "Architecture système",
      "description": "Comment le shell bureau, les services Rust, les APIs serveur et les couches de persistance s'articulent."
    },
    "desktop-app": {
      "title": "Fonctionnement interne de l'app bureau",
      "description": "Shell Tauri v2, couche de commandes Rust, sessions PTY et gestion de l'état UI."
    },
    "server-api": {
      "title": "API serveur et proxy LLM",
      "description": "Auth, routage de providers, configuration de modèle et endpoints WebSocket."
    },
    "mobile-ios": {
      "title": "Architecture client iOS",
      "description": "Workflows Swift, flux de connexion Auth0 et gestion de session device-link."
    },
    "background-jobs": {
      "title": "Jobs en arrière-plan et orchestration",
      "description": "Enregistrements de jobs, orchestration de workflow, processeurs et streaming d'événements."
    },
    "data-model": {
      "title": "Modèle de données et stockage",
      "description": "Entités SQLite, relations et comment l'état est réhydraté."
    },
    "decisions-tradeoffs": {
      "title": "Décisions techniques et compromis",
      "description": "Pourquoi Tauri, SQLite et un proxy LLM dédié ont été choisis et ce qu'ils coûtent."
    },
    "build-your-own": {
      "title": "Construisez votre propre pipeline",
      "description": "Guide conceptuel pour concevoir des workflows de découverte de fichiers et de génération de plans."
    },
    "meeting-ingestion": {
      "title": "Ingestion de réunions et enregistrements",
      "description": "Comment les enregistrements deviennent des entrées de tâches structurées et des artefacts."
    },
    "video-analysis": {
      "title": "Analyse vidéo",
      "description": "Échantillonnage de frames, prompts et artefacts d'analyse à partir des enregistrements."
    },
    "voice-transcription": {
      "title": "Transcription vocale",
      "description": "Cycle de vie d'enregistrement, paramètres conscients du projet et gestion des périphériques."
    },
    "text-improvement": {
      "title": "Amélioration de texte",
      "description": "Popover de sélection, file de jobs et intégrations pour le nettoyage de prompts."
    },
    "file-discovery": {
      "title": "Workflow de découverte de fichiers",
      "description": "Workflow en arrière-plan qui rassemble les chemins pertinents pour chaque tâche."
    },
    "implementation-plans": {
      "title": "Plans d'implémentation",
      "description": "Comment les plans sont streamés dans le visualiseur Monaco et restent liés à l'historique des plans."
    },
    "merge-instructions": {
      "title": "Instructions de fusion",
      "description": "Comment plusieurs brouillons de plans sont fusionnés en utilisant des plans source balisés XML et les directives utilisateur."
    },
    "prompt-types": {
      "title": "Types de prompts et templates",
      "description": "Catalogue des types de jobs pilotés par prompts et assemblage de templates."
    },
    "terminal-sessions": {
      "title": "Sessions terminal",
      "description": "Sessions PTY persistantes, détection CLI et comportement de récupération."
    },
    "copy-buttons": {
      "title": "Boutons de copie",
      "description": "Transfert de templates des plans vers les terminaux et outils externes."
    },
    "deep-research": {
      "title": "Recherche approfondie et recherche web",
      "description": "Workflow de recherche web, intégration API, optimisation des requêtes et intégration au workflow de développement."
    },
    "provider-routing": {
      "title": "Routage de providers et streaming",
      "description": "Comment les requêtes de providers sont normalisées, streamées et suivies."
    },
    "model-configuration": {
      "title": "Configuration de modèle",
      "description": "Modèles autorisés par tâche et garde-fous de tokens dans le toggle de sélection."
    },
    "server-setup": {
      "title": "Configuration de serveur dédié",
      "description": "Infrastructure basée sur Ansible : hardening de base, déploiement d'app et secrets gérés par vault."
    },
    "tauri-v2": {
      "title": "Guide de développement Tauri v2",
      "description": "Structure de projet, commandes et permissions basées sur les capabilities pour Tauri v2."
    },
    "distribution-macos": {
      "title": "Distribution macOS",
      "description": "Signature, notarisation, packaging DMG et artefacts de mise à jour."
    },
    "distribution-windows": {
      "title": "Distribution Windows et Store",
      "description": "Builds NSIS, packaging MSIX et soumission au Microsoft Store."
    }
  },
  "implementationPlans": {
    "meta": {
      "title": "Plans d'implémentation - Révision des modifications IA",
      "description": "Guide de planification d'implémentation IA. Générez, révisez et approuvez des plans fichier par fichier avant l'exécution. Évitez les doublons et les mauvais chemins."
    },
    "category": "Guide produit",
    "context": {
      "audit": "Toutes les métadonnées persistent avec le plan à des fins d'audit. Les équipes entreprise peuvent suivre quels intervenants ont révisé quels plans, quelles modifications ont été demandées et la chaîne de raisonnement complète de la description initiale de la tâche à travers la découverte de fichiers jusqu'au plan final approuvé.",
      "heading": "Contexte et métadonnées pour la gouvernance d'entreprise",
      "storage": "Le panneau stocke quelles racines de dépôt ont été sélectionnées pendant le workflow de découverte de fichiers pour que les actions de suivi réutilisent la même portée. Il enregistre également les métadonnées spécifiques au plan, comme le répertoire du projet et tout contenu de prompt préparé, pour que les prompts en aval puissent être générés ou copiés sans recalculer le workflow.",
      "tokenEstimation": "L'estimation de tokens s'exécute avant que les prompts ne soient copiés. Le panneau appelle la commande d'estimation de tokens avec le répertoire du projet, les fichiers sélectionnés et le modèle actuellement choisi, affichant les totaux de prompt système et utilisateur pour que les équipes puissent rester sous les limites du modèle."
    },
    "cta": {
      "claudeCodeLink": "Voir le workflow mode plan Claude",
      "codexLink": "Voir le workflow mode plan Codex",
      "cursorLink": "Voir le workflow mode plan Cursor",
      "description": "Les plans d'implémentation avec humain dans la boucle sont disponibles dans l'application bureau PlanToCode. Téléchargez la version pour votre plateforme pour expérimenter un développement assisté par IA sûr et gouverné.",
      "heading": "Prêt à adopter les agents de codage IA en toute sécurité ?",
      "links": {
        "architecture": "Architecture système",
        "decisions": "Décisions et compromis",
        "buildYourOwn": "Construisez votre propre pipeline",
        "fileDiscovery": "Workflow de découverte de fichiers"
      }
    },
    "date": "2025-09-19",
    "description": "Comment PlanToCode permet une adoption confiante des agents de codage IA grâce à une gouvernance avec humain dans la boucle, des plans granulaires fichier par fichier et des workflows de révision complets.",
    "fileGranularity": {
      "created": "Créés (avec chemins de fichiers complets et structure de contenu initiale)",
      "declaredFiles": "Chaque étape d'un plan déclare explicitement quels fichiers seront :",
      "deleted": "Supprimés (avec justification et analyse des dépendances)",
      "heading": "Granularité fichier par fichier",
      "impact": "Ce niveau de détail rend l'impact des modifications proposées parfaitement clair avant que tout code ne soit touché. Les responsables d'équipe peuvent immédiatement identifier si du code legacy critique sera modifié, si des changements cassants sont proposés, ou si le plan touche des fichiers nécessitant un examen supplémentaire.",
      "intro": "Les plans d'implémentation utilisent une structure hautement granulaire qui décompose les tâches de développement fichier par fichier, avec des chemins de fichiers exacts correspondant à la structure du dépôt du projet. Cette granularité est fondamentale pour prévenir les régressions et permettre une adoption confiante des agents de codage IA en environnement d'entreprise.",
      "modified": "Modifiés (avec plages de lignes spécifiques et modifications décrites)",
      "referenced": "Référencés (pour le contexte mais non modifiés)",
      "transmission": "L'approche fichier par fichier permet également une transmission précise des plans approuvés aux agents de codage. Au lieu d'instructions vagues comme « mettre à jour le système d'authentification », les agents reçoivent des spécifications exactes : « modifier src/auth/session_manager.rs lignes 45-67 pour ajouter la rotation de token, créer src/auth/token_store.rs avec la structure suivante... »"
    },
    "hitl": {
      "approve": "Approuver :",
      "approveDesc": "Ce n'est qu'après approbation explicite que les plans peuvent être transmis de manière sécurisée à l'agent de codage choisi ou au développeur logiciel assigné pour exécution.",
      "conclusion": "Ce workflow garantit que tous les efforts de développement s'alignent sur les exigences produit de l'entreprise, les workflows d'équipe et les objectifs business. Aucune modification de code ne se produit sans approbation humaine explicite.",
      "edit": "Modifier :",
      "editDesc": "Les intervenants peuvent directement modifier les étapes, ajuster les approches, ajouter des contraintes ou supprimer des opérations risquées en utilisant les fonctionnalités d'édition VS Code.",
      "heading": "Gouvernance avec humain dans la boucle",
      "intro": "PlanToCode implémente un workflow complet avec humain dans la boucle (HITL) qui garantit que les responsables d'équipe et les intervenants conservent un contrôle total sur chaque aspect des plans d'implémentation générés par IA. Ce modèle de gouvernance prévient les régressions, bugs et modifications non intentionnelles qui peuvent survenir quand les agents de codage IA opèrent de manière autonome.",
      "reject": "Rejeter :",
      "rejectDesc": "Les plans qui ne répondent pas aux exigences peuvent être rejetés entièrement, avec des pistes d'audit complètes maintenues pour la conformité et l'apprentissage.",
      "requestChanges": "Demander des modifications :",
      "requestChangesDesc": "Les équipes peuvent demander des modifications au système IA, générant des approches alternatives ou fusionnant plusieurs plans avec des instructions personnalisées.",
      "review": "Réviser :",
      "reviewDesc": "Les plans s'ouvrent dans l'éditeur Monaco où les réviseurs peuvent examiner chaque modification proposée avec coloration syntaxique complète et outils d'édition professionnels.",
      "workflow": "Chaque plan doit passer par un workflow de révision structuré avant que toute modification de code ne commence :"
    },
    "intro": "Révisez et approuvez chaque plan avant l'exécution. La gouvernance avec humain dans la boucle et la granularité fichier par fichier garantissent que les modifications générées par IA s'alignent sur les exigences de l'entreprise et les workflows d'équipe.",
    "metaDescription": "Guide de planification d'implémentation IA. Générez, révisez et approuvez des plans fichier par fichier avant l'exécution. Évitez les doublons et les mauvais chemins.",
    "metaTitle": "Plans d'implémentation - Révision des modifications IA",
    "multiplePlans": {
      "description": "Les plans peuvent être fusionnés, supprimés ou rouverts plus tard. Le panneau garde une liste des identifiants de plans sélectionnés, gère une modale dédiée pour la sortie terminal liée à un plan et expose des aides à la navigation pour que les réviseurs puissent parcourir les plans antérieurs sans fermer le visualiseur. L'accès terminal, les contrôles de copie de prompt et les instructions de fusion partagent tous le même identifiant de job pour que l'historique d'audit reste cohérent.",
      "heading": "Travailler avec plusieurs plans"
    },
    "ogDescription": "Comprenez comment la gouvernance avec humain dans la boucle et les workflows de révision fichier par fichier garantissent un développement IA sûr avec un contrôle complet sur les modifications de code.",
    "ogTitle": "Plans d'implémentation avec humain dans la boucle dans PlanToCode",
    "plansOrigin": {
      "description": "Chaque plan correspond à un job en arrière-plan dans la session actuelle. Le panneau s'abonne aux données de plan, garde une trace de quel plan est actuellement ouvert et expose la navigation entre les jobs plus anciens et plus récents. Ce comportement réside dans {code} et le composant de panneau environnant.",
      "heading": "D'où viennent les plans",
      "processor": "ImplementationPlanProcessor gère la génération de plan. Il lit les fichiers pertinents, génère optionnellement une arborescence de répertoires basée sur les répertoires racine sélectionnés et assemble un prompt unifié pour le LLM.",
      "storage": "Les réponses de plan sont stockées dans la table jobs avec des métadonnées incluant planTitle, summary, sessionName et l'utilisation de tokens. La réponse LLM brute est préservée pour l'audit.",
      "streaming": "Les plans sont streamés via le LlmTaskRunner avec des événements de progression en temps réel. Des avertissements de tokens sont journalisés pour les prompts dépassant 100k tokens mais le traitement continue avec le contenu complet."
    },
    "readTime": "6 min",
    "reviewingPlans": {
      "description": "Le contenu du plan est rendu via le {code} partagé, qui encapsule Monaco Editor. Le visualiseur détecte automatiquement les langages courants, supporte les actions copier-vers-presse-papiers, virtualise les très grands plans et offre des métriques optionnelles comme les comptages de caractères et la coloration syntaxique.",
      "heading": "Réviser les plans avec Monaco",
      "opening": "Quand un plan est ouvert, le panneau résout le plan actif par identifiant de job, passe le contenu à Monaco et permet aux réviseurs de se déplacer entre les jobs voisins sans perdre la modale actuellement ouverte."
    },
    "visuals": {
      "structure": {
        "title": "Structure du plan d'implémentation",
        "description": "Format XML pour les plans d'implémentation avec granularité fichier par fichier et métadonnées.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "caption": "Structure du plan montrant les étapes, fichiers et suivi des dépendances"
      }
    },
    "title": "Plans d'implémentation",
    "planProcessor": {
      "heading": "Pipeline de génération de plan",
      "description": "Le ImplementationPlanProcessor orchestre la génération de plan en chargeant le contenu des fichiers, construisant le contexte et streamant les résultats via le LLM task runner.",
      "inputs": "Contexte de session, description de tâche, fichiers pertinents sélectionnés, arborescence de répertoires optionnelle (configurable via le flag include_project_structure) et flag de recherche web pour la recherche externe.",
      "prompt": "Utilise prompt_utils::build_unified_prompt pour combiner la description de tâche, le contenu complet des fichiers (sans troncature) et l'arborescence de répertoires dans un format spécifique au modèle avec des comptages de tokens estimés.",
      "output": "Réponse LLM brute stockée comme JobResultData::Text. Les métadonnées incluent planTitle, summary, utilisation de tokens, statistiques de cache et coût réel.",
      "display": "Les réponses sont streamées vers l'UI via des événements de progression. Les plans sont rendus dans un VirtualizedCodeViewer basé sur Monaco supportant la coloration syntaxique et les actions de copie."
    },
    "schema": {
      "heading": "Structure de données du plan",
      "description": "Les plans d'implémentation sont stockés comme des réponses LLM brutes avec des métadonnées associées. Le texte de la réponse est préservé exactement tel que généré, tandis que les métadonnées structurées suivent le contexte et l'utilisation du plan.",
      "fieldsHeading": "Champs de métadonnées",
      "fields": [
        "planTitle - Titre généré ou fourni par l'utilisateur pour le plan",
        "summary - Résumé lisible par un humain du plan",
        "sessionName - Nom de la session qui a généré le plan",
        "isStructured - Toujours true pour les plans terminés",
        "isStreaming - False pour les plans terminés (true pendant la génération)",
        "planData - Contient agent_instructions (optionnel) et le tableau steps"
      ],
      "exampleHeading": "Exemple de métadonnées",
      "example": "{\n  \"planTitle\": \"Authentication System Refactor\",\n  \"summary\": \"Implementation plan generated\",\n  \"sessionName\": \"my-project\",\n  \"isStructured\": true,\n  \"isStreaming\": false,\n  \"planData\": {\n    \"agent_instructions\": null,\n    \"steps\": []\n  }\n}"
    }
  },
  "modelConfiguration": {
    "meta": {
      "title": "Configuration des modèles et garde-fous - PlanToCode",
      "description": "Comment PlanToCode vous permet de choisir les modèles autorisés par tâche et maintient les prompts dans la fenêtre de contexte active."
    },
    "category": "Guide Produit",
    "date": "2025-09-20",
    "description": "Listes de modèles par tâche, contrôles de sélection et garde-fous de tokens dans le client desktop.",
    "intro": "PlanToCode traite la sélection de modèle comme une décision au niveau de la tâche. Chaque workflow est livré avec un modèle par défaut et une liste autorisée, et le client desktop expose ces options via un basculeur qui empêche l'envoi de prompts dépassant la fenêtre de contexte active.",
    "metaDescription": "Comment PlanToCode vous permet de choisir les modèles autorisés par tâche et maintient les prompts dans la fenêtre de contexte active.",
    "metaTitle": "Configuration des modèles et garde-fous - PlanToCode",
    "ogDescription": "Découvrez comment les paramètres de modèle par tâche, les basculeurs de sélection et les estimations de tokens fonctionnent ensemble.",
    "ogTitle": "Configuration des modèles et garde-fous - PlanToCode",
    "promptEstimation": {
      "description": "Les comptages de tokens sont calculés via la commande d'estimation de tokens. Le panneau soumet l'identifiant de session, la description de tâche, les fichiers pertinents et le modèle sélectionné pour que le backend puisse retourner les valeurs de tokens système, utilisateur et total. Ces nombres alimentent directement les garde-fous du sélecteur et permettent aux équipes de repérer les prompts hors limite avant de les copier dans un autre outil.",
      "heading": "Estimation de prompt"
    },
    "readTime": "5 min",
    "selectorToggle": {
      "description": "Le panneau Plans d'implémentation affiche les modèles autorisés avec le {code}. Le basculeur affiche chaque modèle autorisé, suit la sélection active et vérifie si le prompt estimé plus les tokens de sortie planifiés tiennent dans la fenêtre de contexte annoncée du modèle avant d'autoriser un changement.",
      "guardrails": "Si un modèle ne peut pas supporter l'exigence totale de tokens, le basculeur désactive le bouton et affiche une infobulle avec le dépassement calculé, maintenant les réviseurs dans des limites sûres avant qu'ils n'envoient du travail à un agent.",
      "heading": "Basculeur de sélection dans le client"
    },
    "taskDefaults": {
      "description": "Les modèles par défaut et les alternatives autorisées sont stockés côté serveur dans la configuration de l'application. Chaque type de tâche - comme les plans d'implémentation, les fusions, la génération de prompts ou la transcription vocale - définit un modèle préféré, une liste d'options autorisées et des limites de tokens que l'application desktop lit au démarrage.",
      "heading": "Paramètres par défaut pilotés par la tâche"
    },
    "title": "Configuration des Modèles"
  },
  "terminalSessions": {
    "meta": {
      "title": "Sessions terminal - PlanToCode",
      "description": "Guide technique de l'implémentation terminal PTY dans PlanToCode. Apprenez comment les sessions persistent, comment fonctionne la détection d'inactivité des agents et les mécanismes de récupération."
    },
    "attentionDetection": {
      "conclusion": "Cette approche vous aide à suivre quand les agents ont terminé des tâches ou ont besoin de conseils, sans essayer de deviner pourquoi ils se sont arrêtés. Les indicateurs d'attention s'effacent automatiquement lorsqu'une nouvelle sortie est reçue.",
      "heading": "Détection d'attention des agents",
      "intro": "Le terminal surveille l'activité des agents via un système de détection d'inactivité à deux niveaux. Quand un agent cesse de produire une sortie, le système vous alerte progressivement pour vérifier ce qui s'est passé :",
      "level1": "Niveau 1 (30 secondes) : \"Agent inactif - peut avoir terminé la tâche\" avec indicateur jaune",
      "level2": "Niveau 2 (2 minutes) : \"L'agent nécessite de l'attention - vérifiez le terminal\" avec indicateur rouge et notification bureau"
    },
    "category": "Guide Produit",
    "date": "2025-09-22",
    "dependencyChecks": {
      "description": "Avant de lancer des commandes, le terminal vérifie la présence d'outils CLI supportés comme claude, cursor, codex et gemini. La même commande rapporte également le shell par défaut pour que les utilisateurs sachent quel environnement sera exécuté. Cela empêche de lancer une session qui ne peut pas trouver le binaire requis.",
      "heading": "Vérifications des dépendances"
    },
    "description": "Sessions PTY persistantes, détection d'attention des agents et comportement de récupération dans le terminal Plans d'implémentation.",
    "intro": "Exécutez des commandes dans un PTY persistant avec vérifications de santé et journalisation. La transcription vocale est disponible quand vous en avez besoin.",
    "lifecycle": {
      "description": "Quand un terminal s'ouvre, le composant UI crée une session PTY et diffuse la sortie via une vue tamponnée. Le composant affiche immédiatement l'état de connexion, transmet les frappes au PTY et réessaie automatiquement si la session échoue. Les métadonnées de session sont stockées dans SQLite avec les horodatages, codes de sortie, répertoires de travail et le journal complet de sortie pour que les redémarrages puissent reprendre le contexte précédent.",
      "heading": "Cycle de vie de la session"
    },
    "metaDescription": "Guide technique de l'implémentation terminal PTY dans PlanToCode. Apprenez comment les sessions persistent, comment fonctionne la détection d'inactivité des agents et les mécanismes de récupération.",
    "metaTitle": "Sessions terminal - PlanToCode",
    "ogDescription": "Comprenez la persistance des sessions, la détection d'attention des agents et la récupération dans le terminal de plan.",
    "ogTitle": "Sessions terminal - PlanToCode",
    "readTime": "6 min",
    "title": "Sessions Terminal",
    "voiceRecovery": {
      "heading": "Transcription vocale et récupération",
      "recovery": "Si une session PTY se déconnecte, la surface du terminal affiche des contrôles de récupération et réessaie la connexion avec un délai exponentiel. Les vérifications de santé continuent de surveiller l'état de la session et fournissent des actions de récupération automatiques lorsque des problèmes de connexion sont détectés.",
      "voice": "Dans la modale du terminal, la transcription vocale peut capturer la parole et la coller dans la zone d'entrée du terminal. Le hook d'enregistrement consulte les paramètres de transcription au niveau du projet, suit l'état d'enregistrement et diffuse le texte reconnu dans la session de plan active."
    }
  },
  "copyButtons": {
    "meta": {
      "title": "Boutons de copie - PlanToCode",
      "description": "Comment les boutons de copie pilotés par templates résolvent les placeholders contre les plans et transfèrent vers les terminaux ou le presse-papiers pour l'exécution des agents."
    },
    "category": "Exécution",
    "date": "2025-09-23",
    "readTime": "10 min",
    "title": "Boutons de Copie",
    "description": "Transfert piloté par templates des plans d'implémentation vers les terminaux PTY et les outils externes.",
    "intro": "Les boutons de copie font le pont entre la planification et l'exécution en résolvant les placeholders de template contre le plan actif, puis en livrant le résultat aux sessions PTY ou au presse-papiers système. Chaque action est liée aux métadonnées de job pour des pistes d'audit complètes, permettant aux équipes de tracer exactement ce qui a été envoyé aux agents.",
    "metaTitle": "Boutons de copie - PlanToCode",
    "metaDescription": "Comment les boutons de copie pilotés par templates résolvent les placeholders contre les plans et transfèrent vers les terminaux ou le presse-papiers pour l'exécution des agents.",
    "ogTitle": "Boutons de copie - PlanToCode",
    "ogDescription": "Guide technique des templates de boutons de copie, résolution des placeholders et transfert terminal.",
    "visuals": {
      "templateFlow": {
        "title": "Flux de résolution de template",
        "description": "Ce diagramme montre le pipeline d'exécution des boutons de copie. Étape 1 'Clic sur le bouton' : L'utilisateur clique sur un bouton de copie dans le visualiseur de plan ou l'en-tête du terminal. La configuration du bouton contient un label, une chaîne de template et une cible (terminal ou presse-papiers). Étape 2 'Extraction des placeholders' : Le processeur de template recherche les motifs à double accolade comme {{IMPLEMENTATION_PLAN}}, {{STEP_CONTENT}}, {{TASK_DESCRIPTION}}. Étape 3 'Résolution du contexte' : Le résolveur interroge les métadonnées de job pour le contenu du plan, puis l'état de session pour la description de tâche et les fichiers sélectionnés. Les placeholders manquants sont préservés dans la sortie pour le débogage. Étape 4 'Livraison à la cible' : Pour les cibles terminal, le contenu est écrit dans le buffer d'entrée PTY via master.take_writer(). Pour les cibles presse-papiers, le contenu est copié via l'API clipboard de Tauri. Une notification toast confirme l'action avec un aperçu du contenu.",
        "imageSrc": "/images/docs/copy-buttons/templates.svg",
        "imageAlt": "Flux montrant la résolution de template des boutons de copie",
        "caption": "Placeholder pour un diagramme de flux de résolution de template."
      }
    },
    "templateConfiguration": {
      "heading": "Sources de configuration des templates",
      "description": "Les templates de boutons de copie suivent un modèle de configuration en couches. Les paramètres par défaut du serveur fournissent des templates de base, les remplacements au niveau projet personnalisent pour les workflows d'équipe, et les configurations spécifiques aux tâches gèrent les scénarios ponctuels.",
      "serverDefaults": {
        "heading": "Paramètres par défaut du serveur",
        "description": "Templates partagés depuis /api/config/desktop-runtime-config. Inclut les labels de boutons, les chaînes de template, la cible (terminal ou presse-papiers) et les conditions de visibilité."
      },
      "projectOverrides": {
        "heading": "Remplacements de projet",
        "description": "Templates stockés dans la table SQLite project_settings. Fusionnés au démarrage avec les paramètres par défaut du serveur pour personnaliser selon les standards de l'équipe."
      },
      "taskSpecific": {
        "heading": "Spécifique à la tâche",
        "description": "Templates per-task_model_config pour les workflows spécialisés. Permet des patterns de transfert personnalisés sans modifier les paramètres globaux."
      }
    },
    "placeholderResolution": {
      "heading": "Résolution des placeholders",
      "description": "Les templates utilisent des placeholders à double accolade qui sont résolus contre le plan actif et le contexte de session au moment du clic. Les placeholders principaux sont {{IMPLEMENTATION_PLAN}} et {{TASK_DESCRIPTION}}.",
      "placeholdersHeading": "Placeholders disponibles",
      "placeholders": [
        {
          "placeholder": "{{IMPLEMENTATION_PLAN}}",
          "description": "Contenu complet du plan d'implémentation tel que généré par le LLM"
        },
        {
          "placeholder": "{{TASK_DESCRIPTION}}",
          "description": "La description de tâche de la session actuelle"
        }
      ],
      "resolutionOrder": "Ordre de résolution : Métadonnées de job d'abord, puis contenu du plan, puis contexte de session. Les placeholders indéfinis sont préservés dans la sortie pour le débogage.",
      "exampleTemplate": "Exemple de template :\n\n{{IMPLEMENTATION_PLAN}}\n\nComprenez le plan d'implémentation ci-dessus en profondeur. Analysez l'architecture, les flux de données et la séquence des événements.\n\nTâche : {{TASK_DESCRIPTION}}"
    },
    "processingPipeline": {
      "heading": "Pipeline de traitement des templates",
      "description": "Quand un bouton est cliqué, le processeur de template exécute un pipeline multi-étapes : extraction des placeholders, recherche de contexte, substitution de valeurs et formatage de sortie.",
      "steps": [
        {
          "number": 1,
          "title": "Extraction des placeholders",
          "description": "Scan regex pour les motifs {{...}} dans la chaîne de template"
        },
        {
          "number": 2,
          "title": "Recherche de contexte",
          "description": "Interroge les métadonnées de job, le contenu du plan et l'état de session pour les valeurs"
        },
        {
          "number": 3,
          "title": "Substitution des valeurs",
          "description": "Remplace les placeholders par les valeurs résolues, en préservant le formatage"
        },
        {
          "number": 4,
          "title": "Formatage de sortie",
          "description": "Applique l'échappement spécifique à la cible (shell pour terminal, plain pour presse-papiers)"
        }
      ],
      "chunking": {
        "heading": "Découpage des grands plans",
        "description": "Les plans dépassant 100KB sont automatiquement découpés en segments séquentiels avec des limites claires pour éviter de surcharger les buffers du terminal ou les limites du presse-papiers. Chaque segment est préfixé avec sa position (ex: '[Partie 1/3]')."
      }
    },
    "terminalHandoff": {
      "heading": "Transfert vers terminal PTY",
      "description": "Les boutons configurés pour le transfert terminal écrivent directement dans le buffer d'entrée de la session PTY. Le template résolu apparaît comme s'il était tapé par l'utilisateur, déclenchant l'exécution de l'agent immédiatement.",
      "detailsHeading": "Détails du transfert",
      "details": [
        "Contenu écrit via master.take_writer() dans le buffer d'entrée PTY",
        "Supporte les entrées multi-lignes et les séquences d'échappement",
        "Le contenu volumineux est découpé en segments de 4KB pour éviter le débordement de buffer",
        "L'UI affiche les 100 premiers caractères comme aperçu de confirmation"
      ],
      "codeExample": "// Terminal handoff implementation\nasync fn handoff_to_terminal(\n    session_id: &str,\n    content: &str,\n    template_id: &str,\n) -> Result<HandoffResult> {\n    // Get PTY writer for session\n    let writer = terminal_manager.get_writer(session_id)?;\n\n    // Write content to PTY input buffer\n    writer.write_all(content.as_bytes()).await?;\n\n    // Log the action for audit\n    copy_button_actions.insert(CopyButtonAction {\n        session_id: session_id.to_string(),\n        template_id: template_id.to_string(),\n        content_hash: sha256(content),\n        created_at: Utc::now(),\n    })?;\n\n    Ok(HandoffResult::Terminal { session_id })\n}"
    },
    "clipboardHandoff": {
      "heading": "Transfert vers presse-papiers",
      "description": "Les boutons configurés pour le presse-papiers copient le template résolu dans le presse-papiers système via l'API clipboard de Tauri. Cela permet le transfert vers des outils externes comme les terminaux IDE ou les agents web.",
      "crossPlatform": {
        "heading": "API multiplateforme",
        "description": "Utilise tauri::api::clipboard::set_text() pour un accès cohérent au presse-papiers sur macOS, Windows et Linux."
      },
      "feedback": {
        "heading": "Retour utilisateur",
        "description": "Une notification toast confirme la copie avec un aperçu du contenu et une estimation du nombre de tokens pour le modèle cible."
      }
    },
    "defaultButtons": {
      "heading": "Boutons de copie par défaut",
      "description": "PlanToCode est livré avec plusieurs boutons de copie par défaut qui couvrent les workflows courants. Ceux-ci peuvent être personnalisés ou étendus via les paramètres de projet.",
      "buttonsHeading": "Boutons intégrés",
      "buttons": [
        {
          "id": "parallel-agents",
          "label": "Agents Claude parallèles",
          "description": "Lance des agents de codage Claude parallèles qui s'exécutent simultanément. Chaque agent reçoit des instructions explicites sur ses responsabilités. Inclut des instructions pour supprimer complètement les fonctionnalités dépréciées."
        },
        {
          "id": "investigate-results",
          "label": "Investiguer les résultats",
          "description": "Examine les résultats des agents lancés et vérifie l'implémentation complète. Effectue une auto-vérification en lisant les fichiers modifiés et en analysant les changements sans lancer d'agents supplémentaires."
        },
        {
          "id": "task-only",
          "label": "Tâche",
          "description": "Copie uniquement la description de tâche pour le contexte. Utilise le placeholder {{TASK_DESCRIPTION}}."
        },
        {
          "id": "task-and-plan",
          "label": "Tâche + Plan",
          "description": "Combine la description de tâche et le plan d'implémentation. Utile pour fournir le contexte complet quand l'agent a besoin à la fois de l'objectif et de la stratégie d'exécution."
        },
        {
          "id": "plan-only",
          "label": "Plan",
          "description": "Copie uniquement le contenu du plan d'implémentation. Idéal pour les agents qui ont déjà le contexte de la tâche et n'ont besoin que des instructions d'exécution."
        }
      ]
    },
    "customization": {
      "heading": "Personnalisation des boutons de copie",
      "description": "Les boutons de copie peuvent être personnalisés à plusieurs niveaux : paramètres globaux par défaut, remplacements au niveau projet et configurations par tâche.",
      "globalDefaults": {
        "heading": "Paramètres globaux par défaut",
        "description": "La configuration côté serveur dans /api/config/desktop-runtime-config définit l'ensemble de base des boutons de copie. Ceux-ci sont chargés au démarrage de l'application desktop et mis en cache pour une utilisation hors ligne."
      },
      "projectSettings": {
        "heading": "Personnalisation au niveau projet",
        "description": "Chaque projet peut remplacer les boutons par défaut via le panneau Paramètres. Les boutons spécifiques au projet sont stockés dans SQLite et fusionnés avec les paramètres par défaut du serveur au démarrage."
      },
      "taskSettings": {
        "heading": "Configuration au niveau tâche",
        "description": "Les tâches individuelles peuvent avoir leurs propres configurations de boutons de copie. Cela permet des ensembles de boutons différents pour les plans d'implémentation, les revues de code ou les tâches de documentation."
      },
      "editorDescription": "L'éditeur de boutons de copie dans les Paramètres permet le réordonnancement par glisser-déposer, l'édition inline des labels et la modification du contenu des templates. Les modifications sont temporisées et persistées automatiquement."
    },
    "uiIntegration": {
      "heading": "Intégration UI et sécurité",
      "description": "Les boutons de copie apparaissent dans les visualiseurs de plan et les en-têtes de terminal. Chaque bouton affiche un popover d'aperçu avec le contenu résolu et l'estimation de tokens avant l'exécution.",
      "tokenEstimation": {
        "heading": "Estimation de tokens",
        "description": "Les estimations de tokens aident les réviseurs à valider que le prompt tient dans la fenêtre de contexte du modèle cible avant le transfert. Affiché à côté de l'aperçu."
      },
      "previewModal": {
        "heading": "Modale d'aperçu complet",
        "description": "Cliquer sur l'icône d'aperçu ouvre une modale avec le template résolu complet, la coloration syntaxique et une vue diff si le template a changé depuis la dernière utilisation."
      },
      "disabledState": {
        "heading": "État désactivé",
        "description": "Les boutons sont désactivés quand le contexte requis est manquant (ex : pas de plan actif, session manquante). Les infobulles expliquent quel contexte est nécessaire pour activer le bouton."
      }
    },
    "auditTrail": {
      "heading": "Métadonnées de job et piste d'audit",
      "description": "Chaque action de bouton de copie est liée aux métadonnées de job pour une traçabilité complète. L'enregistrement d'audit inclut le plan source, la session cible, le hash du contenu résolu et le contexte utilisateur.",
      "schemaHeading": "Schéma d'audit",
      "schema": "-- copy_button_actions table schema\nCREATE TABLE copy_button_actions (\n    action_id    TEXT PRIMARY KEY,\n    plan_id      TEXT NOT NULL REFERENCES implementation_plans(id),\n    job_id       TEXT REFERENCES background_jobs(id),\n    session_id   TEXT REFERENCES terminal_sessions(session_id),\n    template_id  TEXT NOT NULL,\n    content_hash TEXT NOT NULL,  -- SHA-256 for integrity verification\n    created_at   TEXT NOT NULL\n);\n\n-- Query to trace plan handoffs\nSELECT * FROM copy_button_actions\nWHERE plan_id = ?\nORDER BY created_at DESC;",
      "fieldsHeading": "Champs de l'enregistrement d'audit",
      "fields": [
        {
          "field": "action_id",
          "description": "Identifiant unique pour cette action de transfert"
        },
        {
          "field": "plan_id",
          "description": "Référence du plan d'implémentation source"
        },
        {
          "field": "job_id",
          "description": "Job en arrière-plan associé le cas échéant"
        },
        {
          "field": "session_id",
          "description": "Session terminal cible ou null pour presse-papiers"
        },
        {
          "field": "template_id",
          "description": "Configuration de template utilisée"
        },
        {
          "field": "content_hash",
          "description": "SHA-256 du contenu résolu pour l'intégrité"
        },
        {
          "field": "created_at",
          "description": "Horodatage de l'action"
        }
      ],
      "retention": "Rétention : Les enregistrements d'audit sont conservés 90 jours par défaut, configurable dans les paramètres de projet."
    },
    "mobileIntegration": {
      "heading": "Intégration mobile",
      "description": "Les boutons de copie fonctionnent sur les clients desktop et mobile avec un comportement cohérent. Le client iOS utilise la même logique de résolution de placeholders et peut envoyer du contenu vers les terminaux liés.",
      "deviceLink": {
        "heading": "Support Device Link",
        "description": "Quand un appareil mobile est lié à une session desktop, les boutons de copie peuvent cibler directement le terminal desktop. Le contenu résolu est envoyé via la connexion WebSocket de device link."
      },
      "mobileButtons": {
        "heading": "Boutons spécifiques mobile",
        "description": "Les clients mobiles supportent la même personnalisation de boutons que le desktop. Les configurations de boutons se synchronisent via le serveur pour maintenir la cohérence entre les appareils."
      }
    },
    "cta": {
      "heading": "Tracez le transfert jusqu'à l'exécution",
      "description": "Les sessions terminal montrent où atterrit la sortie des boutons de copie et comment elle est journalisée.",
      "terminalLink": "Sessions terminal",
      "plansLink": "Plans d'implémentation"
    }
  },
  "textImprovement": {
    "meta": {
      "title": "Text improvement - PlanToCode",
      "description": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs."
    },
    "category": "Product Guide",
    "cta": {
      "description": "Download PlanToCode to combine voice capture, video context, and inline rewriting before you generate implementation plans.",
      "heading": "Try text improvement in the desktop app",
      "links": {
        "architecture": "Architecture overview",
        "buildYourOwn": "Build your own"
      }
    },
    "date": "2025-09-21",
    "description": "How PlanToCode rewrites highlighted text without changing formatting and links the result back to your workspace.",
    "intro": "Refine text with AI context. Select text in any editor, trigger a background job, and get improved content that keeps your formatting intact.",
    "metaDescription": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs.",
    "metaTitle": "Text improvement - PlanToCode",
    "ogDescription": "Understand the selection popover, job queue, model configuration, and integrations that power text improvement.",
    "ogTitle": "Text improvement - PlanToCode",
    "readTime": "7 min",
    "selectionPopover": {
      "component": "The popover itself is a minimal component rendered by {code}, which simply triggers the provider hook and shows a loading indicator while a rewrite is running. Because the provider registers global listeners, the popover appears in Monaco plan viewers, the plan terminal dictation field, and any task description inputs without extra wiring.",
      "heading": "Selection popover behaviour",
      "provider": "The {code} listens for selection events on standard inputs and Monaco editors. When you highlight non-empty text it positions a popover near the cursor, stores the selected range, and tracks whether the popover should be visible. Clicking the button kicks off the job and disables the control until the result returns. When the job completes the provider applies the improved text back into the same selection and flushes any pending saves to keep session state in sync."
    },
    "title": "Text Improvement",
    "triggerImprovement": {
      "action": "Pressing the popover button calls {code}. The action validates the selection, ensures a session identifier exists, and invokes the Rust command {code} via Tauri. The command builds a {code} containing the original text and queues a background job against the active session.",
      "backend": "On the backend, the {code} resolves the configured model for the {code} task, wraps the selection in XML tags, and runs the request through the {code} without streaming. When the model response returns it records token usage, cost, and the system prompt template before emitting the improved text back to the UI. The default configuration ships with Claude Sonnet 4.5 and Gemini 3 Pro as the approved models, capped at 4,096 tokens with a temperature of 0.7.",
      "heading": "What happens when you trigger an improvement",
      "metadata": "The background jobs sidebar records the original text in job metadata, so you can review what was sent alongside the rewritten copy. If the selection changes while a job is running, the provider skips replacing the text to avoid clobbering manual edits."
    },
    "videoCapture": {
      "dialog": "Screen recordings pass through the video analysis dialog, which combines your current task description with an optional prompt block wrapped in semantic XML tags before sending the request to the Gemini video analysis job. Any notes you dictate during the recording are available as text once analysis completes, so you can feed the resulting summary back through the improvement popover to tighten the instructions before planning.",
      "features": "Video jobs include frame-rate controls, audio capture toggles, and cost reporting. Results appear in the same background jobs sidebar as text improvements, keeping all prompt preparation artefacts in one place.",
      "heading": "Video capture and prompt scaffolding"
    },
    "voiceIntegration": {
      "heading": "Voice transcription integration",
      "hook": "Voice recordings use the {code} hook. It loads per-project transcription defaults, requests microphone access, and inserts transcripts at the cursor inside the task description or terminal dictation buffer. The inserted text can immediately be highlighted and passed through the same improvement popover, and the original transcription job identifier is stored with the improvement payload for auditing.",
      "preferences": "Language, model, and temperature preferences persist at the project level, so teams get consistent transcription quality before refining the copy. Silence detection warns about bad audio levels, and a ten-minute cap prevents oversized recordings from blocking improvement jobs with large payloads."
    },
    "visuals": {
      "popoverFlow": {
        "title": "Text improvement flow",
        "description": "Selection popover triggers improvement job and returns enhanced text.",
        "imageSrc": "/images/docs/text-improvement/flow.svg",
        "imageAlt": "Text improvement flow diagram"
      }
    },
    "processorDetails": {
      "heading": "Processor implementation details",
      "processor": "The {code} handles the text rewriting workflow on the Rust backend.",
      "stepsHeading": "Processing steps",
      "steps": [
        "Parse the incoming payload with original text and selection metadata",
        "Build the system prompt from the configured text_improvement template",
        "Submit the request to the LLM task runner without streaming",
        "Extract the improved text from the model response",
        "Record token usage, cost, and prompt template for billing",
        "Emit the result back to the UI via Tauri events"
      ]
    },
    "inlineRewriting": {
      "heading": "Inline rewriting behaviour",
      "description": "When the improved text returns, the provider automatically replaces the original selection. The rewriting preserves whitespace, line breaks, and any inline formatting present in the source. If the editor is Monaco-based, the change is applied as a single undo-able edit operation.",
      "contextsHeading": "Supported contexts",
      "contexts": [
        "Task description input fields",
        "Plan terminal dictation area",
        "Monaco plan viewers and editors",
        "Any standard HTML input or textarea"
      ]
    },
    "modelConfiguration": {
      "heading": "Model configuration",
      "description": "Text improvement uses the text_improvement task configuration from the desktop runtime config. You can override the default model and parameters in the settings panel.",
      "settingsHeading": "Configurable settings",
      "settings": [
        "Allowed models list (default: Claude Sonnet 4.5, Gemini 3 Pro)",
        "Maximum token limit (default: 4096)",
        "Temperature setting (default: 0.7)",
        "System prompt template override"
      ]
    },
    "keyFiles": {
      "heading": "Key implementation files",
      "items": [
        "desktop/src/contexts/TextImprovementProvider.tsx",
        "desktop/src/components/TextImprovementPopover.tsx",
        "desktop/src/actions/text-improvement/index.ts",
        "desktop/src-tauri/src/jobs/processors/text_improvement.rs",
        "server/src/config/task_model_config.rs"
      ]
    }
  },
  "voiceTranscription": {
    "meta": {
      "title": "Transcription vocale - PlanToCode",
      "description": "Comment PlanToCode enregistre l'audio, diffuse des transcriptions en temps réel via gpt-4o-transcribe, gère les permissions et les paramètres de projet."
    },
    "category": "Guide Produit",
    "date": "2025-09-22",
    "description": "Cycle de vie de l'enregistrement, gestion des appareils et comportement de streaming pour les prompts pilotés par la voix.",
    "deviceManagement": {
      "description": "La fonctionnalité demande l'autorisation du microphone, énumère les entrées audio disponibles et permet aux utilisateurs de changer d'appareil pendant une session. Les niveaux audio sont surveillés en direct pour que l'UI puisse afficher des avertissements de silence si le microphone est coupé ou déconnecté.",
      "heading": "Gestion des appareils",
      "monitoring": "La surveillance des niveaux audio en temps réel affiche un retour visuel pendant l'enregistrement. Le système détecte les périodes de silence et avertit les utilisateurs si le microphone semble coupé ou déconnecté, empêchant les enregistrements échoués avant que l'audio ne soit envoyé pour transcription."
    },
    "intro": "La transcription vocale est disponible partout où l'application desktop expose des contrôles de dictée, incluant le terminal de plan et les éditeurs de prompt. La fonctionnalité enregistre l'audio localement, envoie des chunks au service de transcription et insère le texte reconnu dans le champ de saisie actif sans bloquer la frappe manuelle.",
    "metaDescription": "Comment PlanToCode enregistre l'audio, diffuse des transcriptions en temps réel via gpt-4o-transcribe, gère les permissions et les paramètres de projet.",
    "metaTitle": "Transcription vocale - PlanToCode",
    "ogDescription": "Apprenez comment le hook d'enregistrement gère les appareils, les permissions et le texte en streaming.",
    "ogTitle": "Transcription vocale - PlanToCode",
    "projectSettings": {
      "description": "Quand une session d'enregistrement démarre, le hook consulte la configuration de transcription du projet actif. Les codes de langue, les modèles préférés et autres paramètres sont récupérés avant de capturer l'audio pour que les enregistrements suivent les préférences du projet.",
      "heading": "Paramètres sensibles au projet",
      "storage": "Les préférences de transcription spécifiques au projet sont stockées dans SQLite et incluent le modèle préféré (gpt-4o-transcribe ou gpt-4o-mini-transcribe), le code de langue et les paramètres de température. Ces préférences persistent entre les sessions et se synchronisent avec le serveur pour la facturation."
    },
    "readTime": "5 min",
    "recordingWorkflow": {
      "description": "Le hook d'enregistrement maintient une machine à états avec les états idle, recording, processing et error. Il suit la durée, gère la détection de silence et s'assure que les enregistrements s'arrêtent automatiquement après dix minutes. Les chunks sont mis en buffer et transmis à l'action de transcription, qui retourne le texte reconnu pour insertion.",
      "heading": "Workflow d'enregistrement",
      "statesHeading": "États d'enregistrement",
      "states": [
        "idle : Aucun enregistrement en cours, les permissions de microphone peuvent ou non être accordées",
        "recording : Capture active de l'audio via MediaRecorder, durée suivie, retour visuel affiché",
        "processing : Chunk audio envoyé au serveur, en attente de réponse de transcription de gpt-4o-transcribe",
        "error : L'enregistrement a échoué à cause d'un refus de permission, d'une déconnexion d'appareil ou d'une erreur API de transcription"
      ]
    },
    "routingBehavior": {
      "heading": "Routage multi-destination",
      "description": "Le texte transcrit peut être routé vers plusieurs destinations en fonction du contexte actif. Le callback insertTranscript permet un routage flexible sans couplage. La destination de routage est stockée dans les métadonnées du job pour les pistes d'audit.",
      "destinations": [
        "Éditeurs de description de tâche : Insertion au curseur avec raffinement text_improvement immédiat optionnel",
        "Buffer de dictée du terminal : Exécution de commande (ex: 'run npm test' tapé dans le PTY)",
        "Mode notes de réunion : Buffer accumulé auto-sauvegardé dans SQLite avec task_refinement générant des tâches actionnables",
        "Éditeurs de prompt : Insertion directe dans tout champ de saisie texte à travers l'application"
      ]
    },
    "pipeline": {
      "heading": "Pipeline de transcription",
      "hook": "Le hook React {code} gère le cycle de vie complet de l'enregistrement. Il initialise {code} pour la capture audio au format WebM avec codec Opus, surveille les niveaux audio et gère le changement d'appareil.",
      "command": "L'application desktop invoque {code} pour envoyer les données audio au endpoint serveur {code}. La commande valide la taille de l'audio (minimum 1KB, maximum 25MB), la durée, la température (0.0-1.0) et la longueur du prompt (max 1000 caractères).",
      "constraints": "Les fichiers audio doivent faire entre 1KB et 25MB. Formats supportés : WAV, MP3, M4A, OGG, WebM, FLAC, AAC et MP4. Le modèle de transcription doit être spécifié explicitement - les modèles supportés sont gpt-4o-transcribe et gpt-4o-mini-transcribe d'OpenAI."
    },
    "serverProcessing": {
      "heading": "Traitement côté serveur",
      "endpoint": "Le serveur expose {code} qui accepte les données multipart form. Il route les requêtes vers OpenAI ou Google selon la configuration du fournisseur du modèle, valide les crédits utilisateur et calcule la facturation basée sur la durée audio.",
      "parametersHeading": "Paramètres de requête",
      "parameters": [
        "file : Données du fichier audio (requis) - WAV, MP3, M4A, OGG, WebM, FLAC, AAC ou MP4",
        "model : ID du modèle de transcription (requis) - openai/gpt-4o-transcribe ou openai/gpt-4o-mini-transcribe",
        "duration_ms : Durée de l'enregistrement en millisecondes (requis pour le calcul de facturation)",
        "language : Code de langue ISO 639-1 (optionnel) - améliore la précision pour des langues spécifiques",
        "prompt : Indice de contexte pour la transcription (optionnel, max 1000 caractères) - aide avec le vocabulaire spécifique au domaine",
        "temperature : Température d'échantillonnage 0.0-1.0 (optionnel, défaut 0.0) - les valeurs basses produisent une sortie plus déterministe"
      ]
    },
    "dataFlow": {
      "heading": "Flux de données",
      "description": "Les données audio circulent du navigateur à travers la couche de commandes Tauri vers le serveur, qui proxifie les requêtes vers le fournisseur de transcription approprié.",
      "stepsHeading": "Étapes de traitement",
      "steps": [
        "Le MediaRecorder du navigateur capture les chunks audio au format WebM/Opus",
        "Le hook useVoiceTranscription met en buffer les chunks et surveille la durée",
        "À l'arrêt, le blob audio est converti en bytes et envoyé via transcribe_audio_command",
        "La commande Tauri valide la taille de l'audio, la durée et les paramètres",
        "Requête envoyée au endpoint serveur /api/audio/transcriptions avec le token d'auth",
        "Le serveur valide les crédits utilisateur et route vers le fournisseur OpenAI ou Google",
        "Le fournisseur retourne le texte transcrit, le serveur journalise l'utilisation et déduit les crédits",
        "Le texte transcrit est retourné au desktop et inséré via le callback"
      ]
    },
    "keyFiles": {
      "heading": "Fichiers d'implémentation clés",
      "items": [
        "desktop/src/hooks/useVoiceTranscription.ts",
        "desktop/src-tauri/src/commands/audio_commands.rs",
        "server/src/handlers/proxy/specialized/transcription.rs",
        "server/src/clients/openai/transcription.rs",
        "server/src/clients/google/transcription.rs"
      ]
    },
    "examples": {
      "heading": "Exemples d'utilisation",
      "description": "Les workflows de transcription vocale courants démontrent la flexibilité du système :",
      "items": [
        "Planification de sprint : Enregistrement de réunion avec transcription dirigée vers task_refinement pour générer des descriptions de tâches",
        "Commandes terminal : Dictée transcrite et tapée directement dans le PTY pour exécution",
        "Rapports de bug : Description verbale capturée, raffinée avec text_improvement, puis traitée par task_refinement",
        "Discussions d'architecture : Enregistrement vidéo avec piste audio extraite pour transcription, combinée avec l'analyse de vision"
      ]
    },
    "cta": {
      "heading": "Continuez à explorer",
      "description": "Apprenez comment le texte transcrit peut être raffiné et comment les enregistrements de réunion sont traités en tâches actionnables.",
      "links": {
        "textImprovement": "Amélioration de texte",
        "meetingIngestion": "Ingestion de réunions"
      }
    },
    "title": "Transcription Vocale",
    "visuals": {
      "recordingFlow": {
        "title": "Pipeline de transcription vocale",
        "description": "Capture audio, traitement de transcription GPT-4o et flux de routage du texte.",
        "imageSrc": "/images/docs/voice-transcription/pipeline.svg",
        "imageAlt": "Diagramme du pipeline de transcription vocale",
        "caption": "L'audio circule de la capture navigateur à travers les commandes Tauri vers la transcription GPT-4o côté serveur."
      }
    }
  },
  "overview": {
    "meta": {
      "title": "System overview - PlanToCode",
      "description": "Start here: what PlanToCode does, how the core loop works, and where each component lives in the repo."
    },
    "category": "Overview",
    "date": "2025-09-25",
    "readTime": "15 min",
    "title": "System Overview",
    "description": "A concise map of the system, the core loop, and the required dependencies.",
    "intro": "PlanToCode is a desktop workspace that plans and validates code changes before execution. It coordinates a local Rust job engine, a React UI, and a server proxy for LLM calls. The system follows an offline-first architecture where the desktop app operates independently using SQLite for local state, while the server handles authentication, LLM provider routing, and billing. Without external LLM providers configured with your API keys, the planning and analysis pipelines will not run.",
    "visuals": {
      "systemMap": {
        "title": "System map",
        "description": "Map of the desktop app, the Rust core, local SQLite storage, and the server proxy.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode system map diagram",
        "caption": "Four-layer architecture with data flowing down and events streaming back up."
      }
    },
    "systemLayers": {
      "heading": "System layers",
      "description": "The system is organized into four distinct layers that communicate through well-defined interfaces:",
      "items": [
        "Presentation Layer: React UI with Monaco editors, terminal panels, and workflow controls (desktop/src/)",
        "Command Layer: Tauri commands that bridge React and Rust, handling IPC and state management (desktop/src-tauri/src/commands/)",
        "Processing Layer: Job processors, workflow orchestrator, and business logic in Rust (desktop/src-tauri/src/jobs/)",
        "Persistence Layer: SQLite repositories for local state and server PostgreSQL for auth/billing (desktop/src-tauri/src/db_utils/)"
      ]
    },
    "coreLoop": {
      "heading": "Core loop in practice",
      "description": "Every task flows through a well-defined lifecycle from capture to execution:",
      "steps": [
        "Capture the task from text, voice transcription (via useVoiceTranscription hook), or video recording analysis.",
        "Refine the task description and objectives with text_improvement jobs through TextImprovementProcessor.",
        "Run the file discovery workflow: RootFolderSelectionProcessor selects directories, RegexFileFilterProcessor applies patterns, FileRelevanceAssessmentProcessor scores contents, ExtendedPathFinderProcessor expands context.",
        "Generate implementation plans via ImplementationPlanProcessor, which streams XML-formatted plans to the Monaco viewer.",
        "Optionally merge multiple plan drafts with ImplementationPlanMergeProcessor using XML-tagged source plans.",
        "Execute or export the approved plan through PTY terminal sessions or copy-button templates for external agents.",
        "Persist every job, artifact, and terminal log to SQLite (background_jobs, terminal_sessions tables) for auditability."
      ]
    },
    "components": {
      "heading": "Major components",
      "description": "Each component has a specific responsibility and communicates through typed interfaces:",
      "items": [
        "Desktop UI (React) in desktop/src/ with Monaco plan views, terminal panels, and providers (SessionProvider, TextImprovementProvider).",
        "Rust core (Tauri v2) in desktop/src-tauri/ handling commands, jobs, and persistence with capability-based permissions.",
        "Local SQLite schema in desktop/src-tauri/migrations/consolidated_schema.sql with WAL mode for concurrent access.",
        "Server proxy (Actix-Web) in server/src/ for auth, provider routing, streaming responses, and billing via Stripe.",
        "Mobile iOS client in mobile/ios/Core/ with SwiftUI interface, Auth0 PKCE, and WebSocket device linking.",
        "Infrastructure automation in infrastructure/ansible/ for Hetzner (EU) and InterServer (US) dedicated servers."
      ]
    },
    "dependencies": {
      "heading": "Required dependencies",
      "description": "The system requires these external services and resources:",
      "items": [
        "External LLM providers (OpenAI, Anthropic, Google, X.AI, OpenRouter) for plan generation, transcription, and analysis.",
        "Auth0-based authentication with PKCE flow for desktop and mobile sessions.",
        "PostgreSQL 17 and Redis 7+ for server-side user accounts, billing state, and job queues (self-hosted deployments).",
        "Local filesystem access via git ls-files or directory traversal for file discovery workflows.",
        "Whisper-compatible transcription endpoint for voice input processing."
      ]
    },
    "codeMap": {
      "heading": "Where the behavior lives in the repo",
      "description": "Quick reference to key directories and files:",
      "items": [
        "Tauri commands: desktop/src-tauri/src/commands/ (35+ command modules: job_commands.rs, workflow_commands.rs, terminal_commands.rs, session_commands.rs, auth0_commands.rs)",
        "Workflow orchestration: desktop/src-tauri/src/jobs/workflow_orchestrator/ (definition_loader.rs, stage_scheduler.rs, event_emitter.rs, payload_builder.rs)",
        "Job processors: desktop/src-tauri/src/jobs/processors/ (implementation_plan_processor.rs, text_improvement_processor.rs, root_folder_selection_processor.rs)",
        "SQLite repositories: desktop/src-tauri/src/db_utils/ (background_job_repository/, session_repository.rs, terminal_repository.rs)",
        "Server routes: server/src/routes.rs (configure_routes, configure_public_auth_routes, configure_webhook_routes)",
        "LLM proxy handlers: server/src/handlers/proxy_handlers.rs and server/src/handlers/proxy/ (router.rs, providers/)",
        "Provider transformers: server/src/handlers/provider_transformers/ (openai.rs, google.rs, anthropic.rs, xai.rs)",
        "iOS workflows: mobile/ios/Core/Sources/Workflows/WorkflowManager.swift with MobileSessionManager and APIClient",
        "Infrastructure playbooks: infrastructure/ansible/site-base.yml (hardening, PostgreSQL, Redis) and site-app.yml (deployment)"
      ]
    },
    "keyAbstractions": {
      "heading": "Key abstractions",
      "description": "Understanding these core concepts helps navigate the codebase:",
      "items": [
        "Session: Project context stored in sessions table with task_description, included_files, and model preferences. Identified by UUID.",
        "Background Job: LLM-backed operation stored in background_jobs table with task_type, prompt, response, token tracking, and cost.",
        "Workflow: Multi-stage orchestrated process (e.g., file_finder_workflow) coordinated by WorkflowOrchestrator with IntermediateData passing between stages.",
        "Terminal Session: PTY process stored in terminal_sessions with output_log, status, and optional job_id linking for audit.",
        "Provider: LLM service abstraction in server/src/handlers/proxy/providers/ with request transformation and response normalization."
      ]
    },
    "dataFlowSummary": {
      "heading": "Data flow summary",
      "description": "How data moves through the system for a typical planning task:",
      "items": [
        "User input enters through React components and flows to Tauri commands via @tauri-apps/api/core invoke().",
        "Commands create background_jobs records and dispatch to job processors via the job queue.",
        "Processors build prompts, send requests through the server LLM proxy, and stream responses via Tauri events.",
        "Responses are stored in SQLite and emitted to React providers that update the UI state.",
        "Terminal execution streams PTY output to the UI and persists logs for session recovery."
      ]
    }
  },
  "runtimeWalkthrough": {
    "meta": {
      "title": "Runtime walkthrough - PlanToCode",
      "description": "End-to-end timeline of a task from input to plan output, with job types and artifact flows."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Runtime Walkthrough",
    "description": "End-to-end runtime timeline from task input to plan output.",
    "intro": "This walkthrough traces a single task from initial capture through file discovery, plan generation, and terminal execution. Each stage maps to specific job types and produces artifacts stored in SQLite.",
    "visuals": {
      "timeline": {
        "title": "Runtime timeline",
        "description": "Visual timeline showing task input, workflow stages, and plan output.",
        "imageSrc": "/images/docs/runtime-walkthrough/timeline.svg",
        "imageAlt": "Runtime timeline diagram",
        "caption": "Task execution flows through six stages, with all artifacts persisted to SQLite."
      },
      "walkthroughVideo": {
        "title": "Runtime walkthrough video",
        "description": "Video demonstration of a complete task execution from input to plan output.",
        "videoSrc": "",
        "posterSrc": "",
        "caption": "Video walkthrough placeholder - record a demonstration of the full planning workflow."
      }
    },
    "timeline": {
      "heading": "High-level runtime sequence",
      "description": "A complete task execution follows this sequence of operations:",
      "steps": [
        "User enters or dictates a task description in the desktop UI via TaskDescriptionEditor component.",
        "Optional: text_improvement job refines the raw input through TextImprovementProcessor.",
        "User triggers file discovery workflow via the Implementation Plans panel start_file_finder_workflow command.",
        "WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/ creates a workflow record and schedules stage 1.",
        "Stage 1 (root_folder_selection): RootFolderSelectionProcessor sends directory tree to LLM, stores selected roots in IntermediateData.selectedRoots.",
        "Stage 2 (regex_file_filter): RegexFileFilterProcessor generates patterns, runs git ls-files, stores matches in IntermediateData.locallyFilteredFiles.",
        "Stage 3 (file_relevance_assessment): FileRelevanceAssessmentProcessor chunks file contents, scores relevance, stores in IntermediateData.aiFilteredFiles.",
        "Stage 4 (extended_path_finder): ExtendedPathFinderProcessor expands context with imports and dependencies, stores in IntermediateData.verifiedPaths.",
        "UI receives workflow-completed event via event_emitter.rs, updates file selection display.",
        "User triggers plan generation with selected files via generate_implementation_plan command.",
        "ImplementationPlanProcessor in desktop/src-tauri/src/jobs/processors/implementation_plan_processor.rs streams XML plan content to Monaco viewer via job:stream-progress events.",
        "User reviews plan in VirtualizedCodeViewer component, can edit directly or request merge.",
        "Approved plan is copied to terminal via copy-button templates or exported for external agents.",
        "Terminal session in terminal_commands.rs captures PTY output, detects agent attention states.",
        "All artifacts persist in SQLite background_jobs and terminal_sessions tables for audit and session recovery."
      ]
    },
    "jobTypes": {
      "heading": "Job types in the runtime",
      "description": "Each task_type maps to a specific processor and produces distinct artifacts:",
      "items": [
        "text_improvement: TextImprovementProcessor wraps text in XML, sends to LLM, returns refined text. Stored in background_jobs.response.",
        "root_folder_selection: RootFolderSelectionProcessor receives directory tree, returns JSON array of selected directories.",
        "regex_file_filter: RegexFileFilterProcessor generates patterns from task description, applies to git file list.",
        "file_relevance_assessment: FileRelevanceAssessmentProcessor loads file contents, chunks by token limit, scores relevance.",
        "extended_path_finder: ExtendedPathFinderProcessor analyzes imports/dependencies, expands context with related files.",
        "implementation_plan: ImplementationPlanProcessor streams XML-formatted plans with plan_step elements.",
        "implementation_plan_merge: ImplementationPlanMergeProcessor combines plans using source_plans XML tags and user instructions.",
        "video_analysis: Processes screen recordings via /api/llm/video/analyze endpoint with frame sampling.",
        "web_search_prompts_generation: Generates research_task XML blocks for deep research workflow.",
        "web_search_execution: Executes research prompts in parallel, aggregates findings."
      ]
    },
    "inputCapture": {
      "heading": "Task input capture",
      "description": "Tasks enter the system through multiple input surfaces:",
      "text": "Task descriptions are typed or pasted into TaskDescriptionEditor which persists to sessions.task_description and creates history entries in task_description_history table with device_id for multi-device sync.",
      "voice": "Voice input uses useVoiceTranscription hook which records via MediaRecorder API, sends to /api/audio/transcriptions, and inserts at cursor position.",
      "video": "Video analysis uses VideoAnalysisDialog to capture screen recordings, upload to /api/llm/video/analyze, and extract UI state observations."
    },
    "workflowExecution": {
      "heading": "Workflow execution details",
      "description": "The WorkflowOrchestrator coordinates multi-stage workflows:",
      "scheduling": "workflow_lifecycle_manager.rs creates workflow records and stage_scheduler.rs dispatches stages sequentially based on workflow JSON definitions.",
      "data": "IntermediateData structures in workflow_types.rs pass outputs between stages: selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths.",
      "events": "event_emitter.rs publishes workflow-status and workflow-stage Tauri events consumed by WorkflowTracker in the React UI."
    },
    "persistence": {
      "heading": "State persistence",
      "description": "All artifacts are persisted for audit and recovery:",
      "jobs": "background_job_repository/ stores job records with session_id, task_type, status, prompt, response, tokens_sent/received, actual_cost.",
      "sessions": "session_repository.rs manages sessions table with task_description, included_files, model_used, history versions.",
      "terminals": "terminal_repository.rs persists terminal_sessions with output_log, status, exit_code, working_directory for session recovery.",
      "rehydration": "On app restart, the Rust core rehydrates session state from SQLite, marks stale running jobs as failed, and restores terminal output logs."
    },
    "inputs": {
      "heading": "Task input capture",
      "capture": "Tasks enter the system through multiple input surfaces: typed text in TaskDescriptionEditor, voice dictation via useVoiceTranscription hook, or video analysis through VideoAnalysisDialog.",
      "artifacts": "Each input type produces artifacts stored in SQLite - task_description in sessions table, transcription results in background_jobs, and video frames in associated job metadata."
    },
    "refinement": {
      "heading": "Input refinement",
      "jobs": "The text_improvement job type refines raw input through TextImprovementProcessor, wrapping text in XML and sending to the LLM for grammar, clarity, and structure improvements.",
      "storage": "Refined text is stored in background_jobs.response and can update sessions.task_description via the React provider."
    },
    "discovery": {
      "heading": "File discovery workflow",
      "workflow": "FileFinderWorkflow runs four sequential stages: root_folder_selection narrows directories, regex_file_filter applies patterns, file_relevance_assessment scores content, and extended_path_finder expands with dependencies.",
      "outputs": "Each stage stores results in IntermediateData structures passed between processors, with final file selections persisted to sessions.included_files."
    },
    "planGeneration": {
      "heading": "Plan generation",
      "jobs": "The implementation_plan job type uses ImplementationPlanProcessor to generate XML-formatted plans with plan_step elements containing file paths, operation types, and code changes.",
      "streaming": "Plan content streams to the UI via job:stream-progress Tauri events, displayed in the VirtualizedCodeViewer Monaco component with syntax highlighting."
    },
    "merge": {
      "heading": "Plan merging",
      "instructions": "The implementation_plan_merge job combines multiple plans using source_plans XML tags and user-provided merge instructions to resolve conflicts and consolidate changes.",
      "outputs": "Merged plans maintain traceability to source plans and include merged_from metadata in the final background_jobs record."
    },
    "review": {
      "heading": "Plan review",
      "editor": "Plans open in the Monaco-based VirtualizedCodeViewer for review. Users can edit plan text directly, request modifications, or approve for execution.",
      "audit": "All review actions are logged with timestamps and user context, providing an audit trail of plan evolution."
    },
    "execution": {
      "heading": "Execution handoff",
      "terminal": "Approved plans are copied to the integrated terminal via copy-button templates, or exported for external agents like Claude Code, Cursor, or Codex.",
      "logging": "Terminal sessions in terminal_commands.rs capture PTY output, detect agent attention states, and log all execution activity to terminal_sessions table."
    },
    "state": {
      "heading": "State persistence",
      "jobs": "All job artifacts persist in background_jobs table with session_id, task_type, status, prompt, response, token counts, and cost tracking.",
      "rehydration": "On app restart, the Rust core rehydrates session state from SQLite, marks stale running jobs as failed, and restores terminal output logs."
    },
    "jobMap": {
      "heading": "Job type mapping",
      "items": [
        "text_improvement → TextImprovementProcessor → refined task descriptions",
        "root_folder_selection → RootFolderSelectionProcessor → selected directories",
        "regex_file_filter → RegexFileFilterProcessor → pattern-matched files",
        "file_relevance_assessment → FileRelevanceAssessmentProcessor → scored files",
        "extended_path_finder → ExtendedPathFinderProcessor → expanded context",
        "implementation_plan → ImplementationPlanProcessor → XML plan documents",
        "implementation_plan_merge → ImplementationPlanMergeProcessor → merged plans"
      ]
    },
    "cta": {
      "heading": "Explore the architecture",
      "description": "Understand how the components fit together in detail.",
      "links": {
        "architecture": "Architecture overview",
        "jobs": "Background jobs",
        "desktop": "Desktop app internals",
        "dataModel": "Data model",
        "plans": "Implementation plans"
      }
    }
  },
  "desktopApp": {
    "meta": {
      "title": "Desktop app internals - PlanToCode",
      "description": "How the Tauri desktop shell, Rust command layer, SQLite persistence, and PTY sessions work together."
    },
    "category": "Desktop",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Desktop App Internals",
    "description": "Tauri v2 shell, Rust command layer, PTY sessions, and UI state management.",
    "intro": "The desktop app is a Tauri v2 shell (version 2.9.1) running a React UI. Rust services expose commands for workflows, terminal sessions, and configuration while persisting state locally in SQLite. The capability-based permission model provides fine-grained security controls for filesystem access, HTTP requests, shell execution, and system notifications.",
    "visuals": {
      "shell": {
        "title": "Desktop shell overview",
        "description": "Screenshot showing the plan editor, terminal tabs, and job status sidebar.",
        "imageSrc": "/assets/images/demo-implementation-plans.jpg",
        "imageAlt": "PlanToCode desktop shell",
        "caption": "The desktop app showing the implementation plans panel and sidebar."
      }
    },
    "projectLayout": {
      "heading": "Project layout",
      "description": "The desktop application follows the standard Tauri v2 structure:",
      "items": [
        "desktop/src/: React UI components, hooks, providers, and desktop-specific adapters.",
        "desktop/src-tauri/: Rust core including commands, jobs, repositories, and services.",
        "desktop/src-tauri/src/lib.rs: Application entry point with plugin registration and AppState management.",
        "desktop/src-tauri/src/commands/: 35+ Tauri command handler modules organized by domain.",
        "desktop/src-tauri/src/jobs/: Background job processors, workflow orchestration, and queue management.",
        "desktop/src-tauri/capabilities/: JSON capability definitions for security permissions (default.json, desktop-default.json, plantocode-api.json).",
        "desktop/src-tauri/migrations/: SQLite schema migrations in consolidated_schema.sql."
      ]
    },
    "ui": {
      "heading": "React UI and surface area",
      "description": "The React UI renders the task description editor, plan viewer, and terminal panels:",
      "components": [
        "TaskDescriptionEditor: Multi-line input with voice transcription integration and text improvement popover.",
        "VirtualizedCodeViewer: Monaco-based plan display with syntax highlighting and copy actions.",
        "TerminalSurface: PTY output buffer with connection status, agent attention indicators, and voice input.",
        "SessionProvider: Global state management for active session, file selections, and model preferences.",
        "TextImprovementProvider: Selection listener and popover positioning for inline rewrites.",
        "WorkflowTracker: Real-time progress display for multi-stage workflows."
      ]
    },
    "commands": {
      "heading": "Tauri commands",
      "description": "Commands in desktop/src-tauri/src/commands/ expose Rust functionality to the React UI. Key modules include:",
      "modules": [
        "job_commands.rs: create_job, get_job, cancel_job, get_jobs_for_session, clear_job_history.",
        "workflow_commands.rs: start_file_finder_workflow, get_workflow_status, retry_workflow, pause_workflow, resume_workflow.",
        "terminal_commands.rs: create_terminal_session, send_terminal_input, resize_terminal, get_terminal_output, check_cli_availability.",
        "session_commands.rs: create_session, get_session, update_session, sync_task_description_history, sync_file_selection_history.",
        "auth0_commands.rs: initiate_login, complete_login, refresh_token, logout, get_user_info.",
        "implementation_plan_commands.rs: generate_implementation_plan, merge_implementation_plans, estimate_tokens.",
        "config_commands.rs: get_runtime_config, get_model_config, get_system_prompts, refresh_config_cache.",
        "settings_commands.rs: get_setting, set_setting, get_project_system_prompt, set_project_system_prompt."
      ]
    },
    "appState": {
      "heading": "AppState management",
      "description": "The Rust core manages application state through Tauri's state system:",
      "structure": "AppState struct in lib.rs holds: config_load_error (Option<String>), HTTP client (reqwest::Client), RuntimeConfig (server URL, onboarding status) behind Mutex, and Auth0State for authentication.",
      "config": "RuntimeConfig contains server_url, onboarding_complete flag, and is updated via set_runtime_config command. ConfigCache stores runtime AI configuration with per-project overrides.",
      "tokens": "TokenManager uses the OS keyring (via keyring crate) to securely store access_token, refresh_token, and jwt with automatic refresh before expiry."
    },
    "jobs": {
      "heading": "Job processors and workflows",
      "description": "Job processing architecture in desktop/src-tauri/src/jobs/:",
      "queue": "queue.rs manages the job queue with in-memory pending jobs and SQLite persistence. Jobs transition through statuses: idle, created, queued, acknowledged_by_worker, preparing, preparing_input, running, generating_stream, processing_stream, completed, failed, canceled.",
      "processors": "processors/ directory contains task-specific processors: ImplementationPlanProcessor (streaming plans), TextImprovementProcessor (inline rewrites), RootFolderSelectionProcessor, RegexFileFilterProcessor, FileRelevanceAssessmentProcessor, ExtendedPathFinderProcessor.",
      "orchestrator": "workflow_orchestrator/ coordinates multi-stage workflows: definition_loader.rs loads JSON workflow definitions, stage_scheduler.rs dispatches stages, payload_builder.rs constructs inputs, event_emitter.rs publishes progress events.",
      "streaming": "processors/generic_llm_stream_processor.rs handles streaming LLM responses, emitting job:stream-progress events and accumulating content in background_jobs.response."
    },
    "persistence": {
      "heading": "Local persistence",
      "description": "SQLite storage in desktop/src-tauri/migrations/consolidated_schema.sql:",
      "tables": [
        "sessions: id (UUID), name, project_directory, project_hash, task_description, included_files, force_excluded_files, model_used, history versions.",
        "background_jobs: id (UUID), session_id (FK), task_type, status, prompt, response, tokens_sent/received, cache_read/write_tokens, actual_cost, metadata (JSON), server_request_id.",
        "terminal_sessions: id, job_id (nullable FK), session_id, status, process_pid, output_log, working_directory, environment_vars, last_output_at.",
        "task_description_history: session_id (FK), description, device_id, sequence_number, version for multi-device sync.",
        "file_selection_history: session_id (FK), included_files, force_excluded_files, device_id, sequence_number.",
        "project_system_prompts: project_hash, task_type, system_prompt for per-project prompt overrides.",
        "key_value_store: key, value (JSON), updated_at for app settings.",
        "error_logs: timestamp, level, error_type, message, context, stack, metadata for client-side error tracking."
      ],
      "repositories": "Repositories in db_utils/ provide typed access: background_job_repository/ (modular with base.rs, worker.rs, metadata.rs, cleanup.rs), session_repository.rs, terminal_repository.rs, settings_repository.rs, error_log_repository.rs."
    },
    "terminal": {
      "heading": "Terminal sessions",
      "description": "PTY terminal implementation:",
      "commands": "terminal_commands.rs manages session lifecycle: create_terminal_session spawns PTY via portable-pty crate, send_terminal_input forwards keystrokes, resize_terminal adjusts dimensions, check_cli_availability verifies tool presence (claude, cursor, codex, gemini).",
      "persistence": "terminal_repository.rs persists sessions with output_log (accumulated terminal output), status (idle/running/completed/failed/agent_requires_attention), exit_code, working_directory. Sessions can be restored after app restart.",
      "attention": "Agent attention detection monitors last_output_at timestamps. Level 1 (30s idle): yellow indicator. Level 2 (2min idle): red indicator with desktop notification."
    },
    "inputStability": {
      "heading": "Task description stability",
      "description": "The task description editor includes safeguards to prevent cursor jumps:",
      "items": [
        "Remote updates are queued while the user is typing and flushed on idle or blur.",
        "Selection state is tracked and restored after React re-renders.",
        "Background writers call sessionActions.updateCurrentSessionFields to coordinate updates.",
        "Multi-device sync uses sequence_number and version fields to resolve conflicts."
      ]
    },
    "plugins": {
      "heading": "Tauri plugins",
      "description": "PlanToCode uses the Tauri v2 plugin ecosystem:",
      "list": [
        "tauri-plugin-http (2.5.2): HTTP client with CSP-aware fetch for API calls.",
        "tauri-plugin-dialog (2.4.2): Native file/folder picker and message dialogs.",
        "tauri-plugin-shell (2.3.3): Shell command execution for external CLI tools.",
        "tauri-plugin-store (2.4.1): Persistent key-value storage for app settings.",
        "tauri-plugin-notification (2.3.0): Desktop notifications for agent attention.",
        "tauri-plugin-updater (2.9.0): In-app updates with signature verification.",
        "tauri-plugin-single-instance (2.3.4): Single instance enforcement.",
        "tauri-plugin-process (2.3.1): Process restart capability."
      ]
    }
  },
  "serverApi": {
    "meta": {
      "title": "Server API and LLM proxy - PlanToCode",
      "description": "Auth, provider routing, model configuration, and WebSocket endpoints used by desktop and mobile clients."
    },
    "category": "Server",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Server API & LLM Proxy",
    "description": "Auth, provider routing, model configuration, billing, and WebSocket endpoints.",
    "intro": "The server is an Actix-Web service written in Rust that provides authentication, model configuration, LLM proxying, and billing. Desktop and mobile clients depend on it for secure provider routing and streaming responses. The server runs on dedicated infrastructure in two regions: Hetzner (EU) at api-eu.plantocode.com and InterServer (US) at api-us.plantocode.com.",
    "visuals": {
      "flow": {
        "title": "Server request flow",
        "description": "Diagram showing clients, API routes, and the LLM proxy.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Server request flow diagram",
        "caption": "Placeholder for the server request flow."
      }
    },
    "routeOrganization": {
      "heading": "Route organization",
      "description": "Routes are organized in server/src/routes.rs with three configuration functions:",
      "functions": [
        "configure_routes(): JWT-authenticated routes under /api scope. Includes auth, billing, config, providers, models, llm proxy, audio, system-prompts, consent, devices, notifications.",
        "configure_public_auth_routes(): Browser-based auth flow under /auth scope. Includes Auth0 initiate-login, callback, and logged-out routes.",
        "configure_webhook_routes(): Unauthenticated webhook endpoints under /webhooks scope. Currently handles Stripe webhooks."
      ]
    },
    "auth": {
      "heading": "Authentication endpoints",
      "description": "Authentication uses Auth0 with PKCE flow:",
      "routes": [
        "/auth/auth0/initiate-login (GET): Starts OAuth flow with code_challenge, redirects to Auth0.",
        "/auth/auth0/callback (GET): Handles Auth0 redirect, exchanges code for tokens.",
        "/api/auth/userinfo (GET): Returns authenticated user info from Auth0.",
        "/api/auth/logout (POST): Revokes tokens and clears session.",
        "/api/auth/account (DELETE): Account deletion with cascading cleanup.",
        "/api/auth0/refresh-app-token (POST): Refreshes access token using refresh token."
      ],
      "implementation": "Auth handlers in server/src/handlers/auth0_handlers.rs and server/src/handlers/auth/. JWT validation uses services/auth/jwt.rs with JWKS rotation. Revoked tokens tracked in revoked_token_repository.rs."
    },
    "llmProxy": {
      "heading": "LLM proxy and streaming",
      "description": "The LLM proxy normalizes requests across providers and streams responses:",
      "routes": [
        "/api/llm/chat/completions (POST): Main chat completion endpoint. Routes to OpenAI, Anthropic, Google, X.AI, or OpenRouter based on model ID.",
        "/api/llm/video/analyze (POST): Multipart video upload for frame analysis. Requires google/* models with video capability.",
        "/api/llm/cancel (POST): Cancels in-flight streaming request by request_id.",
        "/api/llm/status/{request_id} (GET): Returns status of a request (active, completed, cancelled).",
        "/api/audio/transcriptions (POST): Whisper-compatible transcription. Multipart upload with audio file and parameters."
      ],
      "routing": "Router in server/src/handlers/proxy/router.rs selects provider based on model ID prefix (openai/, anthropic/, google/, xai/, openrouter/). Provider-specific handlers in server/src/handlers/proxy/providers/ transform requests and normalize responses.",
      "streaming": "Streaming responses use Server-Sent Events (SSE) via streaming/sse_adapter.rs. The proxy forwards chunks from providers, transforms them to a common format, and tracks token usage in real-time."
    },
    "providers": {
      "heading": "Provider routing",
      "description": "Provider handlers in server/src/handlers/proxy/providers/:",
      "handlers": [
        "openai.rs: OpenAI and OpenAI-compatible APIs (GPT-4, o1, o3).",
        "anthropic.rs: Anthropic Claude models with prompt caching support.",
        "google.rs: Google Gemini models including video analysis capability.",
        "xai.rs: X.AI Grok models.",
        "openrouter.rs: OpenRouter aggregation for model routing."
      ],
      "transformers": "Request/response transformers in server/src/handlers/provider_transformers/ normalize API differences. Each transformer handles: request body format, authentication headers, streaming chunk format, usage extraction, error normalization."
    },
    "config": {
      "heading": "Configuration endpoints",
      "description": "Configuration and model metadata endpoints:",
      "routes": [
        "/api/config/all-configurations (GET): Returns all application configurations including model settings per task type.",
        "/api/config/desktop-runtime-config (GET): Desktop-specific runtime configuration.",
        "/api/config/billing (GET/PUT): Billing configuration management.",
        "/api/providers (GET): List of available LLM providers with capabilities.",
        "/api/providers/with-counts (GET): Providers with model counts.",
        "/api/providers/by-capability/{capability} (GET): Filter providers by capability.",
        "/api/models (GET): All available models with pricing.",
        "/api/models/{id} (GET): Single model details.",
        "/api/models/by-provider/{provider_code} (GET): Models for a specific provider.",
        "/api/models/estimate-cost (POST): Cost estimation for a request.",
        "/api/models/estimate-tokens (POST): Token count estimation.",
        "/api/system-prompts/defaults (GET): Default system prompts by task type."
      ]
    },
    "billing": {
      "heading": "Billing endpoints",
      "description": "Credit-based billing system integrated with Stripe:",
      "routes": [
        "/api/billing/dashboard (GET): User billing dashboard data.",
        "/api/billing/usage-summary (GET): Detailed usage with cost breakdown.",
        "/api/billing/credits/balance (GET): Current credit balance.",
        "/api/billing/credits/details (GET): Credit details including grants and purchases.",
        "/api/billing/credits/unified-history (GET): Transaction history.",
        "/api/billing/checkout/credit-purchase (POST): Create Stripe checkout for credits.",
        "/api/billing/checkout/setup (POST): Create Stripe setup session for payment method.",
        "/api/billing/auto-top-off (GET/PUT): Auto top-off settings management."
      ],
      "implementation": "Billing handlers in server/src/handlers/billing/. Credit service in services/credit_service.rs. Stripe integration via services/stripe_service.rs with webhook handling in webhook_handlers.rs."
    },
    "devices": {
      "heading": "Device management",
      "description": "Device registration and push notifications:",
      "routes": [
        "/api/devices/register (POST): Register desktop device with device_id.",
        "/api/devices/mobile/register (POST): Register mobile device with platform info.",
        "/api/devices/{device_id}/heartbeat (POST): Device heartbeat for presence.",
        "/api/devices/{device_id}/push-token (POST): Save push notification token.",
        "/api/devices/{device_id}/connection-descriptor (GET): WebSocket connection info for device linking.",
        "/api/notifications/job-completed (POST): Send push notification for completed job.",
        "/api/notifications/job-progress (POST): Send progress notification."
      ]
    },
    "websockets": {
      "heading": "WebSocket endpoints",
      "description": "Real-time communication via WebSocket:",
      "endpoints": [
        "/ws/device-link: Relay for desktop-mobile device linking. Handles terminal output streaming, job status updates, and RPC commands between linked devices.",
        "/ws/events: General event stream for real-time updates."
      ],
      "implementation": "Device link relay in server/src/handlers/device_link_ws.rs. Sessions managed by services/relay_session_store.rs with heartbeat monitoring and reconnection support."
    },
    "serverStorage": {
      "heading": "Server-side persistence",
      "description": "PostgreSQL database with repositories in server/src/db/repositories/:",
      "repositories": [
        "user_repository.rs: User accounts linked to Auth0 sub.",
        "customer_billing_repository.rs: Stripe customer and credit state.",
        "credit_transaction_repository.rs: Credit transaction history.",
        "provider_repository.rs: LLM provider configuration.",
        "system_prompts_repository.rs: System prompt templates.",
        "consent_repository.rs: Legal consent tracking.",
        "audit_log_repository.rs: Audit trail for sensitive operations.",
        "revoked_token_repository.rs: JWT revocation list.",
        "api_key_repository.rs: API key management with secure hashing."
      ]
    }
  },
  "backgroundJobs": {
    "meta": {
      "title": "Background jobs - PlanToCode",
      "description": "Job queue architecture, processor types, state machine, and artifact storage for the desktop job engine."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Background Jobs",
    "description": "Job queue, processors, state machine, event streaming, and artifact storage.",
    "intro": "All LLM-backed work runs through the background job system in the desktop app. The job queue dispatches work to processors, streams progress events, and persists every prompt and response in SQLite for audit and recovery. This architecture enables cancellation, retry, cost tracking, and real-time UI updates.",
    "visuals": {
      "stateMachine": {
        "title": "Job state machine",
        "description": "Diagram showing job status transitions from created through completion or failure.",
        "imageSrc": "/images/docs/background-jobs/state-machine.svg",
        "imageAlt": "Job state machine diagram",
        "caption": "Placeholder for job state machine diagram."
      }
    },
    "jobRecord": {
      "heading": "Job record structure",
      "description": "Each job creates a background_jobs row in SQLite with these fields:",
      "fields": [
        "id (TEXT PRIMARY KEY): UUID for the job.",
        "session_id (TEXT NOT NULL, FK): References sessions.id with CASCADE DELETE.",
        "task_type (TEXT DEFAULT 'unknown'): Processor identifier (e.g., implementation_plan, text_improvement, root_folder_selection).",
        "status (TEXT): Current state with CHECK constraint for valid values.",
        "prompt (TEXT NOT NULL): Full text sent to the LLM, stored for audit.",
        "response (TEXT): LLM output or error message.",
        "error_message (TEXT): Detailed error information on failure.",
        "tokens_sent (INTEGER DEFAULT 0): Input token count from provider response.",
        "tokens_received (INTEGER DEFAULT 0): Output token count.",
        "cache_read_tokens (INTEGER DEFAULT 0): Tokens read from provider cache (Anthropic).",
        "cache_write_tokens (INTEGER DEFAULT 0): Tokens written to cache.",
        "model_used (TEXT): Model identifier used for the request.",
        "actual_cost (REAL): Computed cost based on token usage and model pricing.",
        "metadata (TEXT): JSON with task-specific data, workflow IDs, stage names.",
        "system_prompt_template (TEXT): Template identifier used for the system prompt.",
        "server_request_id (TEXT): Links to server-side usage tracking.",
        "created_at, updated_at, start_time, end_time (INTEGER): Timestamps.",
        "is_finalized (INTEGER DEFAULT 0): Whether final cost/usage has been recorded."
      ]
    },
    "statusValues": {
      "heading": "Status values and transitions",
      "description": "Jobs transition through well-defined statuses tracked in the database:",
      "statuses": [
        "idle: Initial state before processing starts.",
        "created: Job record created, not yet queued.",
        "queued: Added to job queue, waiting for processor.",
        "acknowledged_by_worker: Processor has picked up the job.",
        "preparing: Processor is gathering inputs (files, prompts).",
        "preparing_input: Building the LLM request payload.",
        "running: Request sent to LLM, awaiting response.",
        "generating_stream: Streaming response in progress.",
        "processing_stream: Processing streamed chunks.",
        "completed: Job finished successfully.",
        "completed_by_tag: Completed via stream end tag detection.",
        "failed: Job failed with error_message populated.",
        "canceled: User requested cancellation."
      ],
      "transitions": "Transitions are enforced in background_job_repository/worker.rs. Invalid transitions are rejected. Status changes emit job:status-changed Tauri events."
    },
    "orchestrator": {
      "heading": "Workflow orchestrator",
      "description": "Multi-stage workflows are managed by WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/:",
      "modules": [
        "mod.rs: Main orchestrator struct and workflow execution entry point.",
        "definition_loader.rs: Loads workflow JSON definitions (e.g., file_finder_workflow.json) specifying stage order and processor types.",
        "stage_scheduler.rs: Schedules stages sequentially, waits for upstream completion.",
        "stage_job_manager.rs: Creates background_job records for each stage.",
        "payload_builder.rs: Constructs stage inputs from IntermediateData.",
        "data_extraction.rs: Extracts outputs from completed stage jobs.",
        "event_emitter.rs: Publishes workflow-status and workflow-stage Tauri events.",
        "state_updater.rs: Updates workflow state in memory and database.",
        "completion_handler.rs: Handles workflow completion and cleanup.",
        "failure_handler.rs: Manages stage failures and retry decisions.",
        "retry_handler.rs: Implements retry logic with exponential backoff."
      ],
      "dataFlow": "Workflows use WorkflowIntermediateData (defined in workflow_types.rs) to pass outputs between stages: directoryTreeContent, selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths, unverifiedPaths."
    },
    "processors": {
      "heading": "Job processors",
      "description": "Each task_type maps to a processor in desktop/src-tauri/src/jobs/processors/:",
      "implementations": [
        "implementation_plan_processor.rs: Loads selected file contents, builds structured prompt with directory tree, streams XML plan to UI. Uses generic_llm_stream_processor for streaming.",
        "text_improvement_processor.rs: Wraps selection in XML tags, sends non-streaming request, returns improved text. Runs via LlmTaskRunner.",
        "root_folder_selection_processor.rs: Sends directory tree to LLM, parses JSON array response of selected directories.",
        "RegexFileFilterProcessor (in processors/mod.rs): Generates regex patterns from task, applies to git file list, filters binaries.",
        "FileRelevanceAssessmentProcessor: Chunks file contents by token limit, scores relevance in batches, aggregates relevant paths.",
        "ExtendedPathFinderProcessor (path_finder_types.rs): Analyzes imports/dependencies, suggests related files, validates paths exist.",
        "web_search_prompts_generator_processor.rs: Generates research_task XML blocks for deep research.",
        "web_search_executor_processor.rs: Executes research prompts in parallel via server search API.",
        "generic_llm_stream_processor.rs: Reusable streaming processor that handles chunk accumulation, event emission, and response finalization."
      ]
    },
    "events": {
      "heading": "Event streaming",
      "description": "Job progress emits Tauri events consumed by the React UI:",
      "eventTypes": [
        "job:status-changed: Payload {jobId, status, error?}. Emitted on every status transition.",
        "job:stream-progress: Payload {jobId, content, tokensReceived}. Emitted for each streaming chunk.",
        "job:completed: Payload {jobId, response, tokensTotal, cost}. Emitted on successful completion.",
        "workflow-status: Payload {workflowId, status, currentStage?}. Workflow-level status updates.",
        "workflow-stage: Payload {workflowId, stageName, status}. Individual stage status."
      ],
      "reactConsumption": "React components subscribe via useEffect with listen() from @tauri-apps/api/event. WorkflowTracker aggregates workflow events. JobStatusIndicator displays real-time status."
    },
    "retry": {
      "heading": "Retry and cancellation",
      "description": "Job retry and cancellation mechanisms:",
      "retryLogic": "retry_handler.rs manages retry counts and delays. Retries use exponential backoff with configurable max attempts. Retry state stored in job.metadata.retryCount.",
      "cancellation": "Cancellation sets a flag checked between streaming chunks in generic_llm_stream_processor.rs. Server-side cancellation sends /api/llm/cancel with request_id.",
      "cleanup": "workflow_cleanup.rs handles cleanup of incomplete workflows. Stale jobs (running status after app restart) are marked failed."
    },
    "artifacts": {
      "heading": "Artifact storage",
      "description": "Job inputs and outputs are fully persisted for audit:",
      "stored": [
        "prompt: Complete LLM prompt including system prompt and user content.",
        "response: Full LLM response text or streaming accumulation.",
        "metadata: JSON with task-specific data (original text for improvements, file lists, workflow context).",
        "system_prompt_template: Identifier linking to server-side prompt template version.",
        "Token counts and cost: Captured from provider response for billing and analysis."
      ],
      "access": "background_job_repository provides queries: get_jobs_for_session, get_job_by_id, get_jobs_by_task_type, get_recent_jobs. Job history displayed in BackgroundJobsSidebar component."
    },
    "costTracking": {
      "heading": "Cost tracking",
      "description": "Per-job cost tracking enables budget management:",
      "calculation": "Cost calculated using model pricing from server/src/models/model_pricing.rs. Formula: (tokens_sent * input_price + tokens_received * output_price) with cache adjustments.",
      "accumulation": "Session-level cost aggregated from background_jobs. UI displays cumulative cost in session header.",
      "serverSync": "server_request_id links desktop jobs to server-side usage records for billing reconciliation."
    },
    "cta": {
      "heading": "See the data model",
      "description": "Understand the SQLite schema that stores jobs, sessions, and terminal output.",
      "links": {
        "dataModel": "Data model",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "buildYourOwn": {
    "meta": {
      "title": "Build your own pipeline - PlanToCode",
      "description": "Conceptual guide for designing file discovery and plan generation workflows similar to PlanToCode."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Build Your Own Pipeline",
    "description": "Conceptual guide for designing file discovery and plan generation workflows.",
    "intro": "This guide distills the key architectural patterns from PlanToCode into a conceptual blueprint. Whether you want to build a similar system or understand why certain design decisions were made, this document covers the foundational patterns you can reuse or adapt.",
    "visuals": {
      "pipelineMap": {
        "title": "Pipeline architecture map",
        "description": "Overview of the multi-stage pipeline from task input to plan output.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Pipeline architecture diagram",
        "caption": "Placeholder for pipeline architecture diagram."
      }
    },
    "keyPatterns": {
      "heading": "Key Architectural Patterns",
      "jobQueue": {
        "title": "Job Queue Pattern",
        "description": "All LLM-backed operations run as background jobs with status tracking, cancellation support, and retry logic. Jobs are persisted to SQLite so state survives app restarts.",
        "benefits": [
          "Decouples UI responsiveness from LLM latency",
          "Enables cancellation mid-stream",
          "Provides audit trail of all operations",
          "Supports retry with exponential backoff"
        ],
        "pitfalls": [
          "Job status management adds complexity",
          "Need careful handling of stale jobs on restart",
          "Stream accumulation can consume memory for large responses"
        ]
      },
      "workflowOrchestrator": {
        "title": "Workflow Orchestrator Pattern",
        "description": "Multi-stage workflows are coordinated by an orchestrator that schedules stages sequentially, passes intermediate data between them, and handles failures at any stage.",
        "components": [
          "Definition loader reads workflow JSON specs",
          "Stage scheduler dispatches stages in order",
          "Payload builder constructs inputs from prior outputs",
          "Event emitter publishes progress for UI updates"
        ]
      },
      "repositoryPattern": {
        "title": "Repository Pattern",
        "description": "All persistence goes through typed repositories that abstract SQLite operations. This provides a clean API, enables testing, and centralizes database access.",
        "benefits": [
          "Typed access prevents SQL injection",
          "Repositories can be mocked for testing",
          "Centralized query optimization",
          "Consistent error handling"
        ]
      }
    },
    "steps": {
      "step1": {
        "title": "1. Define your task model",
        "description": "Start by defining what constitutes a task in your system. PlanToCode uses sessions with task descriptions, file selections, and model preferences.",
        "details": "Store task metadata in a dedicated table with versioning for history tracking."
      },
      "step2": {
        "title": "2. Build the job queue",
        "description": "Create a job queue that persists jobs to storage, emits status events, and supports cancellation. Jobs should track prompts, responses, tokens, and cost.",
        "details": "Use a semaphore-based concurrency limiter to control parallel LLM requests."
      },
      "step3": {
        "title": "3. Implement processors",
        "description": "Each job type needs a processor that builds prompts, calls the LLM, and parses responses. Use streaming for long outputs.",
        "details": "Processors should be stateless and receive all context through job parameters."
      },
      "step4": {
        "title": "4. Create the workflow orchestrator",
        "description": "For multi-stage workflows, build an orchestrator that schedules stages, manages intermediate data, and handles failures.",
        "details": "Store workflow definitions as JSON for easy modification without code changes."
      },
      "step5": {
        "title": "5. Add the routing layer",
        "description": "Route LLM requests through a server proxy that normalizes payloads, manages API keys, and tracks usage.",
        "details": "Keep provider credentials on the server; never embed them in desktop clients."
      }
    },
    "architectureDecisions": {
      "heading": "Architecture Decisions",
      "decisions": [
        {
          "question": "Should you use a local database or server-side storage?",
          "recommendation": "Use local SQLite for job state and artifacts. This enables offline operation and fast queries. Sync to server only for billing and cross-device state."
        },
        {
          "question": "Streaming vs non-streaming responses?",
          "recommendation": "Use streaming for plan generation and any output shown progressively. Use non-streaming for short transformations like text improvement."
        },
        {
          "question": "How to handle LLM provider failures?",
          "recommendation": "Implement automatic retry with exponential backoff. Consider a fallback provider like OpenRouter for resilience."
        },
        {
          "question": "Where should file content be loaded?",
          "recommendation": "Load file content in the processor just before building the prompt. This ensures fresh content and avoids storing large blobs in job records."
        }
      ]
    },
    "customizeVsReuse": {
      "heading": "What to Customize vs Reuse",
      "customize": [
        "Prompt templates for your specific use case",
        "File discovery patterns for your project types",
        "Output format (XML, JSON, Markdown)",
        "Model selection per task type"
      ],
      "reuse": [
        "Job queue architecture with status tracking",
        "Workflow orchestrator pattern",
        "Repository pattern for persistence",
        "Streaming response handling",
        "Provider routing and normalization"
      ]
    },
    "commonPitfalls": {
      "heading": "Common Pitfalls to Avoid",
      "items": [
        {
          "pitfall": "Embedding API keys in the client",
          "solution": "Route all LLM requests through a server proxy that manages credentials securely."
        },
        {
          "pitfall": "Not persisting job state",
          "solution": "Store every job with full prompt and response for audit and recovery."
        },
        {
          "pitfall": "Blocking UI on LLM calls",
          "solution": "Use background jobs with event-driven UI updates for responsive interfaces."
        },
        {
          "pitfall": "Ignoring token limits",
          "solution": "Estimate tokens before sending and chunk large inputs to stay within context windows."
        },
        {
          "pitfall": "No cancellation support",
          "solution": "Check cancellation flags between streaming chunks and propagate to server."
        }
      ]
    },
    "artifacts": {
      "heading": "Artifacts to Persist",
      "items": [
        "Full prompt sent to the LLM (for debugging and audit)",
        "Complete response including streaming accumulation",
        "Token counts from provider response",
        "Computed cost based on model pricing",
        "System prompt template identifier for versioning",
        "Workflow intermediate data for multi-stage flows"
      ]
    },
    "implementationNotes": {
      "heading": "Implementation Notes",
      "items": [
        "Use SQLite with WAL mode for concurrent read/write access",
        "Implement graceful shutdown that marks running jobs as failed",
        "Add health checks for external dependencies before job processing",
        "Log all LLM errors with full context for debugging",
        "Consider caching file content with short TTL to avoid redundant reads"
      ]
    }
  },
  "decisionsTradeoffs": {
    "meta": {
      "title": "Technical decisions and tradeoffs - PlanToCode",
      "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen, and what operational tradeoffs they create."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Technical Decisions & Tradeoffs",
    "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen and what they cost.",
    "intro": "Every architecture involves tradeoffs. This document explains the major technology choices in PlanToCode, what benefits they provide, and what costs or limitations they introduce.",
    "visuals": {
      "tradeoffMatrix": {
        "title": "Tradeoff matrix",
        "description": "Visual comparison of technology choices with their benefits and costs.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Technology tradeoff matrix",
        "caption": "System architecture overview illustrating the technology stack decisions."
      }
    },
    "sections": {
      "tauri": {
        "title": "Tauri v2 for Desktop",
        "description": "Tauri provides a Rust backend with a web-based frontend, enabling cross-platform desktop apps with native performance and small binary sizes.",
        "benefits": [
          "Small binary size (~15MB vs 200MB+ for Electron)",
          "Native Rust performance for file operations and job processing",
          "Capability-based security model with fine-grained permissions",
          "Single codebase for macOS, Windows, and Linux",
          "Access to system APIs (PTY, keychain, notifications)"
        ],
        "tradeoffs": [
          "Smaller ecosystem than Electron",
          "Rust learning curve for backend development",
          "WebView rendering differences across platforms",
          "Less mature tooling for debugging IPC issues"
        ],
        "implementation": "PlanToCode uses Tauri 2.9.1 with ~35 command modules, capability-based permissions, and plugins for shell, dialog, and notifications."
      },
      "sqlite": {
        "title": "SQLite for Local Persistence",
        "description": "SQLite stores all local state including sessions, jobs, terminal output, and settings. This enables offline operation and fast queries.",
        "benefits": [
          "Zero-config embedded database",
          "Fast queries for local data",
          "Enables offline operation",
          "Single file backup and restore",
          "WAL mode for concurrent access"
        ],
        "tradeoffs": [
          "No built-in replication or sync",
          "Large terminal logs can grow the database",
          "Need manual schema migrations",
          "Single-writer limitation (mitigated by WAL)"
        ],
        "implementation": "Schema in consolidated_schema.sql with ~10 tables. Repositories provide typed access with rusqlite."
      },
      "llmProxy": {
        "title": "Dedicated LLM Proxy Server",
        "description": "All LLM requests route through a server proxy that manages API keys, normalizes requests, tracks usage, and handles billing.",
        "benefits": [
          "API keys never leave the server",
          "Single request format for all providers",
          "Centralized usage tracking and billing",
          "Provider failover without client updates",
          "Content filtering and rate limiting"
        ],
        "tradeoffs": [
          "Requires server infrastructure",
          "Adds network latency to requests",
          "Server becomes single point of failure",
          "Need to maintain provider integrations"
        ],
        "implementation": "Actix-Web server with handlers in server/src/handlers/proxy/. Transformers in provider_transformers/ normalize requests."
      },
      "websocket": {
        "title": "WebSocket Relay for Mobile",
        "description": "Desktop and mobile clients connect through a WebSocket relay for device linking, terminal streaming, and job synchronization.",
        "benefits": [
          "Real-time bidirectional communication",
          "No direct P2P networking required",
          "Works across NAT and firewalls",
          "Supports multiple linked devices"
        ],
        "tradeoffs": [
          "Requires persistent server connections",
          "Relay adds latency for large payloads",
          "Connection management complexity",
          "Need reconnection and heartbeat logic"
        ],
        "implementation": "device_link_ws.rs implements the relay with session tracking, heartbeats, and PTC1 binary framing for terminal output."
      }
    },
    "operational": {
      "heading": "Operational Consequences",
      "items": [
        "Tauri: Need separate builds for each platform. CI/CD must cross-compile or use platform-specific runners.",
        "SQLite: Database file grows with terminal output. May need periodic cleanup for long-running instances.",
        "LLM Proxy: Server downtime blocks all LLM operations. Need monitoring and redundancy for production.",
        "WebSocket: Reconnection logic adds complexity. Clients must handle connection drops gracefully."
      ]
    },
    "securityBoundaries": {
      "heading": "Security Boundaries",
      "description": "The architecture creates clear security boundaries that limit exposure:",
      "items": [
        "API keys stored in server vault, never sent to clients",
        "JWT tokens validated on every request with JWKS rotation",
        "Capability-based permissions limit filesystem access",
        "Content sent to LLMs requires explicit user approval",
        "Audit logs track all LLM requests with user context"
      ]
    },
    "whenToReconsider": {
      "heading": "When to Reconsider",
      "description": "These decisions may need revisiting if requirements change significantly:",
      "items": [
        "If browser-only access is required, consider a web-based alternative to Tauri",
        "If multi-device sync is critical, consider server-side job storage",
        "If provider lock-in is acceptable, direct API calls may reduce latency",
        "If mobile is primary, consider native apps instead of device linking"
      ]
    }
  },
  "dataModel": {
    "meta": {
      "title": "Data model and storage - PlanToCode",
      "description": "SQLite entities, relationships, and how state is rehydrated on app restart."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Data Model & Storage",
    "description": "SQLite entities, relationships, and how state is rehydrated.",
    "intro": "PlanToCode uses SQLite for all local state. This document describes the schema, entity relationships, and how state is restored when the app restarts.",
    "sqlite": {
      "heading": "SQLite Configuration",
      "description": "The database uses WAL mode for concurrent read/write access. The file is stored in the Tauri app data directory (~/.local/share/plantocode on Linux, ~/Library/Application Support/plantocode on macOS).",
      "migrations": "Schema migrations are consolidated in consolidated_schema.sql. The app checks schema version on startup and runs any pending migrations."
    },
    "entities": {
      "heading": "Core Entities",
      "items": [
        "sessions: Project context with task description, file selections, model preferences, search settings, video/merge prompts, history indexes",
        "background_jobs: LLM-backed operations with prompt, response, tokens, cost, is_finalized flag, error_message",
        "terminal_sessions: PTY sessions with output log, status, process info",
        "task_description_history: Version history for task descriptions",
        "file_selection_history: Version history for file selections",
        "project_system_prompts: Per-project prompt overrides",
        "key_value_store: App settings and configuration",
        "error_logs: Client-side error tracking",
        "migrations: Tracks applied database migrations with timestamps",
        "db_diagnostic_logs: Records database diagnostic issues and errors",
        "app_settings: Application configuration key-value pairs with descriptions"
      ]
    },
    "visuals": {
      "schema": {
        "title": "Entity relationship diagram",
        "description": "Visual representation of the SQLite schema and relationships.",
        "imageSrc": "/images/docs/data-model/schema.svg",
        "imageAlt": "Database schema diagram",
        "caption": "Placeholder for database schema diagram."
      }
    },
    "relationships": {
      "heading": "Entity Relationships",
      "description": "Entities are linked through foreign keys with cascade delete rules:",
      "links": [
        "sessions → background_jobs: One-to-many, cascade delete",
        "background_jobs → terminal_sessions: Optional one-to-one link via job_id",
        "sessions → task_description_history: One-to-many for version tracking",
        "sessions → file_selection_history: One-to-many for version tracking"
      ]
    },
    "repositories": {
      "heading": "Repository Layer",
      "description": "All database access goes through typed repositories in desktop/src-tauri/src/db_utils/:",
      "examples": [
        "background_job_repository/: Modular with base.rs, worker.rs, metadata.rs, cleanup.rs",
        "session_repository.rs: Session CRUD with history management",
        "terminal_repository.rs: Terminal session persistence and output logging",
        "settings_repository.rs: Key-value settings storage"
      ]
    },
    "rehydration": {
      "heading": "State Rehydration",
      "description": "When the app starts, state is restored from SQLite:",
      "sessions": "Active session is loaded with task description, file selections, and model preferences. Recent sessions are available in the session picker."
    },
    "retention": {
      "heading": "Data Retention",
      "description": "Old data is cleaned up based on configurable retention periods:",
      "exports": "Sessions and jobs can be exported for backup before cleanup."
    },
    "cta": {
      "heading": "Explore job processing",
      "description": "See how background jobs use this data model.",
      "links": {
        "jobs": "Background jobs",
        "terminals": "Terminal sessions"
      }
    }
  },
  "serverSetup": {
    "meta": {
      "title": "Dedicated server setup - PlanToCode",
      "description": "Ansible-based infrastructure setup: base hardening, PostgreSQL, Redis, and application deployment."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Dedicated Server Setup",
    "description": "Ansible-based infrastructure: base hardening, app deployment, and vault-managed secrets.",
    "intro": "PlanToCode runs on dedicated servers managed through Ansible playbooks. This document covers the infrastructure setup, security hardening, and deployment process.",
    "layers": {
      "heading": "Infrastructure Layers",
      "description": "The infrastructure is organized into layers, each managed by dedicated playbooks:",
      "items": [
        "Base layer: OS hardening, SSH configuration, firewall rules",
        "Database layer: PostgreSQL 17 with replication and backups",
        "Cache layer: Redis 7+ for session state and job queues",
        "Application layer: Rust server binary with systemd service",
        "Proxy layer: Nginx reverse proxy with SSL termination"
      ]
    },
    "servers": {
      "heading": "Server Regions",
      "description": "PlanToCode runs in two regions for geographic redundancy:",
      "items": [
        "EU region: Hetzner dedicated server (api-eu.plantocode.com)",
        "US region: InterServer dedicated server (api-us.plantocode.com)"
      ]
    },
    "requirements": {
      "heading": "Server Requirements",
      "items": [
        "Debian 12 or Ubuntu 22.04 LTS",
        "4+ CPU cores, 16GB+ RAM, 200GB+ SSD",
        "Public IPv4 with firewall access to ports 22, 80, 443",
        "SSH key access for Ansible deployment"
      ]
    },
    "hardening": {
      "heading": "Base Hardening",
      "description": "site-base.yml applies security hardening:",
      "items": [
        "Disable root SSH login, require key authentication",
        "Configure UFW firewall with minimal open ports",
        "Install fail2ban for brute force protection",
        "Enable automatic security updates",
        "Configure audit logging"
      ]
    },
    "postgresql": {
      "heading": "PostgreSQL Setup",
      "description": "PostgreSQL 17 is configured for production use:",
      "items": [
        "Connection pooling with PgBouncer",
        "Automated daily backups with pg_dump",
        "WAL archiving for point-in-time recovery",
        "SSL required for all connections",
        "Row-level security for multi-tenant data"
      ]
    },
    "redis": {
      "heading": "Redis Setup",
      "description": "Redis 7+ handles caching and session state:",
      "items": [
        "Password authentication required",
        "AOF persistence for durability",
        "Memory limits with eviction policy",
        "TLS encryption for connections"
      ]
    },
    "zeroDowntime": {
      "heading": "Zero-Downtime Deployment",
      "description": "Deployments use a rolling update strategy:",
      "items": [
        "New binary uploaded alongside running version",
        "Health check confirms new version is ready",
        "Systemd restarts with graceful shutdown",
        "Load balancer drains connections during switch",
        "Rollback available via previous binary symlink"
      ]
    },
    "quickStart": {
      "heading": "Quick Start",
      "steps": [
        "Clone the infrastructure repository",
        "Copy inventory.example to inventory and configure hosts",
        "Set vault password in .vault_pass",
        "Run: ansible-playbook -i inventory site-base.yml",
        "Run: ansible-playbook -i inventory site-app.yml"
      ]
    },
    "vault": {
      "heading": "Secrets Management",
      "description": "Sensitive configuration uses Ansible Vault:",
      "items": [
        "Database credentials",
        "API keys for LLM providers",
        "SSL certificates and private keys",
        "Auth0 client secrets",
        "Stripe webhook secrets"
      ]
    },
    "operations": {
      "heading": "Common Operations",
      "items": [
        "ansible-playbook -i inventory site-app.yml --tags deploy",
        "ansible-playbook -i inventory site-base.yml --tags backup",
        "ansible-playbook -i inventory site-app.yml --tags rollback",
        "ansible-playbook -i inventory site-base.yml --tags logs"
      ]
    },
    "ssl": {
      "heading": "SSL/TLS Configuration",
      "description": "Let's Encrypt provides free SSL certificates:",
      "items": [
        "Certbot configured with Nginx plugin",
        "Automatic renewal via cron job",
        "HSTS headers enabled",
        "TLS 1.2+ only, modern cipher suite"
      ]
    },
    "security": {
      "heading": "Security Checklist",
      "items": [
        "All default passwords changed",
        "SSH key rotation scheduled",
        "Firewall rules audited",
        "Security updates automated",
        "Backup restoration tested"
      ]
    },
    "recovery": {
      "heading": "Disaster Recovery",
      "description": "Recovery procedures for common failure scenarios:",
      "items": [
        "Database corruption: Restore from latest pg_dump backup",
        "Server failure: Provision new server and run playbooks",
        "SSL expiration: Manual certbot renew --force-renewal",
        "Security breach: Rotate all credentials, audit logs"
      ]
    }
  },
  "tauriV2": {
    "meta": {
      "title": "Tauri v2 development guide - PlanToCode",
      "description": "Project layout, commands, capabilities, and development workflow for Tauri v2."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Tauri v2 Development Guide",
    "description": "Project layout, commands, and capability-based permissions for Tauri v2.",
    "intro": "PlanToCode uses Tauri v2 for the desktop application. This guide covers the project structure, command system, capability-based permissions, and development workflow.",
    "projectLayout": {
      "heading": "Project Layout",
      "description": "The desktop application follows standard Tauri v2 conventions:",
      "items": [
        "desktop/src/: React frontend with components, hooks, and providers",
        "desktop/src-tauri/: Rust backend with commands, jobs, and services",
        "desktop/src-tauri/src/lib.rs: Application entry point",
        "desktop/src-tauri/src/commands/: Tauri command handlers (~35 modules)",
        "desktop/src-tauri/capabilities/: Permission definitions",
        "desktop/src-tauri/tauri.conf.json: Tauri configuration"
      ]
    },
    "configuration": {
      "heading": "Tauri Configuration",
      "description": "tauri.conf.json configures the application:",
      "items": [
        "productName, version, identifier for app metadata",
        "build.beforeDevCommand and beforeBuildCommand for frontend",
        "bundle settings for installers (DMG, NSIS, AppImage)",
        "security.csp for Content Security Policy",
        "plugins configuration for official plugins"
      ]
    },
    "capabilities": {
      "heading": "Capability-Based Permissions",
      "description": "Tauri v2 uses capabilities to control what the app can access:",
      "items": [
        "default.json: Base permissions for all windows",
        "desktop-default.json: Desktop-specific permissions",
        "plantocode-api.json: Custom permissions for PlanToCode commands",
        "Permissions grant access to: filesystem, shell, http, dialog, notification"
      ]
    },
    "plugins": {
      "heading": "Tauri Plugins",
      "description": "PlanToCode uses several official Tauri plugins:",
      "items": [
        "tauri-plugin-http: HTTP client for API calls",
        "tauri-plugin-dialog: Native file/folder pickers",
        "tauri-plugin-shell: Shell command execution",
        "tauri-plugin-store: Persistent key-value storage",
        "tauri-plugin-notification: Desktop notifications",
        "tauri-plugin-updater: In-app updates",
        "tauri-plugin-single-instance: Single instance enforcement"
      ]
    },
    "appState": {
      "heading": "Application State",
      "description": "Rust state managed through Tauri's state system:",
      "items": [
        "AppState struct holds shared state",
        "RuntimeConfig for server URLs and feature flags",
        "TokenManager for secure credential storage",
        "ConfigCache for AI model configuration"
      ]
    },
    "commands": {
      "heading": "Creating Commands",
      "description": "Tauri commands expose Rust functions to the frontend:",
      "items": [
        "Use #[tauri::command] attribute on async functions",
        "Return Result<T, String> for error handling",
        "Access state via State<AppState> parameter",
        "Register in lib.rs invoke_handler"
      ]
    },
    "singleInstance": {
      "heading": "Single Instance",
      "description": "The app enforces single instance to prevent data conflicts:",
      "items": [
        "tauri-plugin-single-instance handles detection",
        "Second launch focuses existing window",
        "Deep links forwarded to running instance"
      ]
    },
    "devWorkflow": {
      "heading": "Development Workflow",
      "description": "Common commands for development:",
      "items": [
        "pnpm tauri dev: Start development with hot reload",
        "pnpm tauri build: Build production release",
        "cargo test: Run Rust tests",
        "cargo clippy: Lint Rust code"
      ]
    },
    "mobile": {
      "heading": "Mobile Considerations",
      "description": "Tauri v2 supports mobile, but PlanToCode uses native Swift:",
      "items": [
        "iOS app built with SwiftUI for native experience",
        "Shared API contracts between desktop and mobile",
        "Device linking via WebSocket relay"
      ]
    },
    "distribution": {
      "heading": "Distribution",
      "description": "Build artifacts for each platform:",
      "items": [
        "macOS: .dmg with universal binary (Intel + Apple Silicon)",
        "Windows: NSIS installer and MSIX package",
        "Linux: AppImage for broad compatibility"
      ]
    }
  },
  "distributionMacos": {
    "meta": {
      "title": "macOS distribution - PlanToCode",
      "description": "Code signing, notarization, DMG packaging, and updater configuration for macOS."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "macOS Distribution",
    "description": "Signing, notarization, DMG packaging, and updater artifacts.",
    "intro": "Distributing on macOS requires code signing, notarization, and proper packaging. This document covers the complete process for PlanToCode.",
    "signing": {
      "heading": "Code Signing",
      "description": "All binaries must be signed with an Apple Developer ID:",
      "items": [
        "Developer ID Application certificate for app signing",
        "Developer ID Installer certificate for PKG signing",
        "Certificates stored in CI secrets, imported to keychain",
        "Hardened runtime enabled for notarization compatibility"
      ]
    },
    "entitlements": {
      "heading": "Entitlements",
      "description": "Required entitlements for PlanToCode features:",
      "items": [
        "com.apple.security.cs.allow-jit",
        "com.apple.security.cs.allow-unsigned-executable-memory",
        "com.apple.security.device.audio-input",
        "com.apple.security.network.client",
        "com.apple.security.files.user-selected.read-write"
      ]
    },
    "build": {
      "heading": "Build Process",
      "description": "Steps to build a signed release:",
      "steps": [
        "Run pnpm tauri build --target universal-apple-darwin",
        "Tauri signs with APPLE_SIGNING_IDENTITY from environment",
        "Universal binary created with lipo for Intel + ARM",
        "DMG packaged with custom background and layout"
      ]
    },
    "universalBinaries": {
      "heading": "Universal Binaries",
      "description": "PlanToCode ships as a universal binary:",
      "items": [
        "Single .app supports both Intel and Apple Silicon",
        "Built with --target universal-apple-darwin",
        "Slightly larger binary but simpler distribution",
        "Native performance on both architectures"
      ]
    },
    "notarization": {
      "heading": "Notarization",
      "description": "Apple notarization is required for Gatekeeper approval:",
      "items": [
        "DMG submitted to Apple notary service",
        "Uses notarytool with App Store Connect credentials",
        "Stapling attaches notarization ticket to DMG",
        "Process takes 1-5 minutes typically"
      ]
    },
    "updater": {
      "heading": "In-App Updates",
      "description": "tauri-plugin-updater handles automatic updates:",
      "items": [
        "Checks update endpoint on launch",
        "Downloads new version in background",
        "Prompts user to restart to apply",
        "Signature verification before installation"
      ]
    },
    "latestJson": {
      "heading": "Update Manifest",
      "description": "latest.json describes available updates:",
      "items": [
        "version: Semantic version string",
        "platforms.darwin-universal: URL and signature",
        "notes: Release notes in markdown",
        "pub_date: ISO 8601 publish timestamp"
      ]
    },
    "pitfalls": {
      "heading": "Common Pitfalls",
      "description": "Issues frequently encountered:",
      "items": [
        "Keychain locked during CI: Unlock before signing",
        "Notarization timeout: Retry with exponential backoff",
        "Invalid signature: Check entitlements match capabilities",
        "Gatekeeper rejection: Verify notarization stapled correctly"
      ]
    },
    "verification": {
      "heading": "Verification Commands",
      "description": "Commands to verify signing and notarization:",
      "items": [
        "codesign -dv --verbose=4 PlanToCode.app",
        "spctl --assess --verbose PlanToCode.app",
        "stapler validate PlanToCode.dmg",
        "xcrun notarytool log <submission-id>"
      ]
    }
  },
  "distributionWindows": {
    "meta": {
      "title": "Windows distribution - PlanToCode",
      "description": "NSIS installer, MSIX packaging, Microsoft Store submission, and code signing for Windows."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Windows Distribution & Store",
    "description": "NSIS builds, MSIX packaging, and Microsoft Store submission.",
    "intro": "PlanToCode distributes on Windows through both direct download (NSIS installer) and the Microsoft Store (MSIX package). This document covers both distribution methods.",
    "prereqs": {
      "heading": "Prerequisites",
      "description": "Required tools and certificates:",
      "items": [
        "Code signing certificate (EV or standard)",
        "Windows SDK for signtool",
        "NSIS for installer building",
        "MSIX Packaging Tool for Store submissions"
      ]
    },
    "nsisBuild": {
      "heading": "NSIS Installer",
      "description": "Tauri builds NSIS installers by default:",
      "items": [
        "Custom installer UI with PlanToCode branding",
        "Per-user installation (no admin required)",
        "Start menu and desktop shortcuts",
        "Uninstaller with clean removal"
      ]
    },
    "codeSigning": {
      "heading": "Code Signing",
      "description": "Windows code signing with Authenticode:",
      "items": [
        "Sign with signtool from Windows SDK",
        "Timestamp from trusted TSA server",
        "EV certificate provides SmartScreen reputation",
        "CI uses secrets for certificate and password"
      ]
    },
    "msixPackaging": {
      "heading": "MSIX for Microsoft Store",
      "description": "MSIX provides Store-compatible packaging:",
      "items": [
        "AppxManifest.xml defines capabilities",
        "Virtual filesystem isolation",
        "Automatic updates through Store",
        "Sandboxed execution environment"
      ]
    },
    "msixConfig": {
      "heading": "MSIX Configuration",
      "description": "Key AppxManifest settings:",
      "items": [
        "Identity: Name, Publisher, Version",
        "Capabilities: internetClient, microphone",
        "Visual elements: Tiles, splash screen",
        "File associations and protocol handlers"
      ]
    },
    "msixSteps": {
      "heading": "MSIX Build Steps",
      "description": "Process to create MSIX package:",
      "steps": [
        "Build release with pnpm tauri build",
        "Create AppxManifest.xml with correct identity",
        "Package with MakeAppx.exe",
        "Sign with SignTool",
        "Validate with Windows App Cert Kit"
      ]
    },
    "store": {
      "heading": "Microsoft Store Submission",
      "description": "Store submission process:",
      "items": [
        "Create app in Partner Center",
        "Upload MSIX package",
        "Configure pricing (free with IAP credits)",
        "Submit for certification",
        "Review takes 1-3 business days"
      ]
    },
    "updaterWindows": {
      "heading": "Windows Updates",
      "description": "Update mechanisms for each distribution:",
      "items": [
        "NSIS: tauri-plugin-updater with GitHub releases",
        "MSIX/Store: Automatic through Microsoft Store",
        "Both check for updates on launch"
      ]
    },
    "webview2": {
      "heading": "WebView2 Runtime",
      "description": "Tauri uses WebView2 on Windows:",
      "items": [
        "Bundled WebView2 bootstrapper in installer",
        "Evergreen version auto-updates",
        "Fixed version available for isolation",
        "Windows 10 1803+ required"
      ]
    },
    "troubleshooting": {
      "heading": "Troubleshooting",
      "description": "Common Windows distribution issues:",
      "items": [
        "SmartScreen warning: Use EV certificate or build reputation",
        "Missing WebView2: Ensure bootstrapper runs",
        "Store rejection: Review certification report details",
        "Update failure: Check signature and manifest version"
      ]
    }
  },
  "promptTypes": {
    "meta": {
      "title": "Prompt types and templates - PlanToCode",
      "description": "Catalog of prompt-driven job types and template assembly process."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Prompt Types & Templates",
    "description": "Catalog of prompt-driven job types and template assembly.",
    "intro": "Every LLM-backed job in PlanToCode uses a structured prompt built from templates. This document catalogs the job types and explains how prompts are assembled.",
    "catalog": {
      "heading": "Job Type Catalog",
      "items": [
        {
          "job": "implementation_plan",
          "title": "Implementation Plan",
          "description": "Generates file-by-file implementation plans with XML structure. Uses streaming for progressive display."
        },
        {
          "job": "implementation_plan_merge",
          "title": "Plan Merge",
          "description": "Combines multiple plans with user instructions. Source plans wrapped in XML tags."
        },
        {
          "job": "text_improvement",
          "title": "Text Improvement",
          "description": "Refines selected text while preserving formatting. Non-streaming for quick results."
        },
        {
          "job": "root_folder_selection",
          "title": "Root Folder Selection",
          "description": "Analyzes directory tree to select relevant project roots. Returns JSON array."
        },
        {
          "job": "regex_file_filter",
          "title": "Regex File Filter",
          "description": "Generates regex patterns for file filtering based on task description."
        },
        {
          "job": "file_relevance_assessment",
          "title": "File Relevance Assessment",
          "description": "Scores file content relevance to task. Processes in batches."
        },
        {
          "job": "extended_path_finder",
          "title": "Extended Path Finder",
          "description": "Discovers related files through imports and dependencies."
        },
        {
          "job": "web_search_prompts",
          "title": "Web Search Prompts",
          "description": "Generates research queries for deep research workflow."
        },
        {
          "job": "video_analysis",
          "title": "Video Analysis",
          "description": "Analyzes screen recordings for UI state and action sequences."
        }
      ]
    },
    "templateStructure": {
      "heading": "Template Structure",
      "description": "Prompts are assembled from system templates and user content:",
      "sampleLabel": "Example template structure:",
      "sample": "<system_prompt>\n  You are an AI assistant that generates implementation plans.\n  [template content from server]\n</system_prompt>\n\n<task>\n  [user's task description]\n</task>\n\n<files>\n  [selected file paths and content]\n</files>\n\n<directory_tree>\n  [project structure]\n</directory_tree>"
    },
    "visuals": {
      "template": {
        "title": "Prompt assembly flow",
        "description": "How templates combine with user content to form complete prompts.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "imageAlt": "Prompt template assembly diagram",
        "caption": "Placeholder for prompt assembly diagram."
      }
    },
    "assembly": {
      "heading": "Assembly Process",
      "steps": [
        "Processor retrieves template ID from task model config",
        "System prompt template loaded from server cache",
        "User content wrapped in semantic XML tags",
        "Context (files, tree) added based on job type",
        "Complete prompt stored in job record before sending"
      ]
    },
    "serverConfig": {
      "heading": "Server-Side Configuration",
      "description": "Templates and model settings are configured server-side:",
      "fields": "task_model_config defines: default_model, allowed_models, system_prompt_template_id, max_tokens, temperature"
    },
    "tokenGuards": {
      "heading": "Token Guardrails",
      "description": "Each task type has token limits to prevent context overflow:",
      "items": [
        "max_tokens_input: Maximum prompt size",
        "max_tokens_output: Maximum response size",
        "Validation before sending prevents wasted API calls",
        "UI shows token count and warns when approaching limits"
      ]
    },
    "versioning": {
      "heading": "Template Versioning",
      "description": "System prompt templates are versioned for reproducibility. Each job records the template ID used, enabling audit and comparison of results across template versions."
    },
    "designNotes": {
      "heading": "Design Notes",
      "items": [
        "XML tags provide clear boundaries for LLM parsing",
        "Semantic naming (task, files, context) aids model understanding",
        "Templates avoid instruction injection by sanitizing user input",
        "Streaming jobs use end tags for completion detection"
      ]
    },
    "cta": {
      "heading": "See job processing in action",
      "description": "Learn how these prompts flow through the job system.",
      "links": {
        "jobs": "Background jobs",
        "merge": "Merge instructions"
      }
    }
  },
  "mergeInstructionsDoc": {
    "meta": {
      "title": "Merge instructions - PlanToCode",
      "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance."
    },
    "category": "Planning",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Merge Instructions",
    "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance.",
    "intro": "When you have multiple implementation plans that need to be combined, the merge workflow lets you select plans, provide guidance, and generate a unified plan that incorporates the best elements from each source.",
    "processor": {
      "heading": "ImplementationPlanMergeProcessor",
      "description": "The ImplementationPlanMergeProcessor fetches source plan responses, wraps them in XML-tagged sections, and streams the merged result through the LlmTaskRunner.",
      "payload": "Accepts source_job_ids array, optional merge_instructions string, and inherits model configuration from the session.",
      "storage": "Merged plan stored as JobResultData::Text with metadata including source_job_ids, merge_instructions, source_count, merged_at timestamp, and session context."
    },
    "inputs": {
      "heading": "Merge Inputs",
      "items": [
        "Source plans: 2-5 implementation plans selected from the plan list",
        "Merge instructions: User guidance on how to combine (prioritize, resolve conflicts)",
        "Model selection: LLM model for merge generation",
        "Task context: Original task description for reference"
      ]
    },
    "xmlFormat": {
      "heading": "XML-Tagged Source Plans",
      "description": "Source plans are wrapped in XML tags with sequential identifiers:",
      "example": "<task_description>\n  [original task from session]\n</task_description>\n\n<source_plans>\n  <implementation_plan_1>\n    [full plan content from first source]\n  </implementation_plan_1>\n  <implementation_plan_2>\n    [full plan content from second source]\n  </implementation_plan_2>\n</source_plans>\n\n<user_instructions>\n  Prioritize API structure from plan 1.\n  Use database schema from plan 2.\n  Resolve conflicts by preferring newer patterns.\n</user_instructions>"
    },
    "prompt": {
      "heading": "Merge Prompt Structure",
      "description": "The merge prompt includes all context needed for intelligent combination:",
      "sections": [
        "System prompt with merge guidelines",
        "Source plans in XML tags",
        "User's merge instructions",
        "Task description for context",
        "Output format requirements"
      ]
    },
    "visuals": {
      "mergeWalkthrough": {
        "title": "Merge workflow walkthrough",
        "description": "Video showing the complete merge process from selection to output.",
        "videoSrc": "/videos/docs/merge-instructions/walkthrough.mp4",
        "posterSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Placeholder for merge walkthrough video."
      },
      "mergeFlow": {
        "title": "Merge instructions flow",
        "description": "Diagram showing multi-model merge workflow with XML-tagged source plans.",
        "imageSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Merge flow showing source selection, instruction processing, and output generation"
      }
    },
    "rules": {
      "heading": "Merge Rules",
      "description": "The LLM follows these rules when merging plans:",
      "examples": [
        "Preserve file paths exactly as specified in source plans",
        "Combine non-conflicting changes from all sources",
        "For conflicts, follow explicit user instructions",
        "Maintain consistent code style across merged content",
        "Include provenance comments indicating source plan"
      ]
    },
    "output": {
      "heading": "Merged Output",
      "description": "The merged plan is returned as raw text from the LLM, following the same flexible format as individual plans.",
      "provenance": "Each section includes comments indicating which source plan contributed the content.",
      "metadata": "source_job_ids, merge_instructions, source_count, merged_at timestamp, planTitle, summary, isStructured (false), and sessionName stored in job metadata."
    },
    "ui": {
      "heading": "UI Integration",
      "description": "The Implementation Plans panel supports merge workflow:",
      "audit": "Merged plans link back to source plans for complete audit trail."
    },
    "cta": {
      "heading": "Learn about plan generation",
      "description": "Understand how individual plans are created before merging.",
      "links": {
        "plans": "Implementation plans",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "meetingIngestionDoc": {
    "meta": {
      "title": "Meeting and recording ingestion - PlanToCode",
      "description": "How recordings become structured task inputs and artifacts through video analysis."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Meeting & Recording Ingestion",
    "description": "How recordings become structured task inputs and artifacts.",
    "intro": "PlanToCode can process meeting recordings and screen captures to extract task-relevant information. This document describes the ingestion workflow from recording to structured artifacts.",
    "visuals": {
      "ingestionFlow": {
        "title": "Recording ingestion flow",
        "description": "How recordings flow through transcription and analysis.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Recording ingestion flow diagram",
        "caption": "Placeholder for ingestion flow diagram."
      }
    },
    "inputs": {
      "heading": "Supported Inputs",
      "description": "The meeting ingestion pipeline accepts various recording formats:",
      "items": [
        "Screen recordings (MP4, WebM, MOV)",
        "Meeting recordings from Zoom, Meet, Teams",
        "Audio-only files (MP3, WAV, M4A)",
        "Direct screen capture from desktop"
      ]
    },
    "uploadProcess": {
      "heading": "Upload Process",
      "description": "Recordings are uploaded through multipart form data to the server:",
      "stepsHeading": "Processing Steps",
      "steps": [
        "File uploaded to server temporary storage",
        "Metadata extracted (duration, format, resolution)",
        "Audio track separated for transcription",
        "Video frames sampled for visual analysis",
        "Results combined and returned to client"
      ]
    },
    "normalization": {
      "heading": "Format Normalization",
      "description": "Various input formats are normalized before processing. Audio is converted to 16kHz mono WAV for Whisper compatibility. Video is processed at native resolution with configurable frame sampling.",
      "outputs": "Normalized outputs ensure consistent downstream processing regardless of input format."
    },
    "multimodalAnalysis": {
      "heading": "Multimodal Analysis",
      "description": "Recordings with both audio and video are analyzed using multimodal models. Models with {code} prefix support native video understanding.",
      "combined": "Audio transcription and visual analysis are combined to produce a comprehensive understanding of the recording content."
    },
    "transcription": {
      "heading": "Audio Transcription",
      "description": "Audio tracks are transcribed using OpenAI Whisper through the server API.",
      "attribution": "Speaker diarization attempts to attribute text to different speakers when multiple voices are detected.",
      "featuresHeading": "Transcription Features",
      "features": [
        "Multiple language support with auto-detection",
        "Word-level timestamps for alignment",
        "Speaker diarization (multi-speaker)",
        "Punctuation and formatting restoration"
      ]
    },
    "frames": {
      "heading": "Frame Sampling",
      "description": "Video frames are sampled at configurable intervals to capture UI state changes and user actions.",
      "timestamps": "Each frame includes its timestamp for correlation with the audio transcript."
    },
    "structuredExtraction": {
      "heading": "Structured Extraction",
      "description": "The combined analysis produces structured outputs suitable for planning:",
      "extractedHeading": "Extracted Elements",
      "items": [
        "Action items and decisions mentioned",
        "UI elements and navigation paths shown",
        "Error states and issues demonstrated",
        "Technical context for implementation"
      ]
    },
    "artifacts": {
      "heading": "Analysis Artifacts",
      "description": "Meeting analysis produces several artifacts stored in the session:",
      "items": [
        "meeting_transcript: Full text with timestamps",
        "action_items: Extracted tasks and decisions",
        "ui_observations: Visual state changes",
        "combined_context: Merged analysis summary"
      ]
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "desktop/src/components/meeting/MeetingUploader.tsx",
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs"
      ]
    },
    "handoff": {
      "heading": "Planning Handoff",
      "description": "Meeting analysis artifacts can be incorporated into the task description:",
      "pipeline": "The combined context flows into the file discovery and plan generation pipeline, providing rich context for implementation planning."
    },
    "cta": {
      "heading": "Continue to video analysis",
      "description": "Learn more about how video frames are analyzed.",
      "links": {
        "video": "Video analysis",
        "textImprovement": "Text improvement"
      }
    }
  },
  "videoAnalysisDoc": {
    "meta": {
      "title": "Video analysis - PlanToCode",
      "description": "Frame sampling, prompts, and analysis artifacts from screen recordings."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "6 min",
    "title": "Video Analysis",
    "description": "Frame sampling, prompts, and analysis artifacts from recordings.",
    "intro": "Video analysis extracts UI state and action sequences from screen recordings. This enables understanding of user workflows and bug reproduction contexts.",
    "visuals": {
      "frameNotes": {
        "title": "Video analysis pipeline",
        "description": "How frames flow through the analysis model.",
        "imageSrc": "/assets/images/demo-video-analysis.jpg",
        "imageAlt": "Video analysis interface",
        "caption": "The video analysis interface showing frame capture and analysis options."
      }
    },
    "apiEndpoint": {
      "heading": "API Endpoint",
      "endpoint": "Video analysis is handled by {code} on the server. The endpoint accepts multipart form data with the video file and analysis parameters.",
      "payloadHeading": "Payload Fields",
      "payloadFields": [
        "video: The video file (MP4, WebM, MOV)",
        "model: Model identifier for analysis",
        "prompt: Optional custom analysis prompt",
        "max_frames: Maximum frames to sample",
        "fps: Frame sampling rate"
      ]
    },
    "inputs": {
      "heading": "Supported Input Formats",
      "items": [
        "MP4 with H.264 or H.265 codec",
        "WebM with VP8 or VP9 codec",
        "MOV from screen recording tools",
        "Maximum file size: 100MB"
      ]
    },
    "sampling": {
      "heading": "Frame Sampling",
      "description": "Frames are extracted at configurable intervals to balance coverage and API costs. Lower frame rates reduce token usage but may miss rapid changes.",
      "fps": "Default rate is 1 frame per second. For detailed UI analysis, 2-3 FPS may be needed.",
      "parametersHeading": "Sampling Parameters",
      "parameters": [
        "fps: Frames per second to extract (0.5-5)",
        "max_frames: Maximum total frames (10-100)",
        "start_time: Offset to begin sampling",
        "end_time: Offset to stop sampling"
      ]
    },
    "modelRequirements": {
      "heading": "Model Requirements",
      "format": "Video analysis requires vision-capable models. Model identifiers follow {code} format. Currently only {code} models support native video analysis.",
      "reasoning": "Google Gemini models can process video natively, while other vision models require frame-by-frame image analysis."
    },
    "analysis": {
      "heading": "Analysis Process",
      "description": "Sampled frames are sent to the vision model along with the analysis prompt. The model produces structured observations about UI state and user actions.",
      "prompting": "System prompts guide the model to focus on specific aspects of the recording.",
      "promptElementsHeading": "Prompt Elements",
      "promptElements": [
        "UI inventory: List visible elements and controls",
        "Action sequence: Describe user actions in order",
        "Error detection: Identify error states and messages",
        "Navigation paths: Track screen transitions"
      ]
    },
    "outputs": {
      "heading": "Analysis Outputs",
      "items": [
        "frame_observations: Per-frame UI descriptions",
        "action_timeline: Ordered list of user actions",
        "error_summary: Any errors or issues observed",
        "context_summary: High-level workflow description"
      ]
    },
    "billing": {
      "heading": "Token Usage & Billing",
      "description": "Video analysis consumes tokens based on frame count and resolution. Each frame is processed as an image token.",
      "tracked": [
        "tokens_sent: Prompt + image tokens",
        "tokens_received: Analysis response tokens",
        "actual_cost: Computed from model pricing"
      ]
    },
    "storage": {
      "heading": "Result Storage",
      "description": "Analysis results are stored in the background_jobs table with task_type 'video_analysis'. The response contains the full analysis in JSON format.",
      "reuse": "Results can be incorporated into task descriptions or used directly in the planning workflow."
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs",
        "desktop/src/components/video/VideoAnalyzer.tsx"
      ]
    },
    "integration": {
      "heading": "Integration with Planning",
      "description": "Video analysis outputs can feed directly into the task description for context-aware planning.",
      "followup": "The context_summary is particularly useful as a starting point for implementation planning."
    },
    "cta": {
      "heading": "See meeting ingestion",
      "description": "Learn how video analysis fits into the broader meeting ingestion workflow.",
      "links": {
        "meeting": "Meeting ingestion",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "mobileIos": {
    "meta": {
      "title": "iOS client architecture - PlanToCode",
      "description": "Swift workflows, Auth0 login flow, and device-link session management for the iOS companion app."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "iOS Client Architecture",
    "description": "Swift workflows, Auth0 login flow, and device-link session management.",
    "intro": "The PlanToCode iOS app is a companion client that connects to linked desktop sessions. It provides mobile access to terminal output, job status, and voice transcription while maintaining the desktop as the primary planning workspace.",
    "visuals": {
      "app": {
        "title": "iOS app interface",
        "description": "Screenshots of the iOS app showing device linking and terminal view.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode iOS app screenshots",
        "caption": "Placeholder for iOS app screenshots."
      }
    },
    "packageStructure": {
      "heading": "Swift Package Structure",
      "description": "The iOS app is organized into Swift packages:",
      "packages": [
        {
          "name": "Core",
          "path": "mobile/ios/Core/",
          "description": "Business logic and API clients",
          "components": [
            "WorkflowManager",
            "APIClient",
            "MobileSessionManager",
            "DeviceLinkClient"
          ]
        },
        {
          "name": "Security",
          "path": "mobile/ios/Security/",
          "description": "Authentication and credential storage",
          "components": [
            "Auth0Manager",
            "KeychainHelper",
            "TokenStore"
          ]
        },
        {
          "name": "VibeUI",
          "path": "mobile/ios/VibeUI/",
          "description": "SwiftUI components and design system",
          "components": [
            "TerminalView",
            "JobListView",
            "SettingsView",
            "DeviceLinkView"
          ]
        }
      ]
    },
    "auth": {
      "heading": "Auth0 PKCE Integration",
      "description": "The iOS app uses Auth0 with PKCE flow for secure authentication:",
      "flow": [
        "User taps Sign In, app generates code verifier and challenge",
        "ASWebAuthenticationSession opens Auth0 login page",
        "User authenticates and Auth0 redirects with authorization code",
        "App exchanges code for tokens using code verifier",
        "Tokens stored securely in iOS Keychain"
      ],
      "tokenManagement": {
        "heading": "Token Management",
        "items": [
          "Access token used for API requests",
          "Refresh token stored for silent renewal",
          "Token refresh triggered before expiry",
          "Logout clears all tokens from Keychain"
        ]
      }
    },
    "deviceLink": {
      "heading": "Device Linking via WebSocket Relay",
      "description": "iOS connects to desktop sessions through the server's WebSocket relay:",
      "protocol": {
        "heading": "Linking Protocol",
        "steps": [
          "Desktop generates link code and displays QR",
          "iOS scans QR or enters code manually",
          "Both connect to /ws/device-link with credentials",
          "Server validates and establishes relay",
          "Bidirectional communication enabled"
        ]
      },
      "messageTypes": {
        "heading": "Message Types",
        "items": [
          "terminal_output: PTY output from desktop terminal",
          "job_status: Background job status updates",
          "session_sync: Session state synchronization",
          "rpc_command: Commands from mobile to desktop"
        ]
      },
      "reconnection": {
        "heading": "Reconnection Handling",
        "description": "The WebSocket connection handles network interruptions with automatic reconnection, exponential backoff, and session state recovery."
      }
    },
    "rpcRouting": {
      "heading": "RPC Command Routing",
      "description": "iOS can send commands to the linked desktop:",
      "commands": {
        "heading": "Supported Commands",
        "items": [
          "send_terminal_input: Send keystrokes to terminal",
          "request_job_status: Get status of specific job",
          "start_voice_transcription: Begin recording on mobile",
          "sync_session: Request full session state"
        ]
      },
      "implementation": {
        "heading": "Implementation",
        "description": "Commands are JSON-RPC messages sent over WebSocket. Desktop validates commands and returns results asynchronously."
      }
    },
    "offlineQueue": {
      "heading": "Offline Action Queue",
      "description": "Actions performed while disconnected are queued for sync:",
      "architecture": {
        "heading": "Queue Architecture",
        "items": [
          "Actions stored in local SQLite database",
          "Queue processed on reconnection",
          "Conflicts resolved with server timestamps",
          "Failed actions reported to user"
        ]
      },
      "supportedActions": {
        "heading": "Supported Offline Actions",
        "items": [
          "Voice transcription recording (stored locally)",
          "Session notes and annotations",
          "Preference changes"
        ]
      }
    },
    "localStorage": {
      "heading": "SQLite Local Storage",
      "description": "iOS uses SQLite for local persistence:",
      "database": {
        "heading": "Database Schema",
        "path": "~/Documents/plantocode.sqlite",
        "tables": [
          "linked_devices: Desktop connections",
          "offline_queue: Pending sync actions",
          "cached_sessions: Recent session data",
          "transcriptions: Local voice recordings"
        ]
      },
      "migrations": {
        "heading": "Migrations",
        "description": "Schema version tracked in user_version pragma. Migrations run on app launch."
      }
    },
    "sessions": {
      "heading": "Mobile Sessions",
      "description": "MobileSessionManager coordinates session state:",
      "lifecycle": [
        "Load last active session on launch",
        "Connect to linked desktop if available",
        "Subscribe to session updates via WebSocket",
        "Cache session data for offline access"
      ]
    },
    "workflows": {
      "heading": "Workflow Entry Points",
      "description": "Key workflows accessible from mobile:",
      "items": [
        "Terminal monitoring: View output, send input",
        "Job status: Track background job progress",
        "Voice capture: Record and transcribe on mobile",
        "Session browsing: Review plans and history"
      ]
    },
    "region": {
      "heading": "Region Settings",
      "description": "iOS respects user region preference for API routing:",
      "implementation": "Region stored in UserDefaults, used to select api-eu.plantocode.com or api-us.plantocode.com for all requests."
    }
  },
  "providerRouting": {
    "meta": {
      "title": "Provider routing and streaming - PlanToCode",
      "description": "How PlanToCode routes LLM requests through a proxy, normalizes responses, and streams tokens to the desktop client."
    },
    "category": "Research & Models",
    "date": "2025-09-24",
    "readTime": "10 min",
    "title": "Provider Routing and Streaming",
    "description": "Routing layer that mediates all external LLM requests with normalization, streaming, and usage tracking.",
    "visuals": {
      "routingMap": {
        "title": "Provider routing map",
        "description": "Diagram of how requests flow from the desktop app to the proxy and out to providers.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Diagram of provider routing flow from desktop to external providers",
        "caption": "Placeholder for provider routing diagram."
      }
    },
    "cta": {
      "heading": "Continue into model configuration",
      "description": "Model configuration explains how allowed lists and token guardrails are exposed to the UI.",
      "links": {
        "modelConfiguration": "Model configuration",
        "runtimeWalkthrough": "Runtime walkthrough"
      }
    }
  }
}