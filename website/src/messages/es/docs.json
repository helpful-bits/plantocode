{
  "meta": {
    "title": "Documentación - PlanToCode",
    "description": "Aprende a planificar y entregar cambios de código con PlanToCode: descubrimiento de archivos, planes de implementación, sesiones de terminal, límites de modelos y voz."
  },
  "architecture": {
    "meta": {
      "title": "Visión general de la arquitectura de PlanToCode",
      "description": "Capas de escritorio, orquestación y persistencia que impulsan los planes de implementación, flujos de trabajo y sesiones de terminal."
    },
    "category": "Arquitectura",
    "date": "2025-09-19",
    "description": "Cómo están organizados el shell de escritorio, los flujos de trabajo en segundo plano y los servicios compartidos.",
    "frontend": {
      "heading": "Superficie del frontend",
      "providers": "Los proveedores compartidos manejan notificaciones, configuración en tiempo de ejecución y estado del plan. El panel de Planes de Implementación mantiene los metadatos del plan, gestiona la visibilidad de modales y solicita estimaciones de tokens o contenido de prompts según sea necesario.",
      "ui": "La interfaz de escritorio está construida con componentes React. El contenido del plan de implementación se muestra a través de un visor basado en Monaco que virtualiza planes grandes, detecta lenguajes y soporta acciones de copiado para que los revisores puedan examinar el texto del plan sin problemas de rendimiento. Las sesiones de terminal se renderizan dentro de una vista con búfer que se conecta a la salida PTY y muestra actualizaciones del estado de conexión."
    },
    "intro": "PlanToCode es una aplicación de escritorio Tauri con un frontend React. La interfaz renderiza planes de implementación, terminales y controles de configuración, mientras que el backend en Rust expone comandos para flujos de trabajo, estimación de tokens y sesiones de terminal persistentes. Esta visión general resume cómo encajan estas piezas.",
    "metaDescription": "Capas de escritorio, orquestación y persistencia que impulsan los planes de implementación, flujos de trabajo y sesiones de terminal.",
    "metaTitle": "Visión general de la arquitectura de PlanToCode",
    "ogDescription": "Aprende cómo el frontend React, los comandos Tauri y los servicios en segundo plano cooperan dentro de la aplicación de escritorio.",
    "ogTitle": "Visión general de la arquitectura de PlanToCode",
    "persistence": {
      "database": "La salida del terminal y los metadatos de sesión se almacenan en SQLite a través del repositorio de sesiones de terminal. Cada registro incluye identificadores, marcas de tiempo, directorios de trabajo, variables de entorno y el log acumulado para que los reinicios puedan recuperar la salida anterior. El mismo repositorio emite eventos cuando cambia el estado de la sesión.",
      "heading": "Persistencia y configuración",
      "modelConfig": "Los valores predeterminados del modelo residen en la tabla de configuración de la aplicación. Cada tarea define un modelo predeterminado, una lista de alternativas permitidas, presupuestos de tokens y preajustes opcionales de botones de copiado. La capa React lee estas configuraciones para poblar el selector de modelos y los límites."
    },
    "readTime": "7 min",
    "tauriCommands": {
      "commands": "El lado Rust de la aplicación expone comandos para flujos de trabajo, sesiones de terminal y herramientas de modelos. Los comandos de flujo de trabajo inician trabajos en segundo plano a través del Orquestador de Flujos de Trabajo, validando entradas y emitiendo eventos de progreso mientras se ejecuta el pipeline de descubrimiento de archivos. Los comandos de estimación de tokens calculan tamaños de prompt para el modelo seleccionado actualmente.",
      "heading": "Comandos y servicios Tauri",
      "terminal": "Los comandos de terminal gestionan procesos PTY, rastrean clientes remotos y verifican si los binarios CLI soportados están disponibles antes de lanzar una sesión. Las verificaciones de salud combinan el estado PTY con los registros de la base de datos para informar si una sesión sigue activa."
    },
    "title": "Arquitectura de PlanToCode",
    "voicePipeline": {
      "description": "La transcripción de voz está implementada como un hook de React que coordina permisos de medios, selección de micrófono y solicitudes de transcripción en streaming. El hook se integra con el terminal del plan y los editores de prompts, insertando texto reconocido directamente en el componente activo y mostrando notificaciones si la transcripción falla.",
      "heading": "Pipeline de transcripción de voz"
    },
    "server": {
      "heading": "Capa del servidor",
      "description": "El servidor maneja la configuración de proveedores (claves API en bóveda cifrada, límites de tasa, reglas de enrutamiento para OpenAI, Anthropic, Google), enrutamiento de modelos (proxy de solicitudes, failover automático, balanceo de carga, seguimiento de costos por usuario/proyecto), facturación (gestión de suscripciones, medición de uso, aplicación de cuotas, alertas de costos) y APIs de búsqueda web (caché de resultados con TTL de 30 días/7 días, restricciones geográficas, autenticación JWT)."
    },
    "dataFlows": {
      "heading": "Flujos de datos",
      "description": "Tareas, planes, trabajos y sesiones fluyen entre componentes: (1) Refinamiento de tareas: React UI → TextImprovementPopover → comando Tauri → WorkflowOrchestrator → prompt text_improvement → SQLite → el proveedor React reemplaza el texto. (2) Descubrimiento de archivos: panel de Planes de Implementación → comando Tauri → 4 trabajos secuenciales → eventos de progreso → SQLite → visualización en UI. (3) Planes de implementación: Descubrimiento de archivos → Generar Plan → comando Tauri → streaming LLM → SQLite → visor Monaco → revisar/aprobar → exportar. (4) Ejecución de terminal: sesión PTY → SQLite → ejecución de comandos → streaming de salida → inyección de transcripción de voz → detección de atención del agente → logs de auditoría."
    }
  },
  "deepResearch": {
    "meta": {
      "title": "Investigación profunda - PlanToCode",
      "description": "Documentación técnica para el flujo de trabajo de búsqueda web: integración de API, optimización de consultas, procesamiento de resultados e integración con flujos de trabajo de desarrollo."
    },
    "apiIntegration": {
      "heading": "Detalles de Integración de API",
      "pipeline": {
        "description": "Los hallazgos de investigación pasan por un pipeline de procesamiento estandarizado que extrae información significativa mientras preserva el formato y el contexto. El pipeline maneja varios tipos de contenido y sintetiza los hallazgos en información procesable para flujos de trabajo de desarrollo.",
        "heading": "Pipeline de Procesamiento de Contenido"
      },
      "providerConfig": {
        "description": "El sistema utiliza modelos de lenguaje de IA a través de OpenRouter para realizar investigación web inteligente. El LLM genera consultas de investigación dirigidas basadas en el contexto de tu tarea y sintetiza hallazgos de sus datos de entrenamiento y capacidades de búsqueda web. La selección y configuración del modelo se gestionan a través de la configuración de la aplicación.",
        "heading": "Configuración de Investigación de IA"
      }
    },
    "architecture": {
      "description": "El sistema de investigación profunda opera como un flujo de trabajo de dos etapas: (1) WebSearchPromptsGeneration - la IA analiza tu tarea y contexto del proyecto para generar consultas de investigación dirigidas, y (2) WebSearchExecution - el LLM ejecuta prompts de investigación en paralelo y sintetiza los hallazgos. Cada etapa está diseñada para confiabilidad, eficiencia de costos y relevancia contextual.",
      "heading": "Visión General de la Arquitectura"
    },
    "bestPractices": {
      "examples": {
        "description": "Los patrones de integración comunes demuestran cómo los resultados de búsqueda web mejoran diferentes escenarios de desarrollo, desde la depuración de errores específicos hasta la implementación de nuevas funcionalidades con APIs desconocidas.",
        "heading": "Ejemplos de Integración"
      },
      "heading": "Mejores Prácticas y Ejemplos",
      "strategies": {
        "description": "Para maximizar el valor de la integración de búsqueda web, sigue estas estrategias probadas para formular consultas, interpretar resultados e integrar hallazgos en tu flujo de trabajo de desarrollo.",
        "heading": "Estrategias de Búsqueda Efectivas",
        "queryFormulation": {
          "constraints": "Incluye restricciones de plataforma o entorno",
          "errors": "Combina nombres de bibliotecas con mensajes de error específicos",
          "heading": "Formulación de Consultas",
          "practices": "Usa \"mejores prácticas\" o \"enfoque recomendado\" para búsquedas de patrones",
          "versions": "Incluye números de versión específicos cuando sea relevante"
        },
        "resultEvaluation": {
          "crossReference": "Verifica soluciones cruzando múltiples fuentes",
          "dates": "Revisa las fechas de publicación para información sensible al tiempo",
          "heading": "Evaluación de Resultados",
          "official": "Prioriza la documentación oficial sobre fuentes de terceros",
          "verify": "Verifica los ejemplos de código en tu entorno de desarrollo"
        }
      }
    },
    "category": "Referencia Técnica",
    "configuration": {
      "heading": "Configuración y Personalización",
      "preferences": {
        "description": "El comportamiento de investigación se configura a través de la selección de modelo y ajustes de tarea. Elige tu modelo de IA preferido para tareas de investigación, configura tiempos de espera y selecciona qué archivos incluir para el contexto.",
        "filters": "La selección de modelo determina la calidad y el costo de la investigación",
        "heading": "Configuración de Investigación",
        "limits": "Máximo 12 prompts de investigación generados por tarea",
        "optionsHeading": "Opciones Configurables",
        "patterns": "Incluye archivos de proyecto relevantes para mejor contexto",
        "sources": "Directorio del proyecto y selección de archivos para contexto",
        "triggers": "Inicia la investigación manualmente a través del comando de flujo de trabajo"
      },
      "projectSettings": {
        "description": "La configuración de investigación es consciente de la sesión. El sistema utiliza el directorio del proyecto de la sesión actual y los archivos incluidos para proporcionar contexto. Las rutas excluidas (como node_modules, dist) se filtran automáticamente del árbol de directorios mostrado a la IA.",
        "heading": "Configuración Específica del Proyecto"
      }
    },
    "costs": {
      "heading": "Consideraciones de Costos",
      "optimization": {
        "description": "Los costos de investigación se gestionan a través de la generación inteligente de prompts - el sistema limita los prompts de investigación a un máximo de 12 por tarea. La ejecución en paralelo minimiza el tiempo de reloj. Cada trabajo rastrea el uso de tokens y los costos estimados en sus metadatos para total transparencia.",
        "heading": "Optimización de Costos"
      },
      "rateLimiting": {
        "cacheFirst": "Resultados de investigación almacenados en caché por sesión para evitar consultas redundantes",
        "description": "La investigación profunda utiliza tus créditos de IA configurados a través de OpenRouter. Cada tarea de investigación genera múltiples llamadas LLM en paralelo, por lo que los costos escalan con el número de prompts de investigación generados. El sistema rastrea el uso de tokens y los costos por trabajo para transparencia.",
        "guidelinesHeading": "Consejos de Gestión de Costos",
        "heading": "Uso y Costos",
        "personal": "Uso de tokens rastreado por trabajo de investigación con desglose detallado de costos",
        "team": "Costos gestionados a través de tus créditos de suscripción de OpenRouter o PlanToCode",
        "throttling": "Monitorea los metadatos del trabajo para conteos de tokens y costos estimados"
      }
    },
    "cta": {
      "description": "Las funciones de Investigación Profunda y Búsqueda Web están disponibles en la aplicación de escritorio PlanToCode. Descarga la versión para tu plataforma para comenzar a integrar la investigación web en tu flujo de trabajo de desarrollo.",
      "heading": "¿Listo para usar la Investigación Profunda?",
      "links": {
        "architecture": "Ver Arquitectura del Sistema",
        "buildYourOwn": "Construye Tu Propia Integración"
      }
    },
    "date": "2025-09-20",
    "description": "Cómo PlanToCode realiza búsquedas web, procesa resultados e integra hallazgos en flujos de trabajo de desarrollo.",
    "devIntegration": {
      "caching": {
        "description": "Los resultados de investigación se almacenan en los metadatos del trabajo y se pueden acceder a través del panel de detalles del trabajo. Los resultados persisten durante la duración de la sesión y se pueden referenciar al crear planes de implementación o tomar decisiones de codificación.",
        "heading": "Almacenamiento de Resultados"
      },
      "contextAware": {
        "description": "Las solicitudes de investigación se mejoran automáticamente con el contexto de tu sesión actual. El sistema incluye el árbol de directorios de tu proyecto y el contenido de archivos seleccionados en la fase de generación de prompts, permitiendo que la IA formule consultas de investigación específicas para tu código base.",
        "heading": "Investigación Consciente del Contexto"
      },
      "heading": "Integración con el Flujo de Trabajo de Desarrollo",
      "resultIntegration": {
        "description": "Los hallazgos de investigación se pueden usar para informar los planes de implementación. Cuando las tareas de investigación se completan, los hallazgos se formatean como etiquetas research_finding que se pueden incorporar en tareas de planificación posteriores, asegurando que tu implementación esté guiada por las mejores prácticas actuales y documentación precisa.",
        "heading": "Integración de Resultados"
      }
    },
    "intro": "La función de Investigación Profunda permite a PlanToCode realizar investigación inteligente impulsada por IA, recopilar información relevante e integrar los hallazgos directamente en los flujos de trabajo de desarrollo. Este sistema utiliza modelos de lenguaje grandes para generar consultas de investigación dirigidas basadas en el contexto de tu proyecto, ejecutar tareas de investigación en paralelo y sintetizar información procesable para mejorar la generación de código y las capacidades de resolución de problemas.",
    "metaDescription": "Documentación técnica para el flujo de trabajo de búsqueda web: integración de API, optimización de consultas, procesamiento de resultados e integración con flujos de trabajo de desarrollo.",
    "metaTitle": "Investigación profunda - PlanToCode",
    "ogDescription": "Comprende cómo funciona la búsqueda web dentro de PlanToCode: desde la generación de consultas hasta el procesamiento de resultados y la integración con flujos de trabajo de desarrollo.",
    "ogTitle": "Investigación profunda - PlanToCode",
    "readTime": "8 min",
    "title": "Investigación Profunda y Búsqueda Web",
    "troubleshooting": {
      "commonIssues": {
        "description": "La mayoría de los problemas de investigación provienen de la conectividad de la API LLM, créditos insuficientes o prompts demasiado amplios. El sistema proporciona mensajes de error claros y seguimiento del estado del trabajo para la resolución de problemas.",
        "geographic": "Disponibilidad del Modelo",
        "geographicSolution": "Algunos modelos pueden tener restricciones regionales a través de OpenRouter",
        "heading": "Problemas Comunes",
        "noResults": "No se Generaron Prompts de Investigación",
        "noResultsSolution": "Proporciona descripciones de tareas más específicas o incluye archivos relevantes para contexto",
        "rateLimit": "Errores de API",
        "rateLimitSolution": "Verifica el estado de la API de OpenRouter y el saldo de créditos"
      },
      "heading": "Resolución de Problemas y Soporte",
      "performance": {
        "description": "Para un rendimiento óptimo, proporciona descripciones de tareas claras y específicas. Incluye archivos de proyecto relevantes para dar a la IA mejor contexto. El sistema ejecuta prompts de investigación en paralelo para minimizar el tiempo total de ejecución.",
        "heading": "Optimización de Rendimiento"
      }
    },
    "workflow": {
      "execution": {
        "blogs": "Mejores prácticas y patrones de implementación",
        "description": "Los prompts de investigación son ejecutados en paralelo por modelos de lenguaje de IA. Cada prompt se procesa de forma independiente, permitiendo que el sistema recopile información sobre múltiples aspectos de tu tarea simultáneamente. Los resultados se sintetizan en hallazgos estructurados con títulos e información procesable.",
        "documentation": "Documentación de API y especificaciones técnicas",
        "forums": "Resolución de errores y enfoques de depuración",
        "github": "Ejemplos de código y patrones de implementación",
        "heading": "Ejecución de Investigación",
        "releases": "Compatibilidad de versiones y guía de migración",
        "sourcesHeading": "Áreas de Enfoque de Investigación"
      },
      "heading": "Etapas del Flujo de Trabajo de Investigación",
      "processing": {
        "deduplication": "Hallazgos consolidados a través de múltiples prompts de investigación",
        "description": "Los hallazgos de investigación se estructuran en formato JSON con títulos y hallazgos detallados. El sistema agrega resultados de tareas de investigación paralelas, rastrea conteos de éxitos y fallos, y proporciona un resumen de los resultados de la investigación. Los resultados se almacenan en los metadatos del trabajo para fácil acceso.",
        "extraction": "Hallazgos clave extraídos y formateados para integración",
        "heading": "Procesamiento y Síntesis de Resultados",
        "scoring": "Resultados organizados por tema de investigación y relevancia",
        "snippets": "Información procesable y recomendaciones destacadas",
        "stepsHeading": "Pasos de Procesamiento",
        "timestamp": "Ejecución de investigación rastreada con métricas de tiempo"
      },
      "queryGeneration": {
        "api": "Documentación de API e investigación específica de bibliotecas",
        "compatibility": "Compatibilidad de versiones y rutas de migración",
        "description": "Los prompts de investigación se generan automáticamente por IA basándose en tu descripción de tarea, contexto del proyecto y archivos incluidos. El sistema analiza la estructura de tu código base a través del árbol de directorios y contenido de archivos para formular consultas de investigación dirigidas. Se generan hasta 12 prompts de investigación enfocados por tarea.",
        "errors": "Resolución de errores y enfoques de depuración",
        "heading": "Generación de Prompts",
        "practices": "Mejores prácticas y patrones recomendados",
        "security": "Consideraciones de seguridad y conciencia de vulnerabilidades",
        "typesHeading": "Temas de Investigación"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Pipeline de Investigación Profunda",
        "description": "El flujo de trabajo de dos etapas: generación de prompts y ejecución de investigación en paralelo.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Diagrama del pipeline de investigación profunda mostrando las etapas de generación de prompts y ejecución",
        "caption": "Flujo de trabajo de investigación profunda mostrando las etapas de generación de prompts y ejecución en paralelo"
      },
      "workflow": {
        "title": "Flujo de trabajo de investigación profunda",
        "description": "El flujo de trabajo de dos etapas: generación de prompts y ejecución de investigación en paralelo.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "caption": "Flujo de trabajo de investigación profunda mostrando todas las etapas de procesamiento"
      }
    }
  },
  "fileDiscovery": {
    "meta": {
      "title": "Flujo de trabajo de descubrimiento de archivos - PlanToCode",
      "description": "Guía técnica completa del flujo de trabajo de IA de 4 etapas que identifica y filtra archivos relevantes para la ejecución de tareas."
    },
    "apiUsage": {
      "heading": "Ejemplos de Uso de API",
      "monitoring": "Monitoreo de Progreso",
      "retrieving": "Recuperación de Resultados",
      "starting": "Iniciar un Flujo de Trabajo"
    },
    "architecture": {
      "caching": "Caché de resultados intermedios para optimización de rendimiento",
      "costTracking": "Seguimiento de costos y gestión de tiempos de espera para operaciones de IA",
      "distributed": "El sistema utiliza una arquitectura de trabajos distribuidos donde cada etapa se ejecuta como un trabajo en segundo plano independiente, permitiendo cancelación, lógica de reintentos y seguimiento detallado del progreso. Los eventos en tiempo real se publican a lo largo de la ejecución para proporcionar retroalimentación inmediata a la interfaz de usuario.",
      "errorHandling": "Manejo integral de errores con mecanismos de reintento automático",
      "eventDriven": "Informes de progreso basados en eventos con actualizaciones tipo WebSocket",
      "featuresHeading": "Características Clave de la Arquitectura:",
      "gitIntegration": "Integración con Git con respaldo a recorrido de directorios",
      "heading": "Arquitectura del Flujo de Trabajo",
      "overview": "El flujo de trabajo opera como un sistema de trabajos en segundo plano orquestados con cuatro etapas distintas que se ejecutan secuencialmente. Cada etapa se construye sobre la salida de la etapa anterior, refinando progresivamente la selección de archivos basándose en los requisitos de la tarea."
    },
    "category": "Guía Técnica",
    "configuration": {
      "exclusion": {
        "description": "Define directorios y patrones de archivos a excluir del proceso de descubrimiento.",
        "heading": "Patrones de Exclusión"
      },
      "heading": "Opciones de Configuración",
      "retry": {
        "description": "Establece el número máximo de reintentos para etapas fallidas con retroceso exponencial.",
        "heading": "Configuración de Reintentos"
      },
      "timeout": {
        "description": "Configura el tiempo máximo de ejecución para todo el flujo de trabajo o etapas individuales para evitar bloqueos indefinidos.",
        "heading": "Gestión de Tiempo de Espera"
      },
      "workflowConfig": "Configuración del Flujo de Trabajo"
    },
    "cta": {
      "description": "El flujo de trabajo de descubrimiento de archivos se ejecuta dentro del cliente de escritorio junto con la planificación de implementación y las sesiones de terminal.",
      "heading": "¿Necesitas la aplicación de escritorio?",
      "links": {
        "architecture": "Aprende sobre la arquitectura",
        "buildYourOwn": "Construye tu propio pipeline"
      }
    },
    "date": "2025-09-21",
    "description": "Guía técnica completa del flujo de trabajo de IA de 4 etapas que identifica y filtra archivos relevantes para la ejecución de tareas.",
    "errorHandling": {
      "commonIssues": {
        "binaryDetection": "Detección de archivos binarios: Utiliza tanto detección basada en extensión como en contenido para archivos binarios",
        "gitNotFound": "Repositorio Git no encontrado: Recurre al recorrido de directorios con exclusiones estándar",
        "heading": "Problemas Comunes",
        "networkTimeout": "Tiempos de espera de red: Reintento automático con retroceso exponencial para fallos transitorios",
        "tokenLimit": "Límite de tokens excedido: Implementa procesamiento por lotes inteligente y proporciona mensajes de error claros"
      },
      "debugging": {
        "description": "El flujo de trabajo proporciona registro completo, exportación de métricas de rendimiento y contexto de error detallado incluyendo información de etapa, intentos de reintento y datos intermedios para la resolución de problemas.",
        "heading": "Herramientas de Depuración"
      },
      "errorCategories": {
        "billing": "Errores de Facturación: Créditos insuficientes o fallos de pago con orientación procesable",
        "heading": "Categorías de Error",
        "system": "Errores del Sistema: Acceso al sistema de archivos, fallos de comandos git o restricciones de memoria",
        "validation": "Errores de Validación: ID de sesión inválido, descripción de tarea faltante o directorio de proyecto inválido",
        "workflow": "Errores de Flujo de Trabajo: Fallos específicos de etapa con contexto detallado y sugerencias de reintento"
      },
      "heading": "Manejo de Errores y Resolución de Problemas"
    },
    "integration": {
      "desktop": {
        "description": "El flujo de trabajo se integra perfectamente con la aplicación de escritorio a través de comandos Tauri, proporcionando acceso nativo al sistema de archivos y actualizaciones basadas en eventos a través de la clase WorkflowTracker.",
        "heading": "Aplicación de Escritorio"
      },
      "heading": "Patrones de Integración",
      "implementationPlans": {
        "description": "Los archivos seleccionados se alimentan automáticamente al panel de Planes de Implementación, asegurando que la generación de planes use el mismo contexto de archivos optimizado sin requerir la re-ejecución del flujo de trabajo de descubrimiento.",
        "heading": "Integración con Planes de Implementación"
      },
      "sessionManagement": {
        "description": "Los resultados del flujo de trabajo se almacenan en caché por sesión, permitiendo que múltiples operaciones dentro de la misma sesión reutilicen el contexto de archivos descubierto, mejorando significativamente el rendimiento para flujos de trabajo de desarrollo iterativo.",
        "heading": "Gestión de Sesiones"
      }
    },
    "intro": "PlanToCode identifica los archivos correctos antes de que planifiques o ejecutes comandos. El flujo de trabajo de 4 etapas reduce el alcance y mantiene el contexto ajustado.",
    "metaDescription": "Guía técnica completa del flujo de trabajo de IA de 4 etapas que identifica y filtra archivos relevantes para la ejecución de tareas.",
    "metaTitle": "Flujo de trabajo de descubrimiento de archivos - PlanToCode",
    "ogDescription": "Documentación técnica para la arquitectura del flujo de trabajo de descubrimiento de archivos de múltiples etapas.",
    "ogTitle": "Flujo de trabajo de descubrimiento de archivos - PlanToCode",
    "performance": {
      "costOptimization": {
        "description": "Las etapas de IA rastrean los costos reales de las respuestas de API, implementan procesamiento por lotes inteligente para minimizar el uso de tokens y proporcionan estimaciones de costos antes de la ejecución para ayudar a gestionar los gastos.",
        "heading": "Optimización de Costos"
      },
      "heading": "Consideraciones de Rendimiento",
      "memory": {
        "description": "El flujo de trabajo implementa gestión inteligente de memoria con caché de archivos (TTL de 30 segundos), procesamiento por lotes (100 archivos por lote) y limpieza automática de datos intermedios para prevenir el agotamiento de memoria.",
        "heading": "Gestión de Memoria"
      },
      "monitoring": {
        "description": "El seguimiento de rendimiento integrado monitorea tiempos de ejecución, uso de memoria, métricas de rendimiento y proporciona recomendaciones para optimización basadas en análisis de datos históricos.",
        "heading": "Monitoreo de Rendimiento"
      }
    },
    "readTime": "12 min",
    "stages": {
      "heading": "Proceso de Flujo de Trabajo de 4 Etapas",
      "stage1": {
        "description": "Utiliza IA para seleccionar inteligentemente los directorios raíz más relevantes de una lista de rutas candidatas basándose en la descripción de la tarea. El LLM analiza el directorio principal del proyecto y las raíces candidatas para determinar qué directorios tienen más probabilidad de contener archivos relevantes para la tarea.",
        "heading": "Etapa 1: Selección de Carpeta Raíz",
        "technical": "Detalles Técnicos: Recibe directorios raíz candidatos (hasta profundidad 2) y la descripción de la tarea. El LLM evalúa cada ruta contra el contexto de la tarea y devuelve una lista filtrada de directorios raíz que se buscarán en etapas posteriores.",
        "inputOutput": "Entrada/Salida: Recibe el array candidate_roots y task_description. Devuelve el array root_directories conteniendo los directorios seleccionados por IA más relevantes para la tarea."
      },
      "stage2": {
        "binaryDetection": "Detección Binaria: Filtra archivos con extensiones binarias (.jpg, .png, .pdf, .exe, etc.) y usa análisis de contenido para detectar archivos binarios por bytes nulos y proporciones de caracteres no imprimibles.",
        "description": "Utiliza IA para generar grupos de patrones regex inteligentes basados en la descripción de la tarea y la estructura del directorio. Cada grupo de patrones puede incluir patrones de ruta (positivos y negativos) y patrones de contenido. El procesador luego aplica estos patrones para filtrar archivos de cada directorio raíz seleccionado.",
        "gitIntegration": "Integración Git: Encuentra la raíz del repositorio git para cada directorio seleccionado y usa git_utils para obtener todos los archivos no ignorados, respetando las reglas de .gitignore mientras incluye tanto archivos rastreados como no rastreados.",
        "heading": "Etapa 2: Filtro de Archivos por Regex",
        "technical": "Detalles Técnicos: Genera un árbol de directorios para cada raíz, llama al LLM para producir patternGroups con campos path_pattern, content_pattern y negative_path_pattern. Usa fancy-regex para soporte de lookahead/lookbehind. Procesa raíces en paralelo con concurrencia configurable."
      },
      "stage3": {
        "aiProcessing": "Procesamiento IA: Utiliza modelos de lenguaje grandes para evaluar el contenido de archivos contra los requisitos de la tarea, con fragmentación inteligente basada en tamaños de archivo reales y estimaciones de tokens para gestionar las ventanas de contexto eficientemente.",
        "description": "Emplea modelos de IA para analizar el contenido de archivos y evaluar la relevancia para la descripción específica de la tarea. Esta etapa realiza análisis profundo del contenido leyendo los contenidos de archivos y haciendo que el LLM identifique qué archivos son más relevantes para la tarea.",
        "heading": "Etapa 3: Evaluación de Relevancia de Archivos por IA",
        "technical": "Detalles Técnicos: Estima tokens por archivo usando heurísticas conscientes del tipo de archivo (código ~3 caracteres/token, datos estructurados ~5 caracteres/token). Crea fragmentos conscientes del contenido para mantenerse bajo el umbral de 90k tokens. Procesa fragmentos en paralelo con streaming para evitar tiempos de espera. Valida todas las rutas sugeridas por el LLM contra el sistema de archivos."
      },
      "stage4": {
        "description": "Descubre archivos relevantes adicionales proporcionando al LLM los archivos previamente identificados y sus contenidos, junto con el árbol de directorios. La IA analiza imports, dependencias y estructura del proyecto para encontrar archivos relacionados que mejoren el contexto para la tarea.",
        "heading": "Etapa 4: Buscador de Rutas Extendido",
        "relationship": "Análisis de Relaciones: Lee el contenido de todos los archivos previamente identificados y lo proporciona al LLM junto con el árbol de directorios (limitado a las raíces seleccionadas si están disponibles). La IA identifica archivos adicionales basándose en imports, referencias y relaciones estructurales.",
        "technical": "Detalles Técnicos: Genera un árbol de directorios combinado para los directorios raíz seleccionados. Lee el contenido de todos los archivos initial_paths. Usa llamadas LLM en streaming para evitar tiempos de espera de Cloudflare. Valida las rutas descubiertas contra el sistema de archivos y normaliza a rutas relativas dentro del proyecto."
      }
    },
    "stateManagement": {
      "eventDriven": {
        "description": "El sistema publica eventos en tiempo real para cambios de estado del flujo de trabajo, completaciones de etapas y condiciones de error. Estos eventos permiten interfaces de usuario responsivas e integración con sistemas de monitoreo externos.",
        "heading": "Actualizaciones Basadas en Eventos"
      },
      "heading": "Gestión del Estado del Flujo de Trabajo",
      "intermediateData": {
        "description": "Cada etapa almacena su salida en un formato de datos intermedios estructurado, incluyendo contenido del árbol de directorios, patrones regex, resultados de listas de archivos filtrados. Estos datos son accesibles para depuración y pueden usarse para reanudar flujos de trabajo desde etapas específicas.",
        "heading": "Almacenamiento de Datos Intermedios"
      },
      "transitions": {
        "description": "El flujo de trabajo progresa a través de estados claramente definidos: Creado → Ejecutando → Pausado (opcional) → Completado/Fallido/Cancelado. Cada transición de estado publica eventos que pueden monitorearse para actualizaciones en tiempo real.",
        "heading": "Transiciones de Estado"
      }
    },
    "visuals": {
      "pipeline": {
        "title": "Pipeline de descubrimiento de archivos",
        "description": "El flujo de trabajo de 4 etapas: selección de carpeta raíz, filtrado por regex, evaluación de relevancia por IA y descubrimiento de rutas extendido.",
        "imageSrc": "/images/docs/file-discovery/pipeline.svg",
        "caption": "Pipeline de descubrimiento de archivos mostrando las 4 etapas",
        "imageAlt": "Diagrama mostrando el flujo de trabajo de descubrimiento de archivos de 4 etapas: Selección de Carpeta Raíz, Filtro de Archivos por Regex, Evaluación de Relevancia de Archivos por IA y Buscador de Rutas Extendido"
      }
    },
    "title": "Flujo de Trabajo de Descubrimiento de Archivos",
    "sqliteStorage": {
      "heading": "Almacenamiento SQLite",
      "description": "Todo el estado del flujo de trabajo, resultados intermedios y metadatos de trabajos se persisten en SQLite. Cada etapa almacena su salida en la tabla background_jobs, permitiendo reanudación del flujo de trabajo, depuración y pistas de auditoría. Los registros de trabajos incluyen uso de tokens, seguimiento de costos y plantillas de prompts del sistema para cada etapa de IA."
    }
  },
  "hub": {
    "ctaDescription": "Descarga PlanToCode para acceder al planificador de implementación, límites de modelos, sesiones de terminal y funciones de transcripción descritas en esta documentación.",
    "ctaHeading": "¿Listo para probar estos flujos de trabajo?",
    "ctaLinks": {
      "overview": "Comenzar con Visión General",
      "runtime": "Tutorial de Ejecución"
    },
    "description": "Aprende a planificar y entregar cambios de código con PlanToCode: descubrimiento de archivos, planes de implementación, sesiones de terminal, límites de modelos y voz.",
    "exploreHeading": "Explorar Documentación",
    "learnMore": "Más Información",
    "searchAriaLabel": "Buscar documentación",
    "searchPlaceholder": "Buscar documentación...",
    "searchShortcut": "⌘K",
    "title": "Documentación de PlanToCode"
  },
  "onThisPage": {
    "title": "En esta página"
  },
  "sidebar": {
    "title": "Documentación"
  },
  "sections": {
    "architecture": {
      "title": "Arquitectura e Internos"
    },
    "inputs": {
      "title": "Entradas y Captura"
    },
    "planning": {
      "title": "Pipeline de Planificación"
    },
    "execution": {
      "title": "Ejecución y Automatización"
    },
    "research": {
      "title": "Investigación y Modelos"
    },
    "platform": {
      "title": "Construcción y Despliegue"
    }
  },
  "items": {
    "overview": {
      "title": "Visión General del Sistema",
      "description": "Comienza aquí: qué hace el sistema, cómo funciona el ciclo principal y dónde vive cada componente."
    },
    "runtime-walkthrough": {
      "title": "Tutorial de Ejecución",
      "description": "Línea de tiempo de extremo a extremo de lo que sucede desde la entrada de la tarea hasta la ejecución."
    },
    "architecture": {
      "title": "Arquitectura del Sistema",
      "description": "Cómo encajan el shell de escritorio, los servicios Rust, las APIs del servidor y las capas de persistencia."
    },
    "desktop-app": {
      "title": "Internos de la Aplicación de Escritorio",
      "description": "Shell Tauri v2, capa de comandos Rust, sesiones PTY y gestión del estado de la UI."
    },
    "server-api": {
      "title": "API del Servidor y Proxy LLM",
      "description": "Autenticación, enrutamiento de proveedores, configuración de modelos y endpoints WebSocket."
    },
    "mobile-ios": {
      "title": "Arquitectura del Cliente iOS",
      "description": "Flujos de trabajo Swift, flujo de inicio de sesión Auth0 y gestión de sesiones de enlace de dispositivo."
    },
    "background-jobs": {
      "title": "Trabajos en Segundo Plano y Orquestación",
      "description": "Registros de trabajos, orquestación de flujos de trabajo, procesadores y streaming de eventos."
    },
    "data-model": {
      "title": "Modelo de Datos y Almacenamiento",
      "description": "Entidades SQLite, relaciones y cómo se rehidrata el estado."
    },
    "decisions-tradeoffs": {
      "title": "Decisiones Técnicas y Compromisos",
      "description": "Por qué se eligieron Tauri, SQLite y un proxy LLM dedicado y cuáles son sus costos."
    },
    "build-your-own": {
      "title": "Construye Tu Propio Pipeline",
      "description": "Guía conceptual para diseñar flujos de trabajo de descubrimiento de archivos y generación de planes."
    },
    "meeting-ingestion": {
      "title": "Ingesta de Reuniones y Grabaciones",
      "description": "Cómo las grabaciones se convierten en entradas de tareas estructuradas y artefactos."
    },
    "video-analysis": {
      "title": "Análisis de Video",
      "description": "Muestreo de fotogramas, prompts y artefactos de análisis de grabaciones."
    },
    "voice-transcription": {
      "title": "Transcripción de Voz",
      "description": "Ciclo de vida de grabación, configuración consciente del proyecto y gestión de dispositivos."
    },
    "text-improvement": {
      "title": "Mejora de Texto",
      "description": "Popover de selección, cola de trabajos e integraciones para limpieza de prompts."
    },
    "file-discovery": {
      "title": "Flujo de Trabajo de Descubrimiento de Archivos",
      "description": "Flujo de trabajo en segundo plano que recopila rutas relevantes para cada tarea."
    },
    "implementation-plans": {
      "title": "Planes de Implementación",
      "description": "Cómo los planes se transmiten al visor Monaco y permanecen vinculados al historial de planes."
    },
    "merge-instructions": {
      "title": "Instrucciones de Fusión",
      "description": "Cómo se fusionan múltiples borradores de planes usando planes fuente etiquetados con XML y guía del usuario."
    },
    "prompt-types": {
      "title": "Tipos de Prompts y Plantillas",
      "description": "Catálogo de tipos de trabajos impulsados por prompts y ensamblaje de plantillas."
    },
    "terminal-sessions": {
      "title": "Sesiones de Terminal",
      "description": "Sesiones PTY persistentes, detección de CLI y comportamiento de recuperación."
    },
    "copy-buttons": {
      "title": "Botones de Copiado",
      "description": "Transferencia de plantillas desde planes a terminales y herramientas externas."
    },
    "deep-research": {
      "title": "Investigación Profunda y Búsqueda Web",
      "description": "Flujo de trabajo de búsqueda web, integración de API, optimización de consultas e integración con flujos de trabajo de desarrollo."
    },
    "provider-routing": {
      "title": "Enrutamiento de Proveedores y Streaming",
      "description": "Cómo se normalizan, transmiten y rastrean las solicitudes de proveedores."
    },
    "model-configuration": {
      "title": "Configuración de Modelos",
      "description": "Modelos permitidos por tarea y límites de tokens en el selector."
    },
    "server-setup": {
      "title": "Configuración de Servidor Dedicado",
      "description": "Infraestructura basada en Ansible: endurecimiento base, despliegue de aplicaciones y secretos gestionados con vault."
    },
    "tauri-v2": {
      "title": "Guía de Desarrollo Tauri v2",
      "description": "Estructura del proyecto, comandos y permisos basados en capacidades para Tauri v2."
    },
    "distribution-macos": {
      "title": "Distribución macOS",
      "description": "Firma, notarización, empaquetado DMG y artefactos de actualización."
    },
    "distribution-windows": {
      "title": "Distribución Windows y Store",
      "description": "Compilaciones NSIS, empaquetado MSIX y envío a Microsoft Store."
    }
  },
  "implementationPlans": {
    "meta": {
      "title": "Planes de Implementación - Revisar Cambios de IA",
      "description": "Guía para la planificación de implementación con IA. Genera, revisa y aprueba planes archivo por archivo antes de la ejecución. Previene duplicados y rutas incorrectas."
    },
    "category": "Guía del Producto",
    "context": {
      "audit": "Todos los metadatos persisten con el plan para propósitos de auditoría. Los equipos corporativos pueden rastrear qué partes interesadas revisaron qué planes, qué modificaciones se solicitaron y la cadena de razonamiento completa desde la descripción inicial de la tarea a través del descubrimiento de archivos hasta el plan final aprobado.",
      "heading": "Contexto y Metadatos para Gobernanza Corporativa",
      "storage": "El panel almacena qué raíces de repositorio se seleccionaron durante el flujo de trabajo de descubrimiento de archivos para que las acciones de seguimiento reutilicen el mismo alcance. También registra metadatos específicos del plan, como el directorio del proyecto y cualquier contenido de prompt preparado, para que los prompts posteriores puedan generarse o copiarse sin recalcular el flujo de trabajo.",
      "tokenEstimation": "La estimación de tokens se ejecuta antes de copiar los prompts. El panel llama al comando de estimación de tokens con el directorio del proyecto, los archivos seleccionados y el modelo elegido actualmente, mostrando tanto los totales de prompt del sistema como del usuario para que los equipos se mantengan bajo los límites del modelo."
    },
    "cta": {
      "claudeCodeLink": "Ver flujo de trabajo del modo plan de Claude",
      "codexLink": "Ver flujo de trabajo del modo plan de Codex",
      "cursorLink": "Ver flujo de trabajo del modo plan de Cursor",
      "description": "Los planes de implementación con humano en el ciclo están disponibles dentro de la aplicación de escritorio PlanToCode. Descarga la versión para tu plataforma para experimentar el desarrollo asistido por IA seguro y gobernado.",
      "heading": "¿Listo para adoptar agentes de codificación IA de forma segura?",
      "links": {
        "architecture": "Arquitectura del Sistema",
        "decisions": "Decisiones y Compromisos",
        "buildYourOwn": "Construye Tu Propio Pipeline",
        "fileDiscovery": "Flujo de Trabajo de Descubrimiento de Archivos"
      }
    },
    "date": "2025-09-19",
    "description": "Cómo PlanToCode permite la adopción confiada de agentes de codificación IA a través de gobernanza con humano en el ciclo, planes granulares archivo por archivo y flujos de trabajo de revisión completos.",
    "fileGranularity": {
      "created": "Creados (con rutas de archivo completas y estructura de contenido inicial)",
      "declaredFiles": "Cada paso en un plan declara explícitamente qué archivos serán:",
      "deleted": "Eliminados (con justificación y análisis de dependencias)",
      "heading": "Granularidad Archivo por Archivo",
      "impact": "Este nivel de detalle hace que el impacto de los cambios propuestos sea cristalino antes de tocar cualquier código. Los líderes de equipo pueden identificar inmediatamente si se modificará código legado crítico, si se proponen cambios que rompen compatibilidad, o si el plan toca archivos que requieren escrutinio adicional.",
      "intro": "Los planes de implementación utilizan una estructura altamente granular que descompone las tareas de desarrollo archivo por archivo, con rutas de archivo exactas correspondientes a la estructura del repositorio del proyecto. Esta granularidad es fundamental para prevenir regresiones y permitir la adopción confiada de agentes de codificación IA en entornos corporativos.",
      "modified": "Modificados (con rangos de líneas específicos y cambios descritos)",
      "referenced": "Referenciados (para contexto pero no modificados)",
      "transmission": "El enfoque archivo por archivo también permite la transmisión precisa de planes aprobados a agentes de codificación. En lugar de instrucciones vagas como \"actualizar el sistema de autenticación\", los agentes reciben especificaciones exactas: \"modificar src/auth/session_manager.rs líneas 45-67 para agregar rotación de tokens, crear src/auth/token_store.rs con la siguiente estructura...\""
    },
    "hitl": {
      "approve": "Aprobar:",
      "approveDesc": "Solo después de la aprobación explícita los planes pueden transmitirse de forma segura al agente de codificación elegido o al desarrollador de software asignado para su ejecución.",
      "conclusion": "Este flujo de trabajo asegura que todos los esfuerzos de desarrollo se alineen con los requisitos del producto corporativo, los flujos de trabajo del equipo y los objetivos comerciales. No ocurren cambios de código sin aprobación humana explícita.",
      "edit": "Editar:",
      "editDesc": "Las partes interesadas pueden modificar pasos directamente, ajustar enfoques, agregar restricciones o eliminar operaciones riesgosas usando las funciones de edición de VS Code.",
      "heading": "Gobernanza con Humano en el Ciclo",
      "intro": "PlanToCode implementa un flujo de trabajo completo de humano en el ciclo (HITL) que asegura que los líderes de equipo y las partes interesadas retengan control total sobre cada aspecto de los planes de implementación generados por IA. Este modelo de gobernanza previene las regresiones, errores y modificaciones no intencionadas que pueden ocurrir cuando los agentes de codificación IA operan de forma autónoma.",
      "reject": "Rechazar:",
      "rejectDesc": "Los planes que no cumplen los requisitos pueden rechazarse completamente, con pistas de auditoría completas mantenidas para cumplimiento y aprendizaje.",
      "requestChanges": "Solicitar Cambios:",
      "requestChangesDesc": "Los equipos pueden solicitar modificaciones del sistema de IA, generando enfoques alternativos o fusionando múltiples planes con instrucciones personalizadas.",
      "review": "Revisar:",
      "reviewDesc": "Los planes se abren en el editor Monaco donde los revisores pueden examinar cada cambio propuesto con resaltado de sintaxis completo y herramientas de edición profesionales.",
      "workflow": "Cada plan debe pasar por un flujo de trabajo de revisión estructurado antes de que comiencen las modificaciones de código:"
    },
    "intro": "Revisa y aprueba cada plan antes de la ejecución. La gobernanza con humano en el ciclo con granularidad archivo por archivo asegura que los cambios generados por IA se alineen con los requisitos corporativos y los flujos de trabajo del equipo.",
    "metaDescription": "Guía para la planificación de implementación con IA. Genera, revisa y aprueba planes archivo por archivo antes de la ejecución. Previene duplicados y rutas incorrectas.",
    "metaTitle": "Planes de Implementación - Revisar Cambios de IA",
    "multiplePlans": {
      "description": "Los planes pueden fusionarse, eliminarse o reabrirse más tarde. El panel mantiene una lista de identificadores de planes seleccionados, gestiona un modal dedicado para la salida del terminal vinculada a un plan y expone ayudantes de navegación para que los revisores puedan paginar a través de planes anteriores sin cerrar el visor. El acceso al terminal, los controles de copia de prompts y las instrucciones de fusión comparten el mismo identificador de trabajo para que el historial de auditoría se mantenga consistente.",
      "heading": "Trabajando con múltiples planes"
    },
    "ogDescription": "Comprende cómo la gobernanza con humano en el ciclo y los flujos de trabajo de revisión archivo por archivo aseguran el desarrollo de IA seguro con control completo sobre las modificaciones de código.",
    "ogTitle": "Planes de Implementación con Humano en el Ciclo en PlanToCode",
    "plansOrigin": {
      "description": "Cada plan corresponde a un trabajo en segundo plano en la sesión actual. El panel se suscribe a los datos del plan, rastrea qué plan está abierto actualmente y expone navegación entre trabajos anteriores y más recientes. Este comportamiento vive dentro de {code} y el componente del panel circundante.",
      "heading": "De dónde vienen los planes",
      "processor": "ImplementationPlanProcessor maneja la generación de planes. Lee archivos relevantes, opcionalmente genera un árbol de directorios basado en directorios raíz seleccionados y ensambla un prompt unificado para el LLM.",
      "storage": "Las respuestas de planes se almacenan en la tabla de trabajos con metadatos incluyendo planTitle, summary, sessionName y uso de tokens. La respuesta cruda del LLM se preserva para auditoría.",
      "streaming": "Los planes se transmiten a través del LlmTaskRunner con eventos de progreso en tiempo real. Las advertencias de tokens se registran para prompts que exceden 100k tokens pero el procesamiento continúa con el contenido completo."
    },
    "readTime": "6 min",
    "reviewingPlans": {
      "description": "El contenido del plan se renderiza a través del {code} compartido, que envuelve Monaco Editor. El visor detecta automáticamente lenguajes comunes, soporta acciones de copiar al portapapeles, virtualiza planes muy grandes y ofrece métricas opcionales como conteos de caracteres y resaltado consciente de la sintaxis.",
      "heading": "Revisando planes con Monaco",
      "opening": "Cuando se abre un plan, el panel resuelve el plan activo por identificador de trabajo, pasa el contenido a Monaco y permite a los revisores moverse entre trabajos vecinos sin perder el modal actualmente abierto."
    },
    "visuals": {
      "structure": {
        "title": "Estructura del plan de implementación",
        "description": "Formato XML para planes de implementación con granularidad archivo por archivo y metadatos.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "caption": "Estructura del plan mostrando pasos, archivos y seguimiento de dependencias"
      }
    },
    "title": "Planes de Implementación",
    "planProcessor": {
      "heading": "Pipeline de Generación de Planes",
      "description": "El ImplementationPlanProcessor orquesta la generación de planes cargando contenidos de archivos, construyendo contexto y transmitiendo resultados a través del ejecutor de tareas LLM.",
      "inputs": "Contexto de sesión, descripción de tarea, archivos relevantes seleccionados, árbol de directorios opcional (configurable a través de la bandera include_project_structure) y bandera de búsqueda web para investigación externa.",
      "prompt": "Usa prompt_utils::build_unified_prompt para combinar descripción de tarea, contenidos completos de archivos (sin truncamiento) y árbol de directorios en un formato específico del modelo con conteos de tokens estimados.",
      "output": "Respuesta cruda del LLM almacenada como JobResultData::Text. Los metadatos incluyen planTitle, summary, uso de tokens, estadísticas de caché y costo real.",
      "display": "Las respuestas se transmiten a la UI a través de eventos de progreso. Los planes se renderizan en un VirtualizedCodeViewer basado en Monaco que soporta resaltado de sintaxis y acciones de copiado."
    },
    "schema": {
      "heading": "Estructura de Datos del Plan",
      "description": "Los planes de implementación se almacenan como respuestas crudas del LLM con metadatos asociados. El texto de respuesta se preserva exactamente como se generó, mientras que los metadatos estructurados rastrean el contexto del plan y el uso.",
      "fieldsHeading": "Campos de Metadatos",
      "fields": [
        "planTitle - Título generado o proporcionado por el usuario para el plan",
        "summary - Resumen legible por humanos del plan",
        "sessionName - Nombre de la sesión que generó el plan",
        "isStructured - Siempre true para planes completados",
        "isStreaming - False para planes completados (true durante la generación)",
        "planData - Contiene agent_instructions (opcional) y array de steps"
      ],
      "exampleHeading": "Ejemplo de Metadatos",
      "example": "{\n  \"planTitle\": \"Authentication System Refactor\",\n  \"summary\": \"Implementation plan generated\",\n  \"sessionName\": \"my-project\",\n  \"isStructured\": true,\n  \"isStreaming\": false,\n  \"planData\": {\n    \"agent_instructions\": null,\n    \"steps\": []\n  }\n}"
    }
  },
  "modelConfiguration": {
    "meta": {
      "title": "Configuración de modelos y límites - PlanToCode",
      "description": "Cómo PlanToCode te permite elegir modelos permitidos por tarea y mantiene los prompts dentro de la ventana de contexto activa."
    },
    "category": "Guía del Producto",
    "date": "2025-09-20",
    "description": "Listas de modelos a nivel de tarea, controles de selector y límites de tokens en el cliente de escritorio.",
    "intro": "PlanToCode trata la selección de modelos como una decisión a nivel de tarea. Cada flujo de trabajo viene con un modelo predeterminado y una lista de permitidos, y el cliente de escritorio expone estas opciones a través de un selector que previene enviar prompts que excedan la ventana de contexto activa.",
    "metaDescription": "Cómo PlanToCode te permite elegir modelos permitidos por tarea y mantiene los prompts dentro de la ventana de contexto activa.",
    "metaTitle": "Configuración de modelos y límites - PlanToCode",
    "ogDescription": "Aprende cómo funcionan juntos los ajustes de modelo a nivel de tarea, los selectores y las estimaciones de tokens.",
    "ogTitle": "Configuración de modelos y límites - PlanToCode",
    "promptEstimation": {
      "description": "Los conteos de tokens se calculan a través del comando de estimación de tokens. El panel envía el id de sesión, descripción de tarea, archivos relevantes y el modelo seleccionado para que el backend pueda devolver valores de tokens del sistema, usuario y totales. Estos números alimentan directamente los límites del selector y permiten a los equipos detectar prompts que exceden el límite antes de copiarlos a otra herramienta.",
      "heading": "Estimación de prompts"
    },
    "readTime": "5 min",
    "selectorToggle": {
      "description": "El panel de Planes de Implementación renderiza los modelos permitidos con el {code}. El selector muestra cada modelo permitido, rastrea la selección activa y verifica si el prompt estimado más los tokens de salida planificados caben dentro de la ventana de contexto anunciada del modelo antes de permitir un cambio.",
      "guardrails": "Si un modelo no puede soportar el requisito total de tokens, el selector deshabilita el botón y muestra un tooltip con el exceso calculado, manteniendo a los revisores dentro de límites seguros antes de enviar trabajo a un agente.",
      "heading": "Selector en el cliente"
    },
    "taskDefaults": {
      "description": "Los modelos predeterminados y las alternativas permitidas se almacenan del lado del servidor en la configuración de la aplicación. Cada tipo de tarea - como planes de implementación, fusiones, generación de prompts o transcripción de voz - define un modelo preferido, una lista de opciones permitidas y límites de tokens que la aplicación de escritorio lee en tiempo de ejecución.",
      "heading": "Valores predeterminados por tarea"
    },
    "title": "Configuración de Modelos"
  },
  "terminalSessions": {
    "meta": {
      "title": "Sesiones de terminal - PlanToCode",
      "description": "Guía técnica de la implementación de terminal PTY en PlanToCode. Aprende cómo persisten las sesiones, cómo funciona la detección de inactividad del agente y los mecanismos de recuperación."
    },
    "attentionDetection": {
      "conclusion": "Este enfoque te ayuda a rastrear cuándo los agentes han terminado tareas o necesitan orientación, sin intentar adivinar por qué se detuvieron. Los indicadores de atención se limpian automáticamente cuando se recibe nueva salida.",
      "heading": "Detección de atención del agente",
      "intro": "El terminal monitorea la actividad del agente a través de un sistema de detección de inactividad de dos niveles. Cuando un agente deja de producir salida, el sistema te alerta progresivamente para que revises lo que ha sucedido:",
      "level1": "Nivel 1 (30 segundos): \"Agente inactivo - puede haber completado la tarea\" con indicador amarillo",
      "level2": "Nivel 2 (2 minutos): \"El agente requiere atención - revisa el terminal\" con indicador rojo y notificación de escritorio"
    },
    "category": "Guía del Producto",
    "date": "2025-09-22",
    "dependencyChecks": {
      "description": "Antes de lanzar comandos, el terminal verifica la presencia de herramientas CLI soportadas como claude, cursor, codex y gemini. El mismo comando también reporta el shell predeterminado para que los usuarios sepan qué entorno se ejecutará. Esto previene lanzar una sesión que no puede encontrar el binario requerido.",
      "heading": "Verificaciones de dependencias"
    },
    "description": "Sesiones PTY persistentes, detección de atención del agente y comportamiento de recuperación en el terminal de Planes de Implementación.",
    "intro": "Ejecuta comandos en un PTY persistente con verificaciones de salud y registro. La transcripción de voz está disponible cuando la necesites.",
    "lifecycle": {
      "description": "Cuando se abre un terminal, el componente de UI crea una sesión PTY y transmite la salida a través de una vista con búfer. El componente muestra el estado de conexión inmediato, reenvía las pulsaciones de teclas al PTY y reintenta automáticamente si la sesión falla. Los metadatos de sesión se almacenan en SQLite con marcas de tiempo, códigos de salida, directorios de trabajo y el log de salida completo para que los reinicios puedan resumir el contexto anterior.",
      "heading": "Ciclo de vida de la sesión"
    },
    "metaDescription": "Guía técnica de la implementación de terminal PTY en PlanToCode. Aprende cómo persisten las sesiones, cómo funciona la detección de inactividad del agente y los mecanismos de recuperación.",
    "metaTitle": "Sesiones de terminal - PlanToCode",
    "ogDescription": "Comprende la persistencia de sesiones, la detección de atención del agente y la recuperación en el terminal del plan.",
    "ogTitle": "Sesiones de terminal - PlanToCode",
    "readTime": "6 min",
    "title": "Sesiones de Terminal",
    "voiceRecovery": {
      "heading": "Transcripción de voz y recuperación",
      "recovery": "Si una sesión PTY se desconecta, la superficie del terminal muestra controles de recuperación y reintenta la conexión con retroceso exponencial. Las verificaciones de salud continúan monitoreando el estado de la sesión y proporcionan acciones de recuperación automáticas cuando se detectan problemas de conexión.",
      "voice": "Dentro del modal del terminal, la transcripción de voz puede capturar el habla y pegarlo en el área de entrada del terminal. El hook de grabación busca la configuración de transcripción a nivel de proyecto, rastrea el estado de grabación y transmite el texto reconocido a la sesión del plan activa."
    }
  },
  "copyButtons": {
    "meta": {
      "title": "Botones de Copiado - PlanToCode",
      "description": "Cómo los botones de copiado basados en plantillas resuelven marcadores de posición contra planes y los entregan a terminales o portapapeles para ejecución por agentes."
    },
    "category": "Ejecución",
    "date": "2025-09-23",
    "readTime": "10 min",
    "title": "Botones de Copiado",
    "description": "Transferencia basada en plantillas desde planes de implementación a terminales PTY y herramientas externas.",
    "intro": "Los botones de copiado conectan la planificación y la ejecución resolviendo marcadores de posición de plantillas contra el plan activo, luego entregando el resultado a sesiones PTY o al portapapeles del sistema. Cada acción está vinculada a metadatos del trabajo para pistas de auditoría completas, permitiendo a los equipos rastrear exactamente qué se envió a los agentes.",
    "metaTitle": "Botones de copiado - PlanToCode",
    "metaDescription": "Cómo los botones de copiado basados en plantillas resuelven marcadores de posición contra planes y los entregan a terminales o portapapeles para ejecución por agentes.",
    "ogTitle": "Botones de copiado - PlanToCode",
    "ogDescription": "Guía técnica de plantillas de botones de copiado, resolución de marcadores de posición y transferencia a terminal.",
    "visuals": {
      "templateFlow": {
        "title": "Flujo de resolución de plantillas",
        "description": "Este diagrama muestra el pipeline de ejecución del botón de copiado. Etapa 1 'Clic en Botón': El usuario hace clic en un botón de copiado en el visor de planes o en el encabezado del terminal. La configuración del botón contiene una etiqueta, cadena de plantilla y destino (terminal o portapapeles). Etapa 2 'Extracción de Marcadores': El procesador de plantillas busca patrones de doble llave como {{IMPLEMENTATION_PLAN}}, {{STEP_CONTENT}}, {{TASK_DESCRIPTION}}. Etapa 3 'Resolución de Contexto': El resolutor consulta los metadatos del trabajo para el contenido del plan, luego el estado de la sesión para la descripción de la tarea y archivos seleccionados. Los marcadores faltantes se preservan en la salida para depuración. Etapa 4 'Entrega al Destino': Para destinos de terminal, el contenido se escribe al búfer de entrada PTY a través de master.take_writer(). Para destinos de portapapeles, el contenido se copia a través de la API de portapapeles de Tauri. Una notificación toast confirma la acción con vista previa del contenido.",
        "imageSrc": "/images/docs/copy-buttons/templates.svg",
        "imageAlt": "Flujo mostrando la resolución de plantillas del botón de copiado",
        "caption": "Marcador de posición para un diagrama de flujo de resolución de plantillas."
      }
    },
    "templateConfiguration": {
      "heading": "Fuentes de Configuración de Plantillas",
      "description": "Las plantillas de botones de copiado siguen un modelo de configuración en capas. Los valores predeterminados del servidor proporcionan plantillas base, las anulaciones a nivel de proyecto personalizan para flujos de trabajo del equipo, y las configuraciones específicas de tareas manejan escenarios únicos.",
      "serverDefaults": {
        "heading": "Valores Predeterminados del Servidor",
        "description": "Plantillas compartidas desde /api/config/desktop-runtime-config. Incluye etiquetas de botones, cadenas de plantillas, destino (terminal o portapapeles) y condiciones de visibilidad."
      },
      "projectOverrides": {
        "heading": "Anulaciones de Proyecto",
        "description": "Plantillas almacenadas en la tabla project_settings de SQLite. Fusionadas en tiempo de ejecución con los valores predeterminados del servidor para personalizar según los estándares del equipo."
      },
      "taskSpecific": {
        "heading": "Específicas de Tarea",
        "description": "Plantillas por task_model_config para flujos de trabajo especializados. Permite patrones de transferencia personalizados sin modificar la configuración global."
      }
    },
    "placeholderResolution": {
      "heading": "Resolución de Marcadores de Posición",
      "description": "Las plantillas usan marcadores de posición de doble llave que se resuelven contra el plan activo y el contexto de sesión en el momento del clic. Los marcadores principales son {{IMPLEMENTATION_PLAN}} y {{TASK_DESCRIPTION}}.",
      "placeholdersHeading": "Marcadores Disponibles",
      "placeholders": [
        {
          "placeholder": "{{IMPLEMENTATION_PLAN}}",
          "description": "Contenido completo del plan de implementación tal como fue generado por el LLM"
        },
        {
          "placeholder": "{{TASK_DESCRIPTION}}",
          "description": "La descripción de la tarea de la sesión actual"
        }
      ],
      "resolutionOrder": "Orden de resolución: Metadatos del trabajo primero, luego contenido del plan, luego contexto de sesión. Los marcadores no definidos se preservan en la salida para depuración.",
      "exampleTemplate": "Ejemplo de plantilla:\n\n{{IMPLEMENTATION_PLAN}}\n\nComprende el plan de implementación anterior a fondo. Analiza la arquitectura, los flujos de datos y la secuencia de eventos.\n\nTarea: {{TASK_DESCRIPTION}}"
    },
    "processingPipeline": {
      "heading": "Pipeline de Procesamiento de Plantillas",
      "description": "Cuando se hace clic en un botón, el procesador de plantillas ejecuta un pipeline de múltiples pasos: extracción de marcadores, búsqueda de contexto, sustitución de valores y formateo de salida.",
      "steps": [
        {
          "number": 1,
          "title": "Extraer Marcadores",
          "description": "Escaneo regex para patrones {{...}} en la cadena de plantilla"
        },
        {
          "number": 2,
          "title": "Buscar Contexto",
          "description": "Consultar metadatos del trabajo, contenido del plan y estado de sesión para valores"
        },
        {
          "number": 3,
          "title": "Sustituir Valores",
          "description": "Reemplazar marcadores con valores resueltos, preservando el formato"
        },
        {
          "number": 4,
          "title": "Formatear Salida",
          "description": "Aplicar escape específico del destino (shell para terminal, plano para portapapeles)"
        }
      ],
      "chunking": {
        "heading": "Fragmentación de Planes Grandes",
        "description": "Los planes que exceden 100KB se fragmentan automáticamente en segmentos secuenciales con límites claros para evitar sobrecargar los búferes del terminal o los límites del portapapeles. Cada fragmento se prefija con su posición (ej., '[Parte 1/3]')."
      }
    },
    "terminalHandoff": {
      "heading": "Transferencia a Terminal PTY",
      "description": "Los botones configurados para transferencia a terminal escriben directamente al búfer de entrada de la sesión PTY. La plantilla resuelta aparece como si fuera escrita por el usuario, activando la ejecución del agente inmediatamente.",
      "detailsHeading": "Detalles de Transferencia",
      "details": [
        "Contenido escrito a través de master.take_writer() al búfer de entrada PTY",
        "Soporta entrada multilínea y secuencias de escape",
        "Contenido grande fragmentado en segmentos de 4KB para evitar desbordamiento de búfer",
        "La UI muestra los primeros 100 caracteres como vista previa de confirmación"
      ],
      "codeExample": "// Terminal handoff implementation\nasync fn handoff_to_terminal(\n    session_id: &str,\n    content: &str,\n    template_id: &str,\n) -> Result<HandoffResult> {\n    // Get PTY writer for session\n    let writer = terminal_manager.get_writer(session_id)?;\n\n    // Write content to PTY input buffer\n    writer.write_all(content.as_bytes()).await?;\n\n    // Log the action for audit\n    copy_button_actions.insert(CopyButtonAction {\n        session_id: session_id.to_string(),\n        template_id: template_id.to_string(),\n        content_hash: sha256(content),\n        created_at: Utc::now(),\n    })?;\n\n    Ok(HandoffResult::Terminal { session_id })\n}"
    },
    "clipboardHandoff": {
      "heading": "Transferencia al Portapapeles",
      "description": "Los botones configurados para portapapeles copian la plantilla resuelta al portapapeles del sistema usando la API de portapapeles de Tauri. Esto permite la transferencia a herramientas externas como terminales de IDE o agentes basados en web.",
      "crossPlatform": {
        "heading": "API Multiplataforma",
        "description": "Usa tauri::api::clipboard::set_text() para acceso consistente al portapapeles en macOS, Windows y Linux."
      },
      "feedback": {
        "heading": "Retroalimentación al Usuario",
        "description": "Una notificación toast confirma la copia con una vista previa del contenido y estimación de conteo de tokens para el modelo objetivo."
      }
    },
    "defaultButtons": {
      "heading": "Botones de Copiado Predeterminados",
      "description": "PlanToCode viene con varios botones de copiado predeterminados que cubren flujos de trabajo comunes. Estos pueden personalizarse o extenderse a través de la configuración del proyecto.",
      "buttonsHeading": "Botones Integrados",
      "buttons": [
        {
          "id": "parallel-agents",
          "label": "Agentes de Codificación Claude Paralelos",
          "description": "Lanza agentes de codificación Claude paralelos que se ejecutan simultáneamente. Cada agente recibe instrucciones explícitas sobre sus responsabilidades. Incluye instrucciones para eliminar características obsoletas completamente."
        },
        {
          "id": "investigate-results",
          "label": "Investigar Resultados",
          "description": "Revisa los resultados de los agentes lanzados y verifica la implementación completa. Realiza auto-verificación leyendo archivos modificados y analizando cambios sin lanzar agentes adicionales."
        },
        {
          "id": "task-only",
          "label": "Tarea",
          "description": "Copia solo la descripción de la tarea para contexto. Usa el marcador {{TASK_DESCRIPTION}}."
        },
        {
          "id": "task-and-plan",
          "label": "Tarea + Plan",
          "description": "Combina la descripción de la tarea y el plan de implementación. Útil para proporcionar contexto completo cuando el agente necesita tanto el objetivo como la estrategia de ejecución."
        },
        {
          "id": "plan-only",
          "label": "Plan",
          "description": "Copia solo el contenido del plan de implementación. Mejor para agentes que ya tienen contexto de la tarea y solo necesitan instrucciones de ejecución."
        }
      ]
    },
    "customization": {
      "heading": "Personalización de Botones de Copiado",
      "description": "Los botones de copiado pueden personalizarse a múltiples niveles: valores predeterminados globales, anulaciones a nivel de proyecto y configuraciones por tarea.",
      "globalDefaults": {
        "heading": "Valores Predeterminados Globales",
        "description": "La configuración del lado del servidor en /api/config/desktop-runtime-config define el conjunto base de botones de copiado. Estos se cargan cuando la aplicación de escritorio inicia y se almacenan en caché para uso offline."
      },
      "projectSettings": {
        "heading": "Personalización a Nivel de Proyecto",
        "description": "Cada proyecto puede anular los botones predeterminados a través del panel de Configuración. Los botones específicos del proyecto se almacenan en SQLite y se fusionan con los valores predeterminados del servidor en tiempo de ejecución."
      },
      "taskSettings": {
        "heading": "Configuración a Nivel de Tarea",
        "description": "Las tareas individuales pueden tener sus propias configuraciones de botones de copiado. Esto permite diferentes conjuntos de botones para planes de implementación, revisiones de código o tareas de documentación."
      },
      "editorDescription": "El editor de botones de copiado en Configuración permite reordenamiento por arrastrar y soltar, edición de etiquetas en línea y modificación del contenido de plantillas. Los cambios se retardan y persisten automáticamente."
    },
    "uiIntegration": {
      "heading": "Integración de UI y Seguridad",
      "description": "Los botones de copiado aparecen en visores de planes y encabezados de terminal. Cada botón muestra un popover de vista previa con el contenido resuelto y estimación de tokens antes de la ejecución.",
      "tokenEstimation": {
        "heading": "Estimación de Tokens",
        "description": "Las estimaciones de tokens ayudan a los revisores a validar que el prompt cabe dentro de la ventana de contexto del modelo objetivo antes de la transferencia. Se muestra junto a la vista previa."
      },
      "previewModal": {
        "heading": "Modal de Vista Previa Completa",
        "description": "Hacer clic en el icono de vista previa abre un modal con la plantilla resuelta completa, resaltado de sintaxis y vista de diferencias si la plantilla ha cambiado desde el último uso."
      },
      "disabledState": {
        "heading": "Estado Deshabilitado",
        "description": "Los botones se deshabilitan cuando falta el contexto requerido (ej., sin plan activo, sesión faltante). Los tooltips explican qué contexto se necesita para habilitar el botón."
      }
    },
    "auditTrail": {
      "heading": "Metadatos del Trabajo y Pista de Auditoría",
      "description": "Cada acción de botón de copiado está vinculada a metadatos del trabajo para trazabilidad completa. El registro de auditoría incluye el plan fuente, sesión objetivo, hash del contenido resuelto y contexto del usuario.",
      "schemaHeading": "Esquema de Auditoría",
      "schema": "-- copy_button_actions table schema\nCREATE TABLE copy_button_actions (\n    action_id    TEXT PRIMARY KEY,\n    plan_id      TEXT NOT NULL REFERENCES implementation_plans(id),\n    job_id       TEXT REFERENCES background_jobs(id),\n    session_id   TEXT REFERENCES terminal_sessions(session_id),\n    template_id  TEXT NOT NULL,\n    content_hash TEXT NOT NULL,  -- SHA-256 for integrity verification\n    created_at   TEXT NOT NULL\n);\n\n-- Query to trace plan handoffs\nSELECT * FROM copy_button_actions\nWHERE plan_id = ?\nORDER BY created_at DESC;",
      "fieldsHeading": "Campos del Registro de Auditoría",
      "fields": [
        {
          "field": "action_id",
          "description": "Identificador único para esta acción de transferencia"
        },
        {
          "field": "plan_id",
          "description": "Referencia al plan de implementación fuente"
        },
        {
          "field": "job_id",
          "description": "Trabajo en segundo plano asociado si aplica"
        },
        {
          "field": "session_id",
          "description": "Sesión de terminal objetivo o null para portapapeles"
        },
        {
          "field": "template_id",
          "description": "Configuración de plantilla que se usó"
        },
        {
          "field": "content_hash",
          "description": "SHA-256 del contenido resuelto para integridad"
        },
        {
          "field": "created_at",
          "description": "Marca de tiempo de la acción"
        }
      ],
      "retention": "Retención: Los registros de auditoría se retienen por 90 días por defecto, configurable en la configuración del proyecto."
    },
    "mobileIntegration": {
      "heading": "Integración Móvil",
      "description": "Los botones de copiado funcionan a través de clientes de escritorio y móviles con comportamiento consistente. El cliente iOS usa la misma lógica de resolución de marcadores y puede enviar contenido a terminales vinculados.",
      "deviceLink": {
        "heading": "Soporte de Enlace de Dispositivo",
        "description": "Cuando un dispositivo móvil está vinculado a una sesión de escritorio, los botones de copiado pueden apuntar al terminal de escritorio directamente. El contenido resuelto se envía a través de la conexión WebSocket de enlace de dispositivo."
      },
      "mobileButtons": {
        "heading": "Botones Específicos para Móvil",
        "description": "Los clientes móviles soportan la misma personalización de botones que el escritorio. Las configuraciones de botones se sincronizan a través del servidor para mantener consistencia entre dispositivos."
      }
    },
    "cta": {
      "heading": "Rastrea la transferencia a la ejecución",
      "description": "Las sesiones de terminal muestran dónde aterriza la salida del botón de copiado y cómo se registra.",
      "terminalLink": "Sesiones de terminal",
      "plansLink": "Planes de implementación"
    }
  },
  "textImprovement": {
    "meta": {
      "title": "Text improvement - PlanToCode",
      "description": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs."
    },
    "category": "Product Guide",
    "cta": {
      "description": "Download PlanToCode to combine voice capture, video context, and inline rewriting before you generate implementation plans.",
      "heading": "Try text improvement in the desktop app",
      "links": {
        "architecture": "Architecture overview",
        "buildYourOwn": "Build your own"
      }
    },
    "date": "2025-09-21",
    "description": "How PlanToCode rewrites highlighted text without changing formatting and links the result back to your workspace.",
    "intro": "Refine text with AI context. Select text in any editor, trigger a background job, and get improved content that keeps your formatting intact.",
    "metaDescription": "How the desktop workspace rewrites highlighted text, preserves formatting, and links the feature to voice and video inputs.",
    "metaTitle": "Text improvement - PlanToCode",
    "ogDescription": "Understand the selection popover, job queue, model configuration, and integrations that power text improvement.",
    "ogTitle": "Text improvement - PlanToCode",
    "readTime": "7 min",
    "selectionPopover": {
      "component": "The popover itself is a minimal component rendered by {code}, which simply triggers the provider hook and shows a loading indicator while a rewrite is running. Because the provider registers global listeners, the popover appears in Monaco plan viewers, the plan terminal dictation field, and any task description inputs without extra wiring.",
      "heading": "Selection popover behaviour",
      "provider": "The {code} listens for selection events on standard inputs and Monaco editors. When you highlight non-empty text it positions a popover near the cursor, stores the selected range, and tracks whether the popover should be visible. Clicking the button kicks off the job and disables the control until the result returns. When the job completes the provider applies the improved text back into the same selection and flushes any pending saves to keep session state in sync."
    },
    "title": "Text Improvement",
    "triggerImprovement": {
      "action": "Pressing the popover button calls {code}. The action validates the selection, ensures a session identifier exists, and invokes the Rust command {code} via Tauri. The command builds a {code} containing the original text and queues a background job against the active session.",
      "backend": "On the backend, the {code} resolves the configured model for the {code} task, wraps the selection in XML tags, and runs the request through the {code} without streaming. When the model response returns it records token usage, cost, and the system prompt template before emitting the improved text back to the UI. The default configuration ships with Claude Sonnet 4.5 and Gemini 3 Pro as the approved models, capped at 4,096 tokens with a temperature of 0.7.",
      "heading": "What happens when you trigger an improvement",
      "metadata": "The background jobs sidebar records the original text in job metadata, so you can review what was sent alongside the rewritten copy. If the selection changes while a job is running, the provider skips replacing the text to avoid clobbering manual edits."
    },
    "videoCapture": {
      "dialog": "Screen recordings pass through the video analysis dialog, which combines your current task description with an optional prompt block wrapped in semantic XML tags before sending the request to the Gemini video analysis job. Any notes you dictate during the recording are available as text once analysis completes, so you can feed the resulting summary back through the improvement popover to tighten the instructions before planning.",
      "features": "Video jobs include frame-rate controls, audio capture toggles, and cost reporting. Results appear in the same background jobs sidebar as text improvements, keeping all prompt preparation artefacts in one place.",
      "heading": "Video capture and prompt scaffolding"
    },
    "voiceIntegration": {
      "heading": "Voice transcription integration",
      "hook": "Voice recordings use the {code} hook. It loads per-project transcription defaults, requests microphone access, and inserts transcripts at the cursor inside the task description or terminal dictation buffer. The inserted text can immediately be highlighted and passed through the same improvement popover, and the original transcription job identifier is stored with the improvement payload for auditing.",
      "preferences": "Language, model, and temperature preferences persist at the project level, so teams get consistent transcription quality before refining the copy. Silence detection warns about bad audio levels, and a ten-minute cap prevents oversized recordings from blocking improvement jobs with large payloads."
    },
    "visuals": {
      "popoverFlow": {
        "title": "Text improvement flow",
        "description": "Selection popover triggers improvement job and returns enhanced text.",
        "imageSrc": "/images/docs/text-improvement/flow.svg",
        "imageAlt": "Text improvement flow diagram"
      }
    },
    "processorDetails": {
      "heading": "Processor implementation details",
      "processor": "The {code} handles the text rewriting workflow on the Rust backend.",
      "stepsHeading": "Processing steps",
      "steps": [
        "Parse the incoming payload with original text and selection metadata",
        "Build the system prompt from the configured text_improvement template",
        "Submit the request to the LLM task runner without streaming",
        "Extract the improved text from the model response",
        "Record token usage, cost, and prompt template for billing",
        "Emit the result back to the UI via Tauri events"
      ]
    },
    "inlineRewriting": {
      "heading": "Inline rewriting behaviour",
      "description": "When the improved text returns, the provider automatically replaces the original selection. The rewriting preserves whitespace, line breaks, and any inline formatting present in the source. If the editor is Monaco-based, the change is applied as a single undo-able edit operation.",
      "contextsHeading": "Supported contexts",
      "contexts": [
        "Task description input fields",
        "Plan terminal dictation area",
        "Monaco plan viewers and editors",
        "Any standard HTML input or textarea"
      ]
    },
    "modelConfiguration": {
      "heading": "Model configuration",
      "description": "Text improvement uses the text_improvement task configuration from the desktop runtime config. You can override the default model and parameters in the settings panel.",
      "settingsHeading": "Configurable settings",
      "settings": [
        "Allowed models list (default: Claude Sonnet 4.5, Gemini 3 Pro)",
        "Maximum token limit (default: 4096)",
        "Temperature setting (default: 0.7)",
        "System prompt template override"
      ]
    },
    "keyFiles": {
      "heading": "Key implementation files",
      "items": [
        "desktop/src/contexts/TextImprovementProvider.tsx",
        "desktop/src/components/TextImprovementPopover.tsx",
        "desktop/src/actions/text-improvement/index.ts",
        "desktop/src-tauri/src/jobs/processors/text_improvement.rs",
        "server/src/config/task_model_config.rs"
      ]
    }
  },
  "voiceTranscription": {
    "meta": {
      "title": "Transcripción de voz - PlanToCode",
      "description": "Cómo PlanToCode graba audio, transmite transcripciones en tiempo real usando gpt-4o-transcribe, gestiona permisos y configuración del proyecto."
    },
    "category": "Guía del Producto",
    "date": "2025-09-22",
    "description": "Ciclo de vida de grabación, gestión de dispositivos y comportamiento de streaming para prompts impulsados por voz.",
    "deviceManagement": {
      "description": "La función solicita permiso de micrófono, enumera las entradas de audio disponibles y permite a los usuarios cambiar dispositivos durante una sesión. Los niveles de audio se monitorean en vivo para que la UI pueda mostrar advertencias de silencio si el micrófono está silenciado o desconectado.",
      "heading": "Gestión de dispositivos",
      "monitoring": "El monitoreo de nivel de audio en tiempo real muestra retroalimentación visual durante la grabación. El sistema detecta períodos de silencio y advierte a los usuarios si el micrófono parece silenciado o desconectado, previniendo grabaciones fallidas antes de que el audio sea enviado para transcripción."
    },
    "intro": "La transcripción de voz está disponible en cualquier lugar donde la aplicación de escritorio exponga controles de dictado, incluyendo el terminal del plan y editores de prompts. La función graba audio localmente, envía fragmentos al servicio de transcripción e inserta texto reconocido en el campo de entrada activo sin bloquear la escritura manual.",
    "metaDescription": "Cómo PlanToCode graba audio, transmite transcripciones en tiempo real usando gpt-4o-transcribe, gestiona permisos y configuración del proyecto.",
    "metaTitle": "Transcripción de voz - PlanToCode",
    "ogDescription": "Aprende cómo el hook de grabación gestiona dispositivos, permisos y texto en streaming.",
    "ogTitle": "Transcripción de voz - PlanToCode",
    "projectSettings": {
      "description": "Cuando inicia una sesión de grabación, el hook busca la configuración de transcripción del proyecto activo. Los códigos de idioma, modelos preferidos y otras configuraciones se recuperan antes de capturar audio para que las grabaciones sigan las preferencias del proyecto.",
      "heading": "Configuración consciente del proyecto",
      "storage": "Las preferencias de transcripción específicas del proyecto se almacenan en SQLite e incluyen el modelo preferido (gpt-4o-transcribe o gpt-4o-mini-transcribe), código de idioma y configuración de temperatura. Estas preferencias persisten entre sesiones y se sincronizan con el servidor para propósitos de facturación."
    },
    "readTime": "5 min",
    "recordingWorkflow": {
      "description": "El hook de grabación mantiene una máquina de estados con estados idle, recording, processing y error. Rastrea la duración, gestiona la detección de silencio y asegura que las grabaciones se detengan automáticamente después de diez minutos. Los fragmentos se almacenan en búfer y se reenvían a la acción de transcripción, que devuelve texto reconocido para inserción.",
      "heading": "Flujo de trabajo de grabación",
      "statesHeading": "Estados de grabación",
      "states": [
        "idle: Sin grabación en progreso, los permisos de micrófono pueden o no estar otorgados",
        "recording: Capturando audio activamente a través de MediaRecorder, duración rastreada, retroalimentación visual mostrada",
        "processing: Fragmento de audio enviado al servidor, esperando respuesta de transcripción de gpt-4o-transcribe",
        "error: Grabación fallida debido a denegación de permiso, desconexión de dispositivo o error de API de transcripción"
      ]
    },
    "routingBehavior": {
      "heading": "Enrutamiento a múltiples destinos",
      "description": "El texto transcrito puede ser enrutado a múltiples destinos basándose en el contexto activo. El callback insertTranscript permite enrutamiento flexible sin acoplamiento. El destino de enrutamiento se almacena en los metadatos del trabajo para pistas de auditoría.",
      "destinations": [
        "Editores de descripción de tarea: Inserción en cursor con refinamiento text_improvement inmediato opcional",
        "Búfer de dictado del terminal: Ejecución de comandos (ej., 'run npm test' escrito en PTY)",
        "Modo de notas de reunión: Búfer acumulado guardado automáticamente en SQLite con task_refinement generando tareas procesables",
        "Editores de prompts: Inserción directa en cualquier campo de entrada de texto a través de la aplicación"
      ]
    },
    "pipeline": {
      "heading": "Pipeline de transcripción",
      "hook": "El hook React {code} gestiona el ciclo de vida completo de grabación. Inicializa {code} para captura de audio en formato WebM con códec Opus, monitorea niveles de audio y maneja el cambio de dispositivos.",
      "command": "La aplicación de escritorio invoca {code} para enviar datos de audio al endpoint del servidor {code}. El comando valida el tamaño del audio (mínimo 1KB, máximo 25MB), duración, temperatura (0.0-1.0) y longitud del prompt (máximo 1000 caracteres).",
      "constraints": "Los archivos de audio deben estar entre 1KB y 25MB. Formatos soportados: WAV, MP3, M4A, OGG, WebM, FLAC, AAC y MP4. El modelo de transcripción debe especificarse explícitamente - los modelos soportados son gpt-4o-transcribe y gpt-4o-mini-transcribe de OpenAI."
    },
    "serverProcessing": {
      "heading": "Procesamiento del lado del servidor",
      "endpoint": "El servidor expone {code} que acepta datos de formulario multipart. Enruta solicitudes a OpenAI o Google basándose en la configuración del proveedor del modelo, valida créditos del usuario y calcula la facturación basándose en la duración del audio.",
      "parametersHeading": "Parámetros de solicitud",
      "parameters": [
        "file: Datos del archivo de audio (requerido) - WAV, MP3, M4A, OGG, WebM, FLAC, AAC o MP4",
        "model: ID del modelo de transcripción (requerido) - openai/gpt-4o-transcribe o openai/gpt-4o-mini-transcribe",
        "duration_ms: Duración de grabación en milisegundos (requerido para cálculo de facturación)",
        "language: Código de idioma ISO 639-1 (opcional) - mejora la precisión para idiomas específicos",
        "prompt: Pista de contexto para transcripción (opcional, máximo 1000 caracteres) - ayuda con vocabulario específico del dominio",
        "temperature: Temperatura de muestreo 0.0-1.0 (opcional, predeterminado 0.0) - valores más bajos producen salida más determinista"
      ]
    },
    "dataFlow": {
      "heading": "Flujo de datos",
      "description": "Los datos de audio fluyen desde el navegador a través de la capa de comandos Tauri hacia el servidor, que hace proxy de las solicitudes al proveedor de transcripción apropiado.",
      "stepsHeading": "Pasos de procesamiento",
      "steps": [
        "El MediaRecorder del navegador captura fragmentos de audio en formato WebM/Opus",
        "El hook useVoiceTranscription almacena fragmentos en búfer y monitorea la duración",
        "Al detenerse, el blob de audio se convierte a bytes y se envía a través de transcribe_audio_command",
        "El comando Tauri valida el tamaño del audio, duración y parámetros",
        "Solicitud enviada al endpoint del servidor /api/audio/transcriptions con token de autenticación",
        "El servidor valida los créditos del usuario y enruta a proveedor OpenAI o Google",
        "El proveedor devuelve texto transcrito, el servidor registra el uso y deduce créditos",
        "Texto transcrito devuelto al escritorio e insertado a través del callback"
      ]
    },
    "keyFiles": {
      "heading": "Archivos de implementación clave",
      "items": [
        "desktop/src/hooks/useVoiceTranscription.ts",
        "desktop/src-tauri/src/commands/audio_commands.rs",
        "server/src/handlers/proxy/specialized/transcription.rs",
        "server/src/clients/openai/transcription.rs",
        "server/src/clients/google/transcription.rs"
      ]
    },
    "examples": {
      "heading": "Ejemplos de uso",
      "description": "Los flujos de trabajo comunes de transcripción de voz demuestran la flexibilidad del sistema:",
      "items": [
        "Planificación de sprint: Grabación de reunión con transcripción canalizada a task_refinement para generar descripciones de tareas",
        "Comandos de terminal: Dictado transcrito y escrito directamente en PTY para ejecución",
        "Reportes de errores: Descripción verbal capturada, refinada con text_improvement, luego procesada por task_refinement",
        "Discusiones de arquitectura: Grabación de video con pista de audio extraída para transcripción, combinada con análisis de visión"
      ]
    },
    "cta": {
      "heading": "Continúa explorando",
      "description": "Aprende cómo el texto transcrito puede ser refinado y cómo las grabaciones de reuniones se procesan en tareas procesables.",
      "links": {
        "textImprovement": "Mejora de Texto",
        "meetingIngestion": "Ingesta de Reuniones"
      }
    },
    "title": "Transcripción de Voz",
    "visuals": {
      "recordingFlow": {
        "title": "Pipeline de transcripción de voz",
        "description": "Captura de audio, procesamiento de transcripción GPT-4o y flujo de enrutamiento de texto.",
        "imageSrc": "/images/docs/voice-transcription/pipeline.svg",
        "imageAlt": "Diagrama del pipeline de transcripción de voz",
        "caption": "El audio fluye desde la captura del navegador a través de comandos Tauri hacia la transcripción GPT-4o del lado del servidor."
      }
    }
  },
  "overview": {
    "meta": {
      "title": "Visión general del sistema - PlanToCode",
      "description": "Comienza aquí: qué hace PlanToCode, cómo funciona el ciclo principal y dónde vive cada componente en el repositorio."
    },
    "category": "Visión General",
    "date": "2025-09-25",
    "readTime": "15 min",
    "title": "Visión General del Sistema",
    "description": "Un mapa conciso del sistema, el ciclo principal y las dependencias requeridas.",
    "intro": "PlanToCode es un espacio de trabajo de escritorio que planifica y valida cambios de código antes de la ejecución. Coordina un motor de trabajos Rust local, una UI React y un proxy de servidor para llamadas LLM. El sistema sigue una arquitectura offline-first donde la aplicación de escritorio opera de forma independiente usando SQLite para el estado local, mientras que el servidor maneja la autenticación, enrutamiento de proveedores LLM y facturación. Sin proveedores LLM externos configurados con tus claves API, los pipelines de planificación y análisis no se ejecutarán.",
    "visuals": {
      "systemMap": {
        "title": "Mapa del sistema",
        "description": "Mapa de la aplicación de escritorio, el núcleo Rust, almacenamiento SQLite local y el proxy del servidor.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Diagrama del mapa del sistema PlanToCode",
        "caption": "Arquitectura de cuatro capas con datos fluyendo hacia abajo y eventos transmitidos hacia arriba."
      }
    },
    "systemLayers": {
      "heading": "Capas del sistema",
      "description": "El sistema está organizado en cuatro capas distintas que se comunican a través de interfaces bien definidas:",
      "items": [
        "Capa de Presentación: UI React con editores Monaco, paneles de terminal y controles de flujo de trabajo (desktop/src/)",
        "Capa de Comandos: Comandos Tauri que conectan React y Rust, manejando IPC y gestión de estado (desktop/src-tauri/src/commands/)",
        "Capa de Procesamiento: Procesadores de trabajos, orquestador de flujos de trabajo y lógica de negocio en Rust (desktop/src-tauri/src/jobs/)",
        "Capa de Persistencia: Repositorios SQLite para estado local y PostgreSQL del servidor para autenticación/facturación (desktop/src-tauri/src/db_utils/)"
      ]
    },
    "coreLoop": {
      "heading": "Ciclo principal en práctica",
      "description": "Cada tarea fluye a través de un ciclo de vida bien definido desde la captura hasta la ejecución:",
      "steps": [
        "Captura la tarea desde texto, transcripción de voz (a través del hook useVoiceTranscription) o análisis de grabación de video.",
        "Refina la descripción de la tarea y los objetivos con trabajos text_improvement a través de TextImprovementProcessor.",
        "Ejecuta el flujo de trabajo de descubrimiento de archivos: RootFolderSelectionProcessor selecciona directorios, RegexFileFilterProcessor aplica patrones, FileRelevanceAssessmentProcessor puntúa contenidos, ExtendedPathFinderProcessor expande el contexto.",
        "Genera planes de implementación a través de ImplementationPlanProcessor, que transmite planes formateados en XML al visor Monaco.",
        "Opcionalmente fusiona múltiples borradores de planes con ImplementationPlanMergeProcessor usando planes fuente etiquetados con XML.",
        "Ejecuta o exporta el plan aprobado a través de sesiones de terminal PTY o plantillas de botones de copiado para agentes externos.",
        "Persiste cada trabajo, artefacto y log de terminal en SQLite (tablas background_jobs, terminal_sessions) para auditabilidad."
      ]
    },
    "components": {
      "heading": "Componentes principales",
      "description": "Cada componente tiene una responsabilidad específica y se comunica a través de interfaces tipadas:",
      "items": [
        "UI de Escritorio (React) en desktop/src/ con vistas de planes Monaco, paneles de terminal y proveedores (SessionProvider, TextImprovementProvider).",
        "Núcleo Rust (Tauri v2) en desktop/src-tauri/ manejando comandos, trabajos y persistencia con permisos basados en capacidades.",
        "Esquema SQLite local en desktop/src-tauri/migrations/consolidated_schema.sql con modo WAL para acceso concurrente.",
        "Proxy del servidor (Actix-Web) en server/src/ para autenticación, enrutamiento de proveedores, respuestas en streaming y facturación a través de Stripe.",
        "Cliente móvil iOS en mobile/ios/Core/ con interfaz SwiftUI, Auth0 PKCE y enlace de dispositivo WebSocket.",
        "Automatización de infraestructura en infrastructure/ansible/ para servidores dedicados Hetzner (UE) e InterServer (EE.UU.)."
      ]
    },
    "dependencies": {
      "heading": "Dependencias requeridas",
      "description": "El sistema requiere estos servicios y recursos externos:",
      "items": [
        "Proveedores LLM externos (OpenAI, Anthropic, Google, X.AI, OpenRouter) para generación de planes, transcripción y análisis.",
        "Autenticación basada en Auth0 con flujo PKCE para sesiones de escritorio y móvil.",
        "PostgreSQL 17 y Redis 7+ para cuentas de usuario del lado del servidor, estado de facturación y colas de trabajos (despliegues auto-hospedados).",
        "Acceso al sistema de archivos local a través de git ls-files o recorrido de directorios para flujos de trabajo de descubrimiento de archivos.",
        "Endpoint de transcripción compatible con Whisper para procesamiento de entrada de voz."
      ]
    },
    "codeMap": {
      "heading": "Dónde vive el comportamiento en el repositorio",
      "description": "Referencia rápida a directorios y archivos clave:",
      "items": [
        "Comandos Tauri: desktop/src-tauri/src/commands/ (35+ módulos de comandos: job_commands.rs, workflow_commands.rs, terminal_commands.rs, session_commands.rs, auth0_commands.rs)",
        "Orquestación de flujos de trabajo: desktop/src-tauri/src/jobs/workflow_orchestrator/ (definition_loader.rs, stage_scheduler.rs, event_emitter.rs, payload_builder.rs)",
        "Procesadores de trabajos: desktop/src-tauri/src/jobs/processors/ (implementation_plan_processor.rs, text_improvement_processor.rs, root_folder_selection_processor.rs)",
        "Repositorios SQLite: desktop/src-tauri/src/db_utils/ (background_job_repository/, session_repository.rs, terminal_repository.rs)",
        "Rutas del servidor: server/src/routes.rs (configure_routes, configure_public_auth_routes, configure_webhook_routes)",
        "Manejadores de proxy LLM: server/src/handlers/proxy_handlers.rs y server/src/handlers/proxy/ (router.rs, providers/)",
        "Transformadores de proveedores: server/src/handlers/provider_transformers/ (openai.rs, google.rs, anthropic.rs, xai.rs)",
        "Flujos de trabajo iOS: mobile/ios/Core/Sources/Workflows/WorkflowManager.swift con MobileSessionManager y APIClient",
        "Playbooks de infraestructura: infrastructure/ansible/site-base.yml (endurecimiento, PostgreSQL, Redis) y site-app.yml (despliegue)"
      ]
    },
    "keyAbstractions": {
      "heading": "Abstracciones clave",
      "description": "Comprender estos conceptos centrales ayuda a navegar el código base:",
      "items": [
        "Session: Contexto del proyecto almacenado en la tabla sessions con task_description, included_files y preferencias de modelo. Identificado por UUID.",
        "Background Job: Operación respaldada por LLM almacenada en la tabla background_jobs con task_type, prompt, response, seguimiento de tokens y costo.",
        "Workflow: Proceso orquestado de múltiples etapas (ej., file_finder_workflow) coordinado por WorkflowOrchestrator con IntermediateData pasando entre etapas.",
        "Terminal Session: Proceso PTY almacenado en terminal_sessions con output_log, status y vinculación opcional de job_id para auditoría.",
        "Provider: Abstracción de servicio LLM en server/src/handlers/proxy/providers/ con transformación de solicitudes y normalización de respuestas."
      ]
    },
    "dataFlowSummary": {
      "heading": "Resumen del flujo de datos",
      "description": "Cómo se mueven los datos a través del sistema para una tarea de planificación típica:",
      "items": [
        "La entrada del usuario ingresa a través de componentes React y fluye a comandos Tauri a través de @tauri-apps/api/core invoke().",
        "Los comandos crean registros background_jobs y los despachan a procesadores de trabajos a través de la cola de trabajos.",
        "Los procesadores construyen prompts, envían solicitudes a través del proxy LLM del servidor y transmiten respuestas a través de eventos Tauri.",
        "Las respuestas se almacenan en SQLite y se emiten a proveedores React que actualizan el estado de la UI.",
        "La ejecución del terminal transmite salida PTY a la UI y persiste logs para recuperación de sesión."
      ]
    }
  },
  "runtimeWalkthrough": {
    "meta": {
      "title": "Tutorial de ejecución - PlanToCode",
      "description": "Línea de tiempo de extremo a extremo de una tarea desde la entrada hasta la salida del plan, con tipos de trabajo y flujos de artefactos."
    },
    "category": "Arquitectura",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Tutorial de Ejecución",
    "description": "Línea de tiempo de ejecución de extremo a extremo desde la entrada de la tarea hasta la salida del plan.",
    "intro": "Este tutorial traza una sola tarea desde la captura inicial a través del descubrimiento de archivos, generación de planes y ejecución de terminal. Cada etapa se mapea a tipos de trabajos específicos y produce artefactos almacenados en SQLite.",
    "visuals": {
      "timeline": {
        "title": "Línea de tiempo de ejecución",
        "description": "Línea de tiempo visual mostrando entrada de tarea, etapas de flujo de trabajo y salida del plan.",
        "imageSrc": "/images/docs/runtime-walkthrough/timeline.svg",
        "imageAlt": "Diagrama de línea de tiempo de ejecución",
        "caption": "La ejecución de la tarea fluye a través de seis etapas, con todos los artefactos persistidos en SQLite."
      },
      "walkthroughVideo": {
        "title": "Video del tutorial de ejecución",
        "description": "Demostración en video de una ejecución completa de tarea desde la entrada hasta la salida del plan.",
        "videoSrc": "",
        "posterSrc": "",
        "caption": "Marcador de posición del video del tutorial - graba una demostración del flujo de trabajo de planificación completo."
      }
    },
    "timeline": {
      "heading": "Secuencia de ejecución de alto nivel",
      "description": "Una ejecución completa de tarea sigue esta secuencia de operaciones:",
      "steps": [
        "El usuario ingresa o dicta una descripción de tarea en la UI de escritorio a través del componente TaskDescriptionEditor.",
        "Opcional: el trabajo text_improvement refina la entrada sin procesar a través de TextImprovementProcessor.",
        "El usuario activa el flujo de trabajo de descubrimiento de archivos a través del comando start_file_finder_workflow del panel de Planes de Implementación.",
        "WorkflowOrchestrator en desktop/src-tauri/src/jobs/workflow_orchestrator/ crea un registro de flujo de trabajo y programa la etapa 1.",
        "Etapa 1 (root_folder_selection): RootFolderSelectionProcessor envía el árbol de directorios al LLM, almacena las raíces seleccionadas en IntermediateData.selectedRoots.",
        "Etapa 2 (regex_file_filter): RegexFileFilterProcessor genera patrones, ejecuta git ls-files, almacena coincidencias en IntermediateData.locallyFilteredFiles.",
        "Etapa 3 (file_relevance_assessment): FileRelevanceAssessmentProcessor fragmenta contenidos de archivos, puntúa relevancia, almacena en IntermediateData.aiFilteredFiles.",
        "Etapa 4 (extended_path_finder): ExtendedPathFinderProcessor expande el contexto con imports y dependencias, almacena en IntermediateData.verifiedPaths.",
        "La UI recibe el evento workflow-completed a través de event_emitter.rs, actualiza la visualización de selección de archivos.",
        "El usuario activa la generación de planes con los archivos seleccionados a través del comando generate_implementation_plan.",
        "ImplementationPlanProcessor en desktop/src-tauri/src/jobs/processors/implementation_plan_processor.rs transmite contenido del plan XML al visor Monaco a través de eventos job:stream-progress.",
        "El usuario revisa el plan en el componente VirtualizedCodeViewer, puede editar directamente o solicitar fusión.",
        "El plan aprobado se copia al terminal a través de plantillas de botones de copiado o se exporta para agentes externos.",
        "La sesión de terminal en terminal_commands.rs captura la salida PTY, detecta estados de atención del agente.",
        "Todos los artefactos persisten en las tablas SQLite background_jobs y terminal_sessions para auditoría y recuperación de sesión."
      ]
    },
    "jobTypes": {
      "heading": "Tipos de trabajo en la ejecución",
      "description": "Cada task_type se mapea a un procesador específico y produce artefactos distintos:",
      "items": [
        "text_improvement: TextImprovementProcessor envuelve texto en XML, envía al LLM, devuelve texto refinado. Almacenado en background_jobs.response.",
        "root_folder_selection: RootFolderSelectionProcessor recibe árbol de directorios, devuelve array JSON de directorios seleccionados.",
        "regex_file_filter: RegexFileFilterProcessor genera patrones de la descripción de tarea, aplica a la lista de archivos git.",
        "file_relevance_assessment: FileRelevanceAssessmentProcessor carga contenidos de archivos, fragmenta por límite de tokens, puntúa relevancia.",
        "extended_path_finder: ExtendedPathFinderProcessor analiza imports/dependencias, expande contexto con archivos relacionados.",
        "implementation_plan: ImplementationPlanProcessor transmite planes formateados en XML con elementos plan_step.",
        "implementation_plan_merge: ImplementationPlanMergeProcessor combina planes usando etiquetas XML source_plans e instrucciones del usuario.",
        "video_analysis: Procesa grabaciones de pantalla a través del endpoint /api/llm/video/analyze con muestreo de fotogramas.",
        "web_search_prompts_generation: Genera bloques XML research_task para el flujo de trabajo de investigación profunda.",
        "web_search_execution: Ejecuta prompts de investigación en paralelo, agrega hallazgos."
      ]
    },
    "inputCapture": {
      "heading": "Captura de entrada de tarea",
      "description": "Las tareas ingresan al sistema a través de múltiples superficies de entrada:",
      "text": "Las descripciones de tareas se escriben o pegan en TaskDescriptionEditor que persiste a sessions.task_description y crea entradas de historial en la tabla task_description_history con device_id para sincronización multi-dispositivo.",
      "voice": "La entrada de voz usa el hook useVoiceTranscription que graba a través de la API MediaRecorder, envía a /api/audio/transcriptions e inserta en la posición del cursor.",
      "video": "El análisis de video usa VideoAnalysisDialog para capturar grabaciones de pantalla, subir a /api/llm/video/analyze y extraer observaciones del estado de la UI."
    },
    "workflowExecution": {
      "heading": "Detalles de ejecución del flujo de trabajo",
      "description": "El WorkflowOrchestrator coordina flujos de trabajo de múltiples etapas:",
      "scheduling": "workflow_lifecycle_manager.rs crea registros de flujo de trabajo y stage_scheduler.rs despacha etapas secuencialmente basándose en definiciones JSON de flujo de trabajo.",
      "data": "Las estructuras IntermediateData en workflow_types.rs pasan salidas entre etapas: selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths.",
      "events": "event_emitter.rs publica eventos Tauri workflow-status y workflow-stage consumidos por WorkflowTracker en la UI React."
    },
    "persistence": {
      "heading": "Persistencia de estado",
      "description": "Todos los artefactos se persisten para auditoría y recuperación:",
      "jobs": "background_job_repository/ almacena registros de trabajos con session_id, task_type, status, prompt, response, tokens_sent/received, actual_cost.",
      "sessions": "session_repository.rs gestiona la tabla sessions con task_description, included_files, model_used, versiones de historial.",
      "terminals": "terminal_repository.rs persiste terminal_sessions con output_log, status, exit_code, working_directory para recuperación de sesión.",
      "rehydration": "Al reiniciar la aplicación, el núcleo Rust rehidrata el estado de sesión desde SQLite, marca trabajos en ejecución obsoletos como fallidos y restaura logs de salida del terminal."
    },
    "inputs": {
      "heading": "Captura de entrada de tarea",
      "capture": "Las tareas ingresan al sistema a través de múltiples superficies de entrada: texto escrito en TaskDescriptionEditor, dictado de voz a través del hook useVoiceTranscription, o análisis de video a través de VideoAnalysisDialog.",
      "artifacts": "Cada tipo de entrada produce artefactos almacenados en SQLite - task_description en la tabla sessions, resultados de transcripción en background_jobs, y fotogramas de video en metadatos del trabajo asociado."
    },
    "refinement": {
      "heading": "Refinamiento de entrada",
      "jobs": "El tipo de trabajo text_improvement refina la entrada sin procesar a través de TextImprovementProcessor, envolviendo texto en XML y enviándolo al LLM para mejoras de gramática, claridad y estructura.",
      "storage": "El texto refinado se almacena en background_jobs.response y puede actualizar sessions.task_description a través del proveedor React."
    },
    "discovery": {
      "heading": "Flujo de trabajo de descubrimiento de archivos",
      "workflow": "FileFinderWorkflow ejecuta cuatro etapas secuenciales: root_folder_selection reduce directorios, regex_file_filter aplica patrones, file_relevance_assessment puntúa contenido, y extended_path_finder expande con dependencias.",
      "outputs": "Cada etapa almacena resultados en estructuras IntermediateData pasadas entre procesadores, con selecciones finales de archivos persistidas en sessions.included_files."
    },
    "planGeneration": {
      "heading": "Generación de planes",
      "jobs": "El tipo de trabajo implementation_plan usa ImplementationPlanProcessor para generar planes formateados en XML con elementos plan_step conteniendo rutas de archivos, tipos de operación y cambios de código.",
      "streaming": "El contenido del plan se transmite a la UI a través de eventos Tauri job:stream-progress, mostrado en el componente VirtualizedCodeViewer Monaco con resaltado de sintaxis."
    },
    "merge": {
      "heading": "Fusión de planes",
      "instructions": "El trabajo implementation_plan_merge combina múltiples planes usando etiquetas XML source_plans e instrucciones de fusión proporcionadas por el usuario para resolver conflictos y consolidar cambios.",
      "outputs": "Los planes fusionados mantienen trazabilidad a los planes fuente e incluyen metadatos merged_from en el registro final de background_jobs."
    },
    "review": {
      "heading": "Revisión de planes",
      "editor": "Los planes se abren en el VirtualizedCodeViewer basado en Monaco para revisión. Los usuarios pueden editar el texto del plan directamente, solicitar modificaciones o aprobar para ejecución.",
      "audit": "Todas las acciones de revisión se registran con marcas de tiempo y contexto del usuario, proporcionando una pista de auditoría de la evolución del plan."
    },
    "execution": {
      "heading": "Transferencia de ejecución",
      "terminal": "Los planes aprobados se copian al terminal integrado a través de plantillas de botones de copiado, o se exportan para agentes externos como Claude Code, Cursor o Codex.",
      "logging": "Las sesiones de terminal en terminal_commands.rs capturan salida PTY, detectan estados de atención del agente y registran toda la actividad de ejecución en la tabla terminal_sessions."
    },
    "state": {
      "heading": "Persistencia de estado",
      "jobs": "Todos los artefactos de trabajos persisten en la tabla background_jobs con session_id, task_type, status, prompt, response, conteos de tokens y seguimiento de costos.",
      "rehydration": "Al reiniciar la aplicación, el núcleo Rust rehidrata el estado de sesión desde SQLite, marca trabajos en ejecución obsoletos como fallidos y restaura logs de salida del terminal."
    },
    "jobMap": {
      "heading": "Mapeo de tipos de trabajo",
      "items": [
        "text_improvement → TextImprovementProcessor → descripciones de tareas refinadas",
        "root_folder_selection → RootFolderSelectionProcessor → directorios seleccionados",
        "regex_file_filter → RegexFileFilterProcessor → archivos coincidentes por patrón",
        "file_relevance_assessment → FileRelevanceAssessmentProcessor → archivos puntuados",
        "extended_path_finder → ExtendedPathFinderProcessor → contexto expandido",
        "implementation_plan → ImplementationPlanProcessor → documentos de plan XML",
        "implementation_plan_merge → ImplementationPlanMergeProcessor → planes fusionados"
      ]
    },
    "cta": {
      "heading": "Explora la arquitectura",
      "description": "Comprende cómo encajan los componentes en detalle.",
      "links": {
        "architecture": "Visión general de arquitectura",
        "jobs": "Trabajos en segundo plano",
        "desktop": "Internos de la aplicación de escritorio",
        "dataModel": "Modelo de datos",
        "plans": "Planes de implementación"
      }
    }
  },
  "desktopApp": {
    "meta": {
      "title": "Internos de la aplicación de escritorio - PlanToCode",
      "description": "Cómo funcionan juntos el shell de escritorio Tauri, la capa de comandos Rust, la persistencia SQLite y las sesiones PTY."
    },
    "category": "Escritorio",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Internos de la Aplicación de Escritorio",
    "description": "Shell Tauri v2, capa de comandos Rust, sesiones PTY y gestión del estado de la UI.",
    "intro": "La aplicación de escritorio es un shell Tauri v2 (versión 2.9.1) ejecutando una UI React. Los servicios Rust exponen comandos para flujos de trabajo, sesiones de terminal y configuración mientras persisten el estado localmente en SQLite. El modelo de permisos basado en capacidades proporciona controles de seguridad granulares para acceso al sistema de archivos, solicitudes HTTP, ejecución de shell y notificaciones del sistema.",
    "visuals": {
      "shell": {
        "title": "Visión general del shell de escritorio",
        "description": "Captura de pantalla mostrando el editor de planes, pestañas de terminal y barra lateral de estado de trabajos.",
        "imageSrc": "/assets/images/demo-implementation-plans.jpg",
        "imageAlt": "Shell de escritorio PlanToCode",
        "caption": "La aplicación de escritorio mostrando el panel de planes de implementación y la barra lateral."
      }
    },
    "projectLayout": {
      "heading": "Estructura del proyecto",
      "description": "La aplicación de escritorio sigue la estructura estándar de Tauri v2:",
      "items": [
        "desktop/src/: Componentes React de UI, hooks, proveedores y adaptadores específicos de escritorio.",
        "desktop/src-tauri/: Núcleo Rust incluyendo comandos, trabajos, repositorios y servicios.",
        "desktop/src-tauri/src/lib.rs: Punto de entrada de la aplicación con registro de plugins y gestión de AppState.",
        "desktop/src-tauri/src/commands/: 35+ módulos de manejadores de comandos Tauri organizados por dominio.",
        "desktop/src-tauri/src/jobs/: Procesadores de trabajos en segundo plano, orquestación de flujos de trabajo y gestión de colas.",
        "desktop/src-tauri/capabilities/: Definiciones JSON de capacidades para permisos de seguridad (default.json, desktop-default.json, plantocode-api.json).",
        "desktop/src-tauri/migrations/: Migraciones de esquema SQLite en consolidated_schema.sql."
      ]
    },
    "ui": {
      "heading": "UI React y superficie",
      "description": "La UI React renderiza el editor de descripción de tareas, visor de planes y paneles de terminal:",
      "components": [
        "TaskDescriptionEditor: Entrada multilínea con integración de transcripción de voz y popover de mejora de texto.",
        "VirtualizedCodeViewer: Visualización de planes basada en Monaco con resaltado de sintaxis y acciones de copiado.",
        "TerminalSurface: Búfer de salida PTY con estado de conexión, indicadores de atención del agente y entrada de voz.",
        "SessionProvider: Gestión de estado global para sesión activa, selecciones de archivos y preferencias de modelo.",
        "TextImprovementProvider: Listener de selección y posicionamiento de popover para reescrituras en línea.",
        "WorkflowTracker: Visualización de progreso en tiempo real para flujos de trabajo de múltiples etapas."
      ]
    },
    "commands": {
      "heading": "Comandos Tauri",
      "description": "Los comandos en desktop/src-tauri/src/commands/ exponen funcionalidad Rust a la UI React. Los módulos clave incluyen:",
      "modules": [
        "job_commands.rs: create_job, get_job, cancel_job, get_jobs_for_session, clear_job_history.",
        "workflow_commands.rs: start_file_finder_workflow, get_workflow_status, retry_workflow, pause_workflow, resume_workflow.",
        "terminal_commands.rs: create_terminal_session, send_terminal_input, resize_terminal, get_terminal_output, check_cli_availability.",
        "session_commands.rs: create_session, get_session, update_session, sync_task_description_history, sync_file_selection_history.",
        "auth0_commands.rs: initiate_login, complete_login, refresh_token, logout, get_user_info.",
        "implementation_plan_commands.rs: generate_implementation_plan, merge_implementation_plans, estimate_tokens.",
        "config_commands.rs: get_runtime_config, get_model_config, get_system_prompts, refresh_config_cache.",
        "settings_commands.rs: get_setting, set_setting, get_project_system_prompt, set_project_system_prompt."
      ]
    },
    "appState": {
      "heading": "Gestión de AppState",
      "description": "El núcleo Rust gestiona el estado de la aplicación a través del sistema de estado de Tauri:",
      "structure": "La estructura AppState en lib.rs contiene: config_load_error (Option<String>), cliente HTTP (reqwest::Client), RuntimeConfig (URL del servidor, estado de onboarding) detrás de Mutex, y Auth0State para autenticación.",
      "config": "RuntimeConfig contiene server_url, bandera onboarding_complete, y se actualiza a través del comando set_runtime_config. ConfigCache almacena la configuración de IA en tiempo de ejecución con anulaciones por proyecto.",
      "tokens": "TokenManager usa el keyring del SO (a través del crate keyring) para almacenar de forma segura access_token, refresh_token y jwt con actualización automática antes del vencimiento."
    },
    "jobs": {
      "heading": "Procesadores de trabajos y flujos de trabajo",
      "description": "Arquitectura de procesamiento de trabajos en desktop/src-tauri/src/jobs/:",
      "queue": "queue.rs gestiona la cola de trabajos con trabajos pendientes en memoria y persistencia SQLite. Los trabajos transicionan a través de estados: idle, created, queued, acknowledged_by_worker, preparing, preparing_input, running, generating_stream, processing_stream, completed, failed, canceled.",
      "processors": "El directorio processors/ contiene procesadores específicos de tareas: ImplementationPlanProcessor (planes en streaming), TextImprovementProcessor (reescrituras en línea), RootFolderSelectionProcessor, RegexFileFilterProcessor, FileRelevanceAssessmentProcessor, ExtendedPathFinderProcessor.",
      "orchestrator": "workflow_orchestrator/ coordina flujos de trabajo de múltiples etapas: definition_loader.rs carga definiciones JSON de flujo de trabajo, stage_scheduler.rs despacha etapas, payload_builder.rs construye entradas, event_emitter.rs publica eventos de progreso.",
      "streaming": "processors/generic_llm_stream_processor.rs maneja respuestas LLM en streaming, emitiendo eventos job:stream-progress y acumulando contenido en background_jobs.response."
    },
    "persistence": {
      "heading": "Persistencia local",
      "description": "Almacenamiento SQLite en desktop/src-tauri/migrations/consolidated_schema.sql:",
      "tables": [
        "sessions: id (UUID), name, project_directory, project_hash, task_description, included_files, force_excluded_files, model_used, versiones de historial.",
        "background_jobs: id (UUID), session_id (FK), task_type, status, prompt, response, tokens_sent/received, cache_read/write_tokens, actual_cost, metadata (JSON), server_request_id.",
        "terminal_sessions: id, job_id (FK nullable), session_id, status, process_pid, output_log, working_directory, environment_vars, last_output_at.",
        "task_description_history: session_id (FK), description, device_id, sequence_number, version para sincronización multi-dispositivo.",
        "file_selection_history: session_id (FK), included_files, force_excluded_files, device_id, sequence_number.",
        "project_system_prompts: project_hash, task_type, system_prompt para anulaciones de prompt por proyecto.",
        "key_value_store: key, value (JSON), updated_at para configuración de la aplicación.",
        "error_logs: timestamp, level, error_type, message, context, stack, metadata para seguimiento de errores del lado del cliente."
      ],
      "repositories": "Los repositorios en db_utils/ proporcionan acceso tipado: background_job_repository/ (modular con base.rs, worker.rs, metadata.rs, cleanup.rs), session_repository.rs, terminal_repository.rs, settings_repository.rs, error_log_repository.rs."
    },
    "terminal": {
      "heading": "Sesiones de terminal",
      "description": "Implementación de terminal PTY:",
      "commands": "terminal_commands.rs gestiona el ciclo de vida de la sesión: create_terminal_session genera PTY a través del crate portable-pty, send_terminal_input reenvía pulsaciones de teclas, resize_terminal ajusta dimensiones, check_cli_availability verifica presencia de herramientas (claude, cursor, codex, gemini).",
      "persistence": "terminal_repository.rs persiste sesiones con output_log (salida acumulada del terminal), status (idle/running/completed/failed/agent_requires_attention), exit_code, working_directory. Las sesiones pueden restaurarse después del reinicio de la aplicación.",
      "attention": "La detección de atención del agente monitorea marcas de tiempo last_output_at. Nivel 1 (30s inactivo): indicador amarillo. Nivel 2 (2min inactivo): indicador rojo con notificación de escritorio."
    },
    "inputStability": {
      "heading": "Estabilidad de la descripción de tarea",
      "description": "El editor de descripción de tarea incluye salvaguardas para prevenir saltos del cursor:",
      "items": [
        "Las actualizaciones remotas se encolan mientras el usuario está escribiendo y se vacían al estar inactivo o al perder el foco.",
        "El estado de selección se rastrea y restaura después de re-renderizados de React.",
        "Los escritores en segundo plano llaman a sessionActions.updateCurrentSessionFields para coordinar actualizaciones.",
        "La sincronización multi-dispositivo usa campos sequence_number y version para resolver conflictos."
      ]
    },
    "plugins": {
      "heading": "Plugins Tauri",
      "description": "PlanToCode usa el ecosistema de plugins Tauri v2:",
      "list": [
        "tauri-plugin-http (2.5.2): Cliente HTTP con fetch consciente de CSP para llamadas API.",
        "tauri-plugin-dialog (2.4.2): Selector nativo de archivos/carpetas y diálogos de mensajes.",
        "tauri-plugin-shell (2.3.3): Ejecución de comandos shell para herramientas CLI externas.",
        "tauri-plugin-store (2.4.1): Almacenamiento persistente clave-valor para configuración de la aplicación.",
        "tauri-plugin-notification (2.3.0): Notificaciones de escritorio para atención del agente.",
        "tauri-plugin-updater (2.9.0): Actualizaciones dentro de la aplicación con verificación de firma.",
        "tauri-plugin-single-instance (2.3.4): Aplicación de instancia única.",
        "tauri-plugin-process (2.3.1): Capacidad de reinicio de proceso."
      ]
    }
  },
  "serverApi": {
    "meta": {
      "title": "API del servidor y proxy LLM - PlanToCode",
      "description": "Autenticación, enrutamiento de proveedores, configuración de modelos y endpoints WebSocket usados por clientes de escritorio y móviles."
    },
    "category": "Servidor",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "API del Servidor y Proxy LLM",
    "description": "Autenticación, enrutamiento de proveedores, configuración de modelos, facturación y endpoints WebSocket.",
    "intro": "El servidor es un servicio Actix-Web escrito en Rust que proporciona autenticación, configuración de modelos, proxy LLM y facturación. Los clientes de escritorio y móviles dependen de él para enrutamiento seguro de proveedores y respuestas en streaming. El servidor se ejecuta en infraestructura dedicada en dos regiones: Hetzner (UE) en api-eu.plantocode.com e InterServer (EE.UU.) en api-us.plantocode.com.",
    "visuals": {
      "flow": {
        "title": "Server request flow",
        "description": "Diagram showing clients, API routes, and the LLM proxy.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Server request flow diagram",
        "caption": "Placeholder for the server request flow."
      }
    },
    "routeOrganization": {
      "heading": "Route organization",
      "description": "Routes are organized in server/src/routes.rs with three configuration functions:",
      "functions": [
        "configure_routes(): JWT-authenticated routes under /api scope. Includes auth, billing, config, providers, models, llm proxy, audio, system-prompts, consent, devices, notifications.",
        "configure_public_auth_routes(): Browser-based auth flow under /auth scope. Includes Auth0 initiate-login, callback, and logged-out routes.",
        "configure_webhook_routes(): Unauthenticated webhook endpoints under /webhooks scope. Currently handles Stripe webhooks."
      ]
    },
    "auth": {
      "heading": "Authentication endpoints",
      "description": "Authentication uses Auth0 with PKCE flow:",
      "routes": [
        "/auth/auth0/initiate-login (GET): Starts OAuth flow with code_challenge, redirects to Auth0.",
        "/auth/auth0/callback (GET): Handles Auth0 redirect, exchanges code for tokens.",
        "/api/auth/userinfo (GET): Returns authenticated user info from Auth0.",
        "/api/auth/logout (POST): Revokes tokens and clears session.",
        "/api/auth/account (DELETE): Account deletion with cascading cleanup.",
        "/api/auth0/refresh-app-token (POST): Refreshes access token using refresh token."
      ],
      "implementation": "Auth handlers in server/src/handlers/auth0_handlers.rs and server/src/handlers/auth/. JWT validation uses services/auth/jwt.rs with JWKS rotation. Revoked tokens tracked in revoked_token_repository.rs."
    },
    "llmProxy": {
      "heading": "LLM proxy and streaming",
      "description": "The LLM proxy normalizes requests across providers and streams responses:",
      "routes": [
        "/api/llm/chat/completions (POST): Main chat completion endpoint. Routes to OpenAI, Anthropic, Google, X.AI, or OpenRouter based on model ID.",
        "/api/llm/video/analyze (POST): Multipart video upload for frame analysis. Requires google/* models with video capability.",
        "/api/llm/cancel (POST): Cancels in-flight streaming request by request_id.",
        "/api/llm/status/{request_id} (GET): Returns status of a request (active, completed, cancelled).",
        "/api/audio/transcriptions (POST): Whisper-compatible transcription. Multipart upload with audio file and parameters."
      ],
      "routing": "Router in server/src/handlers/proxy/router.rs selects provider based on model ID prefix (openai/, anthropic/, google/, xai/, openrouter/). Provider-specific handlers in server/src/handlers/proxy/providers/ transform requests and normalize responses.",
      "streaming": "Streaming responses use Server-Sent Events (SSE) via streaming/sse_adapter.rs. The proxy forwards chunks from providers, transforms them to a common format, and tracks token usage in real-time."
    },
    "providers": {
      "heading": "Provider routing",
      "description": "Provider handlers in server/src/handlers/proxy/providers/:",
      "handlers": [
        "openai.rs: OpenAI and OpenAI-compatible APIs (GPT-4, o1, o3).",
        "anthropic.rs: Anthropic Claude models with prompt caching support.",
        "google.rs: Google Gemini models including video analysis capability.",
        "xai.rs: X.AI Grok models.",
        "openrouter.rs: OpenRouter aggregation for model routing."
      ],
      "transformers": "Request/response transformers in server/src/handlers/provider_transformers/ normalize API differences. Each transformer handles: request body format, authentication headers, streaming chunk format, usage extraction, error normalization."
    },
    "config": {
      "heading": "Configuration endpoints",
      "description": "Configuration and model metadata endpoints:",
      "routes": [
        "/api/config/all-configurations (GET): Returns all application configurations including model settings per task type.",
        "/api/config/desktop-runtime-config (GET): Desktop-specific runtime configuration.",
        "/api/config/billing (GET/PUT): Billing configuration management.",
        "/api/providers (GET): List of available LLM providers with capabilities.",
        "/api/providers/with-counts (GET): Providers with model counts.",
        "/api/providers/by-capability/{capability} (GET): Filter providers by capability.",
        "/api/models (GET): All available models with pricing.",
        "/api/models/{id} (GET): Single model details.",
        "/api/models/by-provider/{provider_code} (GET): Models for a specific provider.",
        "/api/models/estimate-cost (POST): Cost estimation for a request.",
        "/api/models/estimate-tokens (POST): Token count estimation.",
        "/api/system-prompts/defaults (GET): Default system prompts by task type."
      ]
    },
    "billing": {
      "heading": "Billing endpoints",
      "description": "Credit-based billing system integrated with Stripe:",
      "routes": [
        "/api/billing/dashboard (GET): User billing dashboard data.",
        "/api/billing/usage-summary (GET): Detailed usage with cost breakdown.",
        "/api/billing/credits/balance (GET): Current credit balance.",
        "/api/billing/credits/details (GET): Credit details including grants and purchases.",
        "/api/billing/credits/unified-history (GET): Transaction history.",
        "/api/billing/checkout/credit-purchase (POST): Create Stripe checkout for credits.",
        "/api/billing/checkout/setup (POST): Create Stripe setup session for payment method.",
        "/api/billing/auto-top-off (GET/PUT): Auto top-off settings management."
      ],
      "implementation": "Billing handlers in server/src/handlers/billing/. Credit service in services/credit_service.rs. Stripe integration via services/stripe_service.rs with webhook handling in webhook_handlers.rs."
    },
    "devices": {
      "heading": "Device management",
      "description": "Device registration and push notifications:",
      "routes": [
        "/api/devices/register (POST): Register desktop device with device_id.",
        "/api/devices/mobile/register (POST): Register mobile device with platform info.",
        "/api/devices/{device_id}/heartbeat (POST): Device heartbeat for presence.",
        "/api/devices/{device_id}/push-token (POST): Save push notification token.",
        "/api/devices/{device_id}/connection-descriptor (GET): WebSocket connection info for device linking.",
        "/api/notifications/job-completed (POST): Send push notification for completed job.",
        "/api/notifications/job-progress (POST): Send progress notification."
      ]
    },
    "websockets": {
      "heading": "WebSocket endpoints",
      "description": "Real-time communication via WebSocket:",
      "endpoints": [
        "/ws/device-link: Relay for desktop-mobile device linking. Handles terminal output streaming, job status updates, and RPC commands between linked devices.",
        "/ws/events: General event stream for real-time updates."
      ],
      "implementation": "Device link relay in server/src/handlers/device_link_ws.rs. Sessions managed by services/relay_session_store.rs with heartbeat monitoring and reconnection support."
    },
    "serverStorage": {
      "heading": "Server-side persistence",
      "description": "PostgreSQL database with repositories in server/src/db/repositories/:",
      "repositories": [
        "user_repository.rs: User accounts linked to Auth0 sub.",
        "customer_billing_repository.rs: Stripe customer and credit state.",
        "credit_transaction_repository.rs: Credit transaction history.",
        "provider_repository.rs: LLM provider configuration.",
        "system_prompts_repository.rs: System prompt templates.",
        "consent_repository.rs: Legal consent tracking.",
        "audit_log_repository.rs: Audit trail for sensitive operations.",
        "revoked_token_repository.rs: JWT revocation list.",
        "api_key_repository.rs: API key management with secure hashing."
      ]
    }
  },
  "backgroundJobs": {
    "meta": {
      "title": "Background jobs - PlanToCode",
      "description": "Job queue architecture, processor types, state machine, and artifact storage for the desktop job engine."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "14 min",
    "title": "Background Jobs",
    "description": "Job queue, processors, state machine, event streaming, and artifact storage.",
    "intro": "All LLM-backed work runs through the background job system in the desktop app. The job queue dispatches work to processors, streams progress events, and persists every prompt and response in SQLite for audit and recovery. This architecture enables cancellation, retry, cost tracking, and real-time UI updates.",
    "visuals": {
      "stateMachine": {
        "title": "Job state machine",
        "description": "Diagram showing job status transitions from created through completion or failure.",
        "imageSrc": "/images/docs/background-jobs/state-machine.svg",
        "imageAlt": "Job state machine diagram",
        "caption": "Placeholder for job state machine diagram."
      }
    },
    "jobRecord": {
      "heading": "Job record structure",
      "description": "Each job creates a background_jobs row in SQLite with these fields:",
      "fields": [
        "id (TEXT PRIMARY KEY): UUID for the job.",
        "session_id (TEXT NOT NULL, FK): References sessions.id with CASCADE DELETE.",
        "task_type (TEXT DEFAULT 'unknown'): Processor identifier (e.g., implementation_plan, text_improvement, root_folder_selection).",
        "status (TEXT): Current state with CHECK constraint for valid values.",
        "prompt (TEXT NOT NULL): Full text sent to the LLM, stored for audit.",
        "response (TEXT): LLM output or error message.",
        "error_message (TEXT): Detailed error information on failure.",
        "tokens_sent (INTEGER DEFAULT 0): Input token count from provider response.",
        "tokens_received (INTEGER DEFAULT 0): Output token count.",
        "cache_read_tokens (INTEGER DEFAULT 0): Tokens read from provider cache (Anthropic).",
        "cache_write_tokens (INTEGER DEFAULT 0): Tokens written to cache.",
        "model_used (TEXT): Model identifier used for the request.",
        "actual_cost (REAL): Computed cost based on token usage and model pricing.",
        "metadata (TEXT): JSON with task-specific data, workflow IDs, stage names.",
        "system_prompt_template (TEXT): Template identifier used for the system prompt.",
        "server_request_id (TEXT): Links to server-side usage tracking.",
        "created_at, updated_at, start_time, end_time (INTEGER): Timestamps.",
        "is_finalized (INTEGER DEFAULT 0): Whether final cost/usage has been recorded."
      ]
    },
    "statusValues": {
      "heading": "Status values and transitions",
      "description": "Jobs transition through well-defined statuses tracked in the database:",
      "statuses": [
        "idle: Initial state before processing starts.",
        "created: Job record created, not yet queued.",
        "queued: Added to job queue, waiting for processor.",
        "acknowledged_by_worker: Processor has picked up the job.",
        "preparing: Processor is gathering inputs (files, prompts).",
        "preparing_input: Building the LLM request payload.",
        "running: Request sent to LLM, awaiting response.",
        "generating_stream: Streaming response in progress.",
        "processing_stream: Processing streamed chunks.",
        "completed: Job finished successfully.",
        "completed_by_tag: Completed via stream end tag detection.",
        "failed: Job failed with error_message populated.",
        "canceled: User requested cancellation."
      ],
      "transitions": "Transitions are enforced in background_job_repository/worker.rs. Invalid transitions are rejected. Status changes emit job:status-changed Tauri events."
    },
    "orchestrator": {
      "heading": "Workflow orchestrator",
      "description": "Multi-stage workflows are managed by WorkflowOrchestrator in desktop/src-tauri/src/jobs/workflow_orchestrator/:",
      "modules": [
        "mod.rs: Main orchestrator struct and workflow execution entry point.",
        "definition_loader.rs: Loads workflow JSON definitions (e.g., file_finder_workflow.json) specifying stage order and processor types.",
        "stage_scheduler.rs: Schedules stages sequentially, waits for upstream completion.",
        "stage_job_manager.rs: Creates background_job records for each stage.",
        "payload_builder.rs: Constructs stage inputs from IntermediateData.",
        "data_extraction.rs: Extracts outputs from completed stage jobs.",
        "event_emitter.rs: Publishes workflow-status and workflow-stage Tauri events.",
        "state_updater.rs: Updates workflow state in memory and database.",
        "completion_handler.rs: Handles workflow completion and cleanup.",
        "failure_handler.rs: Manages stage failures and retry decisions.",
        "retry_handler.rs: Implements retry logic with exponential backoff."
      ],
      "dataFlow": "Workflows use WorkflowIntermediateData (defined in workflow_types.rs) to pass outputs between stages: directoryTreeContent, selectedRoots, rawRegexPatterns, locallyFilteredFiles, aiFilteredFiles, verifiedPaths, unverifiedPaths."
    },
    "processors": {
      "heading": "Job processors",
      "description": "Each task_type maps to a processor in desktop/src-tauri/src/jobs/processors/:",
      "implementations": [
        "implementation_plan_processor.rs: Loads selected file contents, builds structured prompt with directory tree, streams XML plan to UI. Uses generic_llm_stream_processor for streaming.",
        "text_improvement_processor.rs: Wraps selection in XML tags, sends non-streaming request, returns improved text. Runs via LlmTaskRunner.",
        "root_folder_selection_processor.rs: Sends directory tree to LLM, parses JSON array response of selected directories.",
        "RegexFileFilterProcessor (in processors/mod.rs): Generates regex patterns from task, applies to git file list, filters binaries.",
        "FileRelevanceAssessmentProcessor: Chunks file contents by token limit, scores relevance in batches, aggregates relevant paths.",
        "ExtendedPathFinderProcessor (path_finder_types.rs): Analyzes imports/dependencies, suggests related files, validates paths exist.",
        "web_search_prompts_generator_processor.rs: Generates research_task XML blocks for deep research.",
        "web_search_executor_processor.rs: Executes research prompts in parallel via server search API.",
        "generic_llm_stream_processor.rs: Reusable streaming processor that handles chunk accumulation, event emission, and response finalization."
      ]
    },
    "events": {
      "heading": "Event streaming",
      "description": "Job progress emits Tauri events consumed by the React UI:",
      "eventTypes": [
        "job:status-changed: Payload {jobId, status, error?}. Emitted on every status transition.",
        "job:stream-progress: Payload {jobId, content, tokensReceived}. Emitted for each streaming chunk.",
        "job:completed: Payload {jobId, response, tokensTotal, cost}. Emitted on successful completion.",
        "workflow-status: Payload {workflowId, status, currentStage?}. Workflow-level status updates.",
        "workflow-stage: Payload {workflowId, stageName, status}. Individual stage status."
      ],
      "reactConsumption": "React components subscribe via useEffect with listen() from @tauri-apps/api/event. WorkflowTracker aggregates workflow events. JobStatusIndicator displays real-time status."
    },
    "retry": {
      "heading": "Retry and cancellation",
      "description": "Job retry and cancellation mechanisms:",
      "retryLogic": "retry_handler.rs manages retry counts and delays. Retries use exponential backoff with configurable max attempts. Retry state stored in job.metadata.retryCount.",
      "cancellation": "Cancellation sets a flag checked between streaming chunks in generic_llm_stream_processor.rs. Server-side cancellation sends /api/llm/cancel with request_id.",
      "cleanup": "workflow_cleanup.rs handles cleanup of incomplete workflows. Stale jobs (running status after app restart) are marked failed."
    },
    "artifacts": {
      "heading": "Artifact storage",
      "description": "Job inputs and outputs are fully persisted for audit:",
      "stored": [
        "prompt: Complete LLM prompt including system prompt and user content.",
        "response: Full LLM response text or streaming accumulation.",
        "metadata: JSON with task-specific data (original text for improvements, file lists, workflow context).",
        "system_prompt_template: Identifier linking to server-side prompt template version.",
        "Token counts and cost: Captured from provider response for billing and analysis."
      ],
      "access": "background_job_repository provides queries: get_jobs_for_session, get_job_by_id, get_jobs_by_task_type, get_recent_jobs. Job history displayed in BackgroundJobsSidebar component."
    },
    "costTracking": {
      "heading": "Cost tracking",
      "description": "Per-job cost tracking enables budget management:",
      "calculation": "Cost calculated using model pricing from server/src/models/model_pricing.rs. Formula: (tokens_sent * input_price + tokens_received * output_price) with cache adjustments.",
      "accumulation": "Session-level cost aggregated from background_jobs. UI displays cumulative cost in session header.",
      "serverSync": "server_request_id links desktop jobs to server-side usage records for billing reconciliation."
    },
    "cta": {
      "heading": "See the data model",
      "description": "Understand the SQLite schema that stores jobs, sessions, and terminal output.",
      "links": {
        "dataModel": "Data model",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "buildYourOwn": {
    "meta": {
      "title": "Build your own pipeline - PlanToCode",
      "description": "Conceptual guide for designing file discovery and plan generation workflows similar to PlanToCode."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Build Your Own Pipeline",
    "description": "Conceptual guide for designing file discovery and plan generation workflows.",
    "intro": "This guide distills the key architectural patterns from PlanToCode into a conceptual blueprint. Whether you want to build a similar system or understand why certain design decisions were made, this document covers the foundational patterns you can reuse or adapt.",
    "visuals": {
      "pipelineMap": {
        "title": "Pipeline architecture map",
        "description": "Overview of the multi-stage pipeline from task input to plan output.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Pipeline architecture diagram",
        "caption": "Placeholder for pipeline architecture diagram."
      }
    },
    "keyPatterns": {
      "heading": "Key Architectural Patterns",
      "jobQueue": {
        "title": "Job Queue Pattern",
        "description": "All LLM-backed operations run as background jobs with status tracking, cancellation support, and retry logic. Jobs are persisted to SQLite so state survives app restarts.",
        "benefits": [
          "Decouples UI responsiveness from LLM latency",
          "Enables cancellation mid-stream",
          "Provides audit trail of all operations",
          "Supports retry with exponential backoff"
        ],
        "pitfalls": [
          "Job status management adds complexity",
          "Need careful handling of stale jobs on restart",
          "Stream accumulation can consume memory for large responses"
        ]
      },
      "workflowOrchestrator": {
        "title": "Workflow Orchestrator Pattern",
        "description": "Multi-stage workflows are coordinated by an orchestrator that schedules stages sequentially, passes intermediate data between them, and handles failures at any stage.",
        "components": [
          "Definition loader reads workflow JSON specs",
          "Stage scheduler dispatches stages in order",
          "Payload builder constructs inputs from prior outputs",
          "Event emitter publishes progress for UI updates"
        ]
      },
      "repositoryPattern": {
        "title": "Repository Pattern",
        "description": "All persistence goes through typed repositories that abstract SQLite operations. This provides a clean API, enables testing, and centralizes database access.",
        "benefits": [
          "Typed access prevents SQL injection",
          "Repositories can be mocked for testing",
          "Centralized query optimization",
          "Consistent error handling"
        ]
      }
    },
    "steps": {
      "step1": {
        "title": "1. Define your task model",
        "description": "Start by defining what constitutes a task in your system. PlanToCode uses sessions with task descriptions, file selections, and model preferences.",
        "details": "Store task metadata in a dedicated table with versioning for history tracking."
      },
      "step2": {
        "title": "2. Build the job queue",
        "description": "Create a job queue that persists jobs to storage, emits status events, and supports cancellation. Jobs should track prompts, responses, tokens, and cost.",
        "details": "Use a semaphore-based concurrency limiter to control parallel LLM requests."
      },
      "step3": {
        "title": "3. Implement processors",
        "description": "Each job type needs a processor that builds prompts, calls the LLM, and parses responses. Use streaming for long outputs.",
        "details": "Processors should be stateless and receive all context through job parameters."
      },
      "step4": {
        "title": "4. Create the workflow orchestrator",
        "description": "For multi-stage workflows, build an orchestrator that schedules stages, manages intermediate data, and handles failures.",
        "details": "Store workflow definitions as JSON for easy modification without code changes."
      },
      "step5": {
        "title": "5. Add the routing layer",
        "description": "Route LLM requests through a server proxy that normalizes payloads, manages API keys, and tracks usage.",
        "details": "Keep provider credentials on the server; never embed them in desktop clients."
      }
    },
    "architectureDecisions": {
      "heading": "Architecture Decisions",
      "decisions": [
        {
          "question": "Should you use a local database or server-side storage?",
          "recommendation": "Use local SQLite for job state and artifacts. This enables offline operation and fast queries. Sync to server only for billing and cross-device state."
        },
        {
          "question": "Streaming vs non-streaming responses?",
          "recommendation": "Use streaming for plan generation and any output shown progressively. Use non-streaming for short transformations like text improvement."
        },
        {
          "question": "How to handle LLM provider failures?",
          "recommendation": "Implement automatic retry with exponential backoff. Consider a fallback provider like OpenRouter for resilience."
        },
        {
          "question": "Where should file content be loaded?",
          "recommendation": "Load file content in the processor just before building the prompt. This ensures fresh content and avoids storing large blobs in job records."
        }
      ]
    },
    "customizeVsReuse": {
      "heading": "What to Customize vs Reuse",
      "customize": [
        "Prompt templates for your specific use case",
        "File discovery patterns for your project types",
        "Output format (XML, JSON, Markdown)",
        "Model selection per task type"
      ],
      "reuse": [
        "Job queue architecture with status tracking",
        "Workflow orchestrator pattern",
        "Repository pattern for persistence",
        "Streaming response handling",
        "Provider routing and normalization"
      ]
    },
    "commonPitfalls": {
      "heading": "Common Pitfalls to Avoid",
      "items": [
        {
          "pitfall": "Embedding API keys in the client",
          "solution": "Route all LLM requests through a server proxy that manages credentials securely."
        },
        {
          "pitfall": "Not persisting job state",
          "solution": "Store every job with full prompt and response for audit and recovery."
        },
        {
          "pitfall": "Blocking UI on LLM calls",
          "solution": "Use background jobs with event-driven UI updates for responsive interfaces."
        },
        {
          "pitfall": "Ignoring token limits",
          "solution": "Estimate tokens before sending and chunk large inputs to stay within context windows."
        },
        {
          "pitfall": "No cancellation support",
          "solution": "Check cancellation flags between streaming chunks and propagate to server."
        }
      ]
    },
    "artifacts": {
      "heading": "Artifacts to Persist",
      "items": [
        "Full prompt sent to the LLM (for debugging and audit)",
        "Complete response including streaming accumulation",
        "Token counts from provider response",
        "Computed cost based on model pricing",
        "System prompt template identifier for versioning",
        "Workflow intermediate data for multi-stage flows"
      ]
    },
    "implementationNotes": {
      "heading": "Implementation Notes",
      "items": [
        "Use SQLite with WAL mode for concurrent read/write access",
        "Implement graceful shutdown that marks running jobs as failed",
        "Add health checks for external dependencies before job processing",
        "Log all LLM errors with full context for debugging",
        "Consider caching file content with short TTL to avoid redundant reads"
      ]
    }
  },
  "decisionsTradeoffs": {
    "meta": {
      "title": "Technical decisions and tradeoffs - PlanToCode",
      "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen, and what operational tradeoffs they create."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Technical Decisions & Tradeoffs",
    "description": "Why Tauri, SQLite, and a dedicated LLM proxy were chosen and what they cost.",
    "intro": "Every architecture involves tradeoffs. This document explains the major technology choices in PlanToCode, what benefits they provide, and what costs or limitations they introduce.",
    "visuals": {
      "tradeoffMatrix": {
        "title": "Tradeoff matrix",
        "description": "Visual comparison of technology choices with their benefits and costs.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "Technology tradeoff matrix",
        "caption": "System architecture overview illustrating the technology stack decisions."
      }
    },
    "sections": {
      "tauri": {
        "title": "Tauri v2 for Desktop",
        "description": "Tauri provides a Rust backend with a web-based frontend, enabling cross-platform desktop apps with native performance and small binary sizes.",
        "benefits": [
          "Small binary size (~15MB vs 200MB+ for Electron)",
          "Native Rust performance for file operations and job processing",
          "Capability-based security model with fine-grained permissions",
          "Single codebase for macOS, Windows, and Linux",
          "Access to system APIs (PTY, keychain, notifications)"
        ],
        "tradeoffs": [
          "Smaller ecosystem than Electron",
          "Rust learning curve for backend development",
          "WebView rendering differences across platforms",
          "Less mature tooling for debugging IPC issues"
        ],
        "implementation": "PlanToCode uses Tauri 2.9.1 with ~35 command modules, capability-based permissions, and plugins for shell, dialog, and notifications."
      },
      "sqlite": {
        "title": "SQLite for Local Persistence",
        "description": "SQLite stores all local state including sessions, jobs, terminal output, and settings. This enables offline operation and fast queries.",
        "benefits": [
          "Zero-config embedded database",
          "Fast queries for local data",
          "Enables offline operation",
          "Single file backup and restore",
          "WAL mode for concurrent access"
        ],
        "tradeoffs": [
          "No built-in replication or sync",
          "Large terminal logs can grow the database",
          "Need manual schema migrations",
          "Single-writer limitation (mitigated by WAL)"
        ],
        "implementation": "Schema in consolidated_schema.sql with ~10 tables. Repositories provide typed access with rusqlite."
      },
      "llmProxy": {
        "title": "Dedicated LLM Proxy Server",
        "description": "All LLM requests route through a server proxy that manages API keys, normalizes requests, tracks usage, and handles billing.",
        "benefits": [
          "API keys never leave the server",
          "Single request format for all providers",
          "Centralized usage tracking and billing",
          "Provider failover without client updates",
          "Content filtering and rate limiting"
        ],
        "tradeoffs": [
          "Requires server infrastructure",
          "Adds network latency to requests",
          "Server becomes single point of failure",
          "Need to maintain provider integrations"
        ],
        "implementation": "Actix-Web server with handlers in server/src/handlers/proxy/. Transformers in provider_transformers/ normalize requests."
      },
      "websocket": {
        "title": "WebSocket Relay for Mobile",
        "description": "Desktop and mobile clients connect through a WebSocket relay for device linking, terminal streaming, and job synchronization.",
        "benefits": [
          "Real-time bidirectional communication",
          "No direct P2P networking required",
          "Works across NAT and firewalls",
          "Supports multiple linked devices"
        ],
        "tradeoffs": [
          "Requires persistent server connections",
          "Relay adds latency for large payloads",
          "Connection management complexity",
          "Need reconnection and heartbeat logic"
        ],
        "implementation": "device_link_ws.rs implements the relay with session tracking, heartbeats, and PTC1 binary framing for terminal output."
      }
    },
    "operational": {
      "heading": "Operational Consequences",
      "items": [
        "Tauri: Need separate builds for each platform. CI/CD must cross-compile or use platform-specific runners.",
        "SQLite: Database file grows with terminal output. May need periodic cleanup for long-running instances.",
        "LLM Proxy: Server downtime blocks all LLM operations. Need monitoring and redundancy for production.",
        "WebSocket: Reconnection logic adds complexity. Clients must handle connection drops gracefully."
      ]
    },
    "securityBoundaries": {
      "heading": "Security Boundaries",
      "description": "The architecture creates clear security boundaries that limit exposure:",
      "items": [
        "API keys stored in server vault, never sent to clients",
        "JWT tokens validated on every request with JWKS rotation",
        "Capability-based permissions limit filesystem access",
        "Content sent to LLMs requires explicit user approval",
        "Audit logs track all LLM requests with user context"
      ]
    },
    "whenToReconsider": {
      "heading": "When to Reconsider",
      "description": "These decisions may need revisiting if requirements change significantly:",
      "items": [
        "If browser-only access is required, consider a web-based alternative to Tauri",
        "If multi-device sync is critical, consider server-side job storage",
        "If provider lock-in is acceptable, direct API calls may reduce latency",
        "If mobile is primary, consider native apps instead of device linking"
      ]
    }
  },
  "dataModel": {
    "meta": {
      "title": "Data model and storage - PlanToCode",
      "description": "SQLite entities, relationships, and how state is rehydrated on app restart."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Data Model & Storage",
    "description": "SQLite entities, relationships, and how state is rehydrated.",
    "intro": "PlanToCode uses SQLite for all local state. This document describes the schema, entity relationships, and how state is restored when the app restarts.",
    "sqlite": {
      "heading": "SQLite Configuration",
      "description": "The database uses WAL mode for concurrent read/write access. The file is stored in the Tauri app data directory (~/.local/share/plantocode on Linux, ~/Library/Application Support/plantocode on macOS).",
      "migrations": "Schema migrations are consolidated in consolidated_schema.sql. The app checks schema version on startup and runs any pending migrations."
    },
    "entities": {
      "heading": "Core Entities",
      "items": [
        "sessions: Project context with task description, file selections, model preferences, search settings, video/merge prompts, history indexes",
        "background_jobs: LLM-backed operations with prompt, response, tokens, cost, is_finalized flag, error_message",
        "terminal_sessions: PTY sessions with output log, status, process info",
        "task_description_history: Version history for task descriptions",
        "file_selection_history: Version history for file selections",
        "project_system_prompts: Per-project prompt overrides",
        "key_value_store: App settings and configuration",
        "error_logs: Client-side error tracking",
        "migrations: Tracks applied database migrations with timestamps",
        "db_diagnostic_logs: Records database diagnostic issues and errors",
        "app_settings: Application configuration key-value pairs with descriptions"
      ]
    },
    "visuals": {
      "schema": {
        "title": "Entity relationship diagram",
        "description": "Visual representation of the SQLite schema and relationships.",
        "imageSrc": "/images/docs/data-model/schema.svg",
        "imageAlt": "Database schema diagram",
        "caption": "Placeholder for database schema diagram."
      }
    },
    "relationships": {
      "heading": "Entity Relationships",
      "description": "Entities are linked through foreign keys with cascade delete rules:",
      "links": [
        "sessions → background_jobs: One-to-many, cascade delete",
        "background_jobs → terminal_sessions: Optional one-to-one link via job_id",
        "sessions → task_description_history: One-to-many for version tracking",
        "sessions → file_selection_history: One-to-many for version tracking"
      ]
    },
    "repositories": {
      "heading": "Repository Layer",
      "description": "All database access goes through typed repositories in desktop/src-tauri/src/db_utils/:",
      "examples": [
        "background_job_repository/: Modular with base.rs, worker.rs, metadata.rs, cleanup.rs",
        "session_repository.rs: Session CRUD with history management",
        "terminal_repository.rs: Terminal session persistence and output logging",
        "settings_repository.rs: Key-value settings storage"
      ]
    },
    "rehydration": {
      "heading": "State Rehydration",
      "description": "When the app starts, state is restored from SQLite:",
      "sessions": "Active session is loaded with task description, file selections, and model preferences. Recent sessions are available in the session picker."
    },
    "retention": {
      "heading": "Data Retention",
      "description": "Old data is cleaned up based on configurable retention periods:",
      "exports": "Sessions and jobs can be exported for backup before cleanup."
    },
    "cta": {
      "heading": "Explore job processing",
      "description": "See how background jobs use this data model.",
      "links": {
        "jobs": "Background jobs",
        "terminals": "Terminal sessions"
      }
    }
  },
  "serverSetup": {
    "meta": {
      "title": "Dedicated server setup - PlanToCode",
      "description": "Ansible-based infrastructure setup: base hardening, PostgreSQL, Redis, and application deployment."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "Dedicated Server Setup",
    "description": "Ansible-based infrastructure: base hardening, app deployment, and vault-managed secrets.",
    "intro": "PlanToCode runs on dedicated servers managed through Ansible playbooks. This document covers the infrastructure setup, security hardening, and deployment process.",
    "layers": {
      "heading": "Infrastructure Layers",
      "description": "The infrastructure is organized into layers, each managed by dedicated playbooks:",
      "items": [
        "Base layer: OS hardening, SSH configuration, firewall rules",
        "Database layer: PostgreSQL 17 with replication and backups",
        "Cache layer: Redis 7+ for session state and job queues",
        "Application layer: Rust server binary with systemd service",
        "Proxy layer: Nginx reverse proxy with SSL termination"
      ]
    },
    "servers": {
      "heading": "Server Regions",
      "description": "PlanToCode runs in two regions for geographic redundancy:",
      "items": [
        "EU region: Hetzner dedicated server (api-eu.plantocode.com)",
        "US region: InterServer dedicated server (api-us.plantocode.com)"
      ]
    },
    "requirements": {
      "heading": "Server Requirements",
      "items": [
        "Debian 12 or Ubuntu 22.04 LTS",
        "4+ CPU cores, 16GB+ RAM, 200GB+ SSD",
        "Public IPv4 with firewall access to ports 22, 80, 443",
        "SSH key access for Ansible deployment"
      ]
    },
    "hardening": {
      "heading": "Base Hardening",
      "description": "site-base.yml applies security hardening:",
      "items": [
        "Disable root SSH login, require key authentication",
        "Configure UFW firewall with minimal open ports",
        "Install fail2ban for brute force protection",
        "Enable automatic security updates",
        "Configure audit logging"
      ]
    },
    "postgresql": {
      "heading": "PostgreSQL Setup",
      "description": "PostgreSQL 17 is configured for production use:",
      "items": [
        "Connection pooling with PgBouncer",
        "Automated daily backups with pg_dump",
        "WAL archiving for point-in-time recovery",
        "SSL required for all connections",
        "Row-level security for multi-tenant data"
      ]
    },
    "redis": {
      "heading": "Redis Setup",
      "description": "Redis 7+ handles caching and session state:",
      "items": [
        "Password authentication required",
        "AOF persistence for durability",
        "Memory limits with eviction policy",
        "TLS encryption for connections"
      ]
    },
    "zeroDowntime": {
      "heading": "Zero-Downtime Deployment",
      "description": "Deployments use a rolling update strategy:",
      "items": [
        "New binary uploaded alongside running version",
        "Health check confirms new version is ready",
        "Systemd restarts with graceful shutdown",
        "Load balancer drains connections during switch",
        "Rollback available via previous binary symlink"
      ]
    },
    "quickStart": {
      "heading": "Quick Start",
      "steps": [
        "Clone the infrastructure repository",
        "Copy inventory.example to inventory and configure hosts",
        "Set vault password in .vault_pass",
        "Run: ansible-playbook -i inventory site-base.yml",
        "Run: ansible-playbook -i inventory site-app.yml"
      ]
    },
    "vault": {
      "heading": "Secrets Management",
      "description": "Sensitive configuration uses Ansible Vault:",
      "items": [
        "Database credentials",
        "API keys for LLM providers",
        "SSL certificates and private keys",
        "Auth0 client secrets",
        "Stripe webhook secrets"
      ]
    },
    "operations": {
      "heading": "Common Operations",
      "items": [
        "ansible-playbook -i inventory site-app.yml --tags deploy",
        "ansible-playbook -i inventory site-base.yml --tags backup",
        "ansible-playbook -i inventory site-app.yml --tags rollback",
        "ansible-playbook -i inventory site-base.yml --tags logs"
      ]
    },
    "ssl": {
      "heading": "SSL/TLS Configuration",
      "description": "Let's Encrypt provides free SSL certificates:",
      "items": [
        "Certbot configured with Nginx plugin",
        "Automatic renewal via cron job",
        "HSTS headers enabled",
        "TLS 1.2+ only, modern cipher suite"
      ]
    },
    "security": {
      "heading": "Security Checklist",
      "items": [
        "All default passwords changed",
        "SSH key rotation scheduled",
        "Firewall rules audited",
        "Security updates automated",
        "Backup restoration tested"
      ]
    },
    "recovery": {
      "heading": "Disaster Recovery",
      "description": "Recovery procedures for common failure scenarios:",
      "items": [
        "Database corruption: Restore from latest pg_dump backup",
        "Server failure: Provision new server and run playbooks",
        "SSL expiration: Manual certbot renew --force-renewal",
        "Security breach: Rotate all credentials, audit logs"
      ]
    }
  },
  "tauriV2": {
    "meta": {
      "title": "Tauri v2 development guide - PlanToCode",
      "description": "Project layout, commands, capabilities, and development workflow for Tauri v2."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Tauri v2 Development Guide",
    "description": "Project layout, commands, and capability-based permissions for Tauri v2.",
    "intro": "PlanToCode uses Tauri v2 for the desktop application. This guide covers the project structure, command system, capability-based permissions, and development workflow.",
    "projectLayout": {
      "heading": "Project Layout",
      "description": "The desktop application follows standard Tauri v2 conventions:",
      "items": [
        "desktop/src/: React frontend with components, hooks, and providers",
        "desktop/src-tauri/: Rust backend with commands, jobs, and services",
        "desktop/src-tauri/src/lib.rs: Application entry point",
        "desktop/src-tauri/src/commands/: Tauri command handlers (~35 modules)",
        "desktop/src-tauri/capabilities/: Permission definitions",
        "desktop/src-tauri/tauri.conf.json: Tauri configuration"
      ]
    },
    "configuration": {
      "heading": "Tauri Configuration",
      "description": "tauri.conf.json configures the application:",
      "items": [
        "productName, version, identifier for app metadata",
        "build.beforeDevCommand and beforeBuildCommand for frontend",
        "bundle settings for installers (DMG, NSIS, AppImage)",
        "security.csp for Content Security Policy",
        "plugins configuration for official plugins"
      ]
    },
    "capabilities": {
      "heading": "Capability-Based Permissions",
      "description": "Tauri v2 uses capabilities to control what the app can access:",
      "items": [
        "default.json: Base permissions for all windows",
        "desktop-default.json: Desktop-specific permissions",
        "plantocode-api.json: Custom permissions for PlanToCode commands",
        "Permissions grant access to: filesystem, shell, http, dialog, notification"
      ]
    },
    "plugins": {
      "heading": "Tauri Plugins",
      "description": "PlanToCode uses several official Tauri plugins:",
      "items": [
        "tauri-plugin-http: HTTP client for API calls",
        "tauri-plugin-dialog: Native file/folder pickers",
        "tauri-plugin-shell: Shell command execution",
        "tauri-plugin-store: Persistent key-value storage",
        "tauri-plugin-notification: Desktop notifications",
        "tauri-plugin-updater: In-app updates",
        "tauri-plugin-single-instance: Single instance enforcement"
      ]
    },
    "appState": {
      "heading": "Application State",
      "description": "Rust state managed through Tauri's state system:",
      "items": [
        "AppState struct holds shared state",
        "RuntimeConfig for server URLs and feature flags",
        "TokenManager for secure credential storage",
        "ConfigCache for AI model configuration"
      ]
    },
    "commands": {
      "heading": "Creating Commands",
      "description": "Tauri commands expose Rust functions to the frontend:",
      "items": [
        "Use #[tauri::command] attribute on async functions",
        "Return Result<T, String> for error handling",
        "Access state via State<AppState> parameter",
        "Register in lib.rs invoke_handler"
      ]
    },
    "singleInstance": {
      "heading": "Single Instance",
      "description": "The app enforces single instance to prevent data conflicts:",
      "items": [
        "tauri-plugin-single-instance handles detection",
        "Second launch focuses existing window",
        "Deep links forwarded to running instance"
      ]
    },
    "devWorkflow": {
      "heading": "Development Workflow",
      "description": "Common commands for development:",
      "items": [
        "pnpm tauri dev: Start development with hot reload",
        "pnpm tauri build: Build production release",
        "cargo test: Run Rust tests",
        "cargo clippy: Lint Rust code"
      ]
    },
    "mobile": {
      "heading": "Mobile Considerations",
      "description": "Tauri v2 supports mobile, but PlanToCode uses native Swift:",
      "items": [
        "iOS app built with SwiftUI for native experience",
        "Shared API contracts between desktop and mobile",
        "Device linking via WebSocket relay"
      ]
    },
    "distribution": {
      "heading": "Distribution",
      "description": "Build artifacts for each platform:",
      "items": [
        "macOS: .dmg with universal binary (Intel + Apple Silicon)",
        "Windows: NSIS installer and MSIX package",
        "Linux: AppImage for broad compatibility"
      ]
    }
  },
  "distributionMacos": {
    "meta": {
      "title": "macOS distribution - PlanToCode",
      "description": "Code signing, notarization, DMG packaging, and updater configuration for macOS."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "macOS Distribution",
    "description": "Signing, notarization, DMG packaging, and updater artifacts.",
    "intro": "Distributing on macOS requires code signing, notarization, and proper packaging. This document covers the complete process for PlanToCode.",
    "signing": {
      "heading": "Code Signing",
      "description": "All binaries must be signed with an Apple Developer ID:",
      "items": [
        "Developer ID Application certificate for app signing",
        "Developer ID Installer certificate for PKG signing",
        "Certificates stored in CI secrets, imported to keychain",
        "Hardened runtime enabled for notarization compatibility"
      ]
    },
    "entitlements": {
      "heading": "Entitlements",
      "description": "Required entitlements for PlanToCode features:",
      "items": [
        "com.apple.security.cs.allow-jit",
        "com.apple.security.cs.allow-unsigned-executable-memory",
        "com.apple.security.device.audio-input",
        "com.apple.security.network.client",
        "com.apple.security.files.user-selected.read-write"
      ]
    },
    "build": {
      "heading": "Build Process",
      "description": "Steps to build a signed release:",
      "steps": [
        "Run pnpm tauri build --target universal-apple-darwin",
        "Tauri signs with APPLE_SIGNING_IDENTITY from environment",
        "Universal binary created with lipo for Intel + ARM",
        "DMG packaged with custom background and layout"
      ]
    },
    "universalBinaries": {
      "heading": "Universal Binaries",
      "description": "PlanToCode ships as a universal binary:",
      "items": [
        "Single .app supports both Intel and Apple Silicon",
        "Built with --target universal-apple-darwin",
        "Slightly larger binary but simpler distribution",
        "Native performance on both architectures"
      ]
    },
    "notarization": {
      "heading": "Notarization",
      "description": "Apple notarization is required for Gatekeeper approval:",
      "items": [
        "DMG submitted to Apple notary service",
        "Uses notarytool with App Store Connect credentials",
        "Stapling attaches notarization ticket to DMG",
        "Process takes 1-5 minutes typically"
      ]
    },
    "updater": {
      "heading": "In-App Updates",
      "description": "tauri-plugin-updater handles automatic updates:",
      "items": [
        "Checks update endpoint on launch",
        "Downloads new version in background",
        "Prompts user to restart to apply",
        "Signature verification before installation"
      ]
    },
    "latestJson": {
      "heading": "Update Manifest",
      "description": "latest.json describes available updates:",
      "items": [
        "version: Semantic version string",
        "platforms.darwin-universal: URL and signature",
        "notes: Release notes in markdown",
        "pub_date: ISO 8601 publish timestamp"
      ]
    },
    "pitfalls": {
      "heading": "Common Pitfalls",
      "description": "Issues frequently encountered:",
      "items": [
        "Keychain locked during CI: Unlock before signing",
        "Notarization timeout: Retry with exponential backoff",
        "Invalid signature: Check entitlements match capabilities",
        "Gatekeeper rejection: Verify notarization stapled correctly"
      ]
    },
    "verification": {
      "heading": "Verification Commands",
      "description": "Commands to verify signing and notarization:",
      "items": [
        "codesign -dv --verbose=4 PlanToCode.app",
        "spctl --assess --verbose PlanToCode.app",
        "stapler validate PlanToCode.dmg",
        "xcrun notarytool log <submission-id>"
      ]
    }
  },
  "distributionWindows": {
    "meta": {
      "title": "Windows distribution - PlanToCode",
      "description": "NSIS installer, MSIX packaging, Microsoft Store submission, and code signing for Windows."
    },
    "category": "Deployment",
    "date": "2025-09-25",
    "readTime": "10 min",
    "title": "Windows Distribution & Store",
    "description": "NSIS builds, MSIX packaging, and Microsoft Store submission.",
    "intro": "PlanToCode distributes on Windows through both direct download (NSIS installer) and the Microsoft Store (MSIX package). This document covers both distribution methods.",
    "prereqs": {
      "heading": "Prerequisites",
      "description": "Required tools and certificates:",
      "items": [
        "Code signing certificate (EV or standard)",
        "Windows SDK for signtool",
        "NSIS for installer building",
        "MSIX Packaging Tool for Store submissions"
      ]
    },
    "nsisBuild": {
      "heading": "NSIS Installer",
      "description": "Tauri builds NSIS installers by default:",
      "items": [
        "Custom installer UI with PlanToCode branding",
        "Per-user installation (no admin required)",
        "Start menu and desktop shortcuts",
        "Uninstaller with clean removal"
      ]
    },
    "codeSigning": {
      "heading": "Code Signing",
      "description": "Windows code signing with Authenticode:",
      "items": [
        "Sign with signtool from Windows SDK",
        "Timestamp from trusted TSA server",
        "EV certificate provides SmartScreen reputation",
        "CI uses secrets for certificate and password"
      ]
    },
    "msixPackaging": {
      "heading": "MSIX for Microsoft Store",
      "description": "MSIX provides Store-compatible packaging:",
      "items": [
        "AppxManifest.xml defines capabilities",
        "Virtual filesystem isolation",
        "Automatic updates through Store",
        "Sandboxed execution environment"
      ]
    },
    "msixConfig": {
      "heading": "MSIX Configuration",
      "description": "Key AppxManifest settings:",
      "items": [
        "Identity: Name, Publisher, Version",
        "Capabilities: internetClient, microphone",
        "Visual elements: Tiles, splash screen",
        "File associations and protocol handlers"
      ]
    },
    "msixSteps": {
      "heading": "MSIX Build Steps",
      "description": "Process to create MSIX package:",
      "steps": [
        "Build release with pnpm tauri build",
        "Create AppxManifest.xml with correct identity",
        "Package with MakeAppx.exe",
        "Sign with SignTool",
        "Validate with Windows App Cert Kit"
      ]
    },
    "store": {
      "heading": "Microsoft Store Submission",
      "description": "Store submission process:",
      "items": [
        "Create app in Partner Center",
        "Upload MSIX package",
        "Configure pricing (free with IAP credits)",
        "Submit for certification",
        "Review takes 1-3 business days"
      ]
    },
    "updaterWindows": {
      "heading": "Windows Updates",
      "description": "Update mechanisms for each distribution:",
      "items": [
        "NSIS: tauri-plugin-updater with GitHub releases",
        "MSIX/Store: Automatic through Microsoft Store",
        "Both check for updates on launch"
      ]
    },
    "webview2": {
      "heading": "WebView2 Runtime",
      "description": "Tauri uses WebView2 on Windows:",
      "items": [
        "Bundled WebView2 bootstrapper in installer",
        "Evergreen version auto-updates",
        "Fixed version available for isolation",
        "Windows 10 1803+ required"
      ]
    },
    "troubleshooting": {
      "heading": "Troubleshooting",
      "description": "Common Windows distribution issues:",
      "items": [
        "SmartScreen warning: Use EV certificate or build reputation",
        "Missing WebView2: Ensure bootstrapper runs",
        "Store rejection: Review certification report details",
        "Update failure: Check signature and manifest version"
      ]
    }
  },
  "promptTypes": {
    "meta": {
      "title": "Prompt types and templates - PlanToCode",
      "description": "Catalog of prompt-driven job types and template assembly process."
    },
    "category": "Reference",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Prompt Types & Templates",
    "description": "Catalog of prompt-driven job types and template assembly.",
    "intro": "Every LLM-backed job in PlanToCode uses a structured prompt built from templates. This document catalogs the job types and explains how prompts are assembled.",
    "catalog": {
      "heading": "Job Type Catalog",
      "items": [
        {
          "job": "implementation_plan",
          "title": "Implementation Plan",
          "description": "Generates file-by-file implementation plans with XML structure. Uses streaming for progressive display."
        },
        {
          "job": "implementation_plan_merge",
          "title": "Plan Merge",
          "description": "Combines multiple plans with user instructions. Source plans wrapped in XML tags."
        },
        {
          "job": "text_improvement",
          "title": "Text Improvement",
          "description": "Refines selected text while preserving formatting. Non-streaming for quick results."
        },
        {
          "job": "root_folder_selection",
          "title": "Root Folder Selection",
          "description": "Analyzes directory tree to select relevant project roots. Returns JSON array."
        },
        {
          "job": "regex_file_filter",
          "title": "Regex File Filter",
          "description": "Generates regex patterns for file filtering based on task description."
        },
        {
          "job": "file_relevance_assessment",
          "title": "File Relevance Assessment",
          "description": "Scores file content relevance to task. Processes in batches."
        },
        {
          "job": "extended_path_finder",
          "title": "Extended Path Finder",
          "description": "Discovers related files through imports and dependencies."
        },
        {
          "job": "web_search_prompts",
          "title": "Web Search Prompts",
          "description": "Generates research queries for deep research workflow."
        },
        {
          "job": "video_analysis",
          "title": "Video Analysis",
          "description": "Analyzes screen recordings for UI state and action sequences."
        }
      ]
    },
    "templateStructure": {
      "heading": "Template Structure",
      "description": "Prompts are assembled from system templates and user content:",
      "sampleLabel": "Example template structure:",
      "sample": "<system_prompt>\n  You are an AI assistant that generates implementation plans.\n  [template content from server]\n</system_prompt>\n\n<task>\n  [user's task description]\n</task>\n\n<files>\n  [selected file paths and content]\n</files>\n\n<directory_tree>\n  [project structure]\n</directory_tree>"
    },
    "visuals": {
      "template": {
        "title": "Prompt assembly flow",
        "description": "How templates combine with user content to form complete prompts.",
        "imageSrc": "/images/docs/implementation-plans/structure.svg",
        "imageAlt": "Prompt template assembly diagram",
        "caption": "Placeholder for prompt assembly diagram."
      }
    },
    "assembly": {
      "heading": "Assembly Process",
      "steps": [
        "Processor retrieves template ID from task model config",
        "System prompt template loaded from server cache",
        "User content wrapped in semantic XML tags",
        "Context (files, tree) added based on job type",
        "Complete prompt stored in job record before sending"
      ]
    },
    "serverConfig": {
      "heading": "Server-Side Configuration",
      "description": "Templates and model settings are configured server-side:",
      "fields": "task_model_config defines: default_model, allowed_models, system_prompt_template_id, max_tokens, temperature"
    },
    "tokenGuards": {
      "heading": "Token Guardrails",
      "description": "Each task type has token limits to prevent context overflow:",
      "items": [
        "max_tokens_input: Maximum prompt size",
        "max_tokens_output: Maximum response size",
        "Validation before sending prevents wasted API calls",
        "UI shows token count and warns when approaching limits"
      ]
    },
    "versioning": {
      "heading": "Template Versioning",
      "description": "System prompt templates are versioned for reproducibility. Each job records the template ID used, enabling audit and comparison of results across template versions."
    },
    "designNotes": {
      "heading": "Design Notes",
      "items": [
        "XML tags provide clear boundaries for LLM parsing",
        "Semantic naming (task, files, context) aids model understanding",
        "Templates avoid instruction injection by sanitizing user input",
        "Streaming jobs use end tags for completion detection"
      ]
    },
    "cta": {
      "heading": "See job processing in action",
      "description": "Learn how these prompts flow through the job system.",
      "links": {
        "jobs": "Background jobs",
        "merge": "Merge instructions"
      }
    }
  },
  "mergeInstructionsDoc": {
    "meta": {
      "title": "Merge instructions - PlanToCode",
      "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance."
    },
    "category": "Planning",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Merge Instructions",
    "description": "How multiple plan drafts are merged using XML-tagged source plans and user guidance.",
    "intro": "When you have multiple implementation plans that need to be combined, the merge workflow lets you select plans, provide guidance, and generate a unified plan that incorporates the best elements from each source.",
    "processor": {
      "heading": "ImplementationPlanMergeProcessor",
      "description": "The ImplementationPlanMergeProcessor fetches source plan responses, wraps them in XML-tagged sections, and streams the merged result through the LlmTaskRunner.",
      "payload": "Accepts source_job_ids array, optional merge_instructions string, and inherits model configuration from the session.",
      "storage": "Merged plan stored as JobResultData::Text with metadata including source_job_ids, merge_instructions, source_count, merged_at timestamp, and session context."
    },
    "inputs": {
      "heading": "Merge Inputs",
      "items": [
        "Source plans: 2-5 implementation plans selected from the plan list",
        "Merge instructions: User guidance on how to combine (prioritize, resolve conflicts)",
        "Model selection: LLM model for merge generation",
        "Task context: Original task description for reference"
      ]
    },
    "xmlFormat": {
      "heading": "XML-Tagged Source Plans",
      "description": "Source plans are wrapped in XML tags with sequential identifiers:",
      "example": "<task_description>\n  [original task from session]\n</task_description>\n\n<source_plans>\n  <implementation_plan_1>\n    [full plan content from first source]\n  </implementation_plan_1>\n  <implementation_plan_2>\n    [full plan content from second source]\n  </implementation_plan_2>\n</source_plans>\n\n<user_instructions>\n  Prioritize API structure from plan 1.\n  Use database schema from plan 2.\n  Resolve conflicts by preferring newer patterns.\n</user_instructions>"
    },
    "prompt": {
      "heading": "Merge Prompt Structure",
      "description": "The merge prompt includes all context needed for intelligent combination:",
      "sections": [
        "System prompt with merge guidelines",
        "Source plans in XML tags",
        "User's merge instructions",
        "Task description for context",
        "Output format requirements"
      ]
    },
    "visuals": {
      "mergeWalkthrough": {
        "title": "Merge workflow walkthrough",
        "description": "Video showing the complete merge process from selection to output.",
        "videoSrc": "/videos/docs/merge-instructions/walkthrough.mp4",
        "posterSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Placeholder for merge walkthrough video."
      },
      "mergeFlow": {
        "title": "Merge instructions flow",
        "description": "Diagram showing multi-model merge workflow with XML-tagged source plans.",
        "imageSrc": "/images/docs/merge-instructions/flow.svg",
        "caption": "Merge flow showing source selection, instruction processing, and output generation"
      }
    },
    "rules": {
      "heading": "Merge Rules",
      "description": "The LLM follows these rules when merging plans:",
      "examples": [
        "Preserve file paths exactly as specified in source plans",
        "Combine non-conflicting changes from all sources",
        "For conflicts, follow explicit user instructions",
        "Maintain consistent code style across merged content",
        "Include provenance comments indicating source plan"
      ]
    },
    "output": {
      "heading": "Merged Output",
      "description": "The merged plan is returned as raw text from the LLM, following the same flexible format as individual plans.",
      "provenance": "Each section includes comments indicating which source plan contributed the content.",
      "metadata": "source_job_ids, merge_instructions, source_count, merged_at timestamp, planTitle, summary, isStructured (false), and sessionName stored in job metadata."
    },
    "ui": {
      "heading": "UI Integration",
      "description": "The Implementation Plans panel supports merge workflow:",
      "audit": "Merged plans link back to source plans for complete audit trail."
    },
    "cta": {
      "heading": "Learn about plan generation",
      "description": "Understand how individual plans are created before merging.",
      "links": {
        "plans": "Implementation plans",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "meetingIngestionDoc": {
    "meta": {
      "title": "Meeting and recording ingestion - PlanToCode",
      "description": "How recordings become structured task inputs and artifacts through video analysis."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "8 min",
    "title": "Meeting & Recording Ingestion",
    "description": "How recordings become structured task inputs and artifacts.",
    "intro": "PlanToCode can process meeting recordings and screen captures to extract task-relevant information. This document describes the ingestion workflow from recording to structured artifacts.",
    "visuals": {
      "ingestionFlow": {
        "title": "Recording ingestion flow",
        "description": "How recordings flow through transcription and analysis.",
        "imageSrc": "/images/docs/deep-research/workflow.svg",
        "imageAlt": "Recording ingestion flow diagram",
        "caption": "Placeholder for ingestion flow diagram."
      }
    },
    "inputs": {
      "heading": "Supported Inputs",
      "description": "The meeting ingestion pipeline accepts various recording formats:",
      "items": [
        "Screen recordings (MP4, WebM, MOV)",
        "Meeting recordings from Zoom, Meet, Teams",
        "Audio-only files (MP3, WAV, M4A)",
        "Direct screen capture from desktop"
      ]
    },
    "uploadProcess": {
      "heading": "Upload Process",
      "description": "Recordings are uploaded through multipart form data to the server:",
      "stepsHeading": "Processing Steps",
      "steps": [
        "File uploaded to server temporary storage",
        "Metadata extracted (duration, format, resolution)",
        "Audio track separated for transcription",
        "Video frames sampled for visual analysis",
        "Results combined and returned to client"
      ]
    },
    "normalization": {
      "heading": "Format Normalization",
      "description": "Various input formats are normalized before processing. Audio is converted to 16kHz mono WAV for Whisper compatibility. Video is processed at native resolution with configurable frame sampling.",
      "outputs": "Normalized outputs ensure consistent downstream processing regardless of input format."
    },
    "multimodalAnalysis": {
      "heading": "Multimodal Analysis",
      "description": "Recordings with both audio and video are analyzed using multimodal models. Models with {code} prefix support native video understanding.",
      "combined": "Audio transcription and visual analysis are combined to produce a comprehensive understanding of the recording content."
    },
    "transcription": {
      "heading": "Audio Transcription",
      "description": "Audio tracks are transcribed using OpenAI Whisper through the server API.",
      "attribution": "Speaker diarization attempts to attribute text to different speakers when multiple voices are detected.",
      "featuresHeading": "Transcription Features",
      "features": [
        "Multiple language support with auto-detection",
        "Word-level timestamps for alignment",
        "Speaker diarization (multi-speaker)",
        "Punctuation and formatting restoration"
      ]
    },
    "frames": {
      "heading": "Frame Sampling",
      "description": "Video frames are sampled at configurable intervals to capture UI state changes and user actions.",
      "timestamps": "Each frame includes its timestamp for correlation with the audio transcript."
    },
    "structuredExtraction": {
      "heading": "Structured Extraction",
      "description": "The combined analysis produces structured outputs suitable for planning:",
      "extractedHeading": "Extracted Elements",
      "items": [
        "Action items and decisions mentioned",
        "UI elements and navigation paths shown",
        "Error states and issues demonstrated",
        "Technical context for implementation"
      ]
    },
    "artifacts": {
      "heading": "Analysis Artifacts",
      "description": "Meeting analysis produces several artifacts stored in the session:",
      "items": [
        "meeting_transcript: Full text with timestamps",
        "action_items: Extracted tasks and decisions",
        "ui_observations: Visual state changes",
        "combined_context: Merged analysis summary"
      ]
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "desktop/src/components/meeting/MeetingUploader.tsx",
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs"
      ]
    },
    "handoff": {
      "heading": "Planning Handoff",
      "description": "Meeting analysis artifacts can be incorporated into the task description:",
      "pipeline": "The combined context flows into the file discovery and plan generation pipeline, providing rich context for implementation planning."
    },
    "cta": {
      "heading": "Continue to video analysis",
      "description": "Learn more about how video frames are analyzed.",
      "links": {
        "video": "Video analysis",
        "textImprovement": "Text improvement"
      }
    }
  },
  "videoAnalysisDoc": {
    "meta": {
      "title": "Video analysis - PlanToCode",
      "description": "Frame sampling, prompts, and analysis artifacts from screen recordings."
    },
    "category": "Inputs",
    "date": "2025-09-25",
    "readTime": "6 min",
    "title": "Video Analysis",
    "description": "Frame sampling, prompts, and analysis artifacts from recordings.",
    "intro": "Video analysis extracts UI state and action sequences from screen recordings. This enables understanding of user workflows and bug reproduction contexts.",
    "visuals": {
      "frameNotes": {
        "title": "Video analysis pipeline",
        "description": "How frames flow through the analysis model.",
        "imageSrc": "/assets/images/demo-video-analysis.jpg",
        "imageAlt": "Video analysis interface",
        "caption": "The video analysis interface showing frame capture and analysis options."
      }
    },
    "apiEndpoint": {
      "heading": "API Endpoint",
      "endpoint": "Video analysis is handled by {code} on the server. The endpoint accepts multipart form data with the video file and analysis parameters.",
      "payloadHeading": "Payload Fields",
      "payloadFields": [
        "video: The video file (MP4, WebM, MOV)",
        "model: Model identifier for analysis",
        "prompt: Optional custom analysis prompt",
        "max_frames: Maximum frames to sample",
        "fps: Frame sampling rate"
      ]
    },
    "inputs": {
      "heading": "Supported Input Formats",
      "items": [
        "MP4 with H.264 or H.265 codec",
        "WebM with VP8 or VP9 codec",
        "MOV from screen recording tools",
        "Maximum file size: 100MB"
      ]
    },
    "sampling": {
      "heading": "Frame Sampling",
      "description": "Frames are extracted at configurable intervals to balance coverage and API costs. Lower frame rates reduce token usage but may miss rapid changes.",
      "fps": "Default rate is 1 frame per second. For detailed UI analysis, 2-3 FPS may be needed.",
      "parametersHeading": "Sampling Parameters",
      "parameters": [
        "fps: Frames per second to extract (0.5-5)",
        "max_frames: Maximum total frames (10-100)",
        "start_time: Offset to begin sampling",
        "end_time: Offset to stop sampling"
      ]
    },
    "modelRequirements": {
      "heading": "Model Requirements",
      "format": "Video analysis requires vision-capable models. Model identifiers follow {code} format. Currently only {code} models support native video analysis.",
      "reasoning": "Google Gemini models can process video natively, while other vision models require frame-by-frame image analysis."
    },
    "analysis": {
      "heading": "Analysis Process",
      "description": "Sampled frames are sent to the vision model along with the analysis prompt. The model produces structured observations about UI state and user actions.",
      "prompting": "System prompts guide the model to focus on specific aspects of the recording.",
      "promptElementsHeading": "Prompt Elements",
      "promptElements": [
        "UI inventory: List visible elements and controls",
        "Action sequence: Describe user actions in order",
        "Error detection: Identify error states and messages",
        "Navigation paths: Track screen transitions"
      ]
    },
    "outputs": {
      "heading": "Analysis Outputs",
      "items": [
        "frame_observations: Per-frame UI descriptions",
        "action_timeline: Ordered list of user actions",
        "error_summary: Any errors or issues observed",
        "context_summary: High-level workflow description"
      ]
    },
    "billing": {
      "heading": "Token Usage & Billing",
      "description": "Video analysis consumes tokens based on frame count and resolution. Each frame is processed as an image token.",
      "tracked": [
        "tokens_sent: Prompt + image tokens",
        "tokens_received: Analysis response tokens",
        "actual_cost: Computed from model pricing"
      ]
    },
    "storage": {
      "heading": "Result Storage",
      "description": "Analysis results are stored in the background_jobs table with task_type 'video_analysis'. The response contains the full analysis in JSON format.",
      "reuse": "Results can be incorporated into task descriptions or used directly in the planning workflow."
    },
    "keyFiles": {
      "heading": "Key Source Files",
      "items": [
        "server/src/handlers/proxy/video_handler.rs",
        "server/src/services/video_processor.rs",
        "desktop/src/components/video/VideoAnalyzer.tsx"
      ]
    },
    "integration": {
      "heading": "Integration with Planning",
      "description": "Video analysis outputs can feed directly into the task description for context-aware planning.",
      "followup": "The context_summary is particularly useful as a starting point for implementation planning."
    },
    "cta": {
      "heading": "See meeting ingestion",
      "description": "Learn how video analysis fits into the broader meeting ingestion workflow.",
      "links": {
        "meeting": "Meeting ingestion",
        "runtime": "Runtime walkthrough"
      }
    }
  },
  "mobileIos": {
    "meta": {
      "title": "iOS client architecture - PlanToCode",
      "description": "Swift workflows, Auth0 login flow, and device-link session management for the iOS companion app."
    },
    "category": "Architecture",
    "date": "2025-09-25",
    "readTime": "12 min",
    "title": "iOS Client Architecture",
    "description": "Swift workflows, Auth0 login flow, and device-link session management.",
    "intro": "The PlanToCode iOS app is a companion client that connects to linked desktop sessions. It provides mobile access to terminal output, job status, and voice transcription while maintaining the desktop as the primary planning workspace.",
    "visuals": {
      "app": {
        "title": "iOS app interface",
        "description": "Screenshots of the iOS app showing device linking and terminal view.",
        "imageSrc": "/images/docs/overview/system-map.svg",
        "imageAlt": "PlanToCode iOS app screenshots",
        "caption": "Placeholder for iOS app screenshots."
      }
    },
    "packageStructure": {
      "heading": "Swift Package Structure",
      "description": "The iOS app is organized into Swift packages:",
      "packages": [
        {
          "name": "Core",
          "path": "mobile/ios/Core/",
          "description": "Business logic and API clients",
          "components": [
            "WorkflowManager",
            "APIClient",
            "MobileSessionManager",
            "DeviceLinkClient"
          ]
        },
        {
          "name": "Security",
          "path": "mobile/ios/Security/",
          "description": "Authentication and credential storage",
          "components": [
            "Auth0Manager",
            "KeychainHelper",
            "TokenStore"
          ]
        },
        {
          "name": "VibeUI",
          "path": "mobile/ios/VibeUI/",
          "description": "SwiftUI components and design system",
          "components": [
            "TerminalView",
            "JobListView",
            "SettingsView",
            "DeviceLinkView"
          ]
        }
      ]
    },
    "auth": {
      "heading": "Auth0 PKCE Integration",
      "description": "The iOS app uses Auth0 with PKCE flow for secure authentication:",
      "flow": [
        "User taps Sign In, app generates code verifier and challenge",
        "ASWebAuthenticationSession opens Auth0 login page",
        "User authenticates and Auth0 redirects with authorization code",
        "App exchanges code for tokens using code verifier",
        "Tokens stored securely in iOS Keychain"
      ],
      "tokenManagement": {
        "heading": "Token Management",
        "items": [
          "Access token used for API requests",
          "Refresh token stored for silent renewal",
          "Token refresh triggered before expiry",
          "Logout clears all tokens from Keychain"
        ]
      }
    },
    "deviceLink": {
      "heading": "Device Linking via WebSocket Relay",
      "description": "iOS connects to desktop sessions through the server's WebSocket relay:",
      "protocol": {
        "heading": "Linking Protocol",
        "steps": [
          "Desktop generates link code and displays QR",
          "iOS scans QR or enters code manually",
          "Both connect to /ws/device-link with credentials",
          "Server validates and establishes relay",
          "Bidirectional communication enabled"
        ]
      },
      "messageTypes": {
        "heading": "Message Types",
        "items": [
          "terminal_output: PTY output from desktop terminal",
          "job_status: Background job status updates",
          "session_sync: Session state synchronization",
          "rpc_command: Commands from mobile to desktop"
        ]
      },
      "reconnection": {
        "heading": "Reconnection Handling",
        "description": "The WebSocket connection handles network interruptions with automatic reconnection, exponential backoff, and session state recovery."
      }
    },
    "rpcRouting": {
      "heading": "RPC Command Routing",
      "description": "iOS can send commands to the linked desktop:",
      "commands": {
        "heading": "Supported Commands",
        "items": [
          "send_terminal_input: Send keystrokes to terminal",
          "request_job_status: Get status of specific job",
          "start_voice_transcription: Begin recording on mobile",
          "sync_session: Request full session state"
        ]
      },
      "implementation": {
        "heading": "Implementation",
        "description": "Commands are JSON-RPC messages sent over WebSocket. Desktop validates commands and returns results asynchronously."
      }
    },
    "offlineQueue": {
      "heading": "Offline Action Queue",
      "description": "Actions performed while disconnected are queued for sync:",
      "architecture": {
        "heading": "Queue Architecture",
        "items": [
          "Actions stored in local SQLite database",
          "Queue processed on reconnection",
          "Conflicts resolved with server timestamps",
          "Failed actions reported to user"
        ]
      },
      "supportedActions": {
        "heading": "Supported Offline Actions",
        "items": [
          "Voice transcription recording (stored locally)",
          "Session notes and annotations",
          "Preference changes"
        ]
      }
    },
    "localStorage": {
      "heading": "SQLite Local Storage",
      "description": "iOS uses SQLite for local persistence:",
      "database": {
        "heading": "Database Schema",
        "path": "~/Documents/plantocode.sqlite",
        "tables": [
          "linked_devices: Desktop connections",
          "offline_queue: Pending sync actions",
          "cached_sessions: Recent session data",
          "transcriptions: Local voice recordings"
        ]
      },
      "migrations": {
        "heading": "Migrations",
        "description": "Schema version tracked in user_version pragma. Migrations run on app launch."
      }
    },
    "sessions": {
      "heading": "Mobile Sessions",
      "description": "MobileSessionManager coordinates session state:",
      "lifecycle": [
        "Load last active session on launch",
        "Connect to linked desktop if available",
        "Subscribe to session updates via WebSocket",
        "Cache session data for offline access"
      ]
    },
    "workflows": {
      "heading": "Workflow Entry Points",
      "description": "Key workflows accessible from mobile:",
      "items": [
        "Terminal monitoring: View output, send input",
        "Job status: Track background job progress",
        "Voice capture: Record and transcribe on mobile",
        "Session browsing: Review plans and history"
      ]
    },
    "region": {
      "heading": "Region Settings",
      "description": "iOS respects user region preference for API routing:",
      "implementation": "Region stored in UserDefaults, used to select api-eu.plantocode.com or api-us.plantocode.com for all requests."
    }
  },
  "providerRouting": {
    "meta": {
      "title": "Provider routing and streaming - PlanToCode",
      "description": "How PlanToCode routes LLM requests through a proxy, normalizes responses, and streams tokens to the desktop client."
    },
    "category": "Research & Models",
    "date": "2025-09-24",
    "readTime": "10 min",
    "title": "Provider Routing and Streaming",
    "description": "Routing layer that mediates all external LLM requests with normalization, streaming, and usage tracking.",
    "visuals": {
      "routingMap": {
        "title": "Provider routing map",
        "description": "Diagram of how requests flow from the desktop app to the proxy and out to providers.",
        "imageSrc": "/images/docs/provider-routing/routing-map.svg",
        "imageAlt": "Diagram of provider routing flow from desktop to external providers",
        "caption": "Placeholder for provider routing diagram."
      }
    },
    "cta": {
      "heading": "Continue into model configuration",
      "description": "Model configuration explains how allowed lists and token guardrails are exposed to the UI.",
      "links": {
        "modelConfiguration": "Model configuration",
        "runtimeWalkthrough": "Runtime walkthrough"
      }
    }
  }
}